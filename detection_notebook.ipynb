{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1789bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ca719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import orbit\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "#pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd7abc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.modeling.factory import detection_generator\n",
    "\n",
    "detection_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac83b35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m pipeline_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/coco_spinenet49_mobile_tpu.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load pipeline config and build a detection model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m configs \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_util\u001b[49m\u001b[38;5;241m.\u001b[39mget_configs_from_pipeline_file(model_yaml[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m model_config \u001b[38;5;241m=\u001b[39m configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m detection_model \u001b[38;5;241m=\u001b[39m model_builder\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[0;32m     10\u001b[0m       model_config\u001b[38;5;241m=\u001b[39mmodel_config, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_util' is not defined"
     ]
    }
   ],
   "source": [
    "#pipeline_config = os.path.join('models/research/object_detection/configs/tf2/',\n",
    "#                                model_name + '.config')\n",
    "#model_dir = 'models/research/object_detection/test_data/checkpoint/'\n",
    "pipeline_config = \"models/coco_spinenet49_mobile_tpu.yaml\"\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(model_yaml[\"task\"][\"model\"])\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "22fbc2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import yaml\n",
    "# Load YAML file\n",
    "with tf.io.gfile.GFile(pipeline_config, 'r') as yaml_file:\n",
    "    yaml_string = yaml_file.read()\n",
    "\n",
    "# Parse YAML string\n",
    "model_yaml = yaml.safe_load(yaml_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986dc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.modeling.backbones import resnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8589a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SpineNet output level 3 out of range [min_level, max_level] = [4, 6] will not be used for further processing.\n",
      "WARNING:absl:SpineNet output level 7 out of range [min_level, max_level] = [4, 6] will not be used for further processing.\n",
      "WARNING:absl:SpineNet output level 2 out of range [min_level, max_level] = [4, 6] will not be used for further processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spine_net\n",
      "{'4': <KerasTensor: shape=(1, 8, 8, 128) dtype=float32 (created by layer 'spine_net')>, '5': <KerasTensor: shape=(1, 4, 4, 128) dtype=float32 (created by layer 'spine_net')>, '6': <KerasTensor: shape=(1, 2, 2, 128) dtype=float32 (created by layer 'spine_net')>}\n"
     ]
    }
   ],
   "source": [
    "input_size = 128\n",
    "filter_size_scale, block_repeats, resample_alpha, endpoints_num_filters, min_level, max_level = 0.65, 1, 0.5, 128, 4, 6\n",
    "input_specs = tf.keras.layers.InputSpec(\n",
    "    shape=[None, input_size, input_size, 3])\n",
    "model = tfm.vision.backbones.SpineNet(\n",
    "    input_specs=input_specs,\n",
    "    min_level=min_level,\n",
    "    max_level=max_level,\n",
    "    endpoints_num_filters=endpoints_num_filters,\n",
    "    resample_alpha=resample_alpha,\n",
    "    block_repeats=block_repeats,\n",
    "    filter_size_scale=filter_size_scale,\n",
    "    init_stochastic_depth_rate=0.2,\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)\n",
    "endpoints = model(inputs)\n",
    "print(model.name)\n",
    "print(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c396fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "official.vision.modeling.backbones.spinenet.SpineNet() argument after ** must be a mapping, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\backbones\\spinenet.py:537\u001b[0m, in \u001b[0;36mSpineNet.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 537\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "\u001b[1;31mTypeError\u001b[0m: official.vision.modeling.backbones.spinenet.SpineNet() argument after ** must be a mapping, not str"
     ]
    }
   ],
   "source": [
    "model.from_config(pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f9c4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': {'anchor_size': 3,\n",
       "  'aspect_ratios': [0.5, 1.0, 2.0],\n",
       "  'num_scales': 3},\n",
       " 'backbone': {'spinenet_mobile': {'stochastic_depth_drop_rate': 0.2,\n",
       "   'model_id': '49',\n",
       "   'se_ratio': 0.2},\n",
       "  'type': 'spinenet_mobile'},\n",
       " 'decoder': {'type': 'identity'},\n",
       " 'head': {'num_convs': 4, 'num_filters': 48, 'use_separable_conv': True},\n",
       " 'input_size': [384, 384, 3],\n",
       " 'max_level': 7,\n",
       " 'min_level': 3,\n",
       " 'norm_activation': {'activation': 'hard_swish',\n",
       "  'norm_epsilon': 0.001,\n",
       "  'norm_momentum': 0.99,\n",
       "  'use_sync_bn': True}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yaml[\"task\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b689c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/image1.jpg\n",
      "129862/129862 [==============================] - 0s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/image2.jpg\n",
      "1415684/1415684 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def download_images():\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/test_images/'\n",
    "    filenames = ['image1.jpg', 'image2.jpg']\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "        image_path = tf.keras.utils.get_file(fname=filename,\n",
    "                                            origin=base_url + filename,\n",
    "                                            untar=False)\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0adb44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_coco17_tpu-32.tar.gz\n",
      "1426460092/1426460092 [==============================] - 93s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and extract model\n",
    "def download_model(model_name, model_date):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(fname=model_name,\n",
    "                                        origin=base_url + model_date + '/' + model_file,\n",
    "                                        untar=True)\n",
    "    return str(model_dir)\n",
    "\n",
    "MODEL_DATE = '20200711'\n",
    "MODEL_NAME = 'centernet_hg104_1024x1024_coco17_tpu-32'\n",
    "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b21f6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
      "5056/5056 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "# Download labels file\n",
    "def download_labels(filename):\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "    label_dir = tf.keras.utils.get_file(fname=filename,\n",
    "                                        origin=base_url + filename,\n",
    "                                        untar=False)\n",
    "    label_dir = pathlib.Path(label_dir)\n",
    "    return str(label_dir)\n",
    "\n",
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "PATH_TO_LABELS = download_labels(LABEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dee2dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m viz_utils\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "PATH_TO_CFG = PATH_TO_MODEL_DIR + \"/pipeline.config\"\n",
    "PATH_TO_CKPT = PATH_TO_MODEL_DIR + \"/checkpoint\"\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaafe421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SpineNet output level 2 out of range [min_level, max_level] = [3, 7] will not be used for further processing.\n"
     ]
    }
   ],
   "source": [
    "model2 = tfm.vision.backbones.SpineNet.from_config(model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25af299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2aff7a7fd90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=model2)\n",
    "ckpt.restore(\"models/ckpt-277200\").expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9372951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.Checkpoint at 0x2aff7b316a0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93383a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "ret = model2.predict(np.zeros((1,512,512,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30417dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 256)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[\"3\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dac60f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 256)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[\"7\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc1dbadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 256)\n",
      "(1, 32, 32, 256)\n",
      "(1, 16, 16, 256)\n",
      "(1, 8, 8, 256)\n",
      "(1, 4, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "for key, val in ret.items():\n",
    "    print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4aa8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.tasks import RetinaNetTask\n",
    "from official.vision.configs.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5e896e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = RetinaNetTask(model_yaml[\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c86e8ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\tasks\\retinanet.py:49\u001b[0m, in \u001b[0;36mRetinaNetTask.build_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Build RetinaNet model.\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputSpec(\n\u001b[1;32m---> 49\u001b[0m       shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minput_size)\n\u001b[0;32m     51\u001b[0m   l2_weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_config\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39ml2_weight_decay\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;66;03m# Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;66;03m# (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "task.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65520962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runtime': {'distribution_strategy': 'tpu',\n",
       "  'mixed_precision_dtype': 'bfloat16'},\n",
       " 'task': {'losses': {'l2_weight_decay': 3e-05},\n",
       "  'model': {'anchor': {'anchor_size': 3,\n",
       "    'aspect_ratios': ListWrapper([0.5, 1.0, 2.0]),\n",
       "    'num_scales': 3},\n",
       "   'backbone': {'spinenet_mobile': {'stochastic_depth_drop_rate': 0.2,\n",
       "     'model_id': '49',\n",
       "     'se_ratio': 0.2},\n",
       "    'type': 'spinenet_mobile'},\n",
       "   'decoder': {'type': 'identity'},\n",
       "   'head': {'num_convs': 4, 'num_filters': 48, 'use_separable_conv': True},\n",
       "   'input_size': ListWrapper([384, 384, 3]),\n",
       "   'max_level': 7,\n",
       "   'min_level': 3,\n",
       "   'norm_activation': {'activation': 'hard_swish',\n",
       "    'norm_epsilon': 0.001,\n",
       "    'norm_momentum': 0.99,\n",
       "    'use_sync_bn': True}},\n",
       "  'train_data': {'dtype': 'bfloat16',\n",
       "   'global_batch_size': 256,\n",
       "   'is_training': True,\n",
       "   'parser': {'aug_rand_hflip': True,\n",
       "    'aug_scale_max': 2.0,\n",
       "    'aug_scale_min': 0.5}},\n",
       "  'validation_data': {'dtype': 'bfloat16',\n",
       "   'global_batch_size': 256,\n",
       "   'is_training': False,\n",
       "   'drop_remainder': False}},\n",
       " 'trainer': {'checkpoint_interval': 462,\n",
       "  'optimizer_config': {'learning_rate': {'stepwise': {'boundaries': ListWrapper([263340, 272580]),\n",
       "     'values': ListWrapper([0.32, 0.032, 0.0032])},\n",
       "    'type': 'stepwise'},\n",
       "   'warmup': {'linear': {'warmup_learning_rate': 0.0067,\n",
       "     'warmup_steps': 2000}}},\n",
       "  'steps_per_loop': 462,\n",
       "  'train_steps': 277200,\n",
       "  'validation_interval': 462,\n",
       "  'validation_steps': 20}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b34d6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.core import config_definitions as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9aa4cf26",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The key 'runtime' does not exist in <class 'official.modeling.hyperparams.base_config.Config'>. To extend the existing keys, use `override` with `is_strict` = False.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:292\u001b[0m, in \u001b[0;36mConfig.from_yaml\u001b[1;34m(cls, file_path)\u001b[0m\n\u001b[0;32m    290\u001b[0m loaded \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(f, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m    291\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m--> 292\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:181\u001b[0m, in \u001b[0;36mParamsDict.override\u001b[1;34m(self, override_params, is_strict)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(override_params, ParamsDict):\n\u001b[0;32m    180\u001b[0m   override_params \u001b[38;5;241m=\u001b[39m override_params\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverride_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:252\u001b[0m, in \u001b[0;36mConfig._override\u001b[1;34m(self, override_dict, is_strict)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_strict:\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe key \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not exist in \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo extend the existing keys, use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`override` with `is_strict` = False.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    255\u001b[0m                        k, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set(k, v)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The key 'runtime' does not exist in <class 'official.modeling.hyperparams.base_config.Config'>. To extend the existing keys, use `override` with `is_strict` = False.\""
     ]
    }
   ],
   "source": [
    "cfg.base_config.Config.from_yaml(pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "06f76c4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'map' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mofficial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_definitions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_config\n\u001b[1;32m----> 2\u001b[0m task \u001b[38;5;241m=\u001b[39m RetinaNetTask(\u001b[43mbase_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_yaml\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:82\u001b[0m, in \u001b[0;36mConfig.__post_init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, default_params, restrictions):\n\u001b[1;32m---> 82\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestrictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:91\u001b[0m, in \u001b[0;36mParamsDict.__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m   default_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:181\u001b[0m, in \u001b[0;36mParamsDict.override\u001b[1;34m(self, override_params, is_strict)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(override_params, ParamsDict):\n\u001b[0;32m    180\u001b[0m   override_params \u001b[38;5;241m=\u001b[39m override_params\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverride_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:257\u001b[0m, in \u001b[0;36mConfig._override\u001b[1;34m(self, override_dict, is_strict)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe key \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not exist in \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo extend the existing keys, use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`override` with `is_strict` = False.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    255\u001b[0m                        k, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:204\u001b[0m, in \u001b[0;36mConfig._set\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_null(k):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# If the key not exist or the value is None, a new Config-family object\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# sould be created for the key.\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[43msubconfig_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]\u001b[38;5;241m.\u001b[39moverride(v)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:82\u001b[0m, in \u001b[0;36mConfig.__post_init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, default_params, restrictions):\n\u001b[1;32m---> 82\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestrictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:91\u001b[0m, in \u001b[0;36mParamsDict.__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m   default_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:181\u001b[0m, in \u001b[0;36mParamsDict.override\u001b[1;34m(self, override_params, is_strict)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(override_params, ParamsDict):\n\u001b[0;32m    180\u001b[0m   override_params \u001b[38;5;241m=\u001b[39m override_params\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverride_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:257\u001b[0m, in \u001b[0;36mConfig._override\u001b[1;34m(self, override_dict, is_strict)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe key \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not exist in \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo extend the existing keys, use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`override` with `is_strict` = False.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    255\u001b[0m                        k, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:204\u001b[0m, in \u001b[0;36mConfig._set\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_null(k):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# If the key not exist or the value is None, a new Config-family object\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# sould be created for the key.\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[43msubconfig_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]\u001b[38;5;241m.\u001b[39moverride(v)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:82\u001b[0m, in \u001b[0;36mConfig.__post_init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, default_params, restrictions):\n\u001b[1;32m---> 82\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestrictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:91\u001b[0m, in \u001b[0;36mParamsDict.__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m   default_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:181\u001b[0m, in \u001b[0;36mParamsDict.override\u001b[1;34m(self, override_params, is_strict)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(override_params, ParamsDict):\n\u001b[0;32m    180\u001b[0m   override_params \u001b[38;5;241m=\u001b[39m override_params\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverride_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:257\u001b[0m, in \u001b[0;36mConfig._override\u001b[1;34m(self, override_dict, is_strict)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe key \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not exist in \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo extend the existing keys, use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`override` with `is_strict` = False.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    255\u001b[0m                        k, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:204\u001b[0m, in \u001b[0;36mConfig._set\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_null(k):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# If the key not exist or the value is None, a new Config-family object\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# sould be created for the key.\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[43msubconfig_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]\u001b[38;5;241m.\u001b[39moverride(v)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:82\u001b[0m, in \u001b[0;36mConfig.__post_init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, default_params, restrictions):\n\u001b[1;32m---> 82\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestrictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:91\u001b[0m, in \u001b[0;36mParamsDict.__init__\u001b[1;34m(self, default_params, restrictions)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m   default_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\params_dict.py:181\u001b[0m, in \u001b[0;36mParamsDict.override\u001b[1;34m(self, override_params, is_strict)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(override_params, ParamsDict):\n\u001b[0;32m    180\u001b[0m   override_params \u001b[38;5;241m=\u001b[39m override_params\u001b[38;5;241m.\u001b[39mas_dict()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_override\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverride_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_strict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:257\u001b[0m, in \u001b[0;36mConfig._override\u001b[1;34m(self, override_dict, is_strict)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe key \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m does not exist in \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    253\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo extend the existing keys, use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    254\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`override` with `is_strict` = False.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    255\u001b[0m                        k, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k]:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:221\u001b[0m, in \u001b[0;36mConfig._set\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_import_config(v, subconfig_type)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_import_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubconfig_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:126\u001b[0m, in \u001b[0;36mConfig._import_config\u001b[1;34m(cls, v, subconfig_type)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid sequence: only supports single level \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict or ParamsDict found: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mSEQUENCE_TYPES,\n\u001b[0;32m    123\u001b[0m                                                 \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mIMMUTABLE_TYPES, v))\n\u001b[0;32m    124\u001b[0m   import_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    125\u001b[0m       \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_import_config, subconfig_type\u001b[38;5;241m=\u001b[39msubconfig_type)\n\u001b[1;32m--> 126\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimport_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, params_dict\u001b[38;5;241m.\u001b[39mParamsDict):\n\u001b[0;32m    128\u001b[0m   \u001b[38;5;66;03m# Deepcopy here is a temporary solution for preserving type in nested\u001b[39;00m\n\u001b[0;32m    129\u001b[0m   \u001b[38;5;66;03m# Config object.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(v)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\trackable\\data_structures.py:487\u001b[0m, in \u001b[0;36mListWrapper.__init__\u001b[1;34m(self, wrapped_list)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_append_mutation_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_external_modification_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mListWrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapped_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_wrapped_list_snapshot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\trackable\\data_structures.py:373\u001b[0m, in \u001b[0;36mList.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_storage(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m--> 373\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_value(\n\u001b[0;32m    374\u001b[0m       element, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_element(index))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'map' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "from official.core.config_definitions import base_config\n",
    "task = RetinaNetTask(base_config.Config(model_yaml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7e47cf7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\tasks\\retinanet.py:49\u001b[0m, in \u001b[0;36mRetinaNetTask.build_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Build RetinaNet model.\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputSpec(\n\u001b[1;32m---> 49\u001b[0m       shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minput_size)\n\u001b[0;32m     51\u001b[0m   l2_weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_config\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39ml2_weight_decay\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;66;03m# Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;66;03m# (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "task.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29ad4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.configs.retinanet import RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "06c0cc05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'map' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m RetinaNet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(model_yaml[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[1;32m<string>:4\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, default_params, restrictions, num_classes, input_size, min_level, max_level, anchor, backbone, decoder, head, detection_generator, norm_activation)\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:232\u001b[0m, in \u001b[0;36mConfig.__setattr__\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    230\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_locked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Config has been locked. \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo change is allowed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:221\u001b[0m, in \u001b[0;36mConfig._set\u001b[1;34m(self, k, v)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_import_config(v, subconfig_type)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_import_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubconfig_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\modeling\\hyperparams\\base_config.py:126\u001b[0m, in \u001b[0;36mConfig._import_config\u001b[1;34m(cls, v, subconfig_type)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid sequence: only supports single level \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict or ParamsDict found: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mSEQUENCE_TYPES,\n\u001b[0;32m    123\u001b[0m                                                 \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mIMMUTABLE_TYPES, v))\n\u001b[0;32m    124\u001b[0m   import_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    125\u001b[0m       \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_import_config, subconfig_type\u001b[38;5;241m=\u001b[39msubconfig_type)\n\u001b[1;32m--> 126\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimport_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, params_dict\u001b[38;5;241m.\u001b[39mParamsDict):\n\u001b[0;32m    128\u001b[0m   \u001b[38;5;66;03m# Deepcopy here is a temporary solution for preserving type in nested\u001b[39;00m\n\u001b[0;32m    129\u001b[0m   \u001b[38;5;66;03m# Config object.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(v)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\trackable\\data_structures.py:487\u001b[0m, in \u001b[0;36mListWrapper.__init__\u001b[1;34m(self, wrapped_list)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_append_mutation_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_external_modification_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mListWrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapped_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_wrapped_list_snapshot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\trackable\\data_structures.py:373\u001b[0m, in \u001b[0;36mList.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_storage(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m--> 373\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_value(\n\u001b[0;32m    374\u001b[0m       element, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_element(index))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'map' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "RetinaNet(**(model_yaml[\"task\"][\"model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6e85171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.core.config_definitions import ExperimentConfig, TaskConfig, TrainerConfig, RuntimeConfig\n",
    "from official.vision.configs import retinanet\n",
    "from official.vision.tasks import RetinaNetTask\n",
    "import dataclasses\n",
    "@dataclasses.dataclass\n",
    "class RetinanetExperimentConfig(base_config.Config):\n",
    "    task: TaskConfig = retinanet.RetinaNetTask()\n",
    "    trainer: TrainerConfig = TrainerConfig()\n",
    "    runtime: RuntimeConfig = RuntimeConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "acd7a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = RetinanetExperimentConfig.from_yaml(pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dbbcdab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf= RetinaNetTask(cfg.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fda151bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = cf.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a23ca464",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.initialize(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8019a7c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\MAXIME~1.CAR\\AppData\\Local\\Temp\\__autograph_generated_filems8gl5d_.py\", line 90, in tf__call\n        (raw_scores, raw_boxes, raw_attributes) = ag__.converted_call(ag__.ld(self).head, (ag__.ld(features),), None, fscope)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\heads\\dense_prediction_heads.py\", line 169, in build\n        self._classifier = conv_op(name='scores', **classifier_kwargs)\n\n    ValueError: Exception encountered when calling layer \"retina_net_model_1\" \"                 f\"(type RetinaNetModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\retinanet_model.py\", line 131, in call  *\n            raw_scores, raw_boxes, raw_attributes = self.head(features)\n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\heads\\dense_prediction_heads.py\", line 169, in build\n            self._classifier = conv_op(name='scores', **classifier_kwargs)\n    \n        ValueError: Invalid value for argument `filters`. Expected a strictly positive value. Received filters=0.\n    \n    \n    Call arguments received by layer \"retina_net_model_1\" \"                 f\"(type RetinaNetModel):\n      • images=tf.Tensor(shape=(None, 384, 384, 3), dtype=float32)\n      • image_shape=None\n      • anchor_boxes=None\n      • output_intermediate_features=False\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\MAXIME~1.CAR\\AppData\\Local\\Temp\\__autograph_generated_filem6z903ox.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\MAXIME~1.CAR\\AppData\\Local\\Temp\\__autograph_generated_filems8gl5d_.py:90\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, images, image_shape, anchor_boxes, output_intermediate_features, training)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     89\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(output_intermediate_features), if_body_2, else_body_2, get_state_2, set_state_2, (), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m (raw_scores, raw_boxes, raw_attributes) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mhead, (ag__\u001b[38;5;241m.\u001b[39mld(features),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_8\u001b[39m():\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (do_return, retval_, anchor_boxes)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\heads\\dense_prediction_heads.py:169\u001b[0m, in \u001b[0;36mRetinaNetHead.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_separable_conv\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    165\u001b[0m   classifier_kwargs\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m    166\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_initializer\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39minitializers\u001b[38;5;241m.\u001b[39mRandomNormal(stddev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[0;32m    167\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_regularizer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_regularizer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    168\u001b[0m   })\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier \u001b[38;5;241m=\u001b[39m conv_op(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclassifier_kwargs)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Box net.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_convs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\MAXIME~1.CAR\\AppData\\Local\\Temp\\__autograph_generated_filems8gl5d_.py\", line 90, in tf__call\n        (raw_scores, raw_boxes, raw_attributes) = ag__.converted_call(ag__.ld(self).head, (ag__.ld(features),), None, fscope)\n    File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\heads\\dense_prediction_heads.py\", line 169, in build\n        self._classifier = conv_op(name='scores', **classifier_kwargs)\n\n    ValueError: Exception encountered when calling layer \"retina_net_model_1\" \"                 f\"(type RetinaNetModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\retinanet_model.py\", line 131, in call  *\n            raw_scores, raw_boxes, raw_attributes = self.head(features)\n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\maxime.carrere\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\modeling\\heads\\dense_prediction_heads.py\", line 169, in build\n            self._classifier = conv_op(name='scores', **classifier_kwargs)\n    \n        ValueError: Invalid value for argument `filters`. Expected a strictly positive value. Received filters=0.\n    \n    \n    Call arguments received by layer \"retina_net_model_1\" \"                 f\"(type RetinaNetModel):\n      • images=tf.Tensor(shape=(None, 384, 384, 3), dtype=float32)\n      • image_shape=None\n      • anchor_boxes=None\n      • output_intermediate_features=False\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "mdl.predict(np.zeros((1,384,384,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ecb14a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from official.vision.serving import detection\n",
    "cfg.task.model.num_classes = 91\n",
    "cfg.task.init_checkpoint = \"./models/ckpt-277200\"\n",
    "det = detection.DetectionModule(cfg, batch_size=1, input_image_size=[384, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ef10a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget -q 'https://unsplash.com/photos/XOxsVJmCyxk/download?force=true&w=640' -O 'fox.jpg'\n",
    "\n",
    "x = np.expand_dims(tf.keras.preprocessing.image.load_img(\"james-resly-XOxsVJmCyxk-unsplash.jpg\", target_size=(384, 384)), 0)\n",
    "x = np.array(x, dtype=np.float32) #/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cb80e1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_boxes': <tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=\n",
       " array([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]], dtype=float32)>,\n",
       " 'detection_scores': <tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       " array([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "         -0., -0., -0., -0., -0., -0., -0., -0., -0.]], dtype=float32)>,\n",
       " 'detection_classes': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>,\n",
       " 'num_detections': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>,\n",
       " 'image_info': <tf.Tensor: shape=(1, 4, 2), dtype=float32, numpy=\n",
       " array([[[384., 384.],\n",
       "         [384., 384.],\n",
       "         [  1.,   1.],\n",
       "         [  0.,   0.]]], dtype=float32)>}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det.serve(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8b8a7a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "official.vision.configs.retinanet.DetectionGenerator"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.vision.configs.retinanet.DetectionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f9b944c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384, 384, 3)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "aa9fc0f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'sync_batch_normalization_855/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00676957, -0.09634139, -0.18770218, ...,  0.19944258,\n          -0.14135365,  0.18210804],\n         [-0.22393149,  0.19635543,  0.3284623 , ...,  0.00707996,\n           0.17528068,  0.10661352],\n         [-0.06039536,  0.03249402, -0.04811416, ..., -0.02716474,\n          -0.34512892,  0.44819278],\n         ...,\n         [ 0.1813063 , -0.062728  ,  0.04288131, ...,  0.22318785,\n           0.03546751, -0.18583813],\n         [ 0.04279966,  0.35971355,  0.3433167 , ...,  0.11765954,\n          -0.15561853, -0.4560668 ],\n         [ 0.2192535 , -0.16841394,  0.34175915, ..., -0.12580775,\n           0.20856485,  0.08633108]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_3/bias:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.0997659 , -0.00611321, -0.18242279, ...,  0.11405627,\n          -0.20777628,  0.00823767],\n         [-0.15320902, -0.11812736, -0.03383697, ..., -0.07117647,\n          -0.16950558,  0.19228572],\n         [-0.10441853,  0.04289228,  0.05561689, ...,  0.09746017,\n          -0.10889871,  0.03978932],\n         ...,\n         [-0.05037222,  0.02201761,  0.05079253, ..., -0.01017809,\n          -0.01778072,  0.11996267],\n         [-0.06045947,  0.02519628,  0.14621687, ...,  0.00115731,\n           0.04565639, -0.12305149],\n         [-0.00972935, -0.05885803,  0.06527564, ..., -0.01145692,\n          -0.08041909,  0.11880798]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 8, 240) dtype=float32, numpy=\narray([[[[ 0.27731138,  0.04643292, -0.38297847, ...,  0.4261856 ,\n          -0.4225839 , -0.32063508],\n         [ 0.24490221, -0.7143248 ,  0.47505182, ..., -0.12800658,\n          -0.3476433 , -0.35257545],\n         [ 0.39996067,  0.10616689, -0.05825517, ..., -0.11987177,\n           0.2880929 , -0.01947466],\n         ...,\n         [-0.42928702,  0.6382745 , -0.5178266 , ..., -0.5657525 ,\n          -0.13675056, -0.21231355],\n         [ 0.5169263 , -0.01521067, -0.07734648, ...,  0.35280368,\n           0.00682982,  0.14982584],\n         [-0.63911027, -0.7410649 ,  0.21043786, ...,  0.17746843,\n           0.14269972,  0.222384  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/conv2d_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32, numpy=\narray([[[[-0.09169228, -0.17684546,  0.00077084, ...,  0.08946985,\n           0.12061378, -0.03456267],\n         [ 0.08814655, -0.03033741,  0.00327894, ..., -0.05660526,\n          -0.03112386, -0.03194665],\n         [ 0.03745024, -0.11542568,  0.15877414, ...,  0.0266645 ,\n          -0.03882101,  0.02975029],\n         ...,\n         [ 0.165348  , -0.00459389, -0.05289736, ..., -0.03627867,\n           0.08504474,  0.02361331],\n         [-0.02914958,  0.04039643, -0.04958714, ...,  0.07881252,\n          -0.02740583, -0.1303127 ],\n         [ 0.05912042,  0.13693923, -0.00121247, ...,  0.03564801,\n           0.00267298,  0.11568356]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01851536],\n         [ 0.00733757],\n         [-0.02172983],\n         ...,\n         [-0.01355479],\n         [-0.01662578],\n         [-0.01723021]],\n\n        [[-0.01505743],\n         [-0.00514163],\n         [-0.00984013],\n         ...,\n         [ 0.00863782],\n         [ 0.01521116],\n         [ 0.00124205]],\n\n        [[-0.01724247],\n         [ 0.01015843],\n         [ 0.00190519],\n         ...,\n         [ 0.00429162],\n         [ 0.01235284],\n         [-0.02300341]]],\n\n\n       [[[-0.0053674 ],\n         [ 0.01600971],\n         [ 0.01254517],\n         ...,\n         [ 0.00232234],\n         [ 0.02664229],\n         [-0.00911285]],\n\n        [[-0.00159731],\n         [ 0.0068529 ],\n         [-0.00538531],\n         ...,\n         [-0.00150066],\n         [-0.00620795],\n         [-0.00976478]],\n\n        [[-0.01721664],\n         [-0.00563165],\n         [-0.00876007],\n         ...,\n         [-0.01049968],\n         [-0.00411376],\n         [ 0.01610754]]],\n\n\n       [[[ 0.00756265],\n         [ 0.01863839],\n         [-0.00499333],\n         ...,\n         [ 0.02452152],\n         [ 0.00356664],\n         [ 0.02676314]],\n\n        [[-0.02471363],\n         [-0.01248526],\n         [-0.01646867],\n         ...,\n         [ 0.02315362],\n         [-0.02153059],\n         [ 0.01352349]],\n\n        [[-0.01798632],\n         [-0.00676703],\n         [ 0.01538937],\n         ...,\n         [ 0.01650815],\n         [-0.0081065 ],\n         [-0.01477999]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[-0.02889698,  0.02226775, -0.01635587, ..., -0.0593063 ,\n           0.00962293,  0.04774904],\n         [-0.05340093, -0.00032051, -0.04290819, ..., -0.04047496,\n           0.05356967, -0.03279585],\n         [-0.0034331 ,  0.0413938 ,  0.06591232, ...,  0.06192049,\n           0.00501347,  0.00511633],\n         ...,\n         [-0.06566343,  0.05439257, -0.01089434, ...,  0.03299806,\n          -0.01511324,  0.05338838],\n         [-0.07359076,  0.10325756, -0.07991882, ..., -0.05974494,\n          -0.00324952,  0.03667715],\n         [ 0.05204966, -0.03199239,  0.00443521, ...,  0.05713964,\n          -0.00215116,  0.00376912]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 4, 144) dtype=float32, numpy=\narray([[[[-4.46340144e-01,  7.93159604e-02,  7.18156472e-02,\n          -7.01569438e-01,  7.22354710e-01, -5.13633430e-01,\n          -9.11757708e-01, -6.91454392e-03,  1.84001654e-01,\n           1.79240108e-01,  7.31972337e-01, -5.57208061e-03,\n          -5.27487576e-01,  1.97126582e-01, -3.50069672e-01,\n           1.47738814e-01,  9.46457446e-01, -2.83633918e-01,\n          -1.66928172e-01, -7.94632196e-01, -9.70720947e-02,\n          -3.29954833e-01,  2.78714225e-02, -5.83465099e-01,\n           5.06822169e-01,  4.15582180e-01,  9.81585801e-01,\n          -2.36347020e-01, -8.95969383e-03, -3.64610165e-01,\n           1.53712071e-02, -8.52691708e-04, -2.87975639e-01,\n          -9.55588758e-01,  7.16764271e-01, -1.63399026e-01,\n           1.04565933e-01, -6.00904465e-01,  7.43077517e-01,\n          -6.49221897e-01,  4.11271870e-01,  3.67594481e-01,\n           6.40672982e-01,  1.00946164e+00,  8.60740423e-01,\n           2.02992275e-01, -3.13182235e-01,  9.43895817e-01,\n          -1.91528112e-01,  5.41741431e-01, -1.30889997e-01,\n           5.65349609e-02,  9.55905497e-01, -1.12009741e-01,\n           6.85158074e-01, -4.55812737e-03,  6.70388758e-01,\n           6.32442296e-01,  2.01906741e-01,  1.63134206e-02,\n           7.01259255e-01,  3.75902832e-01, -1.70112163e-01,\n           1.45945415e-01, -1.37455270e-01, -8.20871949e-01,\n           4.51416224e-02, -3.38635981e-01, -8.08708891e-02,\n           4.60304111e-01,  7.34384358e-01, -4.16380525e-01,\n           6.80697858e-01,  2.19746679e-01, -1.59120068e-01,\n           5.40223658e-01,  2.91262895e-01,  4.63455826e-01,\n          -1.82620689e-01, -2.90297776e-01, -2.02242151e-01,\n           2.94709682e-01,  5.09671532e-02, -9.59728658e-02,\n           7.87021518e-01, -4.36704755e-01,  9.82804745e-02,\n           6.05372667e-01, -5.98747373e-01, -1.31339297e-01,\n           6.46744609e-01, -3.97263914e-01, -4.49462742e-01,\n          -1.12317979e-01, -1.87217683e-01, -5.61753154e-01,\n           2.76214778e-01,  3.13881367e-01, -2.64108018e-03,\n           4.43142891e-01,  1.42929871e-02, -1.07067004e-01,\n          -4.35749531e-01,  5.00990570e-01,  7.81666338e-02,\n          -1.86943308e-01, -8.74825940e-02, -1.95845455e-01,\n          -9.71517265e-01, -2.46700689e-01, -1.21074267e-01,\n           7.11524129e-01,  7.43147314e-01, -2.28119478e-01,\n           1.76789705e-02, -5.13711631e-01, -5.87541282e-01,\n          -1.10757565e+00, -2.46246591e-01,  8.27490464e-02,\n           3.55259217e-02, -3.69520217e-01,  3.83370727e-01,\n           1.12603873e-01, -2.94867903e-01, -2.65561044e-01,\n          -1.14038594e-01,  9.16518688e-01,  1.01806760e-01,\n          -3.32017750e-01, -3.21504623e-02, -7.78673172e-01,\n           3.97894114e-01, -4.69386011e-01, -6.51777327e-01,\n           8.36739302e-01, -1.92956522e-01,  2.48538435e-01,\n          -1.65233955e-01, -1.02110110e-01, -3.46793592e-01,\n           1.66390046e-01,  4.63413656e-01, -6.09368309e-02],\n         [ 2.76504248e-01, -2.94113219e-01,  4.90575284e-02,\n           3.86512250e-01, -3.06029528e-01,  1.85810909e-01,\n           1.77106068e-01,  9.27807391e-01, -4.23859917e-02,\n          -6.75970986e-02,  9.85717699e-02,  1.09832954e+00,\n          -8.14502221e-03, -7.64670670e-02, -1.52079388e-01,\n          -3.73686522e-01, -5.59421107e-02, -1.32697582e-01,\n           9.30295169e-01, -2.77064502e-01, -9.45520699e-01,\n           8.12557995e-01,  8.00177038e-01,  5.38711429e-01,\n          -8.94329667e-01,  6.10652447e-01,  6.77239716e-01,\n          -2.12189794e-01,  4.58199292e-01, -5.68707764e-01,\n           5.70656002e-01,  5.05347997e-02,  1.30876914e-01,\n           3.29079062e-01, -4.46394026e-01, -6.18453681e-01,\n          -8.79559875e-01,  3.98167223e-02,  3.04595739e-01,\n          -2.21079096e-01, -1.53937593e-01,  5.78534722e-01,\n           6.67724311e-01, -4.53105450e-01,  9.52875391e-02,\n           6.73621535e-01, -7.00639069e-01, -9.73989606e-01,\n          -1.49385750e-01, -4.82515961e-01,  5.46199158e-02,\n           2.99282581e-01,  4.52675112e-02,  7.50335217e-01,\n          -9.60190892e-02,  4.18219298e-01, -2.91757584e-01,\n           7.80740142e-01,  1.22061417e-01,  6.62682593e-01,\n          -8.01023766e-02,  2.94262677e-01,  4.93465364e-02,\n           1.05587947e+00, -2.51865014e-02, -4.22197692e-02,\n           5.25712907e-01, -1.80739880e-01,  5.01862466e-01,\n          -3.85191804e-03,  2.37913519e-01, -2.26544797e-01,\n          -1.43163921e-02, -1.82581231e-01, -1.31738216e-01,\n           1.59695849e-01,  2.34032586e-01,  1.82970181e-01,\n           4.83427286e-01,  3.55180949e-02, -8.24137852e-02,\n           1.85222834e-01, -7.93191865e-02,  8.83779109e-01,\n           9.55560684e-01,  2.58072317e-01,  3.00341874e-01,\n          -6.02832139e-01, -6.10780299e-01,  2.43433952e-01,\n           2.48009369e-01,  1.64592668e-01,  8.47473443e-01,\n          -8.64022553e-01, -7.44314551e-01, -3.96793604e-01,\n          -2.08855346e-01,  7.68810868e-01, -2.07488388e-01,\n          -6.36597872e-01, -4.05166149e-01, -3.89181107e-01,\n          -1.24542795e-01,  3.86424541e-01,  7.89532959e-02,\n          -6.95697144e-02,  9.79464725e-02, -4.74115819e-01,\n          -6.35868907e-01,  6.31757796e-01,  3.92273217e-01,\n          -2.37837628e-01, -5.28538287e-01, -1.99763123e-02,\n          -2.92223305e-01, -9.70181108e-01, -5.42902470e-01,\n          -2.08970517e-01,  1.92479700e-01,  7.17415363e-02,\n          -7.67787173e-02,  1.00109899e+00, -6.63973808e-01,\n          -3.65166783e-01, -3.50617528e-01, -8.60527992e-01,\n          -4.39661533e-01,  6.59075100e-03, -5.49427807e-01,\n           7.50225127e-01, -4.81145352e-01, -2.90592372e-01,\n          -2.30954289e-01,  6.48002028e-01, -7.20387816e-01,\n          -8.25280011e-01, -7.63143241e-01,  3.37564975e-01,\n          -1.28592372e-01,  4.89051163e-01, -3.48206647e-02,\n          -9.77943361e-01, -9.25292552e-01,  1.01913050e-01],\n         [ 1.10909067e-01, -2.23356664e-01,  1.10569155e+00,\n           7.47347295e-01,  1.69710085e-01, -5.11639833e-01,\n          -2.51277834e-01, -1.05084740e-01,  5.02517879e-01,\n           3.27106386e-01, -4.16090161e-01, -1.07925355e+00,\n          -1.47663996e-01, -2.50119835e-01,  2.58389741e-01,\n          -2.11905435e-01,  4.73861605e-01, -3.48890841e-01,\n           1.63393077e-02,  3.86200756e-01,  2.19942808e-01,\n           6.32769763e-01,  2.43289188e-01, -2.86607683e-01,\n           9.48658049e-01, -2.99302429e-01, -3.13399374e-01,\n           2.48380557e-01, -4.71069813e-01,  2.82425672e-01,\n          -7.29298055e-01, -1.87825933e-01,  1.24720372e-01,\n           7.79111981e-02, -5.25923789e-01, -7.58746624e-01,\n          -4.21178751e-02, -4.00482416e-01, -3.40509355e-01,\n           1.06970072e+00,  3.95473912e-02, -8.18126500e-02,\n           2.00698879e-02, -5.46225943e-02, -6.07739091e-02,\n          -6.66431308e-01, -2.33661473e-01, -3.61612320e-01,\n          -1.22290738e-01,  2.80953884e-01,  3.68051529e-01,\n          -4.07108277e-01,  4.84371871e-01,  1.46658465e-01,\n          -4.40875918e-01, -1.02284839e-02, -3.61073792e-01,\n           1.61406174e-01, -4.69722360e-01, -6.18475556e-01,\n           1.08635701e-01, -7.86353290e-01, -4.74258274e-01,\n          -4.69396174e-01, -2.74679512e-01,  9.30852443e-02,\n          -3.57051164e-01, -7.75208417e-03, -2.70747423e-01,\n          -8.40524510e-02,  1.40307471e-01,  1.02327496e-01,\n          -1.33433370e-02,  7.11541995e-02, -9.31351006e-01,\n          -4.55794722e-01, -3.94440830e-01,  3.88966531e-01,\n          -2.58769006e-01,  7.85629213e-01,  7.57014394e-01,\n           7.45148420e-01, -3.81585956e-01, -1.06873953e+00,\n           5.79514027e-01, -6.60916626e-01, -6.05771422e-01,\n           5.31518102e-01, -1.74734741e-01, -3.17256570e-01,\n          -6.16019607e-01,  7.00652242e-01,  5.14042489e-02,\n           9.31720376e-01, -1.62156180e-01, -8.97937268e-03,\n           8.61314535e-01,  3.67090523e-01,  4.20677900e-01,\n           3.40258867e-01,  7.01290369e-01,  2.06433669e-01,\n          -8.80719543e-01,  4.33599502e-01,  8.15899491e-01,\n          -2.69388348e-01, -6.08404875e-01,  8.38132501e-01,\n          -4.82518703e-01, -9.51939672e-02,  5.60109913e-01,\n           4.68016446e-01, -4.18788880e-01, -3.20009366e-02,\n          -3.68941784e-01,  5.67998588e-01, -1.49871394e-01,\n          -2.72118077e-02,  7.01223671e-01,  7.89658844e-01,\n           1.34858459e-01,  2.42518559e-01, -7.89716184e-01,\n           9.52703580e-02, -1.02502263e+00,  5.45569919e-02,\n           7.07489192e-01,  1.34081081e-01,  7.90163219e-01,\n          -7.57170379e-01, -4.23197180e-01,  6.75555766e-01,\n          -1.08942008e+00, -3.29081357e-01, -8.88271406e-02,\n          -3.92588153e-02, -5.77842295e-01, -7.46620238e-01,\n           5.12914181e-01,  7.76664972e-01, -4.65337604e-01,\n           8.07154596e-01, -5.98765910e-01, -4.93479878e-01],\n         [ 6.18531406e-01, -3.77676547e-01,  2.67430753e-01,\n          -1.75654635e-01,  3.99663538e-01, -2.46960267e-01,\n          -4.25701410e-01, -8.47621262e-01, -2.75878787e-01,\n          -2.16059238e-01,  7.27733135e-01,  8.09149146e-01,\n           5.23460627e-01,  1.89121395e-01,  2.72398710e-01,\n           2.40583286e-01, -1.21978886e-01,  2.52825290e-01,\n          -5.97628236e-01,  9.89215672e-02, -6.27292812e-01,\n           1.21734841e-02, -1.76808581e-01,  1.62136108e-01,\n           5.05934775e-01, -1.36404738e-01,  3.34036201e-01,\n          -4.85410661e-01,  2.48070583e-01,  2.82083243e-01,\n          -5.07388592e-01,  9.31717753e-02,  4.93431002e-01,\n           3.34313154e-01,  9.01049137e-01, -4.87115294e-01,\n           4.43518966e-01, -5.83407342e-01,  5.32543600e-01,\n          -5.05783930e-02, -5.59384584e-01, -8.95728767e-02,\n           1.56855389e-01, -1.67145401e-01, -1.07825927e-01,\n           1.03315282e+00,  1.26618827e-02,  2.91273147e-01,\n           2.96938159e-02, -1.41806126e-01,  1.80486709e-01,\n          -9.66712952e-01, -5.32025278e-01,  4.00541723e-01,\n           7.04733074e-01, -8.97689521e-01, -4.85900551e-01,\n          -9.44968998e-01, -1.00858247e+00,  5.43566167e-01,\n          -3.50022644e-01, -3.59959714e-02, -4.16132718e-01,\n           8.45791399e-01,  1.97148561e-01, -6.80939019e-01,\n          -7.70855248e-01,  1.51649043e-01, -7.47665465e-01,\n          -3.37648422e-01, -7.84658849e-01,  2.34365296e-02,\n          -3.64647448e-01, -1.29679143e-01,  3.48851770e-01,\n           3.19147468e-01, -3.59509200e-01, -1.08784211e+00,\n           1.16424151e-01,  7.83614159e-01,  2.37695828e-01,\n          -7.62130439e-01, -1.04980206e+00,  1.02022171e-01,\n          -1.14864133e-01,  2.93863803e-01, -1.03277087e+00,\n          -2.08005197e-02,  4.51303273e-01, -2.62943745e-01,\n          -5.94456196e-02, -7.21348226e-02, -2.28022151e-02,\n           3.91022652e-01, -8.68185282e-01,  2.02530205e-01,\n           6.35487363e-02, -8.52396429e-01,  2.23136991e-01,\n           8.82301092e-01, -2.86025405e-01, -4.99148756e-01,\n           5.88356517e-02, -3.87952387e-01,  8.32631364e-02,\n          -3.40651751e-01,  4.48175788e-01,  3.13712984e-01,\n           2.90078670e-02,  3.06020021e-01, -8.41080308e-01,\n           2.32717413e-02,  2.93076247e-01,  4.49456125e-01,\n          -6.33266211e-01,  9.77284431e-01,  6.75373733e-01,\n           7.46764779e-01,  6.19113922e-01, -3.31757188e-01,\n          -9.16023314e-01,  1.99519824e-02,  3.93653721e-01,\n           1.15947768e-01,  4.90968525e-01, -1.38241267e-02,\n          -4.91675556e-01,  8.30584943e-01,  1.73599020e-01,\n          -7.58920372e-01,  3.67022157e-01, -3.55812103e-01,\n          -4.41733152e-01, -1.54181877e-02,  6.82702601e-01,\n          -9.76422668e-01, -5.17291427e-01, -7.55771637e-01,\n          -3.00056726e-01,  6.22777104e-01,  6.67394936e-01,\n           5.46495795e-01,  3.48491430e-01, -3.67247522e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/conv2d/kernel:0' shape=(1, 1, 40, 240) dtype=float32, numpy=\narray([[[[-0.10846975, -0.04387538,  0.04996194, ..., -0.22216865,\n          -0.02056042,  0.12688816],\n         [-0.29914814, -0.16314988, -0.00831862, ..., -0.06202249,\n          -0.07067244,  0.2181089 ],\n         [ 0.07977994,  0.05879841, -0.04792768, ..., -0.31141752,\n           0.01455813,  0.25767425],\n         ...,\n         [-0.04463792,  0.01344586, -0.03338015, ...,  0.12839402,\n           0.02043189,  0.07568845],\n         [ 0.01852733,  0.03186574,  0.08006775, ..., -0.18717928,\n           0.20442119,  0.05691642],\n         [ 0.02191412, -0.03355732,  0.07488471, ..., -0.24066308,\n          -0.19299074, -0.17654353]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_866/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.2501783 ,  0.07888674,  0.0325722 , ...,  0.08762973,\n          -0.19800052, -0.01862198],\n         [ 0.00796617,  0.13541149,  0.0856686 , ..., -0.04317694,\n           0.02006071, -0.07993342],\n         [ 0.09086728, -0.05608286, -0.05533084, ..., -0.08206446,\n          -0.09444878,  0.09587992],\n         ...,\n         [-0.08529392,  0.16880657, -0.20645188, ...,  0.03909325,\n          -0.00030573,  0.18943132],\n         [-0.0479279 ,  0.18441351, -0.09271561, ...,  0.12802796,\n           0.05643995, -0.15682791],\n         [ 0.08678026,  0.04738859, -0.02438919, ...,  0.00179102,\n          -0.05145963, -0.10679142]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/moving_variance:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.03893273,  0.06076668,  0.02495129, ...,  0.01068159,\n          -0.0079745 ,  0.09844283],\n         [ 0.12363878,  0.16640107,  0.03771288, ..., -0.16220391,\n          -0.07075275, -0.02629996],\n         [-0.05427835,  0.02844169, -0.10229241, ...,  0.0790605 ,\n           0.0564952 ,  0.06399786],\n         ...,\n         [ 0.01145475,  0.0648926 , -0.1306466 , ...,  0.03741225,\n           0.02403267, -0.04959186],\n         [ 0.02992491,  0.00162175, -0.15101081, ..., -0.08398304,\n          -0.01948462, -0.20555066],\n         [-0.07307259,  0.06151012,  0.05935737, ..., -0.11286869,\n          -0.03899459,  0.05054926]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_3/bias:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_840/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[-3.98744762e-01,  3.24916959e-01, -1.56644732e-02,\n          -2.09920958e-01,  1.69025540e-01, -6.15426712e-02,\n           4.03022617e-01, -1.10374950e-01, -2.86790401e-01,\n          -1.91736761e-02, -7.49783218e-02, -1.57237574e-02,\n          -3.27626437e-01, -4.13801908e-01, -7.88480118e-02,\n           7.31269643e-02, -1.63358394e-02, -4.06948738e-02,\n           1.17733777e-01, -3.35734099e-01, -5.46164811e-02,\n          -2.22047776e-01,  9.15764943e-02,  3.62923890e-01],\n         [-2.05070563e-02,  4.03076053e-01,  1.46990508e-01,\n          -8.69363546e-02,  1.31527603e-01, -2.77412739e-02,\n           1.91128820e-01,  5.62993065e-02,  4.24983263e-01,\n           2.72930056e-01, -1.57165870e-01,  6.90236911e-02,\n           4.01723981e-01,  4.08069156e-02,  4.25368268e-03,\n          -1.02996364e-01, -1.73692092e-01,  7.09248483e-02,\n           1.10495528e-02,  4.50279027e-01,  9.94370133e-02,\n           3.64469051e-01, -1.48290396e-01,  1.27464771e-01],\n         [ 4.02755588e-02,  1.59933910e-01, -1.57675534e-01,\n          -3.17200005e-01,  2.35306904e-01, -1.11838907e-01,\n           3.23110074e-01, -2.73816377e-01, -2.59810776e-01,\n           1.08839892e-01, -1.27539545e-01, -1.33992150e-01,\n          -1.28702551e-01, -1.39400929e-01,  1.38803840e-01,\n          -1.27892852e-01,  3.24678391e-01, -7.78625533e-02,\n           1.09737344e-01,  2.20608041e-02,  1.57077298e-01,\n           1.41585454e-01, -3.30714276e-03, -1.40463755e-01],\n         [ 1.39412344e-01,  6.55381382e-02,  1.96098864e-01,\n          -7.53276348e-02,  1.78287134e-01, -2.57888436e-01,\n          -1.60236061e-01,  2.12951466e-01,  2.37015352e-01,\n          -6.44323081e-02,  1.67331584e-02,  4.13743407e-01,\n           9.24480185e-02,  2.63279706e-01,  1.40750051e-01,\n          -6.97017983e-02,  1.58374347e-02, -2.42212042e-01,\n          -2.44212709e-02,  2.84537431e-02,  1.03397556e-02,\n           1.11399263e-01,  1.14202015e-01, -2.11482793e-01],\n         [-1.51300415e-01,  2.09614500e-01, -3.51036072e-01,\n          -1.28431082e-01,  2.47942507e-01, -4.25407588e-02,\n           1.23179868e-01, -5.62894344e-02,  8.31497088e-02,\n           1.68619007e-01, -7.96044022e-02,  1.82905998e-02,\n          -4.65847738e-02, -6.94306865e-02,  9.54045728e-02,\n          -1.84405312e-01, -9.19958204e-02,  1.42244488e-01,\n          -2.49998555e-01, -5.38746938e-02,  8.80688652e-02,\n          -1.94409594e-01,  1.39907569e-01, -3.11363280e-01],\n         [ 1.09884217e-02, -1.07570486e-02, -4.30404425e-01,\n           1.46780327e-01, -1.43354133e-01, -1.63133115e-01,\n           1.54467762e-01, -1.57679155e-01, -8.23075324e-03,\n          -1.52325764e-01,  2.63443798e-01,  1.37349531e-01,\n           2.05407053e-01,  2.24886313e-02, -7.65604526e-02,\n          -2.44678661e-01,  3.22479129e-01,  3.24740589e-01,\n          -4.96664345e-02,  1.65633574e-01, -2.85297874e-02,\n          -3.07544172e-01,  2.17049867e-02,  1.63968518e-01],\n         [ 4.61600691e-01, -1.29953653e-01, -1.06489714e-02,\n           1.72597855e-01, -2.89302822e-02, -3.33692491e-01,\n           1.31310746e-01, -1.20318025e-01, -2.24358261e-01,\n          -1.49492174e-01,  3.33057523e-01,  2.25320905e-01,\n          -1.91151679e-01, -5.77321723e-02, -3.57097536e-02,\n          -9.69030783e-02, -1.92144424e-01, -1.17964879e-01,\n           6.01199530e-02, -2.27425084e-01, -1.60159260e-01,\n          -1.62799418e-01,  2.29591817e-01, -1.57995597e-01],\n         [-2.65026569e-01, -3.31593037e-01,  3.76743168e-01,\n          -1.14735991e-01,  1.68919191e-02, -4.06032115e-01,\n           1.64764434e-01, -2.25920193e-02,  1.09369040e-01,\n          -4.04786497e-01, -2.01515984e-02, -1.35330796e-01,\n          -4.60773855e-01,  4.55053039e-02,  2.03868493e-01,\n          -1.06567919e-01, -2.66350120e-01,  2.50047930e-02,\n           1.74135208e-01,  2.33586356e-01,  1.03171922e-01,\n          -1.90436572e-01, -1.31052747e-01, -3.81031454e-01],\n         [-1.19460367e-01, -2.54753321e-01, -3.32350999e-01,\n           2.55292002e-02, -1.62125126e-01, -2.54650079e-02,\n          -5.71575090e-02, -3.05143625e-01, -6.22119121e-02,\n          -3.88620734e-01,  3.82516682e-01, -2.05147177e-01,\n           1.59026250e-01, -3.26179832e-01, -5.47350235e-02,\n          -1.50111243e-01,  3.23475718e-01, -3.49901081e-03,\n          -7.45047554e-02, -3.00459743e-01,  3.52437586e-01,\n          -2.74110496e-01, -3.67665112e-01,  1.42708808e-01],\n         [-4.23080847e-02,  3.97151709e-01,  3.16315204e-01,\n          -1.78291082e-01,  2.05567658e-01,  2.22794682e-01,\n           3.96551862e-02,  3.10912073e-01,  2.46468261e-01,\n          -1.72455937e-01, -2.54351646e-01, -3.05025876e-01,\n          -1.99753076e-01, -7.87938386e-02, -4.16367739e-01,\n           4.41769250e-02,  7.48884901e-02, -8.84809345e-02,\n           4.17002112e-01,  4.63550687e-01, -1.90631539e-01,\n           2.38003150e-01,  5.50110117e-02, -3.08317572e-01],\n         [-1.51426569e-01,  5.12997173e-02, -3.14696640e-01,\n           4.21107888e-01,  1.26865610e-01, -1.26972675e-01,\n           8.99012983e-02,  3.18751007e-01,  2.52864808e-01,\n          -1.09527014e-01, -3.34995277e-02, -1.95748597e-01,\n           3.52941722e-01, -1.43602654e-01, -3.21989954e-01,\n          -2.16904938e-01, -3.52620214e-01, -1.43125907e-01,\n          -9.02584866e-02, -2.15404645e-01,  6.95308018e-03,\n          -1.19512856e-01, -1.21129759e-01, -3.55999559e-01],\n         [-1.62083600e-02, -2.06755877e-01,  3.47617894e-01,\n           7.53517300e-02,  4.21195067e-02,  4.13988918e-01,\n           1.29725367e-01, -1.33498847e-01, -2.32933134e-01,\n           3.22412193e-01, -8.78358632e-02, -5.47286570e-02,\n           6.71751238e-03,  1.73532560e-01, -2.91200966e-01,\n           1.99565738e-01, -3.37108791e-01, -4.63949591e-02,\n          -3.11299652e-01, -5.49414791e-02, -2.38083929e-01,\n           1.24285787e-01,  2.66104549e-01, -1.49634453e-02],\n         [-5.54125719e-02, -4.06134665e-01,  2.39789441e-01,\n           8.64854604e-02, -3.12907308e-01,  2.89627194e-01,\n           1.49804845e-01, -1.31035745e-01,  1.94335476e-01,\n          -1.00586958e-01, -8.08686465e-02,  2.81991363e-01,\n          -5.43198884e-02,  2.61789203e-01, -1.99542344e-01,\n          -2.29650438e-01, -2.51374573e-01,  3.85829985e-01,\n          -1.16104394e-01, -1.67164415e-01,  1.63868546e-01,\n           1.38005242e-01,  1.40464649e-01, -1.12362720e-01],\n         [ 9.39455181e-02, -1.14810310e-01,  9.80247632e-02,\n          -2.84063190e-01, -3.62394005e-01,  3.12610865e-01,\n          -3.25615406e-02,  1.38691023e-01,  2.56698225e-02,\n          -4.78386171e-02, -5.30254208e-02,  5.96855059e-02,\n           3.32654297e-01, -2.29626477e-01,  2.09042281e-01,\n          -7.00509027e-02,  2.27016106e-01,  2.34369040e-01,\n           3.46022516e-01,  9.78177488e-02,  7.70256966e-02,\n          -1.65916562e-01, -1.18930466e-01, -2.33623803e-01],\n         [ 5.68194082e-03,  5.87251969e-03,  4.39089872e-02,\n          -1.63235366e-01,  6.34942502e-02, -1.10668465e-01,\n          -1.60611600e-01, -9.51056331e-02, -9.89433601e-02,\n          -1.40878618e-01,  7.66124502e-02,  1.34672701e-01,\n          -2.15953872e-01, -1.89283550e-01,  1.90985352e-01,\n          -1.42657936e-01, -3.00903678e-01, -1.91503257e-01,\n           1.26229122e-01, -2.79375166e-01, -1.41020060e-01,\n           3.25634837e-01,  1.99098643e-02, -2.14155942e-01],\n         [-4.14262503e-01,  9.65789426e-03,  6.06729724e-02,\n          -1.07294813e-01,  2.43518203e-01,  2.91277841e-02,\n          -1.63813204e-01,  2.67330885e-01,  1.40205026e-01,\n           4.80431691e-02, -3.29997465e-02,  3.51133168e-01,\n           3.79026192e-03,  4.05593693e-01,  1.20759252e-02,\n          -7.09572285e-02, -4.00459707e-01,  3.46686272e-03,\n          -3.45991611e-01, -1.96331263e-01, -1.42853022e-01,\n           1.44334704e-01,  1.28495526e-02, -1.28752232e-01],\n         [ 1.91116348e-01,  1.51617810e-01,  2.38321975e-01,\n           2.02236965e-01,  2.59949803e-01,  6.20558299e-02,\n           5.42467274e-02, -8.37595761e-02,  7.52476528e-02,\n           2.58312404e-01, -1.42123461e-01,  1.21520972e-03,\n          -5.81599809e-02, -3.00382733e-01, -1.18727058e-01,\n           3.48826647e-01, -1.23561613e-01, -9.53824073e-02,\n           4.20462579e-01, -1.16105795e-01, -1.37909159e-01,\n           3.18094432e-01,  2.00111181e-01,  6.23314343e-02],\n         [ 1.94858655e-01,  1.29717276e-01,  4.50915881e-02,\n           1.04895294e-01,  1.66301742e-01, -1.17047653e-01,\n          -8.04652125e-02, -1.04753025e-01,  1.01913013e-01,\n           1.57645747e-01, -1.72372103e-01, -2.13018358e-01,\n           1.44036189e-01, -2.93255836e-01, -4.60918695e-01,\n           1.21040404e-01, -1.30950913e-01, -1.20325968e-01,\n          -4.02127594e-01,  1.43194184e-01,  8.73684511e-02,\n          -4.21112441e-02,  6.86736703e-02, -4.70029414e-02],\n         [ 1.23182110e-01, -4.40145433e-01, -5.24939783e-02,\n           2.58331690e-02, -2.19020009e-01, -2.37944871e-02,\n           1.39680386e-01,  2.28184342e-01, -4.95996960e-02,\n           9.30376053e-02, -7.83670098e-02, -1.72877580e-01,\n          -9.93379485e-03,  1.16599269e-01,  6.37399033e-02,\n           1.05182111e-01,  1.81904390e-01, -4.61650081e-02,\n          -4.29680087e-02, -2.19654460e-02,  1.01285279e-01,\n           8.48396719e-02, -5.89997768e-02, -2.23560050e-01],\n         [-3.71553183e-01,  7.06115738e-02,  9.01893750e-02,\n          -1.17594097e-02, -2.55040154e-02,  1.79949865e-01,\n           3.13523859e-01,  1.05610371e-01, -1.88348547e-01,\n           2.01815471e-01,  1.25793397e-01,  3.02127004e-02,\n          -8.18207636e-02,  6.55046627e-02,  4.37186770e-02,\n          -3.46403182e-01, -2.90146828e-01, -2.86445208e-02,\n          -4.23482507e-01,  1.54915720e-01, -3.69703293e-01,\n           3.50470632e-01, -2.25925469e-04, -1.01971906e-02],\n         [ 2.58627415e-01,  2.21890822e-01, -1.73520654e-01,\n           3.13217193e-01, -9.56916884e-02, -9.93056744e-02,\n          -8.41328502e-02,  3.38838369e-01, -1.75692048e-02,\n          -3.21697861e-01,  5.91104180e-02,  2.25315392e-01,\n           3.08550775e-01, -1.81837603e-01, -2.84738421e-01,\n          -4.09840196e-02,  2.66594976e-01,  7.65532926e-02,\n          -9.29761603e-02,  1.05110586e-01, -1.58268496e-01,\n           3.36448364e-02, -1.26135442e-02, -8.99771079e-02],\n         [-2.45816737e-01,  2.28358909e-01,  3.93657833e-01,\n          -1.80596903e-01, -2.82370336e-02, -2.00656891e-01,\n           3.37813497e-01,  1.42774448e-01,  2.43834838e-01,\n          -1.22346049e-02, -1.47147983e-01,  3.88199538e-01,\n          -7.80526474e-02,  2.52547324e-01,  1.74797207e-01,\n           2.79319525e-01,  2.18980670e-01, -6.12645708e-02,\n          -1.58138603e-01, -2.87641454e-02, -6.28589019e-02,\n          -1.25012070e-01,  1.71689525e-01, -2.94187307e-01],\n         [ 1.97546318e-01,  2.53386497e-01,  3.59842509e-01,\n          -1.24021269e-01, -1.22953303e-01, -3.46196204e-01,\n          -7.42975622e-02,  2.71183789e-01,  2.69713461e-01,\n           3.56877632e-02, -1.16049848e-01,  1.36917144e-01,\n           3.21504146e-01,  1.82195708e-01, -1.50063047e-02,\n           4.58752736e-02,  1.28179729e-01, -1.69096023e-01,\n          -2.73996871e-02, -3.99021924e-01,  1.87969744e-01,\n          -3.50153029e-01, -1.87828943e-01, -1.81775600e-01],\n         [ 5.18975817e-02, -3.16288918e-01,  5.82023636e-02,\n          -1.56205118e-01,  4.49688099e-02, -1.71544239e-01,\n           5.87657839e-02, -3.64348203e-01, -6.03703707e-02,\n          -1.82167247e-01, -3.34396333e-01,  8.89104456e-02,\n           9.60206985e-02, -5.33072539e-02, -2.50643104e-01,\n           6.04541674e-02, -1.52715549e-01, -4.38896865e-02,\n           3.30199510e-01,  1.02455333e-01, -1.62076354e-01,\n          -2.01144323e-01, -2.54707307e-01,  6.30588606e-02]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.08950169, -0.25865227, -0.06576162, ..., -0.38716087,\n          -0.07422686, -0.11374398],\n         [ 0.22133687, -0.28971478, -0.1050359 , ...,  0.3236601 ,\n          -0.1195141 , -0.0255743 ],\n         [-0.15862454,  0.41304547,  0.12608218, ..., -0.02676832,\n           0.15773886,  0.1698634 ],\n         ...,\n         [ 0.14942987, -0.07665537, -0.12274998, ...,  0.2091249 ,\n           0.38524148, -0.2502452 ],\n         [ 0.05583834,  0.01493152,  0.29702696, ..., -0.09265302,\n          -0.21088955, -0.19551441],\n         [ 0.01877302,  0.10190286,  0.05397153, ..., -0.1455231 ,\n          -0.24930139, -0.16344942]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_358/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.09909619],\n         [-0.02956621],\n         [ 0.0698209 ],\n         [-0.14270182],\n         [ 0.07355852],\n         [-0.01430281],\n         [-0.14692292],\n         [ 0.04224443],\n         [ 0.05718258],\n         [-0.10113262],\n         [ 0.09023923],\n         [ 0.10247001],\n         [ 0.15992272],\n         [ 0.05188684],\n         [ 0.13800377],\n         [ 0.14307356],\n         [ 0.00031848],\n         [-0.15293229],\n         [-0.00499187],\n         [-0.08258998],\n         [ 0.04502176],\n         [-0.05584588],\n         [-0.02169788],\n         [-0.08357633]],\n\n        [[ 0.16015646],\n         [ 0.11668113],\n         [ 0.15233621],\n         [ 0.11061075],\n         [-0.06030728],\n         [-0.00650655],\n         [ 0.0602138 ],\n         [-0.12718593],\n         [ 0.11524957],\n         [-0.07546226],\n         [-0.03680794],\n         [-0.03238069],\n         [-0.08612224],\n         [-0.02131626],\n         [-0.08379517],\n         [-0.02109718],\n         [-0.09916514],\n         [-0.10943486],\n         [ 0.07645503],\n         [ 0.1535987 ],\n         [ 0.04075666],\n         [ 0.1363785 ],\n         [-0.04356521],\n         [-0.04439578]],\n\n        [[-0.08615786],\n         [-0.08540169],\n         [ 0.12593207],\n         [-0.04387029],\n         [ 0.06912524],\n         [-0.03282422],\n         [-0.00832836],\n         [ 0.1493716 ],\n         [ 0.10355681],\n         [-0.15342818],\n         [-0.00367993],\n         [ 0.03987932],\n         [ 0.04110281],\n         [-0.03921442],\n         [ 0.15538517],\n         [ 0.03929731],\n         [ 0.05357227],\n         [-0.09325339],\n         [-0.0428125 ],\n         [-0.10149283],\n         [-0.12642007],\n         [ 0.05854729],\n         [-0.05914173],\n         [ 0.05474395]]],\n\n\n       [[[ 0.15013662],\n         [-0.01382847],\n         [-0.04366453],\n         [-0.05605047],\n         [-0.10222307],\n         [-0.02066007],\n         [-0.01637095],\n         [-0.15933923],\n         [-0.01362984],\n         [ 0.10024902],\n         [-0.13368884],\n         [-0.12773812],\n         [ 0.12727407],\n         [-0.11175829],\n         [ 0.05217604],\n         [ 0.08648308],\n         [-0.09171625],\n         [-0.03058755],\n         [-0.0588693 ],\n         [-0.06708916],\n         [-0.14114463],\n         [ 0.03217798],\n         [-0.07087292],\n         [ 0.0522975 ]],\n\n        [[-0.11327608],\n         [-0.08812973],\n         [-0.12393415],\n         [ 0.04434143],\n         [ 0.03394838],\n         [-0.08565713],\n         [-0.11106519],\n         [-0.13610008],\n         [-0.0353155 ],\n         [ 0.16052529],\n         [ 0.06148985],\n         [ 0.16215825],\n         [ 0.09222496],\n         [-0.03287268],\n         [ 0.02266651],\n         [-0.11426122],\n         [ 0.13656399],\n         [ 0.00689763],\n         [ 0.07830137],\n         [-0.1181777 ],\n         [ 0.0571273 ],\n         [-0.09140735],\n         [-0.15239005],\n         [-0.15231857]],\n\n        [[-0.14446247],\n         [ 0.0694325 ],\n         [-0.13059588],\n         [ 0.09653911],\n         [-0.10974457],\n         [ 0.14987305],\n         [-0.01269048],\n         [ 0.11169916],\n         [-0.0048551 ],\n         [ 0.15250611],\n         [-0.13860102],\n         [ 0.01482467],\n         [ 0.14114752],\n         [ 0.05875041],\n         [-0.08388655],\n         [ 0.12867272],\n         [ 0.13420573],\n         [ 0.12607074],\n         [-0.01583573],\n         [-0.12415342],\n         [ 0.08703214],\n         [ 0.00876562],\n         [ 0.15634888],\n         [-0.07655971]]],\n\n\n       [[[ 0.04984291],\n         [-0.12087651],\n         [ 0.02824812],\n         [ 0.07182212],\n         [ 0.16318181],\n         [ 0.04174647],\n         [-0.10650666],\n         [-0.00305332],\n         [-0.02595964],\n         [ 0.0749481 ],\n         [-0.0838104 ],\n         [-0.13124374],\n         [ 0.12892017],\n         [ 0.09525967],\n         [ 0.0594992 ],\n         [ 0.01839675],\n         [-0.05466194],\n         [-0.07664335],\n         [ 0.14835158],\n         [-0.1481158 ],\n         [-0.13520001],\n         [-0.12603863],\n         [-0.01207814],\n         [ 0.07727383]],\n\n        [[-0.08818506],\n         [ 0.10962209],\n         [-0.12476332],\n         [-0.15919876],\n         [ 0.07413194],\n         [ 0.08007558],\n         [-0.13655373],\n         [ 0.02392535],\n         [ 0.0981971 ],\n         [ 0.04804409],\n         [-0.14920314],\n         [ 0.15518731],\n         [-0.04636278],\n         [-0.0246865 ],\n         [ 0.1576007 ],\n         [ 0.08813962],\n         [-0.13416617],\n         [ 0.00997911],\n         [-0.13372767],\n         [ 0.06163052],\n         [ 0.11980361],\n         [ 0.06730548],\n         [-0.12897146],\n         [-0.07424024]],\n\n        [[ 0.13176432],\n         [-0.00475018],\n         [-0.06270719],\n         [-0.15862982],\n         [ 0.0837425 ],\n         [ 0.01337494],\n         [-0.02384974],\n         [-0.13205332],\n         [ 0.02677096],\n         [ 0.00769542],\n         [ 0.1328499 ],\n         [-0.05490007],\n         [-0.05947647],\n         [ 0.03733104],\n         [-0.05754548],\n         [-0.09941907],\n         [-0.15656252],\n         [-0.12614204],\n         [-0.15259391],\n         [ 0.135916  ],\n         [-0.09641857],\n         [ 0.09233513],\n         [-0.09538508],\n         [ 0.149683  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_857/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.0093849 , -0.07618431,  0.0412395 , ..., -0.00709378,\n           0.06516431,  0.14116032],\n         [ 0.0328113 ,  0.07770959,  0.04106437, ..., -0.1046966 ,\n          -0.12375969,  0.06138004],\n         [-0.00601875, -0.15626875,  0.11754517, ...,  0.01796212,\n           0.00588956,  0.04789983],\n         ...,\n         [ 0.07529315,  0.04426454, -0.02899083, ...,  0.03000407,\n           0.04389154,  0.04538391],\n         [ 0.10521343,  0.0657078 ,  0.1492111 , ..., -0.09759308,\n          -0.04631427, -0.15683034],\n         [-0.00703483,  0.06134846,  0.00979729, ...,  0.09885541,\n          -0.08550805,  0.0487494 ]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_357/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.1543562 ],\n         [-0.04362474],\n         [-0.10527924],\n         [-0.11073216],\n         [-0.00844142],\n         [ 0.00394292],\n         [ 0.05242486],\n         [ 0.0921374 ],\n         [ 0.0365122 ],\n         [-0.083565  ],\n         [-0.00918292],\n         [ 0.04601164],\n         [-0.09692603],\n         [-0.03396317],\n         [ 0.03052402],\n         [ 0.15421212],\n         [ 0.08781141],\n         [-0.08901333],\n         [ 0.04679628],\n         [-0.16155326],\n         [-0.08809371],\n         [ 0.0776916 ],\n         [ 0.05964163],\n         [ 0.08641852]],\n\n        [[-0.09491013],\n         [ 0.12147394],\n         [ 0.01445842],\n         [-0.10457781],\n         [ 0.14931008],\n         [-0.09531979],\n         [-0.03378026],\n         [-0.07134888],\n         [ 0.09466723],\n         [ 0.06590986],\n         [ 0.04273611],\n         [-0.02090174],\n         [ 0.08818796],\n         [ 0.15370569],\n         [ 0.10529679],\n         [-0.13825265],\n         [ 0.13934472],\n         [ 0.13935784],\n         [ 0.11456934],\n         [ 0.1285601 ],\n         [ 0.03718372],\n         [ 0.15407264],\n         [ 0.01547852],\n         [ 0.00163241]],\n\n        [[ 0.06718656],\n         [-0.16097058],\n         [ 0.09880129],\n         [ 0.13922703],\n         [-0.06356275],\n         [ 0.02876227],\n         [ 0.07081075],\n         [ 0.09418106],\n         [ 0.09011522],\n         [ 0.0220903 ],\n         [-0.1626848 ],\n         [-0.01907805],\n         [-0.02069713],\n         [ 0.05405334],\n         [-0.13838615],\n         [-0.09404799],\n         [-0.03725034],\n         [-0.13277519],\n         [-0.1632656 ],\n         [ 0.00141963],\n         [-0.05724858],\n         [-0.14265315],\n         [-0.0902316 ],\n         [ 0.10271519]]],\n\n\n       [[[ 0.15806687],\n         [ 0.08697987],\n         [ 0.13376415],\n         [ 0.06312501],\n         [-0.0792517 ],\n         [-0.00787194],\n         [ 0.06238902],\n         [ 0.09803048],\n         [-0.00146383],\n         [-0.09744529],\n         [-0.02142079],\n         [-0.02368778],\n         [ 0.12281302],\n         [-0.11794558],\n         [ 0.1358988 ],\n         [ 0.0239289 ],\n         [-0.1349137 ],\n         [-0.09999404],\n         [-0.03907274],\n         [ 0.07486373],\n         [ 0.08161961],\n         [-0.09107754],\n         [-0.0688071 ],\n         [-0.09561346]],\n\n        [[-0.0906777 ],\n         [-0.12004145],\n         [-0.12519537],\n         [-0.04437791],\n         [-0.01172151],\n         [-0.07900128],\n         [ 0.13290188],\n         [ 0.06057709],\n         [-0.01205812],\n         [-0.1340361 ],\n         [-0.14699666],\n         [-0.06868816],\n         [-0.07166008],\n         [-0.13240318],\n         [ 0.08321027],\n         [ 0.04692961],\n         [ 0.12844568],\n         [ 0.09649256],\n         [-0.08155961],\n         [ 0.10885033],\n         [ 0.11869517],\n         [-0.10353096],\n         [-0.08013324],\n         [ 0.15228513]],\n\n        [[-0.11148256],\n         [-0.09595013],\n         [-0.09668165],\n         [-0.13286163],\n         [ 0.06489603],\n         [-0.05243362],\n         [ 0.15236193],\n         [ 0.08546574],\n         [ 0.06281959],\n         [ 0.15405712],\n         [-0.13763885],\n         [-0.12025383],\n         [ 0.14673862],\n         [ 0.07903893],\n         [ 0.07684024],\n         [ 0.08145736],\n         [ 0.01015949],\n         [ 0.14129975],\n         [ 0.01512048],\n         [ 0.09721512],\n         [ 0.04439126],\n         [ 0.15398738],\n         [-0.02733403],\n         [ 0.08779907]]],\n\n\n       [[[ 0.11620066],\n         [-0.04848894],\n         [-0.03970467],\n         [-0.02734143],\n         [-0.01454303],\n         [-0.16219392],\n         [-0.11013629],\n         [-0.09952668],\n         [ 0.08644702],\n         [ 0.00041242],\n         [ 0.09040463],\n         [-0.04100852],\n         [-0.11363298],\n         [-0.11777081],\n         [-0.06029735],\n         [ 0.03269087],\n         [-0.00095099],\n         [-0.14430529],\n         [-0.01997325],\n         [-0.14634211],\n         [-0.03172581],\n         [-0.14706472],\n         [ 0.05975731],\n         [-0.12937275]],\n\n        [[-0.01046547],\n         [-0.15458684],\n         [-0.0688919 ],\n         [ 0.09468397],\n         [-0.14597122],\n         [-0.08475629],\n         [-0.013016  ],\n         [-0.06790439],\n         [-0.08426689],\n         [ 0.09009016],\n         [ 0.03769231],\n         [ 0.13048407],\n         [ 0.1603406 ],\n         [-0.09607479],\n         [ 0.0582872 ],\n         [-0.13456967],\n         [-0.13953456],\n         [-0.15219185],\n         [-0.13091385],\n         [-0.13461235],\n         [-0.0481285 ],\n         [-0.08452639],\n         [-0.13123249],\n         [-0.06883012]],\n\n        [[ 0.01952091],\n         [ 0.08030018],\n         [ 0.070032  ],\n         [-0.08933768],\n         [ 0.041169  ],\n         [ 0.10776007],\n         [ 0.01371825],\n         [ 0.02999565],\n         [ 0.07270238],\n         [-0.14533222],\n         [-0.01930654],\n         [-0.06409241],\n         [ 0.09145212],\n         [ 0.07270864],\n         [ 0.01512721],\n         [-0.03076972],\n         [-0.16121466],\n         [-0.00368296],\n         [ 0.01001096],\n         [ 0.11736131],\n         [ 0.08949232],\n         [ 0.05252285],\n         [ 0.08120197],\n         [-0.05429608]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_363/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.05298261],\n         [-0.04347412],\n         [-0.01350139],\n         [-0.07802997],\n         [-0.03586381],\n         [-0.049035  ],\n         [-0.00903175],\n         [ 0.06359079],\n         [ 0.06810628],\n         [ 0.03028417],\n         [-0.02746696],\n         [-0.03742422],\n         [ 0.08608593],\n         [-0.06236688],\n         [ 0.06328404],\n         [ 0.01399911],\n         [ 0.08174984],\n         [ 0.00155799],\n         [ 0.06581785],\n         [-0.00386532],\n         [-0.04672595],\n         [-0.01339091],\n         [ 0.00997933],\n         [-0.08026826],\n         [-0.01987337],\n         [ 0.02174885],\n         [ 0.00448915],\n         [-0.08418126],\n         [ 0.04969518],\n         [-0.08991464],\n         [-0.01489896],\n         [ 0.01607019],\n         [ 0.05493298],\n         [ 0.01094002],\n         [ 0.05647634],\n         [-0.04087238],\n         [ 0.0366326 ],\n         [-0.08721789],\n         [ 0.07907724],\n         [ 0.07253528],\n         [ 0.01775885],\n         [-0.01116306],\n         [ 0.04144582],\n         [-0.02251227],\n         [-0.08523309],\n         [-0.03461389],\n         [-0.00214615],\n         [-0.00633627],\n         [-0.02008063],\n         [-0.00991018],\n         [-0.01565913],\n         [ 0.0463427 ],\n         [ 0.0894313 ],\n         [-0.01497076],\n         [-0.05059624],\n         [-0.0795712 ],\n         [-0.06200073],\n         [-0.06233876],\n         [ 0.02639455],\n         [ 0.01312596],\n         [-0.07568688],\n         [-0.01599316],\n         [-0.05819158],\n         [ 0.08128271],\n         [ 0.05769262],\n         [ 0.01808815],\n         [ 0.03537878],\n         [-0.00030422],\n         [ 0.06659919],\n         [ 0.0604445 ],\n         [-0.01232339],\n         [ 0.08944979],\n         [-0.00807615],\n         [-0.05304118],\n         [-0.00095755],\n         [ 0.04006597],\n         [-0.03759263],\n         [-0.00827473],\n         [-0.02523082],\n         [-0.08866937]],\n\n        [[ 0.06721216],\n         [-0.033228  ],\n         [-0.02984305],\n         [-0.02302394],\n         [-0.03617355],\n         [-0.04404538],\n         [-0.07946093],\n         [ 0.00733095],\n         [-0.01416339],\n         [-0.06243047],\n         [-0.0339571 ],\n         [ 0.01188467],\n         [-0.00579628],\n         [-0.01025797],\n         [ 0.00913981],\n         [ 0.00266241],\n         [ 0.00711801],\n         [-0.01336891],\n         [-0.01964373],\n         [-0.05814767],\n         [ 0.06108975],\n         [ 0.02508366],\n         [-0.03270208],\n         [-0.06563758],\n         [ 0.0451217 ],\n         [ 0.07777625],\n         [-0.032192  ],\n         [ 0.08708495],\n         [-0.04778069],\n         [-0.02581466],\n         [ 0.0673447 ],\n         [-0.03781473],\n         [-0.04186957],\n         [ 0.05974098],\n         [-0.07189693],\n         [-0.04388811],\n         [ 0.04808757],\n         [-0.03152012],\n         [-0.02359442],\n         [-0.06109343],\n         [ 0.03437553],\n         [-0.07121469],\n         [ 0.07225282],\n         [-0.07119821],\n         [ 0.05967121],\n         [-0.08783079],\n         [ 0.07344154],\n         [ 0.06890786],\n         [-0.0204224 ],\n         [-0.064471  ],\n         [-0.01348638],\n         [ 0.02241152],\n         [-0.03053715],\n         [-0.02360081],\n         [ 0.08707763],\n         [ 0.03087157],\n         [ 0.00497337],\n         [-0.02413388],\n         [-0.03502923],\n         [ 0.03661242],\n         [-0.08585317],\n         [-0.02968189],\n         [-0.05406392],\n         [ 0.07562643],\n         [ 0.05342093],\n         [-0.018076  ],\n         [ 0.03067385],\n         [-0.09006127],\n         [ 0.08526392],\n         [ 0.05969599],\n         [-0.00272769],\n         [-0.08159765],\n         [-0.02885702],\n         [-0.04006831],\n         [-0.0331138 ],\n         [ 0.08193074],\n         [ 0.0533026 ],\n         [ 0.02221341],\n         [-0.03098813],\n         [ 0.02527017]],\n\n        [[ 0.04726015],\n         [-0.01815253],\n         [ 0.04471627],\n         [-0.04870324],\n         [ 0.03126625],\n         [-0.03874011],\n         [ 0.06912351],\n         [-0.0589094 ],\n         [ 0.00022583],\n         [-0.05100746],\n         [-0.07912616],\n         [-0.0871629 ],\n         [ 0.01365352],\n         [-0.03702554],\n         [-0.06915888],\n         [ 0.01731355],\n         [-0.02114066],\n         [ 0.06711836],\n         [ 0.06623952],\n         [-0.07287711],\n         [ 0.07039808],\n         [-0.06500651],\n         [ 0.05655946],\n         [-0.00628769],\n         [-0.04188831],\n         [ 0.0305813 ],\n         [-0.01088352],\n         [-0.00107394],\n         [ 0.02528505],\n         [-0.05269863],\n         [-0.08048852],\n         [ 0.04626392],\n         [ 0.01949695],\n         [-0.07173852],\n         [-0.03160785],\n         [-0.00349265],\n         [-0.03054293],\n         [-0.08337758],\n         [-0.00249264],\n         [-0.05081286],\n         [ 0.06019534],\n         [-0.06080283],\n         [-0.03675844],\n         [-0.05031133],\n         [-0.05524943],\n         [-0.04518622],\n         [ 0.04622447],\n         [-0.06099726],\n         [ 0.08748516],\n         [ 0.07312602],\n         [ 0.04065117],\n         [ 0.08390489],\n         [ 0.03313102],\n         [-0.02060351],\n         [ 0.05807929],\n         [-0.03745567],\n         [ 0.08511746],\n         [ 0.04580659],\n         [-0.05775608],\n         [ 0.06441122],\n         [ 0.00236078],\n         [ 0.08545871],\n         [-0.02402986],\n         [-0.0313197 ],\n         [ 0.02121241],\n         [ 0.00371366],\n         [-0.04359438],\n         [ 0.06536743],\n         [ 0.00878463],\n         [-0.00990772],\n         [-0.06612951],\n         [-0.01553001],\n         [ 0.05379207],\n         [-0.05864786],\n         [ 0.04181433],\n         [-0.04101801],\n         [-0.01809502],\n         [-0.04798959],\n         [ 0.0044298 ],\n         [ 0.07202011]]],\n\n\n       [[[ 0.01571522],\n         [-0.08249842],\n         [ 0.04081289],\n         [-0.04097222],\n         [ 0.06612709],\n         [ 0.03860056],\n         [-0.05283637],\n         [ 0.01772668],\n         [-0.07369085],\n         [ 0.05207188],\n         [ 0.06155628],\n         [-0.06448035],\n         [-0.06146879],\n         [ 0.01903883],\n         [ 0.05274113],\n         [ 0.01721144],\n         [ 0.08812451],\n         [-0.06960922],\n         [ 0.07264848],\n         [-0.06785725],\n         [ 0.04883473],\n         [ 0.03855909],\n         [ 0.06614052],\n         [ 0.01925318],\n         [ 0.02403027],\n         [-0.01164994],\n         [ 0.05619629],\n         [-0.01376058],\n         [-0.04031971],\n         [ 0.0783277 ],\n         [ 0.00162792],\n         [-0.0168032 ],\n         [-0.04760144],\n         [-0.03753326],\n         [ 0.01017631],\n         [ 0.06980033],\n         [-0.04708187],\n         [-0.03060254],\n         [-0.02584827],\n         [ 0.0454063 ],\n         [-0.00314181],\n         [-0.00030353],\n         [-0.07321988],\n         [ 0.06647891],\n         [ 0.07937758],\n         [-0.05759005],\n         [-0.01126476],\n         [-0.01097655],\n         [-0.06537954],\n         [ 0.03605646],\n         [ 0.01161013],\n         [-0.02746631],\n         [-0.07507539],\n         [-0.02132445],\n         [-0.03053897],\n         [-0.00925839],\n         [ 0.05670334],\n         [ 0.02233458],\n         [ 0.045771  ],\n         [-0.01127307],\n         [-0.07189704],\n         [ 0.04654463],\n         [-0.07568552],\n         [-0.0503938 ],\n         [-0.03569761],\n         [-0.05492818],\n         [-0.02972945],\n         [ 0.01547472],\n         [ 0.01795328],\n         [ 0.07521172],\n         [-0.00142259],\n         [-0.02028974],\n         [ 0.05948153],\n         [ 0.06484537],\n         [-0.0812482 ],\n         [ 0.06278796],\n         [ 0.06614925],\n         [-0.06125926],\n         [-0.08631949],\n         [ 0.00303072]],\n\n        [[-0.00266889],\n         [ 0.08065954],\n         [-0.04317368],\n         [ 0.0442248 ],\n         [-0.03473748],\n         [-0.01913017],\n         [ 0.06842253],\n         [-0.00265791],\n         [ 0.05259986],\n         [-0.00095547],\n         [ 0.06180498],\n         [-0.08946654],\n         [ 0.08469266],\n         [-0.0693448 ],\n         [ 0.03283013],\n         [ 0.00894292],\n         [ 0.08305295],\n         [ 0.02657752],\n         [ 0.06467365],\n         [ 0.02476718],\n         [-0.0036898 ],\n         [ 0.03831585],\n         [-0.05206412],\n         [ 0.08993454],\n         [ 0.05236973],\n         [-0.0387344 ],\n         [-0.03027005],\n         [ 0.02459002],\n         [ 0.00051364],\n         [ 0.07413289],\n         [-0.00449672],\n         [ 0.08163607],\n         [ 0.04305558],\n         [ 0.01502527],\n         [-0.06636741],\n         [ 0.01509394],\n         [ 0.05712076],\n         [-0.08372039],\n         [-0.0810435 ],\n         [ 0.07587318],\n         [-0.05791973],\n         [-0.00268707],\n         [-0.08797746],\n         [ 0.03167923],\n         [ 0.03817368],\n         [-0.0076912 ],\n         [-0.0421892 ],\n         [ 0.07932676],\n         [-0.02824998],\n         [-0.00691365],\n         [-0.03368426],\n         [-0.05339067],\n         [-0.05721544],\n         [-0.04501102],\n         [ 0.01614258],\n         [ 0.03812931],\n         [ 0.0330843 ],\n         [ 0.05067943],\n         [ 0.00049805],\n         [-0.06293675],\n         [-0.02410887],\n         [ 0.07818595],\n         [-0.08515929],\n         [-0.07787246],\n         [-0.08551484],\n         [ 0.04034814],\n         [ 0.07823198],\n         [-0.03642376],\n         [ 0.08446436],\n         [ 0.05211797],\n         [-0.02316309],\n         [-0.04471039],\n         [-0.06390339],\n         [-0.08627055],\n         [-0.06609765],\n         [ 0.06933999],\n         [-0.02983825],\n         [ 0.07841526],\n         [-0.00213304],\n         [ 0.06222995]],\n\n        [[-0.03588343],\n         [ 0.03703536],\n         [-0.00444068],\n         [ 0.03706549],\n         [ 0.00963035],\n         [-0.04150868],\n         [ 0.02572786],\n         [-0.01584096],\n         [ 0.01269603],\n         [ 0.02560978],\n         [ 0.06326759],\n         [-0.00191157],\n         [ 0.0634764 ],\n         [ 0.00415725],\n         [ 0.0539695 ],\n         [-0.02289873],\n         [ 0.08630808],\n         [ 0.06478935],\n         [ 0.060959  ],\n         [-0.06802785],\n         [-0.07226115],\n         [ 0.00746965],\n         [-0.01279968],\n         [ 0.00385953],\n         [-0.02551024],\n         [ 0.01889488],\n         [-0.02910643],\n         [-0.08493765],\n         [-0.02938167],\n         [ 0.01749137],\n         [ 0.05749936],\n         [ 0.06803107],\n         [-0.03659533],\n         [ 0.03387409],\n         [ 0.05340947],\n         [-0.03732654],\n         [ 0.04502469],\n         [-0.01601503],\n         [-0.00757568],\n         [ 0.03061714],\n         [-0.03595238],\n         [-0.06391613],\n         [ 0.01188499],\n         [-0.00677743],\n         [-0.02018975],\n         [-0.00623009],\n         [ 0.05532146],\n         [ 0.07544403],\n         [-0.05821245],\n         [ 0.05636743],\n         [-0.05188254],\n         [ 0.08644456],\n         [-0.05895536],\n         [ 0.0145921 ],\n         [-0.04498322],\n         [ 0.00558998],\n         [ 0.06568819],\n         [ 0.05248705],\n         [-0.05197334],\n         [ 0.01833608],\n         [-0.05774587],\n         [-0.03460502],\n         [ 0.04242615],\n         [ 0.08387536],\n         [-0.01924414],\n         [-0.00437728],\n         [-0.07669821],\n         [-0.05113975],\n         [-0.05438313],\n         [ 0.05110666],\n         [ 0.07018316],\n         [ 0.02231926],\n         [ 0.00381547],\n         [-0.0223685 ],\n         [ 0.03747644],\n         [ 0.03459541],\n         [-0.04563073],\n         [ 0.0736798 ],\n         [ 0.03316008],\n         [-0.01813395]]],\n\n\n       [[[-0.02423878],\n         [ 0.07797226],\n         [ 0.03807068],\n         [-0.00631899],\n         [-0.00876914],\n         [-0.04925011],\n         [ 0.00236251],\n         [-0.06933993],\n         [ 0.03974116],\n         [ 0.0631649 ],\n         [-0.03801271],\n         [ 0.08618852],\n         [ 0.07530051],\n         [-0.05619071],\n         [-0.03838229],\n         [ 0.08453862],\n         [-0.01077602],\n         [ 0.00805382],\n         [-0.00778618],\n         [-0.07304459],\n         [-0.06350236],\n         [ 0.07296205],\n         [ 0.05610761],\n         [-0.05298892],\n         [-0.01056236],\n         [ 0.05716655],\n         [-0.02405711],\n         [-0.04933511],\n         [ 0.00080677],\n         [-0.05880363],\n         [ 0.00881442],\n         [ 0.05351634],\n         [ 0.08383499],\n         [-0.0343006 ],\n         [-0.05330446],\n         [ 0.07195105],\n         [-0.0642347 ],\n         [-0.0041671 ],\n         [ 0.0244135 ],\n         [-0.08328581],\n         [ 0.06141348],\n         [-0.06520589],\n         [ 0.08840807],\n         [ 0.00100643],\n         [ 0.02748553],\n         [-0.03759426],\n         [-0.01107072],\n         [ 0.0114359 ],\n         [ 0.00114785],\n         [-0.08934857],\n         [ 0.04356533],\n         [ 0.00132091],\n         [-0.04682833],\n         [-0.033108  ],\n         [-0.03509461],\n         [-0.03491593],\n         [ 0.05675182],\n         [ 0.07475892],\n         [-0.01360677],\n         [ 0.07503277],\n         [ 0.02173384],\n         [-0.03374   ],\n         [ 0.01120178],\n         [-0.04248057],\n         [ 0.08882083],\n         [-0.01205386],\n         [ 0.00249625],\n         [-0.03216157],\n         [ 0.00605943],\n         [ 0.04429269],\n         [-0.07407198],\n         [-0.04262311],\n         [ 0.03181848],\n         [-0.00508138],\n         [ 0.06243475],\n         [-0.06759265],\n         [-0.02038645],\n         [-0.04766614],\n         [-0.05789425],\n         [ 0.03875859]],\n\n        [[-0.05498375],\n         [ 0.07196572],\n         [-0.03352485],\n         [ 0.05193637],\n         [ 0.08970053],\n         [ 0.03560111],\n         [ 0.08372411],\n         [ 0.0727316 ],\n         [ 0.05939794],\n         [-0.08119646],\n         [-0.0663714 ],\n         [ 0.08519144],\n         [-0.08296606],\n         [-0.02253439],\n         [-0.07285725],\n         [-0.02640917],\n         [ 0.08806486],\n         [-0.08965061],\n         [ 0.01921749],\n         [-0.03408625],\n         [ 0.06478612],\n         [-0.08946513],\n         [ 0.00086991],\n         [-0.01710597],\n         [ 0.04944408],\n         [-0.03569393],\n         [ 0.08852285],\n         [-0.02689541],\n         [ 0.05829068],\n         [-0.02087124],\n         [-0.079473  ],\n         [ 0.0412841 ],\n         [-0.00937908],\n         [-0.05664892],\n         [ 0.09037028],\n         [-0.00119993],\n         [ 0.03810446],\n         [ 0.06485112],\n         [ 0.02597673],\n         [-0.07480225],\n         [ 0.03263115],\n         [ 0.06719066],\n         [ 0.03863017],\n         [-0.0874357 ],\n         [ 0.06974791],\n         [ 0.04161599],\n         [ 0.05079345],\n         [-0.06709854],\n         [-0.0559641 ],\n         [ 0.00122615],\n         [-0.08903044],\n         [-0.00087019],\n         [ 0.08381924],\n         [ 0.00430283],\n         [-0.01478854],\n         [ 0.03676821],\n         [ 0.00955837],\n         [ 0.09017073],\n         [-0.04440818],\n         [-0.08323701],\n         [ 0.06960882],\n         [-0.01692379],\n         [ 0.01286794],\n         [ 0.0579643 ],\n         [-0.0024348 ],\n         [ 0.02280697],\n         [ 0.00862096],\n         [ 0.02688994],\n         [ 0.02745242],\n         [-0.00347713],\n         [-0.01137786],\n         [ 0.04120582],\n         [ 0.07254343],\n         [-0.01458654],\n         [ 0.03719547],\n         [-0.01093223],\n         [-0.07239213],\n         [ 0.0102988 ],\n         [-0.07117034],\n         [-0.07215825]],\n\n        [[ 0.06401111],\n         [ 0.03959036],\n         [ 0.05608577],\n         [ 0.04146512],\n         [ 0.03233084],\n         [ 0.0883051 ],\n         [ 0.02049804],\n         [ 0.0679214 ],\n         [-0.02757848],\n         [-0.02697765],\n         [ 0.03461236],\n         [-0.05619473],\n         [-0.04930007],\n         [ 0.00036307],\n         [ 0.03059166],\n         [-0.07037257],\n         [-0.05837158],\n         [ 0.02039538],\n         [-0.05001729],\n         [-0.01006038],\n         [ 0.01551396],\n         [-0.03320389],\n         [ 0.08062479],\n         [ 0.02198747],\n         [-0.08660924],\n         [ 0.08359334],\n         [ 0.0221254 ],\n         [ 0.0420687 ],\n         [-0.01767944],\n         [-0.04771078],\n         [-0.05976676],\n         [-0.01163623],\n         [-0.03774322],\n         [-0.07739663],\n         [ 0.05385284],\n         [-0.07637759],\n         [ 0.03350002],\n         [-0.00863411],\n         [ 0.08102506],\n         [-0.03638881],\n         [ 0.06339975],\n         [ 0.04734057],\n         [ 0.08683293],\n         [-0.00292556],\n         [ 0.05364266],\n         [-0.0047215 ],\n         [-0.01581299],\n         [-0.05688905],\n         [ 0.04153381],\n         [ 0.04032065],\n         [ 0.04003891],\n         [-0.07048607],\n         [-0.05761322],\n         [-0.08222716],\n         [-0.0249026 ],\n         [-0.08375267],\n         [-0.02189976],\n         [-0.08946429],\n         [-0.02234875],\n         [ 0.01131012],\n         [ 0.05345422],\n         [ 0.08069211],\n         [-0.08599442],\n         [-0.06281762],\n         [-0.04166894],\n         [ 0.03026291],\n         [-0.03565991],\n         [ 0.00847517],\n         [-0.05613817],\n         [-0.0522868 ],\n         [ 0.07152873],\n         [-0.06991398],\n         [ 0.02356897],\n         [-0.05245274],\n         [-0.0902288 ],\n         [-0.04701141],\n         [-0.0849292 ],\n         [-0.082191  ],\n         [ 0.05579554],\n         [ 0.03321183]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_365/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.03762719],\n         [-0.06765648],\n         [-0.02261388],\n         ...,\n         [ 0.02738792],\n         [-0.00503846],\n         [ 0.01876736]],\n\n        [[-0.05111894],\n         [-0.0380067 ],\n         [-0.03986791],\n         ...,\n         [ 0.0012834 ],\n         [-0.07362705],\n         [ 0.06896204]],\n\n        [[-0.06999747],\n         [ 0.0544914 ],\n         [-0.04789488],\n         ...,\n         [-0.00994051],\n         [-0.00434703],\n         [-0.05593389]]],\n\n\n       [[[-0.0667069 ],\n         [ 0.04695951],\n         [ 0.05050121],\n         ...,\n         [-0.0364014 ],\n         [ 0.0445068 ],\n         [ 0.01760181]],\n\n        [[-0.009887  ],\n         [ 0.04765859],\n         [-0.06164052],\n         ...,\n         [-0.00143437],\n         [-0.04872097],\n         [-0.07529665]],\n\n        [[-0.01585843],\n         [ 0.04813932],\n         [-0.02708377],\n         ...,\n         [ 0.06668133],\n         [-0.04745383],\n         [-0.00772466]]],\n\n\n       [[[-0.06773119],\n         [-0.00132074],\n         [-0.04974524],\n         ...,\n         [ 0.05137196],\n         [ 0.04442416],\n         [ 0.04990995]],\n\n        [[-0.03002636],\n         [ 0.05004986],\n         [ 0.04871169],\n         ...,\n         [ 0.0603417 ],\n         [-0.05783801],\n         [-0.06110721]],\n\n        [[ 0.0551278 ],\n         [-0.02551181],\n         [-0.05651419],\n         ...,\n         [ 0.03303595],\n         [-0.04500189],\n         [-0.0156684 ]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_3/bias:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.01658905, -0.12280189,  0.06993378, ..., -0.05392851,\n          -0.18978202,  0.10081572],\n         [-0.15168327,  0.19776334,  0.02604588, ..., -0.15478946,\n           0.18204238,  0.04901138],\n         [ 0.08388478,  0.14212546, -0.09431023, ...,  0.09118468,\n          -0.09930729, -0.15872936],\n         ...,\n         [-0.08831567,  0.16264564, -0.16311279, ..., -0.14829364,\n           0.14444685, -0.08092939],\n         [ 0.12456746, -0.14399062,  0.03143291, ..., -0.13659625,\n          -0.01475079, -0.04189293],\n         [ 0.08818238,  0.08747164, -0.20623776, ...,  0.05156706,\n          -0.04760793, -0.08368319]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00488612,  0.06367554, -0.04758362, ..., -0.06799134,\n          -0.07085303, -0.01728459],\n         [-0.04960776, -0.00126126, -0.00250457, ..., -0.03316573,\n          -0.01437286,  0.03525544],\n         [ 0.03727841,  0.00344019,  0.0149868 , ...,  0.00034829,\n          -0.03347583,  0.0214332 ],\n         ...,\n         [ 0.03459127,  0.00861935, -0.02618259, ...,  0.01970274,\n           0.04708534, -0.02193658],\n         [-0.08417591, -0.04112738,  0.02865127, ...,  0.03760048,\n          -0.01352026,  0.03545061],\n         [-0.04757636, -0.01101664,  0.07599798, ..., -0.02374493,\n           0.03344459, -0.03833356]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 1, 48) dtype=float32, numpy=\narray([[[[ 0.7404909 ,  0.56219536,  0.24308355,  1.5340345 ,\n          -0.01874331, -0.03071641,  1.1585215 , -0.38498497,\n          -1.4970548 ,  0.56059647, -0.31612855,  0.75669056,\n           1.7689947 ,  0.8327923 , -1.1946516 , -1.0904458 ,\n          -1.410809  ,  0.3714936 ,  0.22209634,  2.143168  ,\n          -0.88328695, -1.1126337 ,  0.65773   ,  0.2261296 ,\n          -0.04583891,  0.761963  ,  0.13926555, -0.21019983,\n           2.1661325 ,  1.0278002 , -0.61582106,  0.10402781,\n          -0.3814819 , -1.9717189 , -0.13954045,  1.0542117 ,\n          -1.7299129 ,  0.5243758 ,  0.24475217,  0.8119778 ,\n          -1.2099042 ,  1.2681862 , -0.5052424 , -0.05570395,\n          -0.5492941 ,  1.7826109 ,  1.6415349 ,  1.2810686 ]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.03906785, -0.02342352,  0.01477214, ..., -0.02024208,\n          -0.08442139,  0.02677416],\n         [-0.06315084,  0.02019881,  0.02644959, ...,  0.02682174,\n           0.07651258,  0.05560122],\n         [-0.04194982,  0.04132916, -0.02152626, ..., -0.00141184,\n          -0.03437819,  0.01942666],\n         ...,\n         [ 0.02105216, -0.08037941, -0.05350014, ...,  0.07565188,\n          -0.00267469,  0.00558348],\n         [-0.01411896,  0.02114264,  0.03964148, ...,  0.00572557,\n           0.04597827,  0.01819152],\n         [ 0.0159985 , -0.08654074, -0.00345057, ..., -0.02308543,\n          -0.03023461, -0.02956009]]]], dtype=float32)>, <tf.Variable 'conv2d_862/kernel:0' shape=(1, 1, 40, 40) dtype=float32, numpy=\narray([[[[-0.19510962, -0.16538887,  0.14235024, ..., -0.17945194,\n          -0.12381437, -0.1320807 ],\n         [-0.24394798,  0.09417666,  0.18778458, ...,  0.07669416,\n           0.03160644,  0.11128829],\n         [-0.09943087, -0.0457889 , -0.088308  , ...,  0.22536829,\n          -0.3144904 ,  0.280321  ],\n         ...,\n         [ 0.2967983 ,  0.0040529 ,  0.27416223, ..., -0.26558125,\n           0.06644094, -0.01057662],\n         [ 0.01293906, -0.05595003, -0.25726846, ...,  0.04517451,\n          -0.10223775,  0.07583397],\n         [-0.05328713, -0.30322883,  0.04000769, ..., -0.16328062,\n          -0.04939308,  0.14867821]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_372/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-0.02096654],\n         [-0.02547816],\n         [ 0.03509732],\n         [ 0.06326845],\n         [ 0.0393284 ],\n         [ 0.03448409],\n         [ 0.04049325],\n         [-0.07527789],\n         [ 0.07047138],\n         [-0.04551506],\n         [-0.07745431],\n         [-0.05530279],\n         [ 0.08874471],\n         [-0.08881976],\n         [ 0.05326498],\n         [-0.08357954],\n         [-0.03307954],\n         [-0.0772261 ],\n         [ 0.00345832],\n         [ 0.06620777],\n         [-0.06195031],\n         [-0.02191382],\n         [ 0.01365224],\n         [-0.04145774],\n         [ 0.02637491],\n         [-0.00359432],\n         [ 0.00557709],\n         [-0.0500715 ],\n         [-0.02922494],\n         [ 0.0898051 ],\n         [-0.00905362],\n         [-0.04852683],\n         [-0.08758183],\n         [ 0.04163501],\n         [-0.03487174],\n         [-0.00260518],\n         [-0.06572375],\n         [-0.04844665],\n         [-0.04085516],\n         [-0.04487728],\n         [ 0.06034635],\n         [ 0.07380494],\n         [ 0.0814725 ],\n         [ 0.07182264],\n         [ 0.0285807 ],\n         [ 0.05810456],\n         [ 0.06730178],\n         [-0.0727153 ],\n         [ 0.00653466],\n         [-0.01358891],\n         [ 0.04964857],\n         [-0.01387385],\n         [-0.02348863],\n         [ 0.08659266],\n         [-0.03473441],\n         [ 0.09040332],\n         [-0.08477879],\n         [ 0.0029147 ],\n         [ 0.04467465],\n         [ 0.00861053],\n         [-0.08372515],\n         [ 0.01247564],\n         [-0.05152121],\n         [-0.06418285],\n         [-0.03387835],\n         [-0.0171935 ],\n         [ 0.05519977],\n         [-0.04485174],\n         [-0.02811518],\n         [ 0.01969028],\n         [ 0.0749996 ],\n         [-0.0471326 ],\n         [-0.08250969],\n         [-0.08820126],\n         [ 0.00250097],\n         [-0.07256934],\n         [-0.02964795],\n         [ 0.00526609],\n         [-0.0187603 ],\n         [-0.07818399]],\n\n        [[ 0.06431007],\n         [ 0.07228655],\n         [ 0.02512307],\n         [-0.01005116],\n         [ 0.05289756],\n         [ 0.02921235],\n         [-0.01132569],\n         [ 0.04374647],\n         [ 0.05426705],\n         [ 0.06336267],\n         [ 0.06573857],\n         [ 0.03915541],\n         [-0.02891217],\n         [-0.02074149],\n         [ 0.03495865],\n         [-0.055798  ],\n         [-0.02522174],\n         [ 0.0885333 ],\n         [-0.00988602],\n         [-0.04804669],\n         [ 0.07968669],\n         [ 0.07780275],\n         [ 0.06833668],\n         [-0.07959592],\n         [-0.04030773],\n         [ 0.0243078 ],\n         [ 0.08121514],\n         [ 0.02996377],\n         [-0.0576778 ],\n         [ 0.02315063],\n         [ 0.04265656],\n         [ 0.03457145],\n         [-0.0740831 ],\n         [-0.01404648],\n         [ 0.07089727],\n         [-0.02502487],\n         [ 0.08088446],\n         [ 0.06121987],\n         [-0.02627725],\n         [-0.0021539 ],\n         [ 0.05019344],\n         [ 0.02420393],\n         [ 0.08350724],\n         [-0.02342896],\n         [-0.06920002],\n         [ 0.04321969],\n         [ 0.03726254],\n         [-0.04965411],\n         [-0.04356582],\n         [-0.01503351],\n         [ 0.07028621],\n         [-0.06220014],\n         [-0.03167886],\n         [ 0.0043587 ],\n         [-0.07585778],\n         [-0.07803332],\n         [ 0.00506148],\n         [-0.07069439],\n         [ 0.06257975],\n         [-0.06323914],\n         [-0.03800369],\n         [-0.04511073],\n         [-0.04219692],\n         [ 0.01318298],\n         [-0.05358534],\n         [-0.00687379],\n         [-0.04812525],\n         [-0.0050878 ],\n         [ 0.0558354 ],\n         [-0.0167324 ],\n         [-0.00727517],\n         [ 0.06534432],\n         [ 0.00827575],\n         [ 0.0012537 ],\n         [ 0.03155179],\n         [ 0.05589311],\n         [ 0.02829975],\n         [-0.00814244],\n         [-0.00882728],\n         [ 0.08118433]],\n\n        [[ 0.07054847],\n         [ 0.00830815],\n         [-0.0385762 ],\n         [-0.04134419],\n         [-0.07180704],\n         [-0.02081232],\n         [ 0.00679471],\n         [-0.08325174],\n         [ 0.07125555],\n         [-0.00252822],\n         [ 0.03736442],\n         [ 0.06800468],\n         [ 0.07556258],\n         [ 0.01287532],\n         [-0.06845068],\n         [-0.02446204],\n         [-0.02766052],\n         [-0.04308201],\n         [-0.07743364],\n         [-0.02089339],\n         [ 0.04340079],\n         [ 0.08427325],\n         [-0.01094282],\n         [-0.01732856],\n         [-0.0266362 ],\n         [ 0.02797913],\n         [ 0.02802241],\n         [-0.00537102],\n         [-0.01126546],\n         [-0.06643727],\n         [-0.07618685],\n         [-0.01291888],\n         [ 0.05291091],\n         [ 0.03193665],\n         [ 0.03889868],\n         [ 0.034234  ],\n         [-0.00200162],\n         [-0.06482662],\n         [-0.00074173],\n         [-0.01714577],\n         [ 0.04356186],\n         [ 0.01707554],\n         [ 0.06558362],\n         [ 0.00342774],\n         [ 0.05005808],\n         [ 0.00829026],\n         [ 0.0889975 ],\n         [ 0.03153249],\n         [-0.0849438 ],\n         [-0.01617397],\n         [-0.0602076 ],\n         [ 0.07014669],\n         [-0.00766092],\n         [ 0.05153817],\n         [-0.01343189],\n         [ 0.04047537],\n         [ 0.01964018],\n         [ 0.0234865 ],\n         [-0.02720028],\n         [-0.06740729],\n         [ 0.03372145],\n         [ 0.01607075],\n         [-0.08212923],\n         [-0.02866038],\n         [ 0.0323332 ],\n         [-0.03841993],\n         [ 0.06774609],\n         [ 0.00707575],\n         [-0.07641453],\n         [ 0.06000093],\n         [-0.0716135 ],\n         [-0.04864374],\n         [ 0.03839293],\n         [ 0.03807189],\n         [ 0.05814312],\n         [ 0.05412212],\n         [-0.07561401],\n         [-0.00487048],\n         [ 0.07688969],\n         [-0.05863472]]],\n\n\n       [[[ 0.04850857],\n         [ 0.02203775],\n         [ 0.04419391],\n         [-0.00668416],\n         [-0.02577306],\n         [-0.07440465],\n         [ 0.06067465],\n         [-0.03396897],\n         [-0.01490155],\n         [ 0.07188052],\n         [ 0.08106525],\n         [ 0.06434801],\n         [ 0.03524522],\n         [-0.0673974 ],\n         [-0.04316286],\n         [-0.00947765],\n         [ 0.08046174],\n         [-0.02729768],\n         [ 0.06662819],\n         [ 0.02045504],\n         [-0.00288857],\n         [ 0.00769909],\n         [-0.02376673],\n         [ 0.01445522],\n         [-0.04328479],\n         [ 0.01443664],\n         [ 0.06879218],\n         [-0.044843  ],\n         [ 0.00973234],\n         [ 0.02714926],\n         [ 0.04129244],\n         [ 0.03168998],\n         [-0.0696326 ],\n         [-0.01254229],\n         [ 0.04176594],\n         [-0.08683859],\n         [ 0.01200939],\n         [-0.01619533],\n         [-0.07919255],\n         [ 0.08684473],\n         [-0.01949383],\n         [ 0.03971623],\n         [ 0.08568107],\n         [ 0.01009412],\n         [ 0.04217716],\n         [-0.05140586],\n         [ 0.02875973],\n         [-0.02235552],\n         [ 0.05854645],\n         [ 0.06855178],\n         [-0.08368503],\n         [ 0.04721566],\n         [ 0.02016442],\n         [ 0.05235235],\n         [ 0.01004143],\n         [-0.07818023],\n         [-0.03980791],\n         [-0.0514512 ],\n         [-0.01222701],\n         [ 0.05692902],\n         [-0.07067318],\n         [-0.05907113],\n         [ 0.06455272],\n         [ 0.07511957],\n         [-0.04286997],\n         [-0.01924863],\n         [-0.07477586],\n         [-0.08313925],\n         [-0.0453638 ],\n         [-0.00010519],\n         [ 0.08581428],\n         [-0.08763608],\n         [ 0.0280812 ],\n         [-0.01684594],\n         [ 0.01621846],\n         [-0.02964123],\n         [-0.02716133],\n         [-0.05479414],\n         [-0.08460036],\n         [ 0.06485201]],\n\n        [[-0.07736278],\n         [ 0.01318901],\n         [-0.03002301],\n         [-0.0712563 ],\n         [ 0.06034116],\n         [ 0.0679622 ],\n         [-0.06382375],\n         [-0.07024846],\n         [-0.01885255],\n         [ 0.01565122],\n         [ 0.00839986],\n         [-0.05467996],\n         [ 0.06287131],\n         [-0.05307075],\n         [ 0.06207609],\n         [ 0.00709554],\n         [ 0.05369076],\n         [ 0.00696643],\n         [ 0.00054736],\n         [ 0.0574246 ],\n         [-0.04762865],\n         [ 0.02696233],\n         [-0.00376503],\n         [ 0.08204199],\n         [-0.02301029],\n         [-0.08198426],\n         [ 0.00951628],\n         [ 0.07039967],\n         [-0.05864744],\n         [ 0.06031162],\n         [-0.07862911],\n         [ 0.05857252],\n         [ 0.04723008],\n         [-0.05667591],\n         [-0.05684832],\n         [ 0.08514482],\n         [-0.04490302],\n         [ 0.07813905],\n         [ 0.04722664],\n         [-0.01053872],\n         [-0.06755197],\n         [-0.02294171],\n         [ 0.06432956],\n         [-0.0584717 ],\n         [-0.05351225],\n         [ 0.00588548],\n         [ 0.00819024],\n         [-0.07040476],\n         [ 0.07272455],\n         [ 0.0853558 ],\n         [-0.03669061],\n         [ 0.08214718],\n         [ 0.0140751 ],\n         [-0.00635327],\n         [-0.08249711],\n         [-0.04269205],\n         [ 0.03815567],\n         [ 0.08456619],\n         [ 0.01322488],\n         [ 0.02199936],\n         [ 0.01221572],\n         [-0.0168642 ],\n         [ 0.01701418],\n         [ 0.06302094],\n         [-0.08851526],\n         [-0.02659078],\n         [-0.07666338],\n         [-0.07062167],\n         [ 0.08720551],\n         [-0.03129601],\n         [-0.07411682],\n         [-0.02010792],\n         [ 0.0631167 ],\n         [ 0.01662184],\n         [-0.02372219],\n         [ 0.04048118],\n         [ 0.05279231],\n         [-0.00056205],\n         [ 0.02111957],\n         [ 0.04961306]],\n\n        [[ 0.04272774],\n         [ 0.03872673],\n         [ 0.00847818],\n         [-0.04207746],\n         [ 0.01427913],\n         [-0.06165045],\n         [ 0.02240896],\n         [-0.01163524],\n         [ 0.0190302 ],\n         [ 0.0581426 ],\n         [-0.07772157],\n         [-0.07002407],\n         [ 0.05576298],\n         [-0.01095609],\n         [ 0.02564716],\n         [-0.03008649],\n         [ 0.09048761],\n         [-0.03314419],\n         [ 0.02270406],\n         [-0.05169334],\n         [-0.04535194],\n         [-0.05564004],\n         [ 0.07324217],\n         [-0.07798974],\n         [ 0.06658395],\n         [ 0.00336756],\n         [-0.08988246],\n         [ 0.00383535],\n         [ 0.03856547],\n         [-0.05642466],\n         [ 0.07420161],\n         [-0.01294432],\n         [ 0.01173199],\n         [ 0.07420632],\n         [ 0.01575688],\n         [ 0.04694052],\n         [ 0.06166641],\n         [ 0.06386191],\n         [-0.02226904],\n         [-0.02691157],\n         [-0.0608632 ],\n         [ 0.07331561],\n         [-0.04800973],\n         [ 0.0190645 ],\n         [ 0.06243269],\n         [-0.08690052],\n         [ 0.03989702],\n         [-0.06034084],\n         [ 0.06752492],\n         [-0.04753506],\n         [-0.07199165],\n         [ 0.0054161 ],\n         [-0.05494083],\n         [-0.02310949],\n         [ 0.00720659],\n         [ 0.03394851],\n         [-0.09058121],\n         [-0.01702127],\n         [ 0.05085547],\n         [-0.02146744],\n         [ 0.03785522],\n         [-0.06916741],\n         [ 0.05299692],\n         [ 0.05752492],\n         [-0.07440484],\n         [-0.04622466],\n         [ 0.08852999],\n         [-0.04687246],\n         [ 0.07057557],\n         [ 0.00758781],\n         [-0.06313586],\n         [ 0.00298789],\n         [-0.05139844],\n         [-0.04186741],\n         [-0.09011171],\n         [ 0.08500005],\n         [-0.00422204],\n         [ 0.01964055],\n         [-0.05992739],\n         [-0.07362959]]],\n\n\n       [[[-0.0062515 ],\n         [ 0.03474286],\n         [ 0.01174743],\n         [ 0.08167882],\n         [ 0.04475044],\n         [ 0.01691204],\n         [-0.00042626],\n         [-0.08080395],\n         [-0.00449761],\n         [ 0.05042101],\n         [ 0.03930181],\n         [ 0.05393337],\n         [ 0.0236554 ],\n         [-0.0594551 ],\n         [ 0.0058189 ],\n         [ 0.03097823],\n         [ 0.0351432 ],\n         [-0.06183808],\n         [ 0.07068662],\n         [-0.05167258],\n         [ 0.02138497],\n         [-0.06261645],\n         [-0.07179768],\n         [ 0.00119046],\n         [ 0.01810386],\n         [-0.03136839],\n         [ 0.04247981],\n         [-0.00523527],\n         [-0.04733096],\n         [ 0.0492879 ],\n         [ 0.07480505],\n         [ 0.00914552],\n         [ 0.00178145],\n         [ 0.02023649],\n         [-0.03202496],\n         [-0.00268254],\n         [ 0.03125943],\n         [-0.08076902],\n         [ 0.01169275],\n         [ 0.04592285],\n         [ 0.01564611],\n         [ 0.05736056],\n         [ 0.00931108],\n         [ 0.03982349],\n         [ 0.01883637],\n         [-0.04987151],\n         [-0.07901689],\n         [ 0.04290506],\n         [ 0.02868476],\n         [ 0.04719572],\n         [-0.08935738],\n         [ 0.0182775 ],\n         [-0.04729757],\n         [-0.04928945],\n         [-0.04509963],\n         [-0.01589107],\n         [ 0.02286912],\n         [-0.03424212],\n         [-0.0886785 ],\n         [ 0.06276941],\n         [ 0.08624864],\n         [-0.03248364],\n         [ 0.04134592],\n         [ 0.03096685],\n         [-0.05233287],\n         [-0.05949111],\n         [-0.03656288],\n         [ 0.0679131 ],\n         [ 0.03301822],\n         [-0.01287999],\n         [ 0.0664288 ],\n         [-0.02835791],\n         [ 0.05166601],\n         [-0.05069312],\n         [ 0.01608434],\n         [-0.00504393],\n         [ 0.00861233],\n         [-0.0582039 ],\n         [-0.07204382],\n         [ 0.02024458]],\n\n        [[-0.03332053],\n         [-0.0498862 ],\n         [-0.01286675],\n         [ 0.0606083 ],\n         [-0.01025366],\n         [-0.02086185],\n         [-0.06344114],\n         [-0.00023273],\n         [ 0.00954063],\n         [ 0.03457113],\n         [ 0.0004515 ],\n         [-0.04351625],\n         [-0.05198389],\n         [ 0.03092482],\n         [-0.01831917],\n         [-0.08659815],\n         [-0.06976967],\n         [ 0.06121641],\n         [-0.02770391],\n         [-0.05290783],\n         [ 0.01199514],\n         [-0.07603378],\n         [ 0.06242003],\n         [ 0.06310914],\n         [-0.00913354],\n         [ 0.06520289],\n         [ 0.04426734],\n         [-0.06369752],\n         [ 0.06571062],\n         [-0.03191136],\n         [ 0.02299182],\n         [-0.06278758],\n         [ 0.0409327 ],\n         [-0.05916394],\n         [ 0.02686253],\n         [-0.07142431],\n         [ 0.05351509],\n         [ 0.06665725],\n         [-0.08794644],\n         [ 0.08660285],\n         [ 0.03098182],\n         [-0.01195344],\n         [-0.03311287],\n         [ 0.08753082],\n         [ 0.01920377],\n         [-0.04319152],\n         [ 0.08595058],\n         [-0.01667638],\n         [ 0.06866242],\n         [-0.01192815],\n         [-0.08085451],\n         [-0.08900438],\n         [-0.01570557],\n         [-0.04753069],\n         [-0.07312791],\n         [-0.02153127],\n         [ 0.07214935],\n         [-0.01009358],\n         [ 0.00813048],\n         [ 0.06353097],\n         [ 0.04110953],\n         [-0.07320973],\n         [ 0.06237932],\n         [-0.0593524 ],\n         [-0.07025456],\n         [-0.00795604],\n         [ 0.02796981],\n         [ 0.08574452],\n         [ 0.01168211],\n         [ 0.0512486 ],\n         [ 0.04082133],\n         [ 0.08767207],\n         [-0.00188918],\n         [-0.07039621],\n         [-0.03926001],\n         [ 0.02959237],\n         [ 0.06672755],\n         [ 0.02896553],\n         [-0.07579302],\n         [-0.01049784]],\n\n        [[-0.07273716],\n         [ 0.06591006],\n         [ 0.00800654],\n         [-0.05422733],\n         [-0.01153228],\n         [ 0.06819281],\n         [ 0.06602897],\n         [ 0.0622512 ],\n         [-0.08522092],\n         [ 0.01258803],\n         [ 0.0095508 ],\n         [-0.02406327],\n         [-0.04981043],\n         [-0.0350302 ],\n         [ 0.08601013],\n         [ 0.07214412],\n         [-0.00754087],\n         [-0.05119726],\n         [ 0.04609433],\n         [ 0.02311423],\n         [-0.00165007],\n         [ 0.00159662],\n         [ 0.06075557],\n         [ 0.05827439],\n         [ 0.02302987],\n         [ 0.04253817],\n         [-0.01996729],\n         [-0.06868111],\n         [ 0.00878448],\n         [-0.06505431],\n         [-0.02599338],\n         [-0.02824178],\n         [ 0.01245533],\n         [-0.07461295],\n         [ 0.06277986],\n         [ 0.01913171],\n         [-0.02882453],\n         [ 0.04946046],\n         [ 0.07505882],\n         [-0.00213103],\n         [-0.05891795],\n         [-0.02074005],\n         [-0.00479999],\n         [-0.01341091],\n         [ 0.00064433],\n         [ 0.03066996],\n         [-0.04250038],\n         [ 0.07513709],\n         [ 0.00231966],\n         [-0.00559731],\n         [ 0.05141008],\n         [ 0.06028374],\n         [ 0.00111569],\n         [-0.08384176],\n         [ 0.01780206],\n         [-0.02295153],\n         [ 0.0600017 ],\n         [ 0.02266887],\n         [ 0.08067097],\n         [ 0.04385988],\n         [-0.0791125 ],\n         [-0.02357834],\n         [ 0.02407928],\n         [ 0.02520991],\n         [-0.08086591],\n         [-0.0603639 ],\n         [-0.0001128 ],\n         [ 0.061561  ],\n         [-0.03594918],\n         [ 0.06227112],\n         [-0.073638  ],\n         [-0.06218227],\n         [-0.02507477],\n         [-0.03840838],\n         [-0.04152884],\n         [-0.0708226 ],\n         [ 0.0044569 ],\n         [ 0.00351981],\n         [ 0.01712857],\n         [ 0.00354194]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/conv2d_1/kernel:0' shape=(1, 1, 240, 40) dtype=float32, numpy=\narray([[[[ 0.01438806,  0.02846583,  0.03476854, ..., -0.05134127,\n          -0.00119067, -0.03940116],\n         [ 0.02367445, -0.00663239,  0.09057099, ..., -0.0290843 ,\n           0.04782839, -0.07087374],\n         [-0.06886516, -0.0309397 , -0.08667625, ...,  0.00630784,\n          -0.04906496, -0.05037435],\n         ...,\n         [ 0.00997867, -0.02894117,  0.03224835, ...,  0.09210732,\n           0.02721596,  0.03571135],\n         [-0.01300522,  0.03496785, -0.01647761, ...,  0.08279741,\n           0.05215232,  0.04317404],\n         [-0.04642149, -0.0134203 ,  0.00789236, ..., -0.01071561,\n          -0.12139538, -0.03617502]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 96, 3) dtype=float32, numpy=\narray([[[[ 0.11529394, -0.19005272, -0.0508256 ],\n         [ 0.03163886,  0.13168557, -0.00281219],\n         [-0.06332602,  0.00349325, -0.09027126],\n         [-0.11583229,  0.03068131, -0.09671286],\n         [ 0.01713523, -0.10236929,  0.00656186],\n         [ 0.03792822, -0.21867377, -0.03729205],\n         [-0.09240668,  0.16166528, -0.00741112],\n         [ 0.19743049, -0.07242645, -0.207678  ],\n         [ 0.08487293, -0.02394649, -0.13200416],\n         [-0.00217033,  0.11171449, -0.134627  ],\n         [-0.09199473, -0.01641611, -0.05235366],\n         [ 0.01612227,  0.14549679, -0.0782339 ],\n         [-0.01841922,  0.20265526,  0.08458619],\n         [ 0.00484755, -0.15645751,  0.10473868],\n         [ 0.2044313 , -0.05438804,  0.08869832],\n         [-0.05763805,  0.06748469,  0.11423801],\n         [-0.06871525, -0.07132325, -0.13318641],\n         [ 0.21165773, -0.13578555,  0.00436173],\n         [ 0.03225271,  0.02998055, -0.11970099],\n         [-0.01457217, -0.12858051,  0.15676174],\n         [-0.06801501, -0.05626246,  0.1064138 ],\n         [-0.02120746,  0.06891645, -0.13885655],\n         [ 0.03473346, -0.18376318,  0.17463565],\n         [-0.06669161, -0.02821924,  0.07074515],\n         [-0.01802624, -0.11316969,  0.04556481],\n         [ 0.08352954,  0.03605136,  0.06170407],\n         [ 0.22505811,  0.06777298,  0.02074965],\n         [ 0.13030323, -0.18489185, -0.1459201 ],\n         [ 0.07177866, -0.04642604, -0.08602448],\n         [ 0.15876503, -0.00288589, -0.12091316],\n         [-0.09716125,  0.02570831, -0.05773596],\n         [ 0.13099746,  0.0174762 ,  0.02090186],\n         [ 0.02569453,  0.10116073,  0.12606859],\n         [ 0.14799334, -0.04428425, -0.0299858 ],\n         [-0.00562453,  0.11004401,  0.04876237],\n         [-0.12355031, -0.04137211,  0.00679932],\n         [-0.04719581,  0.04032993,  0.09906475],\n         [-0.09093335, -0.06382361,  0.04801764],\n         [ 0.16567501,  0.15825084, -0.05367768],\n         [-0.06483374, -0.05370474,  0.16459854],\n         [-0.04581144, -0.12550072,  0.10000475],\n         [-0.22424969,  0.19402969, -0.14073494],\n         [-0.04884648, -0.02020836,  0.1690562 ],\n         [ 0.06800474, -0.02447421, -0.02108008],\n         [-0.15282641, -0.00806909, -0.16254027],\n         [ 0.13054381, -0.05311068,  0.06653474],\n         [ 0.09858686,  0.20441228,  0.09989334],\n         [-0.04832056, -0.0324885 , -0.07499489],\n         [ 0.07873917, -0.12648521,  0.18005635],\n         [-0.04743432, -0.12588121, -0.09545369],\n         [ 0.0620551 ,  0.16714595,  0.03524103],\n         [-0.21761918, -0.03781874,  0.09311558],\n         [-0.07509334,  0.10337938,  0.05343618],\n         [ 0.020741  , -0.19643253, -0.07543913],\n         [ 0.1292863 , -0.13318788, -0.18732238],\n         [-0.03109914, -0.13218158,  0.13313574],\n         [ 0.06065136, -0.02901631, -0.03300465],\n         [ 0.04551817, -0.14049213, -0.11217486],\n         [-0.03985168, -0.01866202, -0.09609877],\n         [-0.10795367, -0.00183532, -0.07843835],\n         [ 0.10915347, -0.22238018, -0.16731355],\n         [ 0.16228463, -0.03201063, -0.01124189],\n         [-0.22773112, -0.16727057, -0.01567834],\n         [ 0.09202851, -0.03911347,  0.1026272 ],\n         [ 0.04114765,  0.02586829, -0.1376714 ],\n         [ 0.01535225,  0.18614464,  0.12493788],\n         [ 0.16191313, -0.07244462, -0.06197708],\n         [ 0.10320779,  0.07394453, -0.00789879],\n         [-0.01669077, -0.03155337,  0.09156477],\n         [ 0.04016112,  0.12372853,  0.1186845 ],\n         [-0.09438157, -0.09895606,  0.15515584],\n         [ 0.0640391 ,  0.06324702, -0.02418188],\n         [ 0.07815089,  0.03623538, -0.03010223],\n         [ 0.12125967,  0.15153205, -0.11653645],\n         [-0.07477223, -0.09147738,  0.03494742],\n         [ 0.01182703,  0.04470154, -0.033239  ],\n         [-0.18172596,  0.05104116, -0.2216115 ],\n         [ 0.15422064,  0.00991805, -0.1068592 ],\n         [ 0.07886811, -0.05802445,  0.03625564],\n         [-0.00432214, -0.06377818,  0.05842673],\n         [ 0.03245283,  0.02960906, -0.057034  ],\n         [-0.03831642, -0.09886496,  0.03403155],\n         [ 0.0159633 , -0.1884281 , -0.00798337],\n         [-0.03626551,  0.19623046,  0.19226617],\n         [-0.03239216, -0.05791129,  0.11596882],\n         [ 0.1773036 ,  0.03097832, -0.10258909],\n         [ 0.09844261,  0.03721843, -0.00831135],\n         [-0.02457668, -0.01762347, -0.0895867 ],\n         [ 0.09396394, -0.0804811 , -0.0402191 ],\n         [ 0.02126515,  0.09419583, -0.0180923 ],\n         [-0.06845336, -0.14839421, -0.08184258],\n         [ 0.00049325,  0.00986448,  0.01962392],\n         [ 0.05054731, -0.03780394, -0.04168702],\n         [ 0.16093132,  0.05427512,  0.09034681],\n         [ 0.0429286 , -0.0364722 ,  0.07176609],\n         [ 0.06201656,  0.04505612, -0.08795362]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/gamma:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.33241183, -0.2937546 ,  0.12355585, ...,  0.14157043,\n           0.06237433,  0.06119965],\n         [ 0.034905  ,  0.24702272, -0.08934848, ..., -0.22721149,\n          -0.10181592,  0.1973533 ],\n         [ 0.3685421 ,  0.24084756, -0.08125844, ..., -0.01475347,\n          -0.10632188, -0.36566815],\n         ...,\n         [ 0.10422534, -0.05458917, -0.1429891 , ...,  0.16294065,\n           0.0011848 ,  0.30756503],\n         [ 0.2384754 ,  0.00590983,  0.1123225 , ..., -0.23149118,\n          -0.17707796, -0.2737518 ],\n         [ 0.09303021, -0.18381922,  0.15918882, ..., -0.15142928,\n          -0.2874099 ,  0.05408263]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/conv2d/kernel:0' shape=(1, 1, 24, 144) dtype=float32, numpy=\narray([[[[ 0.35420915,  0.33008838,  0.3452662 , ...,  0.09189732,\n           0.32536566, -0.38743702],\n         [-0.18711002,  0.02016944,  0.27389786, ...,  0.00159151,\n          -0.00897067,  0.11584048],\n         [-0.22335051, -0.02474017,  0.41295424, ..., -0.39313602,\n          -0.21290521, -0.01398367],\n         ...,\n         [ 0.19920877,  0.23788583, -0.03997458, ..., -0.29603207,\n          -0.39062157,  0.2418448 ],\n         [-0.21102329, -0.01531912,  0.22907123, ...,  0.4117674 ,\n           0.3190978 , -0.36316037],\n         [-0.1908387 , -0.03800815, -0.32998562, ...,  0.2722815 ,\n          -0.30189952,  0.08635671]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 0.06331954,  0.00464255,  0.03007113, ..., -0.03970123,\n          -0.02585186, -0.01899425],\n         [ 0.00808769, -0.0795731 , -0.00629658, ..., -0.01046361,\n           0.04152304, -0.01951132],\n         [ 0.01454671,  0.09601972, -0.05801756, ..., -0.02340194,\n          -0.03115106,  0.04263923],\n         ...,\n         [ 0.00617959, -0.01886612, -0.04562569, ...,  0.07635859,\n           0.03176695,  0.07576016],\n         [ 0.01468667,  0.06306709, -0.05764097, ..., -0.00786962,\n          -0.05968153,  0.02547954],\n         [ 0.06376211,  0.02800516, -0.06171629, ...,  0.04484987,\n           0.00100972, -0.09002233]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[-0.01325253, -0.04283201, -0.06701066, ...,  0.00467389,\n          -0.02764933, -0.01285624],\n         [ 0.03627107,  0.00053309, -0.04123317, ..., -0.08735143,\n           0.01636383,  0.05468501],\n         [ 0.05870382, -0.00233371, -0.00456893, ...,  0.05729785,\n          -0.01479678, -0.01113155],\n         ...,\n         [ 0.00172727, -0.03193495, -0.00605418, ..., -0.09622826,\n           0.00746031,  0.03231936],\n         [-0.00981625, -0.00311895, -0.08254976, ..., -0.01715622,\n          -0.01422589,  0.03671503],\n         [-0.01628164, -0.04157427, -0.01526071, ...,  0.01514443,\n           0.00383763, -0.03793835]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_364/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.04704373],\n         [ 0.06056309],\n         [ 0.0721183 ],\n         [ 0.07146786],\n         [-0.01066765],\n         [-0.05717065],\n         [-0.03548224],\n         [-0.01117734],\n         [ 0.00929771],\n         [ 0.05523381],\n         [ 0.05893397],\n         [ 0.06006593],\n         [-0.06935412],\n         [ 0.01807272],\n         [-0.04997905],\n         [-0.04595849],\n         [ 0.06593297],\n         [-0.01143034],\n         [ 0.00960699],\n         [-0.08872131],\n         [-0.07694896],\n         [-0.06761415],\n         [-0.05451826],\n         [-0.07269202],\n         [ 0.00442442],\n         [-0.00617701],\n         [-0.03519188],\n         [ 0.00674667],\n         [-0.02921127],\n         [-0.08567056],\n         [ 0.03856634],\n         [-0.01889458],\n         [ 0.0877116 ],\n         [-0.03431522],\n         [ 0.028903  ],\n         [ 0.01695264],\n         [-0.03465905],\n         [ 0.04877891],\n         [-0.07270178],\n         [ 0.02438835],\n         [-0.03839629],\n         [ 0.04967199],\n         [-0.02782054],\n         [ 0.07858919],\n         [ 0.02876765],\n         [-0.07893944],\n         [-0.08342307],\n         [ 0.05609974],\n         [-0.00348295],\n         [ 0.08561575],\n         [ 0.03603517],\n         [ 0.06384791],\n         [-0.09011113],\n         [-0.0869869 ],\n         [-0.06709722],\n         [ 0.02688683],\n         [ 0.00942452],\n         [ 0.08843242],\n         [-0.04515393],\n         [ 0.02329276],\n         [ 0.02487417],\n         [-0.05082238],\n         [ 0.02253887],\n         [ 0.04069966],\n         [ 0.02299331],\n         [ 0.02073387],\n         [ 0.02928872],\n         [-0.06194438],\n         [-0.02693171],\n         [ 0.05400972],\n         [ 0.00060933],\n         [-0.08929549],\n         [ 0.04714367],\n         [-0.03779688],\n         [ 0.00171898],\n         [ 0.0137905 ],\n         [ 0.05600916],\n         [ 0.05895206],\n         [ 0.02303309],\n         [ 0.0176959 ]],\n\n        [[ 0.0682705 ],\n         [-0.00150044],\n         [-0.03549493],\n         [-0.02570357],\n         [ 0.08493383],\n         [ 0.07543114],\n         [-0.01688013],\n         [ 0.03158963],\n         [ 0.08540107],\n         [-0.0404366 ],\n         [-0.04759567],\n         [ 0.04839514],\n         [-0.05346947],\n         [ 0.0433002 ],\n         [-0.02963716],\n         [ 0.00265802],\n         [ 0.02902811],\n         [-0.06198916],\n         [ 0.00034896],\n         [ 0.01594919],\n         [ 0.0362505 ],\n         [ 0.02899686],\n         [-0.02219407],\n         [-0.00951072],\n         [ 0.04514982],\n         [ 0.04951847],\n         [ 0.05662534],\n         [ 0.04164819],\n         [ 0.02749577],\n         [-0.05532193],\n         [-0.08609536],\n         [ 0.00078609],\n         [ 0.03850368],\n         [-0.01517564],\n         [ 0.07998393],\n         [ 0.01605327],\n         [-0.04524564],\n         [-0.04076847],\n         [-0.08834471],\n         [-0.00992285],\n         [ 0.0449373 ],\n         [ 0.06563301],\n         [ 0.01593654],\n         [ 0.0635106 ],\n         [-0.06022611],\n         [-0.00345239],\n         [-0.09034579],\n         [-0.07672048],\n         [-0.0238369 ],\n         [-0.05053338],\n         [ 0.04809389],\n         [ 0.08047256],\n         [ 0.05765498],\n         [ 0.07663722],\n         [ 0.04339464],\n         [ 0.00822868],\n         [ 0.0897519 ],\n         [-0.05692565],\n         [-0.0783579 ],\n         [-0.0097421 ],\n         [-0.06331109],\n         [-0.0276299 ],\n         [-0.07694747],\n         [ 0.00263987],\n         [ 0.06772767],\n         [ 0.02883749],\n         [-0.04284036],\n         [-0.0112284 ],\n         [-0.07528489],\n         [ 0.07307184],\n         [ 0.07088429],\n         [-0.00740915],\n         [-0.02062996],\n         [ 0.05577351],\n         [ 0.08864111],\n         [ 0.01543272],\n         [-0.0059818 ],\n         [ 0.0032592 ],\n         [ 0.03385726],\n         [ 0.08182573]],\n\n        [[-0.05786382],\n         [ 0.05124418],\n         [ 0.00796309],\n         [ 0.04104775],\n         [ 0.00814205],\n         [ 0.00984384],\n         [-0.07605258],\n         [ 0.04822332],\n         [-0.04771995],\n         [ 0.05968463],\n         [-0.0464    ],\n         [-0.02959226],\n         [-0.06653413],\n         [ 0.01143865],\n         [-0.02303614],\n         [-0.02621459],\n         [-0.00504218],\n         [-0.06145014],\n         [-0.0034817 ],\n         [-0.0150359 ],\n         [-0.09018236],\n         [-0.05863693],\n         [ 0.00645811],\n         [-0.04828103],\n         [ 0.08005309],\n         [-0.02524236],\n         [-0.03899967],\n         [ 0.01572896],\n         [-0.04688781],\n         [-0.05755363],\n         [ 0.03826521],\n         [-0.06012757],\n         [-0.00892957],\n         [ 0.03580593],\n         [ 0.04931924],\n         [ 0.02014275],\n         [-0.07311182],\n         [-0.06382143],\n         [-0.00428311],\n         [ 0.02264027],\n         [-0.01483738],\n         [ 0.06842832],\n         [ 0.00974335],\n         [ 0.07694037],\n         [ 0.08917496],\n         [-0.0174689 ],\n         [-0.06696491],\n         [ 0.08753799],\n         [-0.01624309],\n         [ 0.02230313],\n         [ 0.01175712],\n         [ 0.02997867],\n         [-0.06108657],\n         [-0.03932665],\n         [-0.05693884],\n         [-0.06278455],\n         [-0.0527258 ],\n         [-0.0802287 ],\n         [ 0.01776469],\n         [-0.00145677],\n         [-0.01928206],\n         [ 0.03591265],\n         [-0.04345971],\n         [-0.03102019],\n         [ 0.01046301],\n         [ 0.08114894],\n         [ 0.07808657],\n         [ 0.0343423 ],\n         [ 0.06993158],\n         [ 0.01408548],\n         [-0.06093172],\n         [ 0.07527113],\n         [ 0.02670425],\n         [ 0.04057077],\n         [ 0.00105387],\n         [-0.00233775],\n         [-0.0497344 ],\n         [ 0.01712418],\n         [-0.02900213],\n         [-0.039171  ]]],\n\n\n       [[[ 0.07171911],\n         [ 0.01992186],\n         [-0.00048675],\n         [-0.01047093],\n         [-0.04854922],\n         [-0.0869187 ],\n         [-0.08694133],\n         [ 0.03855282],\n         [ 0.03418114],\n         [ 0.0482872 ],\n         [ 0.02242008],\n         [-0.05403198],\n         [-0.03989646],\n         [ 0.00917178],\n         [-0.0233963 ],\n         [ 0.05945697],\n         [-0.03179966],\n         [-0.06871909],\n         [ 0.02402551],\n         [-0.07965973],\n         [-0.03269425],\n         [ 0.04068154],\n         [ 0.04370865],\n         [ 0.09024924],\n         [-0.07195674],\n         [ 0.00187813],\n         [-0.06639826],\n         [-0.04101812],\n         [-0.02680764],\n         [-0.07542536],\n         [-0.02575634],\n         [ 0.07085477],\n         [-0.08113823],\n         [-0.01885943],\n         [-0.05286459],\n         [-0.05928723],\n         [-0.07757103],\n         [-0.07816301],\n         [ 0.08603606],\n         [-0.02677132],\n         [ 0.04176065],\n         [-0.00623716],\n         [-0.01952989],\n         [-0.02471942],\n         [-0.00798147],\n         [-0.07412536],\n         [ 0.00982811],\n         [-0.02755248],\n         [-0.00572737],\n         [-0.08674919],\n         [-0.08371507],\n         [ 0.03365567],\n         [ 0.00358481],\n         [ 0.0862357 ],\n         [-0.04430701],\n         [-0.0487982 ],\n         [-0.01928364],\n         [-0.00506844],\n         [ 0.08807836],\n         [ 0.06924039],\n         [ 0.03669664],\n         [ 0.09061152],\n         [-0.08352878],\n         [-0.0899474 ],\n         [-0.00489838],\n         [ 0.03565852],\n         [-0.05972123],\n         [ 0.05011   ],\n         [ 0.01330084],\n         [-0.02696517],\n         [-0.00146702],\n         [ 0.05984209],\n         [-0.07764994],\n         [-0.01269703],\n         [-0.03961065],\n         [ 0.09051578],\n         [ 0.0622189 ],\n         [-0.04662469],\n         [ 0.01956664],\n         [-0.01184741]],\n\n        [[ 0.04349332],\n         [ 0.05064964],\n         [-0.09030458],\n         [ 0.03592026],\n         [-0.04918632],\n         [ 0.06756341],\n         [ 0.08421725],\n         [ 0.08609986],\n         [-0.03561604],\n         [ 0.03402943],\n         [ 0.08212055],\n         [-0.02423926],\n         [ 0.02402285],\n         [-0.07478475],\n         [ 0.05734667],\n         [ 0.05313645],\n         [ 0.02255929],\n         [-0.01252009],\n         [ 0.04377624],\n         [-0.00457018],\n         [-0.05663389],\n         [-0.0846564 ],\n         [-0.06832376],\n         [-0.04526112],\n         [ 0.00745957],\n         [ 0.01864772],\n         [-0.01856163],\n         [ 0.01058857],\n         [ 0.02573517],\n         [ 0.01911134],\n         [-0.06963755],\n         [-0.04347388],\n         [-0.04250266],\n         [-0.0397717 ],\n         [-0.07477236],\n         [-0.08106872],\n         [ 0.07613871],\n         [-0.05800528],\n         [-0.07058594],\n         [ 0.06900765],\n         [-0.00303721],\n         [-0.07197463],\n         [-0.07419216],\n         [ 0.0455084 ],\n         [-0.00388698],\n         [-0.0844207 ],\n         [-0.03015474],\n         [-0.08194131],\n         [ 0.00217673],\n         [ 0.01919688],\n         [-0.06933632],\n         [-0.02486119],\n         [ 0.05563731],\n         [-0.0250513 ],\n         [ 0.0164082 ],\n         [ 0.02217101],\n         [-0.04376547],\n         [-0.0112013 ],\n         [ 0.04263836],\n         [ 0.01845405],\n         [ 0.08947431],\n         [ 0.01247478],\n         [ 0.05786878],\n         [-0.07704858],\n         [-0.05611079],\n         [ 0.03176845],\n         [-0.0801339 ],\n         [ 0.07353528],\n         [-0.07836683],\n         [ 0.06467517],\n         [ 0.00434677],\n         [-0.07659534],\n         [-0.07338809],\n         [-0.00650786],\n         [ 0.02014197],\n         [ 0.04430179],\n         [ 0.00023256],\n         [-0.06573993],\n         [ 0.02831978],\n         [ 0.07283796]],\n\n        [[-0.0492625 ],\n         [ 0.08175841],\n         [-0.01467117],\n         [ 0.08140634],\n         [-0.02893542],\n         [-0.06952119],\n         [-0.00148071],\n         [ 0.01189283],\n         [ 0.08024627],\n         [ 0.06177506],\n         [-0.0828893 ],\n         [ 0.05096097],\n         [ 0.02192521],\n         [-0.05902066],\n         [-0.07481404],\n         [ 0.00808121],\n         [ 0.00383414],\n         [ 0.02105907],\n         [-0.03091602],\n         [ 0.06825405],\n         [-0.08449872],\n         [-0.09019069],\n         [-0.02370349],\n         [ 0.02014589],\n         [-0.05123652],\n         [-0.01183402],\n         [ 0.06280151],\n         [ 0.01075977],\n         [ 0.03756769],\n         [ 0.00598954],\n         [-0.05516683],\n         [ 0.07520011],\n         [ 0.03805037],\n         [ 0.0346745 ],\n         [ 0.02562486],\n         [ 0.0610421 ],\n         [-0.02265531],\n         [-0.06252722],\n         [-0.04732986],\n         [-0.00676415],\n         [ 0.01371423],\n         [ 0.05977747],\n         [-0.00283324],\n         [-0.05467057],\n         [-0.05722648],\n         [-0.02976395],\n         [-0.01199289],\n         [ 0.05897997],\n         [-0.0575    ],\n         [ 0.00391434],\n         [-0.03992525],\n         [ 0.07603116],\n         [ 0.01011032],\n         [-0.08731288],\n         [-0.06506991],\n         [-0.03852098],\n         [-0.00558478],\n         [-0.05074189],\n         [ 0.03197169],\n         [ 0.07084781],\n         [-0.02094552],\n         [-0.02604324],\n         [-0.09017005],\n         [-0.01307102],\n         [ 0.013785  ],\n         [-0.07050404],\n         [ 0.02062881],\n         [ 0.02823933],\n         [ 0.07621004],\n         [-0.07351783],\n         [ 0.02738342],\n         [ 0.0488292 ],\n         [-0.01945934],\n         [-0.05523234],\n         [ 0.02338751],\n         [ 0.02282194],\n         [ 0.02510735],\n         [ 0.00595392],\n         [-0.0247431 ],\n         [-0.07609938]]],\n\n\n       [[[ 0.05805835],\n         [-0.07733858],\n         [ 0.08293097],\n         [-0.01705019],\n         [ 0.00707767],\n         [ 0.04854189],\n         [ 0.08099033],\n         [ 0.06596185],\n         [ 0.06638467],\n         [-0.06523574],\n         [-0.05881564],\n         [-0.01693588],\n         [-0.07783039],\n         [ 0.07417254],\n         [ 0.0094611 ],\n         [ 0.0600834 ],\n         [-0.00826167],\n         [-0.04777078],\n         [-0.08290255],\n         [ 0.07314818],\n         [ 0.04263854],\n         [-0.02226182],\n         [ 0.00776308],\n         [-0.01051994],\n         [ 0.01010859],\n         [-0.0899748 ],\n         [-0.08219299],\n         [-0.02132332],\n         [-0.08308948],\n         [ 0.00140572],\n         [-0.07739341],\n         [ 0.09015763],\n         [-0.03408002],\n         [ 0.00684948],\n         [-0.03658808],\n         [-0.0031486 ],\n         [ 0.05801111],\n         [ 0.08017521],\n         [ 0.02519094],\n         [ 0.06077428],\n         [-0.04758833],\n         [ 0.04164752],\n         [-0.01551157],\n         [ 0.06210651],\n         [ 0.06496996],\n         [ 0.09033184],\n         [ 0.03659013],\n         [ 0.06152858],\n         [ 0.05315022],\n         [ 0.02018246],\n         [ 0.00908425],\n         [-0.085867  ],\n         [-0.00273442],\n         [-0.06519023],\n         [ 0.07480469],\n         [-0.00352594],\n         [-0.03134401],\n         [ 0.07701938],\n         [ 0.00322416],\n         [ 0.07593456],\n         [-0.07133744],\n         [-0.01306628],\n         [-0.06195418],\n         [-0.04605682],\n         [ 0.03989945],\n         [ 0.0872815 ],\n         [ 0.04746671],\n         [-0.07595263],\n         [ 0.06160074],\n         [-0.07978672],\n         [ 0.08518207],\n         [-0.07278373],\n         [-0.06104528],\n         [-0.067196  ],\n         [-0.01702023],\n         [ 0.05185279],\n         [-0.07997362],\n         [-0.08609275],\n         [-0.03401243],\n         [-0.03260266]],\n\n        [[-0.01962487],\n         [ 0.02234563],\n         [-0.02558486],\n         [-0.04656925],\n         [ 0.035795  ],\n         [ 0.034128  ],\n         [ 0.05595036],\n         [ 0.04335429],\n         [-0.02954203],\n         [ 0.03235081],\n         [ 0.01931924],\n         [-0.04426202],\n         [ 0.06391293],\n         [-0.03830884],\n         [ 0.08866799],\n         [ 0.05905207],\n         [ 0.05443403],\n         [-0.07586487],\n         [-0.0280106 ],\n         [-0.04152397],\n         [-0.05066214],\n         [ 0.00329529],\n         [ 0.00794144],\n         [ 0.058981  ],\n         [ 0.0815784 ],\n         [ 0.00954169],\n         [-0.07233641],\n         [ 0.06311767],\n         [ 0.03498547],\n         [-0.07904547],\n         [-0.03057044],\n         [-0.01521564],\n         [-0.0886955 ],\n         [-0.05344085],\n         [ 0.04329479],\n         [ 0.06085089],\n         [ 0.0775903 ],\n         [ 0.00039548],\n         [-0.02303266],\n         [ 0.03587447],\n         [ 0.00279856],\n         [-0.08086321],\n         [-0.04059656],\n         [-0.03699915],\n         [ 0.0161699 ],\n         [-0.00425708],\n         [-0.05189599],\n         [-0.0820002 ],\n         [ 0.0594317 ],\n         [ 0.01968707],\n         [-0.02304412],\n         [ 0.06859192],\n         [ 0.00324343],\n         [ 0.01166714],\n         [-0.06123722],\n         [ 0.00963801],\n         [-0.03623621],\n         [ 0.05556217],\n         [ 0.0197241 ],\n         [ 0.00622027],\n         [ 0.02136517],\n         [-0.06995655],\n         [-0.00571647],\n         [-0.05176837],\n         [ 0.02858619],\n         [ 0.08529539],\n         [-0.01685704],\n         [ 0.08095355],\n         [-0.04637294],\n         [-0.03460714],\n         [ 0.07622904],\n         [-0.05750208],\n         [ 0.08455302],\n         [-0.03253871],\n         [-0.02496509],\n         [ 0.05329086],\n         [-0.08314498],\n         [ 0.03071259],\n         [-0.03210964],\n         [ 0.06944153]],\n\n        [[ 0.01360323],\n         [-0.07811504],\n         [-0.01610473],\n         [-0.0367619 ],\n         [-0.01997644],\n         [ 0.02199002],\n         [-0.01527436],\n         [-0.03885769],\n         [ 0.05444835],\n         [-0.00828706],\n         [-0.04818514],\n         [-0.03052794],\n         [-0.07078129],\n         [ 0.07921286],\n         [-0.0770357 ],\n         [ 0.02768118],\n         [-0.08084442],\n         [ 0.08914565],\n         [-0.05622789],\n         [-0.04072698],\n         [ 0.02550086],\n         [-0.0258685 ],\n         [ 0.05112925],\n         [-0.08128218],\n         [-0.03900871],\n         [ 0.03260256],\n         [ 0.05361149],\n         [-0.06995216],\n         [-0.07315704],\n         [-0.05321822],\n         [-0.03491809],\n         [-0.0132563 ],\n         [-0.0149237 ],\n         [ 0.08420019],\n         [ 0.08090866],\n         [-0.07596362],\n         [ 0.05581081],\n         [-0.04941811],\n         [ 0.07601336],\n         [ 0.03279651],\n         [-0.055463  ],\n         [-0.02301525],\n         [-0.04591828],\n         [ 0.02297549],\n         [ 0.07285769],\n         [-0.01587545],\n         [-0.07279814],\n         [ 0.03596611],\n         [ 0.08488677],\n         [-0.08835713],\n         [ 0.08163559],\n         [ 0.02366219],\n         [ 0.04443592],\n         [-0.08373445],\n         [ 0.04926142],\n         [ 0.03823374],\n         [ 0.0664776 ],\n         [ 0.04859602],\n         [-0.03474044],\n         [ 0.02676133],\n         [ 0.08789088],\n         [ 0.02141088],\n         [ 0.081526  ],\n         [ 0.06190355],\n         [ 0.09061584],\n         [-0.04921249],\n         [-0.00166885],\n         [-0.02764235],\n         [-0.06155602],\n         [ 0.083459  ],\n         [-0.06625795],\n         [-0.05969647],\n         [ 0.04613832],\n         [-0.03669249],\n         [ 0.03136527],\n         [-0.01489816],\n         [-0.0211824 ],\n         [ 0.02098166],\n         [ 0.0698358 ],\n         [ 0.06118974]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/beta:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_841/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[ 6.84014559e-02, -3.92495468e-02,  2.98464864e-01,\n           1.91253796e-01,  4.47430074e-01, -1.50372639e-01,\n          -8.67424086e-02,  9.80304182e-02,  2.42829069e-01,\n          -1.27617270e-01,  3.22487988e-02, -2.36566514e-01,\n          -1.18546292e-01,  3.08662951e-01, -5.08268140e-02,\n          -2.78982788e-01,  1.28611520e-01, -2.15595096e-01,\n           4.19246256e-01, -4.31423448e-02, -9.88996848e-02,\n           5.83896302e-02, -4.81182151e-02, -2.50762850e-01],\n         [-2.54657294e-04, -2.84498036e-01,  1.11294597e-01,\n           1.58172607e-01,  3.34406197e-02,  9.45988446e-02,\n          -1.13590725e-01, -1.88803896e-01,  2.60639876e-01,\n           3.80886883e-01,  4.98085320e-02, -1.67907774e-01,\n           4.33379769e-01, -4.32502702e-02, -2.12843508e-01,\n          -5.12624085e-02, -2.58914828e-01,  3.82817179e-01,\n          -1.58264160e-01, -2.52384320e-02, -1.20440200e-01,\n          -2.33588099e-01,  1.69621706e-01,  3.29376042e-01],\n         [-1.48603857e-01, -4.94975690e-03, -1.25284821e-01,\n          -3.14235777e-01, -3.06155179e-02, -1.61228910e-01,\n           3.28943431e-01, -2.41157398e-01, -1.72342017e-01,\n          -2.87996471e-01, -2.19827697e-01, -2.90676504e-01,\n          -1.40673921e-01,  2.52290457e-01, -2.30565965e-01,\n           4.12237078e-01, -4.02885258e-01, -3.19941223e-01,\n          -1.91585958e-01,  2.39304081e-01, -2.19422430e-01,\n           3.10061295e-02,  1.30316213e-01,  4.17715222e-01],\n         [-2.83654839e-01,  7.88801908e-02,  3.90030742e-01,\n          -2.80239731e-01, -2.60022700e-01,  5.91021441e-02,\n          -1.63197026e-01, -1.05511598e-01,  3.29035103e-01,\n          -3.08528990e-01, -2.85283744e-01, -8.81652012e-02,\n           7.35683367e-02,  3.97935122e-01, -1.48133829e-01,\n           4.57362354e-01, -2.01754242e-01,  1.40073270e-01,\n           1.45332798e-01, -2.13589311e-01,  2.30834037e-01,\n           2.66146421e-01, -1.22570517e-02, -2.81186908e-01],\n         [ 9.27113742e-02,  2.94797719e-01,  9.52996835e-02,\n          -1.14168040e-01, -2.64537960e-01,  1.61465615e-01,\n           8.48899707e-02,  2.10411370e-01,  3.34415287e-01,\n           1.12497360e-01,  1.54759303e-01,  1.03909755e-03,\n           2.04654440e-01, -1.59201503e-01,  2.31470883e-01,\n           2.08816707e-01, -2.31085315e-01,  2.41122872e-01,\n           3.60894710e-01,  7.51060098e-02, -2.24958569e-01,\n          -2.12644920e-01, -5.56731597e-02,  3.37553889e-01],\n         [-2.08547354e-01,  1.43108457e-01,  3.12944800e-01,\n          -1.38469055e-01, -2.83353180e-01, -4.07728165e-01,\n           1.80686608e-01,  3.35733108e-02, -3.44503552e-01,\n          -1.36209607e-01, -2.27211371e-01,  4.35201190e-02,\n           3.06223273e-01,  3.38013858e-01,  2.14590997e-01,\n           1.02576301e-01,  1.80911765e-01,  2.79255420e-01,\n           1.32999048e-01, -2.50599742e-01, -5.59633598e-02,\n           3.86381984e-01, -2.63577491e-01,  1.09275952e-01],\n         [-2.02991322e-01,  3.20254534e-01, -1.28931120e-01,\n          -2.22821176e-01, -4.50530529e-01, -1.56983003e-01,\n           3.09274308e-02, -2.49952246e-02,  4.32442039e-01,\n           1.62882715e-01,  5.95040247e-02, -1.03708759e-01,\n           5.70462756e-02,  1.81214690e-01,  1.77452281e-01,\n           1.82624996e-01,  2.51515925e-01,  4.01086330e-01,\n          -6.64763749e-02, -7.29998276e-02,  9.23321545e-02,\n          -1.07277729e-01,  1.39081590e-02,  3.53070088e-02],\n         [-2.45736111e-02,  2.32930586e-01,  2.46791229e-01,\n          -4.05412287e-01,  1.77785724e-01, -2.61412829e-01,\n           2.73910607e-03,  2.68365946e-02, -7.55482167e-02,\n           1.20985836e-01,  1.02372609e-01,  2.59972125e-01,\n          -1.53685585e-01,  1.38477132e-01,  1.89108759e-01,\n           3.82816106e-01,  2.86719594e-02,  1.36417747e-01,\n          -1.50075108e-01, -4.15790558e-01, -3.26630086e-01,\n           4.03426319e-01, -3.92406583e-02, -1.68544501e-01],\n         [-1.48958698e-01, -1.12082232e-02, -1.90384895e-01,\n           3.65707502e-02, -2.98519582e-01, -1.38363034e-01,\n           1.43423170e-01, -1.22984327e-01,  2.27974087e-01,\n          -1.44776367e-02, -2.28391871e-01, -1.60584435e-01,\n           1.44059226e-01,  3.87848526e-01,  4.55982924e-01,\n          -1.79180931e-02, -2.30021179e-01, -3.66843604e-02,\n          -1.18387006e-01, -2.21808821e-01,  1.48436546e-01,\n          -1.89776435e-01, -1.68751553e-01,  2.17583150e-01],\n         [-7.92236552e-02,  5.62611893e-02,  1.25069022e-01,\n           1.86897337e-01, -1.08875103e-01, -1.11209430e-01,\n           9.32304114e-02,  2.16538116e-01,  1.99880257e-01,\n          -4.03164364e-02, -7.67890087e-05, -3.16267669e-01,\n          -1.64254472e-01, -1.24856368e-01,  5.18351607e-02,\n          -2.93755352e-01,  1.59803137e-01, -1.59994736e-01,\n          -1.26577973e-01,  2.60245025e-01,  1.66056588e-01,\n          -1.65770039e-01, -1.23697177e-01, -3.05500418e-01],\n         [-5.68155013e-02,  1.60579100e-01, -6.24169186e-02,\n          -2.29602993e-01, -6.72605447e-03, -1.30686015e-02,\n           3.10763627e-01,  1.11883096e-02, -1.43394426e-01,\n           3.96723934e-02, -1.51594937e-01,  4.48242463e-02,\n          -2.00824216e-01, -6.95776343e-02, -8.52244496e-02,\n           3.37708741e-01,  5.81229255e-02,  9.78265405e-02,\n          -2.41187781e-01, -2.33654544e-01,  5.42929620e-02,\n          -1.50632605e-01, -1.39585912e-01, -8.66520852e-02],\n         [ 2.15589121e-01,  3.01770270e-01,  1.81317881e-01,\n          -2.17640847e-01, -1.94202453e-01, -5.57794385e-02,\n          -3.01259816e-01,  1.66748464e-01, -1.52296290e-01,\n          -1.12140011e-02, -4.08235997e-01,  3.36906277e-02,\n           1.24987811e-01,  1.09357908e-01,  1.22211007e-02,\n           2.06163645e-01,  4.32774693e-01,  1.11354612e-01,\n           1.57117352e-01, -8.76159742e-02, -3.88727576e-01,\n           8.88131186e-02, -4.56161648e-02, -1.03748202e-01],\n         [ 2.17320055e-01, -3.06096524e-02, -3.07308167e-01,\n          -1.84150375e-02,  4.32917736e-02,  3.64172727e-01,\n           1.35282487e-01, -3.02516341e-01, -3.60549808e-01,\n          -3.10943313e-02, -7.68045112e-02, -1.74460858e-01,\n           4.30398881e-01,  4.22906131e-01, -2.84746110e-01,\n          -6.90286160e-02, -2.45366335e-01,  5.88738658e-02,\n          -1.36877701e-01,  3.98888767e-01, -3.86585325e-01,\n          -2.37295911e-01, -2.57462233e-01, -1.06367320e-02],\n         [ 1.68956548e-01,  1.31968744e-02,  4.83044051e-02,\n          -1.40180741e-03,  1.56752951e-02,  1.62519328e-02,\n          -3.24289948e-02, -1.64080739e-01,  9.25464206e-04,\n           1.66249156e-01,  1.06085353e-02,  7.51359165e-02,\n          -1.50318056e-01,  1.73974067e-01, -1.30232424e-01,\n          -2.69660264e-01, -1.79689646e-01, -1.04240142e-01,\n           2.90815276e-03,  2.06049412e-01,  1.44253522e-01,\n          -2.34661661e-02,  2.13963658e-01,  9.76187363e-02],\n         [-2.05742612e-01,  3.90633076e-01, -1.25517040e-01,\n           1.06393941e-01, -8.10937732e-02,  1.32084474e-01,\n          -5.05283289e-02,  1.83930472e-01,  1.51309192e-01,\n           1.18198507e-01, -1.69627875e-01, -1.82145491e-01,\n          -3.80770087e-01, -1.77845597e-01, -6.37246221e-02,\n          -6.15027994e-02,  2.90250201e-02,  1.73633680e-01,\n          -2.52395906e-02,  4.51313525e-01,  9.36437696e-02,\n           2.13392470e-02, -5.18125184e-02,  4.51065898e-02],\n         [ 7.21428404e-03, -7.01751485e-02,  6.20292500e-02,\n          -1.78167790e-01, -1.79197952e-01,  1.67951733e-01,\n          -1.47651453e-02,  9.60243866e-02, -3.14050466e-02,\n          -1.73015058e-01,  2.89703339e-01, -3.65354046e-02,\n          -2.73190737e-01, -1.31683704e-02, -5.78405857e-02,\n           1.05742626e-01, -1.31691650e-01, -6.98650405e-02,\n          -2.43575409e-01, -1.10293716e-01, -1.88645765e-01,\n           4.52486724e-02, -1.01314589e-01,  3.55772853e-01],\n         [-8.10470060e-02, -1.17308587e-01, -2.77636021e-01,\n           2.12412551e-02,  2.73361616e-02, -5.80642596e-02,\n          -6.75727800e-02, -3.06788355e-01, -1.47276625e-01,\n           1.06635630e-01,  1.39611363e-01,  1.31797612e-01,\n          -2.58707870e-02, -3.33346933e-01,  2.01822981e-01,\n           1.56069934e-01,  2.27926463e-01,  3.58766988e-02,\n          -4.49413121e-01,  3.55598688e-01,  5.56149445e-02,\n           1.67433154e-02,  2.30916828e-01, -2.30243608e-01],\n         [ 7.94287398e-02,  8.46988857e-02,  1.93133757e-01,\n          -1.63043112e-01,  1.21878631e-01,  4.36030060e-01,\n          -2.90257372e-02,  2.60948658e-01,  3.29847842e-01,\n           1.47622302e-01,  3.63536060e-01,  9.75141749e-02,\n           7.86910206e-02, -8.77018645e-02,  2.08300769e-01,\n           3.69048834e-01,  2.47864962e-01,  2.11841717e-01,\n          -3.38594876e-02,  1.08390287e-01,  1.84072763e-01,\n          -4.53510553e-01, -1.61994800e-01,  1.11818321e-01],\n         [ 4.16301876e-01, -1.04084343e-01,  6.26413748e-02,\n          -1.06780179e-01,  2.17227101e-01,  1.80184394e-01,\n          -1.51087284e-01,  1.70429230e-01, -5.41463606e-02,\n           1.51863573e-02,  2.89891630e-01, -5.25343306e-02,\n           1.15656361e-01,  2.79144675e-01, -4.39649969e-01,\n           1.78336367e-01, -9.21451226e-02, -4.48728278e-02,\n           2.38898680e-01,  4.27428372e-02,  3.10139835e-01,\n          -9.08699110e-02, -1.05184801e-01,  4.37893942e-02],\n         [ 3.25950325e-01,  1.67655542e-01,  1.57173738e-01,\n           2.78030932e-01, -2.86546171e-01,  2.43394569e-01,\n           9.61122215e-02, -2.18070537e-01, -4.29121941e-01,\n          -1.23530671e-01,  7.75913000e-02,  9.19010490e-02,\n           3.39515865e-01,  9.32124481e-02, -1.59385085e-01,\n           2.00431451e-01,  3.26066852e-01,  1.05054518e-02,\n           4.32761848e-01, -7.89537653e-02, -8.59342590e-02,\n          -1.30976126e-01,  2.27657467e-01,  1.91409245e-01],\n         [-3.75073612e-01,  4.23639417e-01,  1.63915738e-01,\n          -1.95530683e-01,  7.29036108e-02, -1.22334443e-01,\n          -3.53962034e-01,  2.20930368e-01, -2.40285084e-01,\n          -2.11275905e-01,  1.98102027e-01,  2.79787555e-02,\n           3.83080766e-02, -4.61515822e-02, -1.04890592e-01,\n           3.96909148e-01,  1.64523184e-01,  2.27796227e-01,\n           3.13703954e-01, -2.78377265e-01,  3.52707654e-02,\n           1.95282340e-01, -3.65794450e-01,  9.66960192e-02],\n         [ 2.22572863e-01,  8.05358812e-02, -5.87769412e-02,\n          -1.57205448e-01,  1.03675090e-01,  3.75404745e-01,\n          -2.65001357e-01,  8.45250934e-02,  2.24628940e-01,\n          -1.57339483e-01, -5.23993634e-02, -9.57649648e-02,\n           2.71222353e-01, -5.40702902e-02,  3.09756845e-01,\n          -2.68340886e-01, -2.59965003e-01, -1.92582071e-01,\n           1.37734994e-01, -3.59820545e-01, -2.65150487e-01,\n           3.58236171e-02, -5.53906597e-02,  8.18005428e-02],\n         [ 2.65695006e-02,  2.01549023e-01, -2.54747361e-01,\n          -1.75153971e-01, -1.96663573e-01,  2.78709143e-01,\n          -3.61500412e-01, -1.69985607e-01,  4.00638580e-01,\n           1.64688677e-02, -1.62304863e-01,  3.04507405e-01,\n           1.61152065e-01, -1.36359632e-01,  2.80574888e-01,\n          -1.25894099e-01, -2.54770458e-01, -1.51105434e-01,\n           1.25800297e-01,  1.28735691e-01,  2.86624402e-01,\n          -4.36355591e-01,  1.06700897e-01,  2.17151165e-01],\n         [ 2.28441834e-01,  6.12825667e-03,  1.10644631e-01,\n           1.20842747e-01, -1.40010253e-01,  1.57839194e-01,\n          -1.51948586e-01,  3.42689008e-02, -4.17883366e-01,\n          -2.57781565e-01, -1.21073298e-01, -1.52606785e-01,\n          -6.51301146e-02,  6.13741390e-02,  1.58175871e-01,\n           3.55882376e-01,  1.06211878e-01, -1.56426564e-01,\n          -1.99634656e-01,  4.23387997e-02, -2.70452397e-03,\n           1.64158419e-01, -5.32924458e-02,  3.25408652e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_3/bias:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 3.2322290e-03, -6.8038426e-02,  3.6254149e-02, ...,\n           3.6164497e-03,  6.0175294e-03, -2.2373835e-02],\n         [ 4.4004988e-02, -6.4516165e-03,  2.9711971e-02, ...,\n          -4.6262234e-02, -2.3361182e-02,  4.8121519e-02],\n         [-2.1454789e-02, -2.3279462e-02, -5.4114871e-02, ...,\n           2.1021353e-02, -6.8069631e-03,  2.6950121e-03],\n         ...,\n         [-2.7204905e-02, -2.7014401e-02,  8.6074593e-05, ...,\n           2.2668173e-03,  2.4217796e-02, -9.2214420e-03],\n         [-6.0749897e-03, -1.7563224e-02, -2.7269751e-02, ...,\n           3.7701081e-02, -4.3942329e-02, -4.1374866e-02],\n         [ 1.6359350e-02,  6.1703615e-02,  1.3785601e-02, ...,\n           8.6689457e-02,  3.8917080e-02, -1.9491883e-03]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 0.09025844, -0.05533385, -0.03332517, ...,  0.0039877 ,\n           0.00332859, -0.01816172],\n         [-0.01412649, -0.07343955, -0.00698643, ...,  0.01780744,\n          -0.09184445, -0.00045122],\n         [ 0.01487028,  0.00755074,  0.00876115, ...,  0.00710829,\n          -0.0276674 , -0.01662439],\n         ...,\n         [ 0.0250209 , -0.01512609, -0.06588375, ..., -0.01853615,\n          -0.07150245,  0.01451693],\n         [-0.00655317, -0.05630272, -0.04374221, ...,  0.04496026,\n           0.02064656,  0.01468199],\n         [ 0.05690276,  0.08352149, -0.0858833 , ...,  0.01890404,\n          -0.08227941,  0.03291428]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_360/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 4.29344326e-02],\n         [-6.74265623e-02],\n         [-5.66367172e-02],\n         [-5.70493937e-02],\n         [-2.74301022e-02],\n         [ 4.10541743e-02],\n         [ 8.79422724e-02],\n         [ 8.19318146e-02],\n         [ 7.59763569e-02],\n         [-2.12059617e-02],\n         [-6.59518391e-02],\n         [-7.30900094e-02],\n         [-4.78762388e-03],\n         [-7.29462355e-02],\n         [-5.85789196e-02],\n         [ 3.28171924e-02],\n         [-7.79883564e-02],\n         [-7.98300877e-02],\n         [-8.37408155e-02],\n         [ 3.93167883e-02],\n         [-5.77830113e-02],\n         [-8.55350941e-02],\n         [-7.77602941e-02],\n         [ 6.17374480e-02],\n         [-4.83440608e-03],\n         [-4.40224931e-02],\n         [ 5.82516640e-02],\n         [-5.34067675e-02],\n         [ 3.82195711e-02],\n         [ 6.16061687e-03],\n         [-8.21940675e-02],\n         [-6.56566992e-02],\n         [ 1.08331218e-02],\n         [ 3.21651623e-02],\n         [ 8.35449845e-02],\n         [-7.32030049e-02],\n         [ 2.01678351e-02],\n         [-4.70406264e-02],\n         [-7.96911567e-02],\n         [ 1.14996210e-02],\n         [-6.58048838e-02],\n         [ 2.80717686e-02],\n         [ 1.50719509e-02],\n         [-2.34491155e-02],\n         [ 6.38113767e-02],\n         [-2.88781933e-02],\n         [ 8.92594457e-04],\n         [ 7.49938190e-02],\n         [ 7.98702538e-02],\n         [-2.71864608e-02],\n         [ 2.11583078e-02],\n         [-3.61310877e-02],\n         [-6.28392547e-02],\n         [ 7.85087198e-02],\n         [ 5.41489273e-02],\n         [-3.24733183e-02],\n         [ 1.07384250e-02],\n         [ 6.80008531e-02],\n         [ 2.99676433e-02],\n         [-1.47967786e-02],\n         [-6.32688850e-02],\n         [ 2.31021121e-02],\n         [-6.99172691e-02],\n         [ 3.02099586e-02],\n         [ 6.50635958e-02],\n         [-7.10258186e-02],\n         [-4.70710173e-02],\n         [ 3.78542691e-02],\n         [ 7.97744691e-02],\n         [ 6.09150082e-02],\n         [-2.20722780e-02],\n         [ 2.05085948e-02],\n         [ 8.80660713e-02],\n         [-7.80842155e-02],\n         [-5.04853837e-02],\n         [ 6.58236146e-02],\n         [-5.87391332e-02],\n         [-5.35612665e-02],\n         [ 6.61478043e-02],\n         [ 8.37584585e-03]],\n\n        [[-5.57722412e-02],\n         [ 3.61501426e-02],\n         [-5.34268171e-02],\n         [-4.32572775e-02],\n         [-4.77816388e-02],\n         [-3.05392519e-02],\n         [-1.21347606e-03],\n         [ 2.16806680e-02],\n         [ 7.74590373e-02],\n         [ 8.20591599e-02],\n         [-3.09635401e-02],\n         [ 8.38502645e-02],\n         [-2.05117092e-02],\n         [-3.74035239e-02],\n         [-7.56601244e-02],\n         [ 3.34321856e-02],\n         [ 4.02154177e-02],\n         [ 3.88269573e-02],\n         [-5.90643361e-02],\n         [ 3.03727388e-03],\n         [-2.26897225e-02],\n         [ 3.79813462e-02],\n         [-8.62237215e-02],\n         [-2.67534330e-02],\n         [-6.60271943e-02],\n         [-8.36863741e-02],\n         [ 6.10805750e-02],\n         [-6.16832450e-02],\n         [ 6.37112260e-02],\n         [-7.60613605e-02],\n         [-7.49831796e-02],\n         [-3.32641043e-02],\n         [ 7.50435293e-02],\n         [ 2.96038687e-02],\n         [-1.81979090e-02],\n         [-6.30560070e-02],\n         [ 1.04436129e-02],\n         [ 4.17065322e-02],\n         [-5.34891337e-03],\n         [-8.31440240e-02],\n         [ 6.70157373e-03],\n         [ 5.84474951e-02],\n         [-1.60550699e-02],\n         [ 7.20931590e-02],\n         [-4.69341427e-02],\n         [-8.97372589e-02],\n         [-9.27480310e-03],\n         [-6.99691400e-02],\n         [ 7.18539208e-03],\n         [ 8.22928995e-02],\n         [ 6.23858869e-02],\n         [-5.61044961e-02],\n         [ 2.46745944e-02],\n         [ 4.56547439e-02],\n         [-7.36372471e-02],\n         [-3.56410444e-02],\n         [-4.07867655e-02],\n         [-4.02390361e-02],\n         [ 5.60247898e-02],\n         [ 5.61400950e-02],\n         [-7.23836496e-02],\n         [-2.01498866e-02],\n         [-4.49745059e-02],\n         [ 5.82775027e-02],\n         [ 3.88439298e-02],\n         [-1.22525766e-02],\n         [-7.82406256e-02],\n         [-6.87655061e-02],\n         [-6.25681430e-02],\n         [-3.91839780e-02],\n         [ 3.23916972e-03],\n         [ 1.80687979e-02],\n         [-5.90614155e-02],\n         [-4.21840288e-02],\n         [ 6.05086237e-03],\n         [-3.73501629e-02],\n         [-5.48547730e-02],\n         [ 5.52416891e-02],\n         [-6.48690313e-02],\n         [ 2.32455358e-02]],\n\n        [[ 3.18724439e-02],\n         [-5.48525415e-02],\n         [-3.72464694e-02],\n         [ 6.36755824e-02],\n         [ 1.23876929e-02],\n         [ 1.00802556e-02],\n         [-6.08836599e-02],\n         [-8.51497799e-02],\n         [-5.28993085e-02],\n         [ 2.09134370e-02],\n         [ 1.96753517e-02],\n         [-2.67902017e-02],\n         [-5.95249236e-03],\n         [ 6.06220514e-02],\n         [ 8.15683901e-02],\n         [ 7.52286613e-02],\n         [ 5.28526753e-02],\n         [-5.78274168e-02],\n         [-6.89721331e-02],\n         [-4.97158170e-02],\n         [ 7.85014778e-02],\n         [ 4.77721691e-02],\n         [ 2.17933133e-02],\n         [-5.05322330e-02],\n         [ 6.45604879e-02],\n         [ 5.96921146e-02],\n         [ 4.62065786e-02],\n         [ 7.20409453e-02],\n         [-4.14944477e-02],\n         [-3.72504517e-02],\n         [-4.75932024e-02],\n         [ 4.66099083e-02],\n         [ 5.08522093e-02],\n         [ 8.87904316e-02],\n         [ 1.52190104e-02],\n         [ 1.36862621e-02],\n         [-5.48737608e-02],\n         [ 4.52680588e-02],\n         [-4.83558476e-02],\n         [ 8.55519474e-02],\n         [-5.60320914e-04],\n         [ 6.84139132e-03],\n         [-3.08615789e-02],\n         [ 6.29861802e-02],\n         [-4.23893593e-02],\n         [-7.56455958e-03],\n         [-3.36619392e-02],\n         [ 7.76530951e-02],\n         [ 7.17651695e-02],\n         [-5.12889288e-02],\n         [-5.41700423e-03],\n         [-1.50008500e-02],\n         [-8.40260237e-02],\n         [ 4.71491069e-02],\n         [ 1.98584646e-02],\n         [-2.80153826e-02],\n         [ 8.66070688e-02],\n         [ 3.64376903e-02],\n         [ 3.87914777e-02],\n         [ 6.96620345e-02],\n         [-5.99293113e-02],\n         [-2.75859013e-02],\n         [ 2.28927583e-02],\n         [ 3.63303423e-02],\n         [-2.93758065e-02],\n         [-3.14049385e-02],\n         [ 8.18703324e-02],\n         [ 6.29567802e-02],\n         [ 5.32104969e-02],\n         [-6.08915761e-02],\n         [ 1.05404109e-03],\n         [-5.11008166e-02],\n         [-3.99032533e-02],\n         [-7.78315589e-02],\n         [-5.50624803e-02],\n         [ 8.02858323e-02],\n         [-6.06996566e-02],\n         [-6.55881166e-02],\n         [-4.85333167e-02],\n         [-2.73325518e-02]]],\n\n\n       [[[ 6.66722208e-02],\n         [ 5.61857224e-02],\n         [-5.38792238e-02],\n         [-7.57335126e-02],\n         [ 6.10074401e-02],\n         [ 2.34873146e-02],\n         [ 6.53727949e-02],\n         [ 6.66008145e-02],\n         [ 3.52994949e-02],\n         [-6.09371737e-02],\n         [ 5.79679459e-02],\n         [ 5.89951575e-02],\n         [-1.51913241e-02],\n         [-4.34279442e-04],\n         [ 1.82931423e-02],\n         [-3.92464437e-02],\n         [ 6.24682158e-02],\n         [-3.11049335e-02],\n         [-5.52010424e-02],\n         [ 7.37842023e-02],\n         [-8.62824395e-02],\n         [-5.48819602e-02],\n         [ 5.34279048e-02],\n         [-1.01780593e-02],\n         [ 3.53550613e-02],\n         [ 1.91469789e-02],\n         [ 7.52201974e-02],\n         [-3.04744393e-03],\n         [-7.33405277e-02],\n         [-7.20890090e-02],\n         [ 6.93914890e-02],\n         [-1.07991621e-02],\n         [-7.93734938e-03],\n         [ 3.57979089e-02],\n         [ 1.31724924e-02],\n         [ 5.95712364e-02],\n         [ 5.93758672e-02],\n         [-7.16141686e-02],\n         [-2.65225768e-02],\n         [-7.75118098e-02],\n         [ 4.08145636e-02],\n         [ 4.88748401e-03],\n         [ 3.49420309e-02],\n         [-4.10383642e-02],\n         [ 8.71990025e-02],\n         [ 6.86141253e-02],\n         [-4.84764315e-02],\n         [ 1.51829794e-02],\n         [ 8.19181651e-02],\n         [ 3.21080387e-02],\n         [-3.92259397e-02],\n         [-9.29236412e-04],\n         [ 1.40778050e-02],\n         [ 4.29151207e-02],\n         [-5.53097539e-02],\n         [-5.04596010e-02],\n         [-1.51994377e-02],\n         [-1.31007433e-02],\n         [-7.63770193e-02],\n         [ 7.10065812e-02],\n         [-6.33141994e-02],\n         [ 3.84250730e-02],\n         [ 5.67469597e-02],\n         [-4.30296436e-02],\n         [-2.41254419e-02],\n         [-7.27467015e-02],\n         [ 7.26108998e-03],\n         [ 8.57848972e-02],\n         [-3.52650322e-02],\n         [-1.23599693e-02],\n         [ 8.85512978e-02],\n         [-5.72096556e-03],\n         [-7.89690018e-03],\n         [-7.84918070e-02],\n         [-6.06409945e-02],\n         [ 4.84788567e-02],\n         [ 6.49842918e-02],\n         [ 4.87396717e-02],\n         [ 1.04672983e-02],\n         [ 8.42150897e-02]],\n\n        [[-7.14472681e-03],\n         [ 1.50961727e-02],\n         [ 2.02860683e-02],\n         [-5.95817715e-03],\n         [ 7.13317692e-02],\n         [-6.41822070e-03],\n         [-5.88177145e-02],\n         [ 3.61466557e-02],\n         [-9.79344547e-03],\n         [-3.84752341e-02],\n         [-4.06880043e-02],\n         [ 4.66035306e-03],\n         [-3.15532312e-02],\n         [ 4.77885008e-02],\n         [-4.86982465e-02],\n         [-3.94218192e-02],\n         [ 3.43336463e-02],\n         [-3.49474847e-02],\n         [-5.24816401e-02],\n         [-7.31157959e-02],\n         [ 3.75106931e-02],\n         [ 2.28761435e-02],\n         [ 5.93446940e-02],\n         [-5.97939640e-03],\n         [-8.61727595e-02],\n         [ 8.15087259e-02],\n         [ 6.96686953e-02],\n         [ 1.81223303e-02],\n         [ 6.59119040e-02],\n         [-7.28418306e-02],\n         [ 7.49230534e-02],\n         [-2.42553055e-02],\n         [ 6.42922670e-02],\n         [-4.68006209e-02],\n         [ 3.40412408e-02],\n         [-1.75423920e-03],\n         [ 3.29241902e-02],\n         [-8.57786238e-02],\n         [-8.45115483e-02],\n         [-6.22605011e-02],\n         [ 2.30288729e-02],\n         [ 5.29200286e-02],\n         [ 2.67355442e-02],\n         [ 6.09720349e-02],\n         [ 2.25575417e-02],\n         [ 6.24920279e-02],\n         [ 3.13568562e-02],\n         [ 6.58864528e-03],\n         [ 6.92223907e-02],\n         [ 1.97137669e-02],\n         [ 3.58247608e-02],\n         [-5.32170497e-02],\n         [-3.64480279e-02],\n         [ 4.19937074e-02],\n         [-8.66998509e-02],\n         [ 8.06423873e-02],\n         [ 6.51427954e-02],\n         [ 7.01786876e-02],\n         [-4.56057489e-03],\n         [ 2.36397833e-02],\n         [-6.85281381e-02],\n         [-4.81368862e-02],\n         [ 8.83001089e-02],\n         [-5.48150167e-02],\n         [ 5.31197190e-02],\n         [ 3.06962356e-02],\n         [ 9.05111283e-02],\n         [-5.87601215e-03],\n         [-6.88491687e-02],\n         [ 8.91793817e-02],\n         [-1.51929706e-02],\n         [-7.95701593e-02],\n         [ 9.93226469e-03],\n         [ 7.71139711e-02],\n         [-9.88832861e-03],\n         [-2.94139236e-03],\n         [ 1.60878152e-03],\n         [ 4.08340991e-02],\n         [ 5.70092499e-02],\n         [ 2.74901018e-02]],\n\n        [[-3.75576131e-02],\n         [ 8.49442184e-03],\n         [ 7.32576698e-02],\n         [ 4.27309424e-03],\n         [ 8.13311338e-02],\n         [-7.17696846e-02],\n         [ 6.19389713e-02],\n         [-7.22269192e-02],\n         [ 4.85557318e-02],\n         [-4.18692939e-02],\n         [-2.59034261e-02],\n         [-6.18938357e-03],\n         [-4.65638936e-03],\n         [-4.84742485e-02],\n         [ 2.76988521e-02],\n         [ 6.96270168e-02],\n         [ 1.38992816e-03],\n         [-3.53288390e-02],\n         [ 3.99927646e-02],\n         [ 4.86508310e-02],\n         [ 8.62990767e-02],\n         [ 2.53553912e-02],\n         [-7.78173059e-02],\n         [ 8.17364752e-02],\n         [-2.70016789e-02],\n         [ 8.92897099e-02],\n         [ 8.04240257e-02],\n         [-3.27163525e-02],\n         [ 4.04493362e-02],\n         [-2.76805758e-02],\n         [ 2.92934477e-04],\n         [-4.88815345e-02],\n         [-5.65674827e-02],\n         [ 4.75613028e-02],\n         [ 7.72858411e-02],\n         [ 4.25950438e-02],\n         [-7.83738419e-02],\n         [ 6.77165240e-02],\n         [-5.72148822e-02],\n         [-2.71096528e-02],\n         [ 5.22156358e-02],\n         [ 1.41286999e-02],\n         [ 3.09604704e-02],\n         [-8.34431201e-02],\n         [-4.56343889e-02],\n         [ 1.58860311e-02],\n         [ 6.50797635e-02],\n         [-9.04949084e-02],\n         [-4.34874594e-02],\n         [ 6.50497228e-02],\n         [ 2.08747014e-02],\n         [-6.09154105e-02],\n         [-7.96606839e-02],\n         [ 2.02128962e-02],\n         [-8.00829381e-03],\n         [ 2.81296521e-02],\n         [-6.88297898e-02],\n         [ 7.20317960e-02],\n         [ 8.42758119e-02],\n         [ 7.56782144e-02],\n         [-5.37575781e-02],\n         [-6.62750527e-02],\n         [ 7.02255517e-02],\n         [-3.22245136e-02],\n         [ 7.34664351e-02],\n         [-8.87734815e-02],\n         [-3.42169814e-02],\n         [-3.47060747e-02],\n         [-5.57857603e-02],\n         [-2.54703313e-03],\n         [-4.43995669e-02],\n         [ 5.99421561e-02],\n         [-2.71768123e-02],\n         [-8.75104219e-03],\n         [ 4.55227345e-02],\n         [-2.82311812e-02],\n         [ 5.33798635e-02],\n         [-7.13920072e-02],\n         [ 6.15008175e-02],\n         [-5.95461167e-02]]],\n\n\n       [[[ 4.09314632e-02],\n         [-3.00359055e-02],\n         [-6.01564422e-02],\n         [-2.70767584e-02],\n         [ 8.66950154e-02],\n         [ 6.30721599e-02],\n         [-4.98142093e-03],\n         [-4.04364951e-02],\n         [-3.98162380e-02],\n         [ 6.16934597e-02],\n         [-7.80112296e-03],\n         [ 4.26832885e-02],\n         [ 8.87503177e-02],\n         [-2.02749744e-02],\n         [ 6.52079284e-03],\n         [-4.29207385e-02],\n         [ 1.52972490e-02],\n         [-3.30999792e-02],\n         [-9.96746123e-04],\n         [ 8.71432871e-02],\n         [-7.61571750e-02],\n         [-8.81171897e-02],\n         [ 7.50855356e-02],\n         [ 3.50174159e-02],\n         [ 4.51110750e-02],\n         [ 3.29613686e-05],\n         [-6.83810562e-02],\n         [-2.18199193e-03],\n         [ 1.70991346e-02],\n         [ 5.43313026e-02],\n         [-3.32697704e-02],\n         [ 1.79088488e-02],\n         [-5.78931496e-02],\n         [ 5.72486520e-02],\n         [-4.73573059e-02],\n         [-8.77198949e-02],\n         [ 2.94127315e-02],\n         [ 4.39245552e-02],\n         [ 5.49036562e-02],\n         [ 4.17197049e-02],\n         [ 4.78607863e-02],\n         [ 9.17787850e-03],\n         [ 5.16690314e-02],\n         [ 5.37209362e-02],\n         [-6.45646378e-02],\n         [-1.89504698e-02],\n         [-2.80972496e-02],\n         [-6.07702956e-02],\n         [-9.09752399e-03],\n         [ 2.38926709e-03],\n         [-2.17687637e-02],\n         [ 1.69982538e-02],\n         [ 1.60267949e-03],\n         [-5.50193079e-02],\n         [-5.46893887e-02],\n         [ 7.89996088e-02],\n         [-4.23323214e-02],\n         [-1.69365481e-02],\n         [-8.10032636e-02],\n         [ 8.76100063e-02],\n         [ 1.64192468e-02],\n         [ 8.16189796e-02],\n         [-3.27221490e-02],\n         [ 7.75498599e-02],\n         [-7.72237033e-03],\n         [-8.04200396e-02],\n         [-3.72867659e-02],\n         [-5.05641103e-04],\n         [-6.10338375e-02],\n         [ 2.92712897e-02],\n         [-3.03162895e-02],\n         [ 6.96438253e-02],\n         [ 3.63813937e-02],\n         [-6.37975782e-02],\n         [-7.93851838e-02],\n         [-9.67326760e-03],\n         [-3.51598896e-02],\n         [ 3.95245105e-03],\n         [-8.70468393e-02],\n         [-8.91821310e-02]],\n\n        [[ 4.83420044e-02],\n         [-8.86211395e-02],\n         [-6.35828376e-02],\n         [-5.52183464e-02],\n         [-4.12087850e-02],\n         [ 3.78708988e-02],\n         [-2.50799134e-02],\n         [ 8.52277875e-03],\n         [-1.03367418e-02],\n         [-6.30564243e-03],\n         [ 1.52819082e-02],\n         [ 4.30926234e-02],\n         [ 4.79936600e-02],\n         [ 4.81131375e-02],\n         [ 5.79863340e-02],\n         [-8.76488388e-02],\n         [-7.12413192e-02],\n         [ 8.82289559e-03],\n         [-7.03447163e-02],\n         [ 2.51292437e-03],\n         [-7.81320632e-02],\n         [-5.88131510e-02],\n         [-5.13185859e-02],\n         [-5.27008995e-02],\n         [ 8.14575255e-02],\n         [ 6.05476648e-02],\n         [ 3.33046839e-02],\n         [ 5.47196865e-02],\n         [-6.85833171e-02],\n         [ 1.86048076e-02],\n         [ 4.11576927e-02],\n         [-6.30540401e-03],\n         [ 6.32075369e-02],\n         [ 7.04057515e-03],\n         [ 2.12824419e-02],\n         [ 3.87721956e-02],\n         [ 8.93926024e-02],\n         [-3.34209427e-02],\n         [-9.00338441e-02],\n         [-2.40196288e-03],\n         [-4.19618487e-02],\n         [-2.56606117e-02],\n         [ 3.69644165e-02],\n         [-7.60750026e-02],\n         [ 6.73455149e-02],\n         [-4.73840199e-02],\n         [ 8.67134631e-02],\n         [ 1.77134573e-03],\n         [-4.07580845e-02],\n         [-8.09224322e-02],\n         [ 8.34113657e-02],\n         [ 5.04807085e-02],\n         [-5.78449778e-02],\n         [-3.32065485e-02],\n         [ 6.15741909e-02],\n         [ 7.22104162e-02],\n         [ 2.03073025e-03],\n         [ 2.50014886e-02],\n         [-5.99884242e-02],\n         [ 7.95099437e-02],\n         [-6.20882437e-02],\n         [ 2.50574872e-02],\n         [ 8.75380933e-02],\n         [ 3.81988734e-02],\n         [-3.58784087e-02],\n         [-7.64407888e-02],\n         [-4.72974367e-02],\n         [-1.57031938e-02],\n         [ 8.40732455e-02],\n         [ 5.64611703e-02],\n         [-6.86501116e-02],\n         [-3.16671990e-02],\n         [-1.21141225e-02],\n         [-6.57598525e-02],\n         [-3.35286595e-02],\n         [ 1.83440745e-04],\n         [ 4.85271513e-02],\n         [-7.28404224e-02],\n         [-2.41426304e-02],\n         [ 8.48646909e-02]],\n\n        [[ 5.40086180e-02],\n         [-5.91942444e-02],\n         [ 3.54364663e-02],\n         [-7.58298561e-02],\n         [-1.15645751e-02],\n         [-4.35891412e-02],\n         [ 5.68303466e-02],\n         [-2.48070806e-02],\n         [-8.09598938e-02],\n         [-8.60085860e-02],\n         [-4.65695523e-02],\n         [ 3.29060033e-02],\n         [ 7.32946247e-02],\n         [-4.12415974e-02],\n         [ 5.93081862e-03],\n         [ 4.22392488e-02],\n         [ 5.22114635e-02],\n         [ 7.57785738e-02],\n         [-4.79519367e-03],\n         [ 2.88132802e-02],\n         [-3.64575014e-02],\n         [ 6.78091496e-02],\n         [ 1.73615739e-02],\n         [-2.07582042e-02],\n         [ 1.40257403e-02],\n         [ 7.80557543e-02],\n         [ 3.89100760e-02],\n         [-8.55767503e-02],\n         [-7.40173906e-02],\n         [ 6.91024363e-02],\n         [ 3.22169065e-03],\n         [ 2.44976431e-02],\n         [ 2.41312534e-02],\n         [-3.76776159e-02],\n         [-4.43982035e-02],\n         [-4.58104126e-02],\n         [ 6.43711537e-02],\n         [-2.89346687e-02],\n         [-3.20175365e-02],\n         [ 6.96352869e-02],\n         [-7.26035386e-02],\n         [-6.58051670e-02],\n         [ 2.13648528e-02],\n         [-3.66676599e-03],\n         [-6.90964609e-02],\n         [ 3.52957845e-02],\n         [-4.54297476e-02],\n         [ 6.65307343e-02],\n         [-6.01144806e-02],\n         [-8.29677209e-02],\n         [-1.71187297e-02],\n         [-6.60229474e-03],\n         [ 2.42938921e-02],\n         [-5.23609668e-02],\n         [-1.13906488e-02],\n         [-3.52183320e-02],\n         [-4.05982211e-02],\n         [ 8.82812887e-02],\n         [-4.34604883e-02],\n         [-9.96544212e-03],\n         [-3.18277366e-02],\n         [ 1.58480033e-02],\n         [-8.30033496e-02],\n         [-6.49069473e-02],\n         [ 2.37236843e-02],\n         [-4.91286144e-02],\n         [ 7.93610215e-02],\n         [-3.11572552e-02],\n         [-3.33710760e-03],\n         [ 1.97163373e-02],\n         [ 8.80932510e-02],\n         [ 8.09532553e-02],\n         [-5.89937158e-02],\n         [ 4.39011753e-02],\n         [-8.83614346e-02],\n         [ 5.19813150e-02],\n         [ 4.68200892e-02],\n         [ 7.40507990e-02],\n         [-4.29757014e-02],\n         [-2.55189762e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/conv2d_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32, numpy=\narray([[[[-0.03761738, -0.09302708, -0.00455803, ...,  0.09968492,\n          -0.08292634, -0.18004176],\n         [ 0.07397097, -0.05770568, -0.09359133, ...,  0.08636907,\n           0.08207563, -0.01524796],\n         [ 0.04500809, -0.07698917,  0.10304452, ..., -0.09371828,\n           0.03791093, -0.16250953],\n         ...,\n         [-0.03889801, -0.07503764,  0.13850221, ..., -0.10007132,\n           0.03929763,  0.07740211],\n         [-0.0008181 ,  0.01029518, -0.14436023, ...,  0.05831387,\n           0.16731787,  0.00278407],\n         [-0.05432349, -0.07435665,  0.11512357, ..., -0.02874178,\n          -0.09887365,  0.02115468]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[-0.10261881,  0.00186404, -0.09650893, ...,  0.09534681,\n           0.27680048,  0.04962253],\n         [-0.01291905, -0.17009313,  0.00516777, ...,  0.117024  ,\n          -0.5519193 , -0.23466766],\n         [ 0.00624772,  0.04299811, -0.11230905, ...,  0.19537391,\n           0.4081307 , -0.02647973],\n         ...,\n         [-0.314635  ,  0.24648157,  0.06411466, ..., -0.35967508,\n           0.39496776, -0.24095005],\n         [-0.09851054,  0.00824645, -0.1350275 , ..., -0.09467279,\n          -0.28634635,  0.20118222],\n         [-0.20103385,  0.07082074,  0.02687496, ..., -0.06844787,\n          -0.02555758,  0.10214295]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/conv2d/kernel:0' shape=(1, 1, 8, 48) dtype=float32, numpy=\narray([[[[-1.30371615e-01,  4.34781075e-01, -2.63606608e-01,\n           2.13728622e-01,  5.38397849e-01, -7.30965734e-01,\n           2.05442011e-02,  2.72836268e-01, -9.61526632e-02,\n          -1.97676629e-01,  6.31961599e-02, -4.35298562e-01,\n           4.06659275e-01,  4.00983930e-01,  1.39350697e-01,\n          -1.07082136e-01, -2.19532400e-01,  3.03581178e-01,\n           9.75310504e-02, -3.49944770e-01, -3.38868380e-01,\n          -7.24230051e-01, -5.44353247e-01,  1.07674621e-01,\n          -2.02909380e-01,  1.24039195e-01, -4.22120541e-01,\n          -6.65409684e-01, -2.15340227e-01, -1.83440134e-01,\n          -5.46591043e-01,  4.54149432e-02, -3.21072280e-01,\n          -6.03864789e-01, -3.95706415e-01,  8.55012536e-02,\n           2.07790121e-01, -8.28182884e-03, -2.48749986e-01,\n           2.77768523e-01, -4.56252933e-01,  1.63866892e-01,\n          -3.35387558e-01, -8.96736607e-02, -1.07812911e-01,\n           6.43281519e-01,  2.23204613e-01,  4.48113441e-01],\n         [ 6.55185759e-01, -5.55557847e-01,  5.82950450e-02,\n          -3.41936380e-01,  1.98506698e-01,  7.40282461e-02,\n          -3.59548390e-01,  6.16541386e-01,  5.34201801e-01,\n           5.03188372e-02, -2.84878444e-03, -3.60877275e-01,\n           3.01806301e-01,  7.78239429e-01,  9.23201814e-02,\n          -3.02196920e-01, -3.74142557e-01,  3.54473665e-02,\n          -4.49993797e-02,  3.29407096e-01, -1.81246951e-01,\n          -2.43523270e-01,  1.64735034e-01, -5.40523976e-02,\n           3.59328836e-01, -1.30323812e-01,  7.11880922e-01,\n           7.40212083e-01, -1.33881375e-01,  6.16194308e-02,\n          -5.38441874e-02,  5.09708188e-03,  4.73726869e-01,\n           6.14206260e-03,  4.43156749e-01, -4.73694354e-02,\n          -3.77877712e-01, -8.59411061e-02,  2.98231304e-01,\n          -3.29143643e-01,  4.27836061e-01, -2.55399108e-01,\n           7.50275552e-01,  2.95219272e-01, -2.79617161e-01,\n           2.34823883e-01, -2.28316277e-01,  1.28759257e-02],\n         [-2.43909493e-01, -1.40647709e-01,  3.53044569e-01,\n           5.43607771e-01,  3.08533698e-01,  3.30507606e-01,\n          -6.00601792e-01,  2.57177532e-01,  6.10143065e-01,\n          -2.53842264e-01, -5.57946801e-01, -6.10121965e-01,\n          -4.22241509e-01, -1.45779595e-01,  2.68900663e-01,\n           4.87116009e-01, -9.39648822e-02, -1.74923763e-01,\n          -9.96524617e-02, -4.79310036e-01,  5.62422812e-01,\n           2.58003682e-01, -3.32977295e-01,  5.05581856e-01,\n          -9.87463370e-02,  1.22005843e-01,  6.50222957e-01,\n          -4.62296247e-01,  2.59927571e-01, -4.55453664e-01,\n           1.39524132e-01,  2.57667005e-01, -1.19908892e-01,\n          -4.53735322e-01, -8.13555941e-02, -1.38005301e-01,\n          -3.10963802e-02, -6.16609395e-01,  2.10809872e-01,\n           4.41926569e-01, -9.22828987e-02,  2.21917108e-02,\n           8.73245224e-02, -1.77177057e-01, -9.73250158e-03,\n           3.23870897e-01, -1.81244999e-01,  5.11008680e-01],\n         [-3.36082697e-01,  3.09857905e-01, -2.78780997e-01,\n          -2.58673787e-01,  1.29167467e-01, -1.06577627e-01,\n          -1.59110114e-01, -1.25208750e-01,  2.89198965e-01,\n          -4.26452249e-01,  2.09363610e-01, -3.92122000e-01,\n          -2.75109380e-01, -1.75988600e-01,  4.58909512e-01,\n          -2.00244665e-01, -2.28982463e-01,  5.42957604e-01,\n           2.70010352e-01, -4.81479466e-02,  3.87907885e-02,\n           2.43521228e-01, -3.51289175e-02, -2.63527334e-01,\n           2.07889736e-01,  9.07293409e-02, -2.51384258e-01,\n          -2.28101879e-01,  1.37124151e-01, -2.41583541e-01,\n          -2.64126539e-01, -4.93406057e-01,  3.44644666e-01,\n           2.08194837e-01,  3.41462553e-01,  1.70319602e-01,\n          -7.22235084e-01,  3.42536092e-01, -3.33575785e-01,\n           4.00603004e-02,  2.95797382e-02, -5.48321724e-01,\n          -4.49197263e-01,  1.99535057e-01, -4.33827579e-01,\n           8.46194923e-02,  4.90510434e-01,  1.03158750e-01],\n         [-6.23774529e-02, -2.06018105e-01,  6.02864549e-02,\n           1.31121233e-01,  3.94064933e-01, -7.98920542e-02,\n          -5.19936025e-01, -1.77942216e-01,  1.14023462e-01,\n          -7.81024933e-01, -2.44508103e-01,  3.14915121e-01,\n           4.98266399e-01,  2.67971531e-02,  7.16745807e-03,\n           6.58785254e-02, -3.74848068e-01, -4.78841402e-02,\n          -1.23381227e-01, -6.53597936e-02,  6.88478425e-02,\n          -4.72472578e-01, -1.91605240e-01, -2.38990456e-01,\n           6.39327645e-01,  9.42275301e-02,  3.27535778e-01,\n           7.85042405e-01,  7.11090624e-01,  2.77356207e-01,\n          -1.42618284e-01,  3.49968761e-01, -3.37542631e-02,\n          -2.46769622e-01,  2.25240812e-02, -5.00006378e-01,\n          -1.73980407e-02, -5.90163767e-01, -3.40581760e-02,\n          -5.86339355e-01,  7.42378116e-01, -3.70029956e-01,\n          -7.99194872e-02, -4.52617258e-01, -2.38281161e-01,\n           4.40894783e-01, -2.81468600e-01, -1.48478588e-02],\n         [ 5.76866679e-02,  5.99527918e-02, -1.59849018e-01,\n          -2.06151139e-02, -3.50611389e-01, -6.26340330e-01,\n           4.06005502e-01,  1.31476391e-02, -2.92590827e-01,\n           6.30301774e-01,  5.17037392e-01, -1.95676252e-01,\n          -3.19275707e-01,  2.68268764e-01,  2.64434814e-01,\n          -5.09364963e-01, -3.89514238e-01,  3.95226270e-01,\n           7.86681920e-02, -2.44901851e-02,  2.62613092e-02,\n           3.33747417e-01, -6.18713677e-01,  2.07166061e-01,\n          -4.67924088e-01, -2.47854307e-01, -4.76317555e-01,\n          -2.15480641e-01,  3.88756633e-01,  5.68588786e-02,\n           1.42194331e-02,  4.45337072e-02,  7.45695651e-01,\n           1.29509017e-01,  3.05707246e-01,  2.91808378e-02,\n          -4.95722800e-01, -4.63369280e-01,  3.27441692e-01,\n           3.29889417e-01,  7.25581348e-01, -2.89845586e-01,\n           1.10017936e-04,  2.22809985e-01,  6.37530625e-01,\n          -5.65512627e-02, -1.40223756e-01, -2.05610245e-01],\n         [-9.20050740e-02, -9.19002518e-02, -3.05859387e-01,\n           3.72999012e-01, -3.64848942e-01,  3.36481541e-01,\n           1.64955139e-01, -7.46131092e-02,  5.16608775e-01,\n          -3.01174045e-01,  2.47647077e-01,  2.49442443e-01,\n          -1.73923865e-01,  3.79293203e-01, -1.96317688e-01,\n           2.70434141e-01, -1.64020136e-01, -6.64107263e-01,\n          -1.65289655e-01,  2.02671945e-01,  5.46404183e-01,\n          -2.92355418e-01,  5.40146604e-02,  2.45934520e-02,\n          -2.24546283e-01,  1.88598827e-01, -3.55933875e-01,\n           1.63007855e-01, -5.02138972e-01,  7.40029573e-01,\n           2.40355730e-01, -2.63393283e-01, -5.39008677e-01,\n           1.75718471e-01, -4.51826096e-01, -5.86757421e-01,\n          -8.68319646e-02,  2.26631295e-02,  1.54240832e-01,\n          -2.30893880e-01,  3.81271064e-01,  1.22051677e-02,\n           3.01055372e-01, -2.26523221e-01,  4.32685018e-01,\n          -2.89458334e-01,  7.70876467e-01,  2.87112683e-01],\n         [-6.86946362e-02, -3.29582065e-01,  2.87968051e-02,\n           4.51442271e-01,  1.85779352e-02, -4.44306672e-01,\n           6.43697858e-01, -5.20319641e-02, -6.39317930e-02,\n          -3.59965384e-01, -5.89129329e-01, -1.40602276e-01,\n          -2.78903514e-01,  3.38965088e-01,  2.29843929e-01,\n          -6.25931680e-01, -5.91522753e-01, -2.07590297e-01,\n           4.98617858e-01, -5.58595136e-02,  3.97536695e-01,\n          -2.38490596e-01, -4.86220509e-01,  4.12451416e-01,\n           2.79874563e-01,  2.80852705e-01,  4.05861996e-02,\n          -5.01023889e-01, -2.62293398e-01, -1.23689428e-01,\n          -4.16729569e-01,  5.37230149e-02, -4.00173604e-01,\n          -1.57297458e-02,  9.78673995e-02, -1.17588557e-01,\n           7.56999910e-01, -4.74577516e-01,  5.85263908e-01,\n          -2.15049103e-01,  9.55235884e-02, -4.91804928e-01,\n           2.19715878e-01,  4.59195942e-01,  1.16604082e-01,\n          -3.55528951e-01,  3.43461663e-01, -2.04408150e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_848/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.00915375,  0.07922173,  0.05572374, ..., -0.09017897,\n           0.07759812,  0.06905492],\n         [-0.11903498, -0.12649974, -0.08317759, ...,  0.20791508,\n           0.22465754,  0.00788698],\n         [ 0.01935739, -0.0347603 , -0.09054393, ..., -0.02241375,\n          -0.04938751, -0.04115076],\n         ...,\n         [ 0.18315037,  0.0811845 , -0.08148584, ...,  0.08541793,\n          -0.16864452,  0.03808182],\n         [-0.12373868, -0.00337576, -0.19018029, ..., -0.11701128,\n           0.15065709, -0.04049372],\n         [ 0.04576219,  0.1178515 , -0.1654289 , ...,  0.03718358,\n          -0.17015322, -0.06578033]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_852/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.00232683, -0.2034802 , -0.03521582, ..., -0.01951274,\n           0.05507628,  0.02393006],\n         [ 0.01362714,  0.16329645,  0.04095648, ..., -0.07993557,\n          -0.0466916 ,  0.04021601],\n         [ 0.01127994,  0.00726154, -0.1984283 , ...,  0.13353664,\n          -0.03450608, -0.02595006],\n         ...,\n         [ 0.00480156,  0.01318917, -0.19670637, ..., -0.06950975,\n           0.07719523, -0.10309383],\n         [ 0.02022886, -0.06834392, -0.02623226, ..., -0.15295224,\n          -0.00376821,  0.04391297],\n         [ 0.08444051,  0.01439427,  0.05817515, ...,  0.04911501,\n           0.01977255, -0.16177143]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_354/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[ 6.52240068e-02],\n         [ 9.90059376e-02],\n         [ 1.28916204e-01],\n         [ 1.22541875e-01],\n         [ 1.33134007e-01],\n         [-1.24415010e-02],\n         [ 6.83899373e-02],\n         [-4.80134934e-02],\n         [ 1.47212148e-01],\n         [ 8.86776447e-02],\n         [ 6.81191534e-02],\n         [-1.36933461e-01],\n         [ 1.59948170e-02],\n         [ 1.99729204e-03],\n         [ 1.61624879e-01],\n         [ 1.08130276e-02],\n         [-8.03222209e-02],\n         [-6.24288097e-02],\n         [-1.17029086e-01],\n         [ 1.24260604e-01],\n         [-3.61075252e-02],\n         [ 8.71927142e-02],\n         [-9.55274999e-02],\n         [ 1.02227002e-01]],\n\n        [[-1.29302114e-01],\n         [-5.29677868e-02],\n         [-7.54742846e-02],\n         [ 7.39828199e-02],\n         [ 1.17655903e-01],\n         [ 1.45157307e-01],\n         [ 1.39297396e-02],\n         [ 1.27525389e-01],\n         [ 1.31117404e-01],\n         [ 4.87599224e-02],\n         [-1.57603621e-03],\n         [-4.18982282e-02],\n         [-1.43140838e-01],\n         [ 9.10517275e-02],\n         [ 1.05135858e-01],\n         [ 8.72172415e-02],\n         [-3.78234833e-02],\n         [-1.09854832e-01],\n         [-1.48266554e-05],\n         [-1.33825690e-02],\n         [ 1.77233070e-02],\n         [-8.80322754e-02],\n         [ 9.68915522e-02],\n         [-1.20830677e-01]],\n\n        [[-1.52912661e-01],\n         [ 1.04539841e-02],\n         [-1.27866790e-01],\n         [-6.87116757e-02],\n         [ 1.53212667e-01],\n         [ 5.72305471e-02],\n         [-1.81117505e-02],\n         [-1.58471018e-02],\n         [ 9.51848924e-03],\n         [-1.07475713e-01],\n         [ 2.71092653e-02],\n         [ 6.52351826e-02],\n         [-1.28496274e-01],\n         [ 1.07269645e-01],\n         [ 4.18805182e-02],\n         [-8.56636465e-03],\n         [ 1.38491154e-01],\n         [-1.12870201e-01],\n         [ 2.52067298e-02],\n         [-9.23469737e-02],\n         [-7.69528300e-02],\n         [ 1.56718522e-01],\n         [ 1.41847253e-01],\n         [ 1.50981247e-01]]],\n\n\n       [[[ 1.15612715e-01],\n         [ 7.52513111e-02],\n         [ 3.03568393e-02],\n         [-3.43554318e-02],\n         [-1.04326651e-01],\n         [-6.60492480e-03],\n         [-1.20138943e-01],\n         [-2.83211917e-02],\n         [ 8.91003013e-02],\n         [-1.53891921e-01],\n         [-6.91871345e-02],\n         [ 6.65346235e-02],\n         [-5.36658317e-02],\n         [ 3.09724510e-02],\n         [-7.31342584e-02],\n         [ 1.38907433e-01],\n         [-1.00144014e-01],\n         [-4.06922400e-03],\n         [-7.73752183e-02],\n         [-6.93918467e-02],\n         [ 9.45885479e-02],\n         [ 1.50894374e-01],\n         [ 8.82004201e-02],\n         [ 1.06200606e-01]],\n\n        [[ 5.25698811e-02],\n         [ 1.38315141e-01],\n         [ 9.27966833e-03],\n         [ 4.35792655e-02],\n         [ 1.59385949e-02],\n         [ 6.64047897e-02],\n         [ 6.64679706e-02],\n         [-1.17619202e-01],\n         [-1.29423678e-01],\n         [ 1.06093585e-01],\n         [-1.09990589e-01],\n         [ 4.63925302e-03],\n         [-8.79362226e-03],\n         [ 5.67833185e-02],\n         [ 1.48648351e-01],\n         [ 4.16786820e-02],\n         [-5.02228960e-02],\n         [-1.27146527e-01],\n         [ 4.83026505e-02],\n         [ 2.97219455e-02],\n         [ 7.98200965e-02],\n         [ 1.41054004e-01],\n         [ 9.28908885e-02],\n         [-5.57319969e-02]],\n\n        [[ 1.75315589e-02],\n         [-1.00096762e-02],\n         [-4.23526764e-03],\n         [ 1.26854628e-02],\n         [-2.89727747e-03],\n         [-1.16087392e-01],\n         [ 7.06425905e-02],\n         [ 1.47367150e-01],\n         [-2.51947492e-02],\n         [-1.20390765e-01],\n         [ 7.00471401e-02],\n         [-7.95526803e-03],\n         [ 1.20374560e-01],\n         [-8.36162344e-02],\n         [ 5.36774099e-03],\n         [-1.18841678e-01],\n         [-1.26130357e-01],\n         [-3.97652537e-02],\n         [ 1.20895803e-01],\n         [ 2.25521624e-02],\n         [-5.53127229e-02],\n         [-3.25261354e-02],\n         [ 1.21469200e-01],\n         [ 1.38733953e-01]]],\n\n\n       [[[ 3.97834331e-02],\n         [ 1.49163812e-01],\n         [-2.21478790e-02],\n         [-8.70692208e-02],\n         [ 1.46821499e-01],\n         [ 2.72739232e-02],\n         [-9.20304060e-02],\n         [-1.40770599e-01],\n         [ 1.44219965e-01],\n         [-1.55585676e-01],\n         [-1.31509155e-02],\n         [ 6.13624156e-02],\n         [ 1.22314483e-01],\n         [ 2.82419622e-02],\n         [ 8.13578218e-02],\n         [ 5.53288460e-02],\n         [ 9.78636444e-02],\n         [ 4.74153459e-03],\n         [-1.57667845e-02],\n         [ 9.97774601e-02],\n         [-9.17739123e-02],\n         [ 8.96225274e-02],\n         [ 2.95868069e-02],\n         [ 8.07301253e-02]],\n\n        [[ 6.49972111e-02],\n         [-3.17596048e-02],\n         [ 3.32279205e-02],\n         [ 2.13889033e-02],\n         [ 3.77313942e-02],\n         [ 1.55904442e-01],\n         [-1.39071181e-01],\n         [ 9.78016257e-02],\n         [-1.48126334e-02],\n         [-5.12042567e-02],\n         [ 1.54785484e-01],\n         [-3.75085026e-02],\n         [ 4.81696129e-02],\n         [ 3.11692208e-02],\n         [ 1.33572131e-01],\n         [ 1.28133476e-01],\n         [-1.27389818e-01],\n         [-1.04279369e-02],\n         [-1.53769046e-01],\n         [ 1.29491448e-01],\n         [ 1.38839006e-01],\n         [-3.78639698e-02],\n         [ 1.10908955e-01],\n         [-1.61532402e-01]],\n\n        [[-4.39729244e-02],\n         [-1.38315827e-01],\n         [-1.17537558e-01],\n         [-1.45617247e-01],\n         [ 1.16562426e-01],\n         [ 1.49718374e-02],\n         [ 2.84336656e-02],\n         [-1.10765018e-01],\n         [ 1.14202261e-01],\n         [ 5.88011742e-02],\n         [ 9.68724489e-02],\n         [-1.25912175e-01],\n         [ 1.50351912e-01],\n         [ 1.09511077e-01],\n         [-1.44106895e-02],\n         [-2.62100548e-02],\n         [ 6.42930269e-02],\n         [-1.18620142e-01],\n         [-1.34632990e-01],\n         [ 1.32978886e-01],\n         [-3.14037949e-02],\n         [-1.18922621e-01],\n         [-1.25461131e-01],\n         [-1.32299349e-01]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_863/kernel:0' shape=(1, 1, 112, 40) dtype=float32, numpy=\narray([[[[-4.11141571e-03,  5.14028668e-02,  1.88590258e-01, ...,\n           1.09885976e-01,  5.87395020e-02,  9.84337851e-02],\n         [-1.25391915e-01, -3.63258226e-03,  1.17762573e-01, ...,\n           1.79382116e-01,  3.93138640e-02, -1.51167496e-03],\n         [-7.33519485e-03, -8.63204449e-02,  6.09833933e-02, ...,\n          -3.09295040e-02,  7.96577930e-02,  9.76926908e-02],\n         ...,\n         [ 1.97812542e-01, -1.43324854e-02, -4.86361720e-02, ...,\n          -2.61177234e-02, -1.29033878e-01, -8.43222216e-02],\n         [-1.17514849e-01,  7.62676671e-02,  5.56366779e-02, ...,\n           3.90190706e-02, -2.36992296e-02, -2.03992680e-01],\n         [-1.29779428e-01, -5.51367957e-05,  6.11162521e-02, ...,\n          -4.13446128e-02, -1.00910733e-03, -4.29802835e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/moving_mean:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_860/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[-0.14280918,  0.08944207, -0.00536764, ...,  0.04808926,\n          -0.22874428, -0.05288725],\n         [-0.040046  ,  0.04191365, -0.0528014 , ...,  0.02481813,\n          -0.02251204,  0.10579248],\n         [ 0.18502708, -0.04964897,  0.23035191, ..., -0.08768127,\n          -0.22695337, -0.01612777],\n         ...,\n         [-0.03270319, -0.02857555,  0.02711721, ..., -0.15849586,\n           0.02381836, -0.14350596],\n         [ 0.16251637, -0.06975949,  0.09996747, ...,  0.02222161,\n           0.12037649,  0.08093608],\n         [-0.09563532,  0.13964333,  0.17470478, ..., -0.0367801 ,\n           0.099773  , -0.23024009]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 3.32582789e-03],\n         [-1.17130531e-02],\n         [ 1.48885278e-02],\n         ...,\n         [ 1.13264993e-02],\n         [-2.33943644e-03],\n         [ 7.31479740e-05]],\n\n        [[-2.20304877e-02],\n         [-7.40307430e-03],\n         [ 1.06865363e-02],\n         ...,\n         [ 1.97748281e-03],\n         [ 5.23314951e-03],\n         [-1.37852854e-03]],\n\n        [[ 5.93560282e-04],\n         [ 1.95680521e-02],\n         [-1.00968806e-02],\n         ...,\n         [ 2.70695658e-03],\n         [ 1.38354534e-02],\n         [-3.93670890e-03]]],\n\n\n       [[[ 1.91939028e-03],\n         [-1.61342565e-02],\n         [ 2.13775318e-02],\n         ...,\n         [-2.70680021e-02],\n         [ 1.06727714e-02],\n         [ 2.34286692e-02]],\n\n        [[-3.78927100e-03],\n         [ 8.22613202e-03],\n         [ 5.86182578e-03],\n         ...,\n         [ 6.76022936e-03],\n         [-1.61515810e-02],\n         [ 1.26128728e-02]],\n\n        [[ 1.53807094e-02],\n         [ 1.70745049e-03],\n         [ 1.95278786e-02],\n         ...,\n         [ 7.11710542e-04],\n         [ 7.52041989e-04],\n         [ 1.68538503e-02]]],\n\n\n       [[[-2.10806518e-03],\n         [ 1.43382081e-03],\n         [ 4.59211646e-03],\n         ...,\n         [-8.86675529e-03],\n         [-1.06040807e-03],\n         [-1.02666160e-02]],\n\n        [[-2.00253967e-02],\n         [ 1.96505580e-02],\n         [ 6.65109092e-03],\n         ...,\n         [-6.07305858e-03],\n         [-7.79461174e-04],\n         [ 1.41850505e-02]],\n\n        [[-2.78654620e-02],\n         [ 1.29442792e-02],\n         [-3.16242711e-03],\n         ...,\n         [ 2.91363578e-02],\n         [-1.58665460e-02],\n         [ 1.40627408e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_843/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[-2.9278424e-01,  4.4285294e-01, -3.4178549e-01, ...,\n          -2.6762027e-01, -3.4465492e-01,  1.6365843e-01],\n         [ 1.7879924e-01,  1.8183777e-01,  3.7378509e-02, ...,\n           1.8761919e-01,  2.4028233e-01,  3.8474981e-02],\n         [-6.6355564e-02, -1.0362403e-01, -2.1356900e-01, ...,\n          -1.8357792e-01, -1.2078777e-01, -3.8993585e-01],\n         ...,\n         [ 2.7171931e-01,  4.4364431e-05, -3.4704161e-01, ...,\n          -6.9470517e-02,  2.4025753e-01, -1.7532812e-01],\n         [ 3.2199988e-01, -7.7251062e-02, -3.2872680e-01, ...,\n          -1.3861954e-01,  1.9196975e-01,  7.4934863e-02],\n         [ 2.7711937e-01,  1.5735106e-01,  1.4614473e-01, ...,\n          -8.7134212e-02, -3.5154852e-03, -1.5122482e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/conv2d/kernel:0' shape=(1, 1, 24, 144) dtype=float32, numpy=\narray([[[[-0.09745612, -0.334278  , -0.06333195, ..., -0.17459834,\n           0.22801118, -0.02319025],\n         [ 0.07986948, -0.03720871, -0.18865833, ...,  0.34430104,\n           0.00423673,  0.26967728],\n         [-0.04505704,  0.19242707, -0.14736629, ..., -0.18781132,\n           0.17052384,  0.10207271],\n         ...,\n         [ 0.18935722, -0.14822224,  0.04780588, ..., -0.29284322,\n           0.2693695 , -0.36066863],\n         [ 0.18947114,  0.09511434, -0.15232453, ...,  0.00888589,\n          -0.25829357, -0.07197316],\n         [ 0.17060845,  0.05940907,  0.2274006 , ..., -0.01121959,\n          -0.2323091 , -0.32475132]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.08956286, -0.13818696,  0.00412288, ..., -0.0019808 ,\n           0.16719177,  0.01161483],\n         [-0.01176096, -0.20416044,  0.09813652, ..., -0.19268797,\n           0.08704478,  0.09809109],\n         [-0.13807404, -0.10888782, -0.02586967, ..., -0.03034157,\n          -0.0376758 , -0.03446921],\n         ...,\n         [-0.10040066,  0.06523328,  0.10319647, ...,  0.10061502,\n           0.01301018, -0.08359861],\n         [-0.03302679, -0.07848048,  0.00971641, ...,  0.0357466 ,\n           0.03501476,  0.10530565],\n         [ 0.06057967,  0.02290075, -0.14311811, ...,  0.01129883,\n          -0.12733826, -0.13624685]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/moving_mean:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_375/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 7.28526711e-02],\n         [ 3.91445011e-02],\n         [-6.39508516e-02],\n         [-6.31077215e-02],\n         [ 3.67473811e-02],\n         [-7.31304809e-02],\n         [ 4.47591394e-02],\n         [-5.83743677e-02],\n         [-1.28615424e-02],\n         [-4.29154187e-02],\n         [ 3.80232185e-02],\n         [-2.10484117e-02],\n         [-5.78490011e-02],\n         [-4.20733914e-02],\n         [ 4.71396744e-02],\n         [-8.78891870e-02],\n         [-1.12204030e-02],\n         [-3.06511186e-02],\n         [ 2.61844173e-02],\n         [-3.27773690e-02],\n         [ 3.83582860e-02],\n         [-8.37524980e-02],\n         [-4.99225780e-02],\n         [-9.04571638e-02],\n         [-7.90802240e-02],\n         [ 5.13298959e-02],\n         [ 4.24787402e-02],\n         [-8.31413642e-02],\n         [ 2.94446722e-02],\n         [-3.57979238e-02],\n         [ 5.77078015e-02],\n         [-5.39896451e-02],\n         [-7.61882588e-02],\n         [-5.06312549e-02],\n         [ 3.29263508e-03],\n         [ 8.68127793e-02],\n         [-6.72610700e-02],\n         [ 2.01254040e-02],\n         [ 6.29937500e-02],\n         [-1.49826184e-02],\n         [-4.08788435e-02],\n         [ 1.57074556e-02],\n         [-1.89496055e-02],\n         [-7.11138099e-02],\n         [ 1.96378231e-02],\n         [-3.23298499e-02],\n         [-2.83720978e-02],\n         [ 4.06721532e-02],\n         [ 1.99259967e-02],\n         [ 9.23228264e-03],\n         [ 8.45717192e-02],\n         [-6.02978617e-02],\n         [-4.15782630e-02],\n         [ 1.69800222e-03],\n         [ 3.31348479e-02],\n         [-2.01477036e-02],\n         [ 1.32120699e-02],\n         [ 9.02311504e-02],\n         [ 6.19045198e-02],\n         [ 1.05432197e-02],\n         [-4.43278626e-02],\n         [-4.06676941e-02],\n         [ 7.36607611e-02],\n         [-7.12154210e-02],\n         [-6.12200648e-02],\n         [ 1.09027028e-02],\n         [ 5.28709590e-02],\n         [-1.15410239e-03],\n         [ 1.31675825e-02],\n         [ 7.34428167e-02],\n         [-4.25008833e-02],\n         [ 6.53146654e-02],\n         [ 1.09130889e-03],\n         [ 6.44366294e-02],\n         [ 7.04599023e-02],\n         [-3.00244167e-02],\n         [ 3.55179906e-02],\n         [-4.90318649e-02],\n         [-1.36217177e-02],\n         [-4.81713675e-02]],\n\n        [[ 4.62757051e-02],\n         [-2.58250833e-02],\n         [-7.21080154e-02],\n         [ 9.05430466e-02],\n         [-2.11749226e-03],\n         [-7.01871440e-02],\n         [-4.72018123e-03],\n         [-4.03886475e-02],\n         [-5.85400946e-02],\n         [-5.54201081e-02],\n         [ 4.69406992e-02],\n         [-3.64886485e-02],\n         [-4.16579694e-02],\n         [ 2.83201188e-02],\n         [ 7.65908808e-02],\n         [-7.60929808e-02],\n         [-5.05150110e-03],\n         [ 6.86824918e-02],\n         [-6.81118369e-02],\n         [ 8.75195861e-02],\n         [-2.30789185e-04],\n         [-1.31695047e-02],\n         [ 8.87021422e-02],\n         [-2.26044357e-02],\n         [-3.54580544e-02],\n         [-5.81807829e-02],\n         [ 3.62536311e-03],\n         [ 6.06642962e-02],\n         [ 6.81681186e-02],\n         [ 8.49124789e-02],\n         [-4.76897359e-02],\n         [ 8.26724321e-02],\n         [ 2.88121551e-02],\n         [ 6.77885115e-02],\n         [-5.72916679e-02],\n         [-4.97065187e-02],\n         [-4.61204946e-02],\n         [ 6.69550449e-02],\n         [ 5.75452596e-02],\n         [ 1.87550262e-02],\n         [ 3.09696421e-02],\n         [ 2.84730420e-02],\n         [ 6.92687482e-02],\n         [-7.22421706e-03],\n         [-4.83463518e-02],\n         [ 5.53288311e-02],\n         [-2.53829509e-02],\n         [-3.32420208e-02],\n         [-7.15535432e-02],\n         [ 5.72077185e-02],\n         [ 8.14914703e-02],\n         [-7.57064149e-02],\n         [ 1.10599548e-02],\n         [ 3.30481529e-02],\n         [ 4.26735133e-02],\n         [-1.02517530e-02],\n         [-1.97751969e-02],\n         [ 5.86749762e-02],\n         [-5.81355765e-02],\n         [-1.45111308e-02],\n         [-2.73989290e-02],\n         [-5.73280044e-02],\n         [-5.38819283e-02],\n         [ 7.53278434e-02],\n         [ 4.84479219e-02],\n         [-2.25935727e-02],\n         [-1.58716887e-02],\n         [-6.39434084e-02],\n         [-4.47247177e-03],\n         [ 7.38793910e-02],\n         [-2.59153023e-02],\n         [ 5.63204437e-02],\n         [-7.31931180e-02],\n         [ 8.39896202e-02],\n         [ 8.25551152e-02],\n         [ 6.70854151e-02],\n         [-3.38122882e-02],\n         [ 2.52601504e-03],\n         [-3.29485685e-02],\n         [ 1.38396397e-02]],\n\n        [[ 2.39235908e-02],\n         [-7.78282285e-02],\n         [-4.27635126e-02],\n         [ 7.72383809e-03],\n         [-1.91079825e-02],\n         [ 8.21057707e-02],\n         [-5.23586534e-02],\n         [ 5.67113012e-02],\n         [-6.30102158e-02],\n         [-8.59436765e-02],\n         [ 8.95319730e-02],\n         [-5.68731539e-02],\n         [-7.90156573e-02],\n         [ 6.28039241e-02],\n         [-5.33127859e-02],\n         [-8.18330273e-02],\n         [-4.84556705e-03],\n         [ 8.82065594e-02],\n         [ 6.33682907e-02],\n         [ 4.38508838e-02],\n         [-4.27640304e-02],\n         [ 1.56025738e-02],\n         [-1.27395913e-02],\n         [-7.49242827e-02],\n         [ 2.25714669e-02],\n         [-4.97327335e-02],\n         [ 3.98306698e-02],\n         [ 7.50660598e-02],\n         [-4.83244173e-02],\n         [-6.62696436e-02],\n         [-6.51264936e-02],\n         [ 3.22473124e-02],\n         [ 1.40005872e-02],\n         [ 3.74150723e-02],\n         [-8.12330619e-02],\n         [ 4.01631296e-02],\n         [ 4.35336679e-02],\n         [ 5.01673669e-02],\n         [ 6.66476488e-02],\n         [-8.52683932e-02],\n         [ 8.89491588e-02],\n         [-5.32492585e-02],\n         [ 5.59690297e-02],\n         [ 8.48520249e-02],\n         [ 6.21380806e-02],\n         [ 1.77809969e-02],\n         [-4.85179834e-02],\n         [-2.54385844e-02],\n         [ 3.14597040e-02],\n         [-6.35620952e-03],\n         [-7.25790262e-02],\n         [ 1.23655051e-03],\n         [ 3.53514403e-02],\n         [-6.95085302e-02],\n         [ 2.95031443e-02],\n         [ 6.24273717e-02],\n         [-8.72204155e-02],\n         [-4.34413441e-02],\n         [-2.56279483e-02],\n         [ 7.19954818e-02],\n         [-8.49455744e-02],\n         [-6.08063564e-02],\n         [-2.84376815e-02],\n         [ 7.50489384e-02],\n         [ 9.05153304e-02],\n         [ 8.43357593e-02],\n         [-7.76858181e-02],\n         [-1.72115490e-02],\n         [ 5.31002134e-03],\n         [ 7.01328814e-02],\n         [ 1.23187900e-03],\n         [-5.38202636e-02],\n         [ 6.26412928e-02],\n         [-3.02521586e-02],\n         [-1.57721713e-02],\n         [ 3.11933756e-02],\n         [ 8.04249495e-02],\n         [ 2.51883715e-02],\n         [ 8.37349296e-02],\n         [-6.06787801e-02]]],\n\n\n       [[[-6.45292476e-02],\n         [ 5.92107028e-02],\n         [ 7.81022161e-02],\n         [-6.03320785e-02],\n         [-1.24569088e-02],\n         [-5.86593188e-02],\n         [ 2.42691040e-02],\n         [ 1.03452802e-02],\n         [-7.08597898e-02],\n         [ 3.28399912e-02],\n         [ 6.88751638e-02],\n         [-8.69218409e-02],\n         [-1.65227875e-02],\n         [-1.00378394e-02],\n         [ 8.04901123e-02],\n         [ 2.57906318e-02],\n         [ 5.30617088e-02],\n         [ 7.15420097e-02],\n         [-1.75978318e-02],\n         [-1.33280903e-02],\n         [-6.22303784e-03],\n         [-8.48682895e-02],\n         [-6.67356700e-03],\n         [-8.15484449e-02],\n         [-3.58800516e-02],\n         [ 6.72456920e-02],\n         [-7.22610950e-02],\n         [ 5.54762781e-02],\n         [-4.18212526e-02],\n         [ 7.74023682e-03],\n         [ 5.67029417e-02],\n         [-4.40338701e-02],\n         [-6.00254536e-02],\n         [-2.29021460e-02],\n         [-4.20210473e-02],\n         [ 2.32432261e-02],\n         [-2.49869302e-02],\n         [ 3.10644507e-04],\n         [ 5.61808497e-02],\n         [-8.32912847e-02],\n         [-7.22687691e-03],\n         [ 7.24358559e-02],\n         [ 4.31810915e-02],\n         [-8.19243267e-02],\n         [-3.16147059e-02],\n         [-6.11914508e-02],\n         [ 4.95075285e-02],\n         [-3.65194678e-03],\n         [-3.83653566e-02],\n         [-4.84741814e-02],\n         [ 1.26120597e-02],\n         [-4.98397350e-02],\n         [-1.47620812e-02],\n         [-2.79058442e-02],\n         [-1.61395967e-02],\n         [-2.40207091e-02],\n         [-3.43447290e-02],\n         [ 6.28131628e-02],\n         [ 8.38486105e-02],\n         [ 2.44739130e-02],\n         [ 6.85842484e-02],\n         [ 1.79838613e-02],\n         [ 3.87794524e-02],\n         [-5.91459014e-02],\n         [-8.94113630e-02],\n         [ 3.66023183e-02],\n         [ 4.77886200e-03],\n         [-6.11699745e-02],\n         [-6.75247759e-02],\n         [ 7.96788037e-02],\n         [ 2.46819481e-02],\n         [ 4.85255569e-02],\n         [ 5.26346713e-02],\n         [ 3.84855568e-02],\n         [ 5.35493493e-02],\n         [ 1.12749338e-02],\n         [ 7.00348467e-02],\n         [ 3.29278931e-02],\n         [ 5.33177555e-02],\n         [ 2.10506544e-02]],\n\n        [[-1.21623576e-02],\n         [ 5.29654920e-02],\n         [ 1.51195154e-02],\n         [ 8.24648291e-02],\n         [-1.44273043e-04],\n         [ 3.69461030e-02],\n         [ 7.65410364e-02],\n         [ 4.07844335e-02],\n         [ 4.88101840e-02],\n         [-1.52005628e-02],\n         [-6.16517551e-02],\n         [ 4.75083441e-02],\n         [-4.54016067e-02],\n         [ 2.66244113e-02],\n         [ 1.92684531e-02],\n         [-8.48959088e-02],\n         [ 3.86045873e-02],\n         [ 5.45019954e-02],\n         [ 2.64833868e-02],\n         [-3.06036435e-02],\n         [-3.23637649e-02],\n         [ 7.90831894e-02],\n         [-6.42551333e-02],\n         [ 8.07065070e-02],\n         [-6.37669489e-02],\n         [-7.24608451e-02],\n         [-6.64085895e-03],\n         [ 1.83803141e-02],\n         [-6.06310889e-02],\n         [ 1.77292079e-02],\n         [ 1.35261565e-03],\n         [ 8.48597884e-02],\n         [-1.24683753e-02],\n         [-2.40745023e-02],\n         [ 8.92076492e-02],\n         [-1.39553323e-02],\n         [-7.14166239e-02],\n         [-4.36916240e-02],\n         [ 7.47563839e-02],\n         [-3.12002748e-03],\n         [ 2.85837874e-02],\n         [-6.52426854e-02],\n         [ 6.30641282e-02],\n         [-2.29202062e-02],\n         [ 5.83567172e-02],\n         [-7.60480538e-02],\n         [-1.40582472e-02],\n         [ 1.08334869e-02],\n         [-1.87237263e-02],\n         [-4.03244048e-03],\n         [-3.70869488e-02],\n         [-7.45608807e-02],\n         [-6.19382188e-02],\n         [-2.57476717e-02],\n         [ 3.40063944e-02],\n         [-7.05833733e-03],\n         [-8.88556913e-02],\n         [-3.27655822e-02],\n         [ 5.68879545e-02],\n         [ 7.18395263e-02],\n         [-8.37288797e-04],\n         [ 3.64573747e-02],\n         [-6.44081011e-02],\n         [ 3.59052569e-02],\n         [ 2.05766410e-03],\n         [ 7.05627650e-02],\n         [-1.75697580e-02],\n         [ 8.53126645e-02],\n         [-7.65192807e-02],\n         [-3.68560962e-02],\n         [ 1.94528475e-02],\n         [ 2.19369158e-02],\n         [-2.82381251e-02],\n         [ 7.23967105e-02],\n         [-3.26840580e-02],\n         [-6.19024001e-02],\n         [ 4.26062346e-02],\n         [ 8.90039653e-02],\n         [ 6.94471747e-02],\n         [ 2.65241787e-02]],\n\n        [[ 3.58991772e-02],\n         [-2.19213888e-02],\n         [ 7.89450556e-02],\n         [ 7.21188635e-03],\n         [-3.38188633e-02],\n         [-6.61256313e-02],\n         [ 5.96107244e-02],\n         [-7.21037388e-03],\n         [-6.26206174e-02],\n         [-1.53709427e-02],\n         [ 2.22101808e-05],\n         [-2.25255713e-02],\n         [-5.94106279e-02],\n         [ 7.82922357e-02],\n         [ 5.65600991e-02],\n         [-9.05037969e-02],\n         [-7.91293457e-02],\n         [ 8.48160535e-02],\n         [ 3.97062153e-02],\n         [ 1.05723962e-02],\n         [ 8.48913491e-02],\n         [ 4.36604917e-02],\n         [ 5.44806570e-02],\n         [ 7.81931281e-02],\n         [-3.88777219e-02],\n         [ 4.86341417e-02],\n         [ 6.42189085e-02],\n         [-4.16465290e-02],\n         [-4.36720476e-02],\n         [ 6.86544776e-02],\n         [ 3.56316417e-02],\n         [-7.78677687e-02],\n         [-8.03625062e-02],\n         [-1.17933303e-02],\n         [ 4.02844101e-02],\n         [ 7.01662302e-02],\n         [-4.15936857e-02],\n         [-6.22089952e-03],\n         [ 2.39614174e-02],\n         [ 7.53175318e-02],\n         [ 8.15684348e-03],\n         [ 2.72658244e-02],\n         [ 2.41537318e-02],\n         [-7.66857639e-02],\n         [ 7.07298964e-02],\n         [ 2.22469121e-02],\n         [ 4.10579145e-04],\n         [-7.72103295e-02],\n         [-3.41709554e-02],\n         [ 2.04440951e-02],\n         [ 8.94210488e-02],\n         [-3.79000790e-02],\n         [-4.78236005e-02],\n         [-6.66265637e-02],\n         [ 1.22942999e-02],\n         [-3.02282572e-02],\n         [ 2.87827626e-02],\n         [ 5.47830015e-02],\n         [-8.94605666e-02],\n         [ 1.39472485e-02],\n         [-6.56372160e-02],\n         [-2.02482939e-03],\n         [-4.17416766e-02],\n         [ 3.36340144e-02],\n         [-5.62084466e-03],\n         [-2.39717811e-02],\n         [ 3.61047238e-02],\n         [-1.90365985e-02],\n         [ 2.50247419e-02],\n         [-9.73640382e-03],\n         [-4.57206033e-02],\n         [ 1.54397637e-03],\n         [-6.20981306e-02],\n         [ 6.28499985e-02],\n         [ 8.22631270e-02],\n         [-7.43961260e-02],\n         [ 4.32961881e-02],\n         [ 7.43341744e-02],\n         [-6.02664761e-02],\n         [ 3.11856121e-02]]],\n\n\n       [[[-5.20213693e-03],\n         [-2.19637826e-02],\n         [-3.77196223e-02],\n         [ 4.07761186e-02],\n         [-7.14565814e-03],\n         [ 3.54129076e-03],\n         [-4.71006706e-02],\n         [ 7.57009536e-03],\n         [-2.32786313e-02],\n         [-5.37906066e-02],\n         [ 4.62897122e-04],\n         [-8.32235366e-02],\n         [ 1.74269751e-02],\n         [ 6.59563839e-02],\n         [ 7.09928721e-02],\n         [-5.89797869e-02],\n         [ 5.53059280e-02],\n         [ 1.83107704e-02],\n         [-8.65707695e-02],\n         [ 1.46503001e-02],\n         [-3.41665745e-03],\n         [-2.09388509e-02],\n         [ 3.61965895e-02],\n         [-2.57043019e-02],\n         [-4.13442738e-02],\n         [ 3.66648883e-02],\n         [ 7.06093758e-02],\n         [-1.04917139e-02],\n         [-9.60182399e-03],\n         [ 7.88238943e-02],\n         [ 6.63465858e-02],\n         [-1.99260190e-02],\n         [ 8.30671191e-02],\n         [-3.56917232e-02],\n         [ 6.04331791e-02],\n         [ 4.92124557e-02],\n         [-2.97531597e-02],\n         [ 8.06064457e-02],\n         [ 2.04716325e-02],\n         [ 8.36217701e-02],\n         [ 8.10841769e-02],\n         [-6.70549572e-02],\n         [ 6.92291558e-02],\n         [ 4.54470813e-02],\n         [ 6.27386719e-02],\n         [ 5.56920022e-02],\n         [ 4.55170423e-02],\n         [-2.96245515e-03],\n         [ 5.07221669e-02],\n         [ 2.14390829e-02],\n         [ 6.56091422e-02],\n         [ 5.14369905e-02],\n         [ 5.46939522e-02],\n         [-3.30587067e-02],\n         [ 4.83030230e-02],\n         [-1.78910047e-02],\n         [ 7.58766681e-02],\n         [-5.74244745e-02],\n         [ 2.39480734e-02],\n         [-4.82290238e-03],\n         [-4.95301932e-02],\n         [ 5.38721234e-02],\n         [ 5.00237197e-02],\n         [-4.83359247e-02],\n         [-5.05763143e-02],\n         [-6.23033494e-02],\n         [-4.20674235e-02],\n         [-9.05465111e-02],\n         [-3.99482027e-02],\n         [ 3.90249193e-02],\n         [-1.12568289e-02],\n         [ 5.15080988e-02],\n         [ 6.01397753e-02],\n         [ 2.47998312e-02],\n         [-9.68587399e-03],\n         [ 7.49327540e-02],\n         [-7.03932345e-03],\n         [ 7.57514536e-02],\n         [ 2.76690423e-02],\n         [ 8.85081440e-02]],\n\n        [[-2.69516259e-02],\n         [-4.10125814e-02],\n         [ 7.35234916e-02],\n         [ 8.16970617e-02],\n         [ 1.52361393e-02],\n         [ 2.40282789e-02],\n         [-1.18974149e-02],\n         [-1.83764622e-02],\n         [-8.21487308e-02],\n         [ 6.77241683e-02],\n         [ 1.93463862e-02],\n         [ 5.81960082e-02],\n         [-3.33017409e-02],\n         [ 7.94080496e-02],\n         [ 6.07161373e-02],\n         [-1.90438479e-02],\n         [-8.36869329e-02],\n         [ 2.54070014e-02],\n         [ 6.19752258e-02],\n         [ 1.21858492e-02],\n         [-1.63578391e-02],\n         [-2.49555707e-02],\n         [ 2.37797722e-02],\n         [-2.58512795e-03],\n         [-1.89727694e-02],\n         [ 8.93401355e-02],\n         [ 2.34006494e-02],\n         [ 3.11205909e-02],\n         [-6.33499473e-02],\n         [-3.11338529e-02],\n         [-3.71104851e-02],\n         [ 6.31003231e-02],\n         [-5.30763045e-02],\n         [-5.65596297e-02],\n         [ 2.24169865e-02],\n         [ 3.96944880e-02],\n         [-2.81705335e-02],\n         [-4.76664603e-02],\n         [ 3.15203741e-02],\n         [ 9.03030336e-02],\n         [ 3.90864909e-02],\n         [ 6.73514605e-03],\n         [ 2.74865776e-02],\n         [ 5.98396510e-02],\n         [-5.45834042e-02],\n         [ 1.20051503e-02],\n         [-1.88664868e-02],\n         [-7.79642165e-02],\n         [-3.52930203e-02],\n         [-8.58702213e-02],\n         [-8.66241083e-02],\n         [ 8.11291337e-02],\n         [ 3.21400911e-02],\n         [-8.24979469e-02],\n         [-3.66144255e-02],\n         [ 8.18242878e-02],\n         [-1.73285604e-02],\n         [-4.01591584e-02],\n         [-8.57183337e-03],\n         [-1.86419636e-02],\n         [ 3.52422744e-02],\n         [ 3.31092775e-02],\n         [ 7.63025582e-02],\n         [ 2.61156186e-02],\n         [ 3.21216434e-02],\n         [ 7.59961456e-02],\n         [ 6.88882321e-02],\n         [-7.30101988e-02],\n         [ 8.02195519e-02],\n         [ 1.46322399e-02],\n         [ 5.47381938e-02],\n         [-6.55098334e-02],\n         [ 8.36387873e-02],\n         [ 3.78289670e-02],\n         [-4.01978977e-02],\n         [ 6.92487955e-02],\n         [-1.41672865e-02],\n         [ 3.78771871e-03],\n         [ 7.58820474e-02],\n         [ 2.45139301e-02]],\n\n        [[-8.75632465e-02],\n         [ 3.81730050e-02],\n         [-7.02923983e-02],\n         [ 4.54707444e-03],\n         [-1.28340498e-02],\n         [-5.77332415e-02],\n         [-2.59560123e-02],\n         [-7.11853057e-03],\n         [-6.90874457e-02],\n         [-6.97539672e-02],\n         [-4.17058356e-02],\n         [-2.74846479e-02],\n         [-2.27770358e-02],\n         [ 3.00727189e-02],\n         [-6.93260431e-02],\n         [-5.61822206e-03],\n         [-1.46241933e-02],\n         [ 6.04444295e-02],\n         [-9.06875804e-02],\n         [ 1.17953420e-02],\n         [ 3.78113985e-02],\n         [-8.73811468e-02],\n         [ 5.08337766e-02],\n         [ 8.52825493e-03],\n         [-8.03018957e-02],\n         [ 6.82555139e-02],\n         [ 2.15331092e-02],\n         [ 1.08911321e-02],\n         [ 3.16039473e-03],\n         [ 5.94700277e-02],\n         [-1.25440583e-02],\n         [ 3.51771563e-02],\n         [-6.95152134e-02],\n         [ 1.12152100e-02],\n         [ 3.27402949e-02],\n         [ 1.67923421e-02],\n         [-9.31046903e-03],\n         [ 7.73964822e-02],\n         [-5.00286072e-02],\n         [-9.07859951e-03],\n         [-5.86229600e-02],\n         [ 9.00965035e-02],\n         [ 1.16679445e-02],\n         [-6.64077699e-02],\n         [ 5.69244176e-02],\n         [-1.73060223e-02],\n         [ 7.85260648e-03],\n         [ 3.87496948e-02],\n         [-7.69980997e-02],\n         [ 5.48219681e-03],\n         [ 2.23567039e-02],\n         [-1.48245245e-02],\n         [ 5.86138368e-02],\n         [ 5.43331355e-03],\n         [-1.51099265e-03],\n         [ 8.90380740e-02],\n         [-5.33448830e-02],\n         [ 1.90043300e-02],\n         [-6.67307079e-02],\n         [ 5.07788807e-02],\n         [-1.80894956e-02],\n         [ 6.81499839e-02],\n         [-2.52219588e-02],\n         [ 5.51844239e-02],\n         [-7.91102275e-02],\n         [ 2.81816050e-02],\n         [-3.06402892e-03],\n         [ 5.25378436e-03],\n         [ 1.63437352e-02],\n         [ 8.58665705e-02],\n         [-7.46324733e-02],\n         [ 1.30385160e-04],\n         [-6.13871813e-02],\n         [ 7.35837370e-02],\n         [ 2.48128101e-02],\n         [ 5.68893999e-02],\n         [-1.42303333e-02],\n         [ 2.09796876e-02],\n         [-2.04328895e-02],\n         [ 8.32817405e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.05046272,  0.06007591, -0.02920844, ...,  0.02695721,\n          -0.01326844, -0.03726521],\n         [ 0.05706462,  0.02744764,  0.037237  , ...,  0.07600765,\n          -0.00168458,  0.04729273],\n         [-0.0384852 ,  0.00893573,  0.03269324, ..., -0.03219349,\n           0.01390442,  0.04274791],\n         ...,\n         [-0.02346644, -0.03999086, -0.01793195, ...,  0.08061599,\n          -0.03513735, -0.06844829],\n         [-0.05227693, -0.00788052,  0.01526452, ..., -0.04924746,\n           0.02425674, -0.01305424],\n         [-0.04080801,  0.06984993,  0.00050349, ...,  0.03508027,\n           0.00279753, -0.00581829]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01144962],\n         [ 0.02522507],\n         [-0.01131751],\n         ...,\n         [ 0.01826764],\n         [ 0.00782056],\n         [-0.01422861]],\n\n        [[ 0.02786309],\n         [-0.01285985],\n         [ 0.00374615],\n         ...,\n         [ 0.00175806],\n         [-0.00141138],\n         [-0.00010296]],\n\n        [[-0.01370689],\n         [ 0.00137622],\n         [-0.02509689],\n         ...,\n         [ 0.01128416],\n         [ 0.01138466],\n         [ 0.01225852]]],\n\n\n       [[[ 0.00208863],\n         [-0.01050105],\n         [-0.0024422 ],\n         ...,\n         [ 0.00156199],\n         [-0.00830486],\n         [-0.00059284]],\n\n        [[-0.00083528],\n         [ 0.02613376],\n         [ 0.00016552],\n         ...,\n         [ 0.0114587 ],\n         [ 0.01363227],\n         [ 0.01592212]],\n\n        [[-0.01017836],\n         [ 0.00562024],\n         [-0.01465356],\n         ...,\n         [-0.009613  ],\n         [-0.00612751],\n         [ 0.01239023]]],\n\n\n       [[[ 0.01934545],\n         [ 0.02392575],\n         [-0.00412514],\n         ...,\n         [ 0.02466849],\n         [ 0.00622535],\n         [-0.01682848]],\n\n        [[-0.00793513],\n         [ 0.00026329],\n         [ 0.00282742],\n         ...,\n         [ 0.01251697],\n         [ 0.00365846],\n         [-0.01177709]],\n\n        [[-0.00191799],\n         [ 0.01195622],\n         [-0.02108802],\n         ...,\n         [-0.00195901],\n         [-0.00041844],\n         [-0.00324453]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_861/kernel:0' shape=(1, 1, 112, 80) dtype=float32, numpy=\narray([[[[-0.1266359 ,  0.11045039, -0.03257483, ...,  0.07228381,\n           0.06834248, -0.07762287],\n         [-0.16911368, -0.01613282,  0.07163119, ..., -0.12762032,\n          -0.05904778, -0.11796178],\n         [ 0.03248651,  0.01917007, -0.12805067, ...,  0.04459731,\n           0.10522509, -0.10257526],\n         ...,\n         [-0.08092996,  0.04544629, -0.00177636, ..., -0.11388078,\n          -0.05956727,  0.04600402],\n         [ 0.02566099, -0.04777094, -0.13341656, ..., -0.12184227,\n          -0.04191307,  0.07000085],\n         [ 0.03580611, -0.02664511,  0.04335059, ..., -0.02161285,\n          -0.08119968,  0.07324789]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.00416902, -0.01898808,  0.02853693, ...,  0.06837913,\n           0.02416613, -0.06433212],\n         [-0.02656428,  0.02689713, -0.03186426, ...,  0.05149912,\n          -0.04246094, -0.03491492],\n         [-0.07809218, -0.04906044,  0.00901009, ...,  0.00561639,\n          -0.06340251, -0.04208315],\n         ...,\n         [ 0.01357094,  0.04832734,  0.01906479, ...,  0.00054336,\n           0.06311432,  0.03820171],\n         [ 0.02446797,  0.07116729, -0.03334276, ...,  0.01078002,\n           0.03525599, -0.02559269],\n         [ 0.00216287, -0.00390734, -0.02744069, ..., -0.02525058,\n          -0.00974055,  0.05592157]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00596912,  0.0758737 , -0.08659466, ..., -0.15314297,\n           0.02904191,  0.13496634],\n         [ 0.09821804, -0.12494116, -0.44603696, ...,  0.3416884 ,\n           0.13141416, -0.10054888],\n         [ 0.23386914,  0.17276263,  0.387499  , ...,  0.4686871 ,\n          -0.05558596,  0.13330305],\n         ...,\n         [-0.203752  ,  0.27078813,  0.08690373, ..., -0.06087269,\n           0.0969606 , -0.06011502],\n         [ 0.17658928,  0.06154617,  0.34182596, ...,  0.12908584,\n           0.15245552,  0.1921593 ],\n         [ 0.3073045 ,  0.28113583, -0.12928748, ..., -0.10187806,\n          -0.13608174, -0.10338311]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/beta:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_853/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.1405574 , -0.15207475, -0.19598041, ..., -0.24251375,\n          -0.02895492,  0.14112568],\n         [ 0.1620136 , -0.01453277,  0.00345453, ...,  0.05906699,\n          -0.03833256,  0.05401867],\n         [ 0.00525054, -0.06357087,  0.01641294, ...,  0.01251843,\n           0.1384145 ,  0.0905272 ],\n         ...,\n         [ 0.07684722, -0.13383977, -0.03951751, ..., -0.05140214,\n          -0.01182997, -0.08430993],\n         [-0.1596365 ,  0.03952034, -0.19004981, ..., -0.2123555 ,\n           0.12149116, -0.12049357],\n         [ 0.03327164,  0.04261284, -0.2406582 , ...,  0.0953455 ,\n           0.07206927, -0.00386533]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.05811423,  0.1362503 , -0.12640454, ...,  0.0612675 ,\n           0.05936417,  0.06814434],\n         [ 0.24953778,  0.06517745,  0.13785414, ..., -0.19750279,\n           0.24649715,  0.03465299],\n         [-0.0102851 ,  0.12188665,  0.23886727, ...,  0.23105785,\n           0.10654452, -0.00086309],\n         ...,\n         [ 0.14659844, -0.08938524,  0.09506432, ...,  0.12803504,\n           0.01484074, -0.17030828],\n         [-0.06372221,  0.11837038, -0.01875271, ..., -0.07410306,\n           0.09678932, -0.21423241],\n         [ 0.15846486,  0.07074511, -0.07767498, ..., -0.08270313,\n          -0.11419809, -0.04867493]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32, numpy=\narray([[[[ 0.00956689],\n         [ 0.0356406 ],\n         [ 0.01431889],\n         ...,\n         [ 0.05390378],\n         [ 0.01126917],\n         [-0.01312892]],\n\n        [[-0.02744819],\n         [-0.00426563],\n         [ 0.02238767],\n         ...,\n         [-0.00807348],\n         [ 0.00312854],\n         [-0.00839325]],\n\n        [[ 0.00305651],\n         [ 0.00924495],\n         [-0.05652652],\n         ...,\n         [-0.01232098],\n         [-0.03633439],\n         [ 0.00542196]]],\n\n\n       [[[-0.01142122],\n         [ 0.00742836],\n         [ 0.02056395],\n         ...,\n         [ 0.01201878],\n         [-0.03293453],\n         [ 0.04826012]],\n\n        [[-0.04431771],\n         [ 0.02888767],\n         [-0.00551713],\n         ...,\n         [-0.01253872],\n         [-0.04157709],\n         [-0.01408566]],\n\n        [[-0.03090854],\n         [-0.01968157],\n         [-0.03782297],\n         ...,\n         [ 0.05346918],\n         [ 0.02460855],\n         [ 0.00706554]]],\n\n\n       [[[ 0.02456337],\n         [-0.0138875 ],\n         [-0.02880254],\n         ...,\n         [ 0.04107539],\n         [-0.03396839],\n         [ 0.01588154]],\n\n        [[-0.0202811 ],\n         [ 0.01597953],\n         [-0.0113443 ],\n         ...,\n         [-0.03704854],\n         [-0.02136291],\n         [-0.05121685]],\n\n        [[ 0.02490765],\n         [-0.01883382],\n         [-0.04230718],\n         ...,\n         [-0.01012593],\n         [ 0.0168143 ],\n         [ 0.04470888]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/moving_mean:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_366/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.05777818],\n         [-0.07062713],\n         [-0.04863792],\n         ...,\n         [-0.02925017],\n         [ 0.0709572 ],\n         [ 0.01591302]],\n\n        [[ 0.06905168],\n         [ 0.00888311],\n         [-0.04712436],\n         ...,\n         [-0.03324165],\n         [-0.04370267],\n         [-0.06064375]],\n\n        [[-0.02441993],\n         [-0.00430445],\n         [-0.03260644],\n         ...,\n         [ 0.03926274],\n         [-0.00930229],\n         [ 0.01656462]]],\n\n\n       [[[ 0.07216664],\n         [ 0.01522211],\n         [ 0.05796278],\n         ...,\n         [-0.05099004],\n         [ 0.00157475],\n         [-0.06897628]],\n\n        [[-0.02899819],\n         [ 0.03885144],\n         [-0.02479792],\n         ...,\n         [ 0.04638881],\n         [-0.00721783],\n         [-0.07116449]],\n\n        [[ 0.04840562],\n         [-0.04435076],\n         [-0.05791862],\n         ...,\n         [ 0.02790711],\n         [-0.03284815],\n         [ 0.07212695]]],\n\n\n       [[[ 0.00313966],\n         [-0.07125422],\n         [ 0.06274168],\n         ...,\n         [-0.00969908],\n         [-0.07146905],\n         [ 0.04169833]],\n\n        [[ 0.06394929],\n         [-0.04918831],\n         [-0.02809804],\n         ...,\n         [-0.0700573 ],\n         [-0.06635001],\n         [ 0.00519253]],\n\n        [[-0.00866704],\n         [ 0.04104125],\n         [ 0.0300544 ],\n         ...,\n         [-0.03125319],\n         [ 0.00083605],\n         [-0.07406119]]]], dtype=float32)>, <tf.Variable 'conv2d_839/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[ 0.03062384,  0.05975721, -0.03346661, -0.33880126,\n          -0.23606431,  0.29597786,  0.15808465, -0.18296699,\n          -0.06879429, -0.33556494,  0.24613525,  0.2809689 ,\n           0.31182453,  0.22688372, -0.13906536,  0.07097469,\n          -0.35635218,  0.03152678, -0.19036905,  0.24615799,\n           0.10249153,  0.19188194,  0.1624396 ,  0.02292239],\n         [ 0.14986424,  0.02821611, -0.26775223, -0.15380436,\n           0.02218385, -0.1316079 ,  0.19371812,  0.3493268 ,\n           0.04507992, -0.21514918,  0.10306091,  0.2060223 ,\n           0.07253455, -0.3264913 ,  0.40296698,  0.22712876,\n           0.39030924,  0.18067755, -0.00258197,  0.00647514,\n           0.12706292,  0.30718383,  0.01694357,  0.14938325],\n         [ 0.16731925,  0.33325297, -0.16143805, -0.12234508,\n           0.36641726,  0.14282916,  0.010698  , -0.18735264,\n           0.2590174 , -0.15867296, -0.10194314, -0.25818986,\n          -0.03503438,  0.00928926,  0.4198281 ,  0.34820598,\n          -0.3424998 , -0.40838495,  0.02942531, -0.3300267 ,\n           0.10154498, -0.41303292, -0.31633624, -0.20879796],\n         [-0.2610408 ,  0.05947717, -0.24533962,  0.19511949,\n          -0.13345174,  0.15967664,  0.22913492,  0.30631018,\n          -0.06068328,  0.02884603, -0.00747847, -0.33075136,\n           0.30835852,  0.0040927 , -0.23449352, -0.15101436,\n          -0.02796182,  0.40440384, -0.3934244 ,  0.04750809,\n           0.01081783, -0.03955649,  0.0570581 , -0.29170084],\n         [ 0.19786401,  0.19868289, -0.19706674,  0.23130663,\n          -0.06471808,  0.11834471,  0.21902914, -0.05880892,\n           0.29722884, -0.34770668,  0.07137018,  0.21155256,\n           0.07821784,  0.17075491,  0.36964014, -0.29860467,\n          -0.34952423, -0.3313592 , -0.1477382 , -0.2984979 ,\n           0.0898985 ,  0.08883379, -0.12428681, -0.29710624],\n         [ 0.00871686, -0.3177807 ,  0.14808397,  0.12337586,\n           0.37275037, -0.07269479,  0.23158231,  0.24588609,\n          -0.38877326, -0.18786578, -0.08267021, -0.03253573,\n          -0.17677768,  0.12795322, -0.41553026,  0.20002545,\n          -0.33620337, -0.1811248 ,  0.1503296 , -0.00269175,\n           0.09756897, -0.1727594 , -0.16738582,  0.1658994 ],\n         [-0.2930601 , -0.06619976, -0.16801223,  0.05647111,\n           0.10939216,  0.11112682,  0.25311172, -0.2813624 ,\n          -0.0155524 , -0.08257523, -0.12003534, -0.07909941,\n           0.0522099 , -0.15316652, -0.01161376,  0.00607055,\n          -0.05688274,  0.03261381, -0.30617902,  0.06390715,\n           0.40037552, -0.08047796,  0.29172945,  0.04309621],\n         [ 0.02464938, -0.25315508, -0.15134117, -0.23585457,\n           0.40225163, -0.14073578, -0.3427851 , -0.08951468,\n          -0.27138686, -0.01378556, -0.26382264, -0.04168974,\n           0.22221409,  0.41841316, -0.40811083,  0.15458937,\n           0.11441573, -0.18662015,  0.21932888, -0.35188037,\n           0.12569113, -0.08755241, -0.06036614, -0.03679732],\n         [-0.11013141,  0.17197676,  0.3541443 ,  0.3513652 ,\n           0.09818143,  0.28762323, -0.03448963, -0.26398298,\n          -0.00319474,  0.22177248, -0.40595487, -0.3044085 ,\n           0.16590184, -0.20552427, -0.27665448, -0.08743719,\n          -0.16769592,  0.05248893, -0.23126014,  0.00926075,\n          -0.1463171 ,  0.30725044, -0.3297196 ,  0.21425904],\n         [-0.07561939, -0.00888482, -0.24991493,  0.18235037,\n           0.09686627,  0.21171066,  0.06929341, -0.29479074,\n           0.01219886, -0.24436158, -0.13154571,  0.03806016,\n          -0.20113187, -0.12866595, -0.10043385,  0.1816125 ,\n          -0.00747695, -0.05718577, -0.31712353,  0.21404618,\n           0.0211068 , -0.19345911,  0.20698118,  0.360039  ],\n         [-0.06167805,  0.02609295, -0.00578767,  0.10609084,\n          -0.23869629, -0.44562635, -0.00382046, -0.42003703,\n           0.16176254, -0.15444446,  0.16199411, -0.16909546,\n          -0.16811593, -0.4162363 , -0.15344496, -0.22493717,\n          -0.32977328,  0.07641749, -0.1423356 ,  0.02339028,\n           0.01226292, -0.22951697,  0.00740699, -0.24002378],\n         [ 0.04044901, -0.36992973, -0.36132413, -0.24512404,\n          -0.43056428,  0.00805652,  0.18561654,  0.17108992,\n          -0.24210158,  0.3415372 , -0.24824871, -0.12206827,\n           0.27597117, -0.33747265,  0.31758174,  0.15134208,\n           0.20065941,  0.30379948,  0.44644666,  0.07389404,\n           0.45044208,  0.03209042, -0.07436906,  0.16061601],\n         [-0.0141491 , -0.20541215,  0.1048103 , -0.04766109,\n          -0.07661922, -0.07068059,  0.01396365, -0.04305394,\n           0.05832002,  0.03372009,  0.42156285,  0.3791529 ,\n           0.31633922, -0.1312994 ,  0.13000363, -0.06698339,\n          -0.3705059 ,  0.14412989, -0.07094464, -0.03259292,\n           0.03049771,  0.03817679, -0.31046775,  0.23206815],\n         [-0.19272232,  0.21480466,  0.21656677, -0.15195301,\n          -0.20480554,  0.4145326 ,  0.23338853,  0.01607073,\n           0.10373566, -0.09180898, -0.26660922,  0.20348437,\n           0.04967656, -0.2505372 , -0.13266155, -0.33720797,\n          -0.02482914,  0.43264255,  0.10365995, -0.13533884,\n          -0.19486524,  0.28157946,  0.09396666,  0.06574298],\n         [-0.22566436, -0.21851535, -0.03780637, -0.19109756,\n          -0.25911537, -0.11516505, -0.2506295 , -0.21663786,\n           0.13686253,  0.21471712, -0.23774998,  0.08448474,\n           0.17156693, -0.00667707, -0.01389841, -0.09369221,\n          -0.25584176, -0.32140395,  0.31716028,  0.11338343,\n           0.29163525, -0.2288073 , -0.09103471,  0.11345904],\n         [-0.06248783, -0.37414935, -0.15546699, -0.12268338,\n          -0.3737889 ,  0.05615642,  0.25393626, -0.38467628,\n           0.21629135,  0.31002408,  0.12528914,  0.20632207,\n          -0.12755255,  0.15369684,  0.05207777,  0.21633607,\n           0.09421716,  0.03524834,  0.45035768,  0.21995534,\n           0.01986365, -0.37133947, -0.05804251, -0.0461649 ],\n         [ 0.16278242,  0.18871406,  0.06990009,  0.14754505,\n          -0.28556508,  0.1414188 ,  0.14136213,  0.27052695,\n          -0.21504745, -0.11579344, -0.02280856, -0.00077459,\n          -0.05663946, -0.1813245 ,  0.4530155 ,  0.38428876,\n           0.17199585, -0.28138945, -0.04958959, -0.09962163,\n          -0.11489036,  0.04478546, -0.30513045,  0.05609461],\n         [ 0.23867261, -0.16115703,  0.36101183,  0.22391926,\n           0.04992346, -0.24192864, -0.13908869, -0.11337838,\n          -0.00324607,  0.01472588, -0.08148538, -0.11955827,\n           0.13516286, -0.27527627,  0.09133917,  0.4631258 ,\n           0.01564591, -0.2031011 ,  0.05332069,  0.08242253,\n           0.30734298, -0.42329094, -0.2918506 , -0.06243388],\n         [-0.12841386,  0.01828032, -0.16718334,  0.17730135,\n           0.13650404,  0.23634061,  0.38420165, -0.22820169,\n           0.1579961 , -0.08466489,  0.24776654,  0.07704747,\n          -0.00329316,  0.13251354, -0.14410871, -0.13284004,\n          -0.14355345, -0.19992374, -0.38058588,  0.01443547,\n          -0.42245463, -0.01773489, -0.35288754, -0.1662134 ],\n         [-0.33470702,  0.15700033,  0.09859345,  0.14431491,\n           0.23564643, -0.2425683 , -0.03697338, -0.20575385,\n          -0.14673854, -0.01472429,  0.1612948 , -0.14106649,\n           0.14757444,  0.22936721, -0.3111225 , -0.2635263 ,\n          -0.07195621,  0.34035832,  0.26897293, -0.02045827,\n           0.05458123, -0.03609987, -0.08548713,  0.16135593],\n         [-0.3062816 ,  0.06850225,  0.17287725,  0.2699886 ,\n           0.28188658,  0.06280138, -0.17741145,  0.1332082 ,\n          -0.02848407, -0.18534917, -0.07542988, -0.062567  ,\n          -0.18157949, -0.14015698,  0.03512174, -0.14426498,\n           0.46195164, -0.21866518, -0.07559689,  0.06073087,\n           0.32994124,  0.09589127,  0.31124058, -0.2716374 ],\n         [-0.27318773, -0.03515729, -0.24954435,  0.2580292 ,\n          -0.4141425 , -0.00817489, -0.30040064,  0.1833177 ,\n          -0.26066595,  0.373142  , -0.12220559,  0.06843333,\n          -0.29299372, -0.23750876,  0.33233926,  0.2588878 ,\n          -0.02341007, -0.01068597,  0.4277101 , -0.10878647,\n          -0.27571967, -0.3156744 ,  0.20871648,  0.30008525],\n         [-0.07741109,  0.08117925, -0.1264433 ,  0.1824279 ,\n          -0.13145943,  0.00227213,  0.01869367,  0.1355617 ,\n          -0.28441185,  0.12468906, -0.37095386, -0.2530106 ,\n           0.13156973, -0.311147  ,  0.40203658,  0.43354946,\n          -0.2974091 , -0.2693129 ,  0.21931358, -0.08465521,\n           0.12334061,  0.3069476 , -0.02620836,  0.02971777],\n         [ 0.15118662, -0.41484675, -0.13121326,  0.08708294,\n          -0.03937778,  0.17534551,  0.10814606, -0.01833585,\n          -0.30633873, -0.40307263, -0.04718204, -0.18892853,\n          -0.13139589, -0.2003905 , -0.06723245, -0.27075645,\n          -0.01098196, -0.12408727, -0.05549768, -0.03080422,\n          -0.08906356, -0.07159022, -0.1983563 , -0.11888842]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 1.90676264e-02, -1.97774060e-02, -4.78887483e-02, ...,\n          -3.27033773e-02, -2.32446212e-02, -2.29693633e-02],\n         [-4.53805663e-02,  3.85349169e-02, -6.62047043e-02, ...,\n          -5.71883135e-02, -5.16317323e-06,  7.92483017e-02],\n         [ 9.67299417e-02, -4.65690903e-02,  3.33701670e-02, ...,\n           2.87869442e-02,  6.03199191e-02, -2.46488675e-02],\n         ...,\n         [-3.50121520e-02, -8.59735813e-03,  1.15065835e-02, ...,\n          -1.26401912e-02,  2.34459955e-02, -5.42363934e-02],\n         [-5.46535589e-02,  1.42816622e-02, -6.21919520e-02, ...,\n          -3.39748152e-02,  8.25458579e-03, -1.40277175e-02],\n         [ 2.09191460e-02,  4.49677333e-02,  1.06156699e-03, ...,\n          -3.97581756e-02,  4.15015183e-02,  6.51729703e-02]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 0.01836401],\n         [ 0.00305542],\n         [-0.00671789],\n         ...,\n         [ 0.00582301],\n         [-0.00762974],\n         [ 0.00800924]],\n\n        [[ 0.01934782],\n         [ 0.00200556],\n         [-0.01744415],\n         ...,\n         [-0.02045186],\n         [-0.00486344],\n         [-0.01852966]],\n\n        [[-0.005448  ],\n         [-0.0284319 ],\n         [ 0.02860772],\n         ...,\n         [ 0.00821805],\n         [ 0.00846048],\n         [ 0.0014784 ]]],\n\n\n       [[[ 0.01531391],\n         [-0.00666285],\n         [-0.00462299],\n         ...,\n         [-0.01995928],\n         [ 0.0055928 ],\n         [ 0.00948393]],\n\n        [[-0.00203383],\n         [ 0.01371246],\n         [-0.01033247],\n         ...,\n         [ 0.00548469],\n         [ 0.0002679 ],\n         [ 0.01887108]],\n\n        [[ 0.00942703],\n         [-0.00409796],\n         [ 0.00100016],\n         ...,\n         [ 0.02226859],\n         [ 0.01233917],\n         [ 0.01580453]]],\n\n\n       [[[ 0.00052949],\n         [-0.01446479],\n         [ 0.00918633],\n         ...,\n         [ 0.00358088],\n         [-0.0256935 ],\n         [ 0.01774043]],\n\n        [[-0.00664139],\n         [-0.00969928],\n         [-0.01671724],\n         ...,\n         [-0.01090497],\n         [ 0.0048924 ],\n         [ 0.01408415]],\n\n        [[ 0.02435453],\n         [-0.01103743],\n         [ 0.00427603],\n         ...,\n         [ 0.00780486],\n         [ 0.00722642],\n         [ 0.02190817]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/conv2d_1/kernel:0' shape=(1, 1, 96, 24) dtype=float32, numpy=\narray([[[[-0.02960172, -0.21402088,  0.08909935, ..., -0.09983931,\n           0.01469804, -0.05941022],\n         [-0.03898183, -0.09291705,  0.03680477, ...,  0.11497281,\n           0.10587574, -0.01784064],\n         [ 0.07008724, -0.03179467,  0.11987862, ...,  0.14260657,\n          -0.04565348,  0.12003692],\n         ...,\n         [-0.0753134 ,  0.06171771,  0.03842597, ..., -0.17637046,\n           0.02448523, -0.03621456],\n         [-0.06465167,  0.17042369, -0.21982998, ...,  0.08420349,\n          -0.17042854, -0.15364723],\n         [ 0.05972956, -0.04064714, -0.14537154, ...,  0.1468447 ,\n           0.05027313, -0.15302312]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_846/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[ 0.05987923, -0.09694598, -0.17655471, ...,  0.09792732,\n          -0.11073738,  0.2826267 ],\n         [ 0.2159577 , -0.2891148 ,  0.29688302, ...,  0.16061127,\n           0.17047794, -0.3602198 ],\n         [-0.17439356, -0.34931198, -0.1628836 , ...,  0.02387322,\n          -0.18901879, -0.38223517],\n         ...,\n         [ 0.17219117, -0.4223906 , -0.19110267, ...,  0.09961442,\n           0.1690301 , -0.10864128],\n         [-0.43203303, -0.34095082,  0.28186017, ...,  0.07875165,\n           0.07673132,  0.13284554],\n         [ 0.15227865, -0.2508964 ,  0.0431558 , ...,  0.1380628 ,\n           0.14246956,  0.42815664]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00961908,  0.06080306,  0.15744434, ..., -0.09736945,\n           0.13440733,  0.08415141],\n         [ 0.00098017, -0.14078653, -0.31074366, ...,  0.3062803 ,\n           0.12811404, -0.32735097],\n         [-0.20890622,  0.07389676,  0.13169768, ...,  0.00800692,\n          -0.39744198, -0.00296691],\n         ...,\n         [-0.06626923,  0.14961419, -0.23377885, ...,  0.22999792,\n          -0.20611005, -0.07051556],\n         [ 0.05424161,  0.1374875 , -0.27732953, ...,  0.17512889,\n          -0.01502043, -0.13449192],\n         [-0.45841926,  0.08037534, -0.00368637, ...,  0.0792795 ,\n           0.01591906,  0.05878564]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_371/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-5.88018149e-02],\n         [-4.65798266e-02],\n         [ 7.94907957e-02],\n         [-2.78239101e-02],\n         [-1.82861164e-02],\n         [ 5.25646508e-02],\n         [-1.33464113e-02],\n         [ 3.95973027e-02],\n         [ 4.69783694e-02],\n         [-1.65359154e-02],\n         [ 2.74144188e-02],\n         [-4.06037122e-02],\n         [-8.52383673e-04],\n         [ 6.95890188e-02],\n         [-4.90803123e-02],\n         [-6.01350963e-02],\n         [-7.97799677e-02],\n         [-8.33069682e-02],\n         [-2.78024971e-02],\n         [ 2.42125615e-02],\n         [-6.09733164e-02],\n         [ 7.54667968e-02],\n         [-8.93830955e-02],\n         [ 2.35835910e-02],\n         [ 6.04362637e-02],\n         [-8.46440345e-03],\n         [-3.54009867e-03],\n         [ 2.09683999e-02],\n         [ 7.38366991e-02],\n         [-8.69697928e-02],\n         [ 3.68010551e-02],\n         [ 6.76703006e-02],\n         [ 8.12256783e-02],\n         [-1.25159845e-02],\n         [-4.06650789e-02],\n         [-1.93166882e-02],\n         [-7.24017546e-02],\n         [ 1.32287294e-02],\n         [ 2.51613110e-02],\n         [-7.36855865e-02],\n         [-7.62073398e-02],\n         [-8.71939436e-02],\n         [ 3.51508409e-02],\n         [ 7.55916834e-02],\n         [ 6.59539104e-02],\n         [ 4.52609360e-03],\n         [-3.51435356e-02],\n         [ 5.69196343e-02],\n         [-8.07921141e-02],\n         [-6.32754564e-02],\n         [ 8.87970924e-02],\n         [ 1.94320083e-03],\n         [ 5.00329286e-02],\n         [-8.39677528e-02],\n         [-2.65094936e-02],\n         [ 5.72784990e-02],\n         [-2.51693577e-02],\n         [ 5.62932342e-03],\n         [-7.45939463e-03],\n         [ 5.48878163e-02],\n         [-9.28423554e-03],\n         [-5.88592850e-02],\n         [-3.85301113e-02],\n         [ 8.99260789e-02],\n         [ 6.65609539e-02],\n         [-2.85437964e-02],\n         [ 3.38473171e-03],\n         [-4.75387797e-02],\n         [ 9.05925483e-02],\n         [-6.15754873e-02],\n         [ 2.10766122e-02],\n         [ 2.19065025e-02],\n         [-5.02840094e-02],\n         [-3.89715508e-02],\n         [-7.49464110e-02],\n         [-8.60774368e-02],\n         [ 8.46531242e-03],\n         [-6.48821145e-02],\n         [ 2.71326452e-02],\n         [ 1.93779394e-02]],\n\n        [[ 3.14907655e-02],\n         [ 9.01153088e-02],\n         [ 2.48504058e-02],\n         [ 1.42137930e-02],\n         [-4.49635088e-03],\n         [ 1.56478584e-03],\n         [-2.81397924e-02],\n         [ 6.15805984e-02],\n         [ 8.95677060e-02],\n         [-2.59169936e-03],\n         [-1.66902915e-02],\n         [ 4.78016734e-02],\n         [-1.20486245e-02],\n         [ 6.82011843e-02],\n         [ 7.54691511e-02],\n         [ 6.50317073e-02],\n         [-7.30016530e-02],\n         [-5.59671894e-02],\n         [ 2.93096602e-02],\n         [ 3.31909060e-02],\n         [ 4.64432687e-03],\n         [ 4.21711206e-02],\n         [-8.41373950e-02],\n         [ 1.15782022e-03],\n         [ 3.22033837e-02],\n         [ 6.71485066e-02],\n         [ 8.31657201e-02],\n         [ 5.67877740e-02],\n         [-8.68596584e-02],\n         [-4.16687205e-02],\n         [-5.33404052e-02],\n         [ 4.92836386e-02],\n         [ 2.86651999e-02],\n         [ 4.40077484e-02],\n         [-8.30438808e-02],\n         [ 3.51902544e-02],\n         [ 1.41116753e-02],\n         [-2.22934037e-03],\n         [ 7.79208988e-02],\n         [ 7.05175847e-02],\n         [ 3.30800787e-02],\n         [ 2.62730569e-03],\n         [ 7.32305646e-02],\n         [-1.58156231e-02],\n         [-4.09118719e-02],\n         [-1.65699199e-02],\n         [-8.05589035e-02],\n         [-5.51819205e-02],\n         [-1.06657296e-02],\n         [-8.41586813e-02],\n         [-8.69862959e-02],\n         [ 8.47201645e-02],\n         [-6.91655502e-02],\n         [ 4.24424410e-02],\n         [ 8.51653367e-02],\n         [-2.91624069e-02],\n         [-7.95209110e-02],\n         [-6.43131882e-02],\n         [ 4.80777323e-02],\n         [-7.98359513e-03],\n         [-7.83308819e-02],\n         [ 6.10658228e-02],\n         [-1.70655251e-02],\n         [ 5.47883511e-02],\n         [-5.08620441e-02],\n         [ 8.43349844e-02],\n         [ 6.33711368e-03],\n         [ 4.21185791e-03],\n         [ 5.87044209e-02],\n         [ 4.49031591e-04],\n         [ 4.08013165e-02],\n         [-7.28978738e-02],\n         [-5.17366678e-02],\n         [ 8.17689747e-02],\n         [-1.33605599e-02],\n         [ 7.83394426e-02],\n         [-7.96886906e-02],\n         [-1.76154822e-03],\n         [ 7.03240782e-02],\n         [ 6.80241883e-02]],\n\n        [[ 5.10010868e-02],\n         [ 1.09636560e-02],\n         [-5.35184629e-02],\n         [ 8.81243050e-02],\n         [-3.80314812e-02],\n         [-7.64153749e-02],\n         [-8.48962963e-02],\n         [-1.39839500e-02],\n         [-8.23974758e-02],\n         [ 2.22831443e-02],\n         [ 3.04850042e-02],\n         [-7.80157745e-03],\n         [ 5.77930510e-02],\n         [ 3.06717530e-02],\n         [ 5.94808161e-02],\n         [-1.31761208e-02],\n         [-6.61691725e-02],\n         [ 7.74216354e-02],\n         [ 2.05044225e-02],\n         [ 5.96930534e-02],\n         [-5.06356359e-04],\n         [-8.84881839e-02],\n         [-5.59980124e-02],\n         [ 5.59908599e-02],\n         [-1.65462345e-02],\n         [ 7.20052719e-02],\n         [ 6.27413094e-02],\n         [-2.94196941e-02],\n         [ 8.60643983e-02],\n         [ 4.75592017e-02],\n         [ 7.57134706e-02],\n         [ 8.65180492e-02],\n         [ 6.79465532e-02],\n         [ 1.43042654e-02],\n         [-3.58423740e-02],\n         [-6.31604493e-02],\n         [ 6.70182258e-02],\n         [-5.62702008e-02],\n         [ 4.78579253e-02],\n         [ 2.71758437e-02],\n         [ 4.99012917e-02],\n         [ 4.63224947e-04],\n         [ 8.45820457e-02],\n         [-6.73233643e-02],\n         [ 5.44849187e-02],\n         [ 5.80747575e-02],\n         [ 3.83271277e-03],\n         [ 2.28725374e-02],\n         [ 2.69350186e-02],\n         [ 2.12122947e-02],\n         [-4.37125564e-05],\n         [-4.77564186e-02],\n         [ 1.70018524e-03],\n         [ 5.67411929e-02],\n         [-5.80439083e-02],\n         [ 6.37245923e-03],\n         [-5.31626306e-02],\n         [-4.24646102e-02],\n         [ 3.21025178e-02],\n         [-1.88745484e-02],\n         [-3.23973112e-02],\n         [-3.58184092e-02],\n         [ 5.23055494e-02],\n         [-8.79088715e-02],\n         [ 3.50897759e-03],\n         [ 4.52711433e-03],\n         [ 7.87090659e-02],\n         [-4.34339494e-02],\n         [-1.58749148e-02],\n         [-2.63066739e-02],\n         [-1.42330602e-02],\n         [-4.45355289e-02],\n         [-9.21272486e-03],\n         [ 3.54353637e-02],\n         [-3.45090292e-02],\n         [ 1.99693888e-02],\n         [-3.19713131e-02],\n         [ 4.61476892e-02],\n         [ 2.91141495e-02],\n         [ 1.81583688e-02]]],\n\n\n       [[[-2.74761915e-02],\n         [ 1.82947442e-02],\n         [-9.07122344e-03],\n         [-3.62894386e-02],\n         [-2.13717297e-02],\n         [ 4.82404083e-02],\n         [ 2.68925577e-02],\n         [-2.93952972e-03],\n         [ 8.33456814e-02],\n         [ 3.37923914e-02],\n         [ 1.16290152e-03],\n         [ 6.28584325e-02],\n         [-1.44057348e-02],\n         [-6.56031445e-02],\n         [-7.48293251e-02],\n         [ 5.90977967e-02],\n         [ 8.04813653e-02],\n         [ 1.96666345e-02],\n         [-7.13724568e-02],\n         [-3.45377736e-02],\n         [-6.23990409e-02],\n         [ 4.54864353e-02],\n         [-4.28588986e-02],\n         [ 7.47649372e-02],\n         [ 4.37712818e-02],\n         [ 4.36615348e-02],\n         [ 8.86613876e-02],\n         [ 5.19126207e-02],\n         [-1.24963671e-02],\n         [-3.03473510e-02],\n         [ 6.35340214e-02],\n         [ 2.35470384e-03],\n         [ 3.47787142e-03],\n         [ 3.11021432e-02],\n         [-8.37772191e-02],\n         [-4.96580899e-02],\n         [ 3.31444293e-02],\n         [ 6.45455122e-02],\n         [ 5.39162308e-02],\n         [ 6.22976571e-03],\n         [ 3.45977545e-02],\n         [ 1.29459798e-02],\n         [-2.20212266e-02],\n         [ 6.82945848e-02],\n         [-8.41173530e-03],\n         [ 7.39825666e-02],\n         [ 7.45048076e-02],\n         [-2.51943618e-03],\n         [-1.02279633e-02],\n         [ 4.61763144e-03],\n         [-2.38726065e-02],\n         [ 4.60766256e-02],\n         [-4.63176295e-02],\n         [ 2.13407129e-02],\n         [-6.13405667e-02],\n         [ 6.35558516e-02],\n         [-3.35059687e-02],\n         [-3.49435210e-03],\n         [ 3.14350277e-02],\n         [ 4.90086973e-02],\n         [ 5.06621003e-02],\n         [-6.86807409e-02],\n         [-2.23655552e-02],\n         [ 4.87334430e-02],\n         [-2.74931937e-02],\n         [ 1.68691650e-02],\n         [ 5.75257391e-02],\n         [ 1.54491067e-02],\n         [-8.62209275e-02],\n         [ 8.75294656e-02],\n         [ 2.94844061e-02],\n         [-5.12281507e-02],\n         [ 7.84778297e-02],\n         [-8.47446322e-02],\n         [ 6.36524409e-02],\n         [-3.26943547e-02],\n         [-5.72600439e-02],\n         [-3.16165388e-04],\n         [-4.20735776e-03],\n         [ 1.85069069e-02]],\n\n        [[ 3.18000466e-02],\n         [-6.81969896e-02],\n         [ 5.05842268e-03],\n         [ 3.17237377e-02],\n         [ 5.32957166e-02],\n         [ 7.30726868e-02],\n         [-3.40822078e-02],\n         [ 7.41805881e-03],\n         [ 1.10020265e-02],\n         [ 8.02206844e-02],\n         [ 2.72393897e-02],\n         [-1.97856128e-03],\n         [-5.57192490e-02],\n         [ 7.42921978e-03],\n         [ 6.18016273e-02],\n         [ 6.79056942e-02],\n         [-6.64412528e-02],\n         [ 6.29316717e-02],\n         [-1.32156163e-02],\n         [ 2.17762068e-02],\n         [ 4.22955006e-02],\n         [-8.83882120e-02],\n         [-8.71733949e-02],\n         [-5.19097261e-02],\n         [-8.19846243e-02],\n         [-7.76862055e-02],\n         [ 1.04196668e-02],\n         [ 5.25583178e-02],\n         [ 8.29672515e-02],\n         [ 8.08352828e-02],\n         [-5.44524156e-02],\n         [-4.35519591e-02],\n         [-5.65075874e-03],\n         [ 2.42175609e-02],\n         [ 3.56302708e-02],\n         [-1.45904496e-02],\n         [ 6.13344908e-02],\n         [-6.81619272e-02],\n         [-7.34260529e-02],\n         [ 3.62001657e-02],\n         [ 3.71783972e-06],\n         [-8.39623436e-02],\n         [-2.52361894e-02],\n         [ 1.25428438e-02],\n         [-8.67305920e-02],\n         [-5.74411303e-02],\n         [ 3.04310769e-02],\n         [ 1.73716098e-02],\n         [-2.14731768e-02],\n         [ 6.05130792e-02],\n         [-9.44293290e-03],\n         [ 5.33591211e-03],\n         [-3.30530852e-03],\n         [ 1.39308050e-02],\n         [-6.96139336e-02],\n         [ 7.68029690e-03],\n         [ 1.80095583e-02],\n         [ 3.64293009e-02],\n         [-2.81212330e-02],\n         [-6.57564402e-03],\n         [ 1.91225559e-02],\n         [ 6.99809939e-02],\n         [ 7.57178068e-02],\n         [ 1.69752836e-02],\n         [-6.03358224e-02],\n         [ 4.58044559e-02],\n         [-6.38880581e-02],\n         [-6.58209622e-02],\n         [-5.48430905e-02],\n         [ 3.19904387e-02],\n         [ 9.02647525e-03],\n         [ 4.01169509e-02],\n         [-1.15756914e-02],\n         [ 3.62778008e-02],\n         [-1.24780238e-02],\n         [-5.88287450e-02],\n         [-5.99050000e-02],\n         [-1.79856122e-02],\n         [ 4.27878201e-02],\n         [-6.20581135e-02]],\n\n        [[-1.21168792e-04],\n         [-4.16063406e-02],\n         [-7.02550858e-02],\n         [ 1.11555159e-02],\n         [-8.30592811e-02],\n         [ 6.35237992e-03],\n         [ 2.20604464e-02],\n         [ 1.77426189e-02],\n         [ 8.17596912e-03],\n         [-5.24880402e-02],\n         [ 1.57025680e-02],\n         [-2.70517766e-02],\n         [ 8.11271518e-02],\n         [ 2.32214257e-02],\n         [ 8.46177340e-02],\n         [ 4.12861109e-02],\n         [-1.33790821e-03],\n         [ 3.32927853e-02],\n         [-8.02079365e-02],\n         [ 5.91319054e-02],\n         [-7.94613361e-03],\n         [ 1.14203244e-02],\n         [-7.79857337e-02],\n         [ 6.85901940e-02],\n         [ 2.90777683e-02],\n         [-3.66676785e-02],\n         [-3.06459703e-02],\n         [ 8.04688036e-03],\n         [ 7.55083710e-02],\n         [-3.15738879e-02],\n         [ 2.37178281e-02],\n         [-6.79171383e-02],\n         [-3.30292694e-02],\n         [-1.94787607e-02],\n         [-5.35087734e-02],\n         [-5.55969551e-02],\n         [ 5.39450496e-02],\n         [ 4.48664427e-02],\n         [-2.84547471e-02],\n         [ 8.16355497e-02],\n         [-6.36542141e-02],\n         [-4.75564748e-02],\n         [-7.52359033e-02],\n         [-3.27689983e-02],\n         [ 8.92854184e-02],\n         [-6.63449615e-02],\n         [-2.22065747e-02],\n         [-8.20852295e-02],\n         [-8.07011798e-02],\n         [-2.52250060e-02],\n         [-8.74431431e-03],\n         [-7.26398304e-02],\n         [ 1.94612369e-02],\n         [-8.01498592e-02],\n         [-1.25075877e-02],\n         [ 3.87320966e-02],\n         [ 1.47733092e-02],\n         [ 2.77080461e-02],\n         [-2.17408016e-02],\n         [-4.88125533e-03],\n         [ 4.79518026e-02],\n         [-2.41644681e-04],\n         [ 6.98694438e-02],\n         [-7.91759789e-03],\n         [-1.10395327e-02],\n         [-4.77359369e-02],\n         [-1.87589377e-02],\n         [-2.54278556e-02],\n         [ 8.32504630e-02],\n         [ 2.48763412e-02],\n         [ 4.51364517e-02],\n         [-7.72685409e-02],\n         [ 3.02845165e-02],\n         [ 2.99702585e-02],\n         [ 3.41760144e-02],\n         [ 3.60536128e-02],\n         [-3.25632133e-02],\n         [ 4.53856289e-02],\n         [ 2.05331296e-03],\n         [-2.11457610e-02]]],\n\n\n       [[[ 2.98502743e-02],\n         [-6.36289343e-02],\n         [ 5.02189249e-03],\n         [-2.26008445e-02],\n         [ 7.19131529e-03],\n         [ 1.25197694e-02],\n         [-4.30957228e-02],\n         [ 2.70145237e-02],\n         [-2.49959305e-02],\n         [ 6.47737682e-02],\n         [-7.54746944e-02],\n         [ 8.10226202e-02],\n         [ 6.46200031e-03],\n         [-4.93434817e-02],\n         [ 1.72294751e-02],\n         [ 1.97882354e-02],\n         [-2.07978711e-02],\n         [-1.44977048e-02],\n         [ 6.35927171e-02],\n         [-4.69534136e-02],\n         [ 6.57587498e-02],\n         [ 2.08891258e-02],\n         [-7.51602203e-02],\n         [ 7.22827464e-02],\n         [-4.80535924e-02],\n         [-7.78346509e-02],\n         [ 4.23701704e-02],\n         [-6.31513447e-03],\n         [-5.38225546e-02],\n         [-5.59786744e-02],\n         [-1.63849890e-02],\n         [-5.27388602e-02],\n         [-8.40497538e-02],\n         [-3.40625644e-03],\n         [ 5.65606654e-02],\n         [ 8.81641954e-02],\n         [-7.80683756e-03],\n         [ 8.74838680e-02],\n         [-5.61197661e-02],\n         [ 4.33781147e-02],\n         [ 3.57892215e-02],\n         [-7.89739788e-02],\n         [ 5.73219955e-02],\n         [ 1.01788864e-02],\n         [ 2.32862458e-02],\n         [-5.12599908e-02],\n         [ 7.20066428e-02],\n         [ 1.35173351e-02],\n         [-3.42971869e-02],\n         [ 3.93975675e-02],\n         [-7.14652464e-02],\n         [ 5.93002141e-03],\n         [-4.78388742e-02],\n         [ 2.87072733e-02],\n         [ 3.62174958e-02],\n         [ 3.57056260e-02],\n         [ 8.59930217e-02],\n         [ 1.70100033e-02],\n         [ 2.89164558e-02],\n         [-3.55652086e-02],\n         [ 4.61629778e-02],\n         [-6.46324009e-02],\n         [ 3.93226445e-02],\n         [ 6.33807331e-02],\n         [-3.66589390e-02],\n         [-3.97481695e-02],\n         [ 4.50608730e-02],\n         [ 1.53198242e-02],\n         [ 3.72625440e-02],\n         [-8.71082023e-02],\n         [ 8.33051056e-02],\n         [ 4.47713435e-02],\n         [-5.75640090e-02],\n         [ 4.20961082e-02],\n         [-5.70861623e-02],\n         [ 7.56520182e-02],\n         [ 1.46467760e-02],\n         [ 1.23398975e-02],\n         [-4.10020910e-02],\n         [ 2.66488120e-02]],\n\n        [[-1.94339007e-02],\n         [-5.32929935e-02],\n         [ 3.56634706e-02],\n         [ 5.58752567e-02],\n         [ 4.90761548e-02],\n         [ 2.27513611e-02],\n         [ 4.80142087e-02],\n         [-6.05893210e-02],\n         [ 8.76296759e-02],\n         [-6.67539611e-02],\n         [-3.49137411e-02],\n         [-7.99823627e-02],\n         [-5.20458855e-02],\n         [-8.54301900e-02],\n         [-9.27980244e-03],\n         [ 1.54380798e-02],\n         [ 5.93365431e-02],\n         [ 6.65570050e-02],\n         [ 1.38361305e-02],\n         [-6.63234144e-02],\n         [ 3.64624411e-02],\n         [ 6.82400912e-02],\n         [-6.26146644e-02],\n         [-6.17798269e-02],\n         [ 8.92982185e-02],\n         [-1.84660330e-02],\n         [-2.14315131e-02],\n         [-4.86147329e-02],\n         [-4.94152084e-02],\n         [ 6.78405762e-02],\n         [-4.60152030e-02],\n         [ 3.28237191e-02],\n         [-6.72991574e-02],\n         [-2.38789469e-02],\n         [-5.33166565e-02],\n         [-3.60438116e-02],\n         [-7.24330246e-02],\n         [ 7.79664367e-02],\n         [ 2.31977999e-02],\n         [ 8.49186480e-02],\n         [ 8.09496045e-02],\n         [-5.04219867e-02],\n         [-1.40614808e-03],\n         [-8.14942420e-02],\n         [ 3.95540595e-02],\n         [-5.18862344e-02],\n         [-2.67770514e-02],\n         [ 1.52870342e-02],\n         [ 4.96704429e-02],\n         [-2.55383626e-02],\n         [-5.74119724e-02],\n         [-2.34784931e-03],\n         [ 4.65544909e-02],\n         [-6.37246892e-02],\n         [-6.54730201e-02],\n         [ 9.02112126e-02],\n         [-1.83752254e-02],\n         [-5.49509376e-02],\n         [-1.17177963e-02],\n         [ 4.57173437e-02],\n         [-8.96015093e-02],\n         [ 6.96691573e-02],\n         [-7.17541575e-02],\n         [ 2.77614668e-02],\n         [-5.14259338e-02],\n         [ 1.67303234e-02],\n         [-7.90323168e-02],\n         [-5.18907793e-02],\n         [-5.23210168e-02],\n         [ 8.22981149e-02],\n         [ 1.80394724e-02],\n         [ 6.48482144e-03],\n         [-4.53045331e-02],\n         [-3.80680971e-02],\n         [ 1.34538263e-02],\n         [ 3.17321122e-02],\n         [-8.17431360e-02],\n         [-1.54386833e-02],\n         [ 2.35653147e-02],\n         [-3.47129330e-02]],\n\n        [[ 1.49880052e-02],\n         [ 7.97562599e-02],\n         [-3.04464996e-03],\n         [ 8.05029422e-02],\n         [ 2.60416865e-02],\n         [ 2.85558254e-02],\n         [ 1.92568824e-02],\n         [-5.03327660e-02],\n         [ 8.33154917e-02],\n         [-4.47868705e-02],\n         [-8.74434635e-02],\n         [-4.79212180e-02],\n         [-8.50960612e-03],\n         [ 3.15978080e-02],\n         [-5.00576757e-02],\n         [-3.19065973e-02],\n         [ 9.35173780e-03],\n         [-8.36795345e-02],\n         [-7.80179203e-02],\n         [-4.78347428e-02],\n         [ 3.79682332e-03],\n         [-3.57308984e-03],\n         [-5.43522686e-02],\n         [ 6.03474379e-02],\n         [-7.80702233e-02],\n         [-7.70357251e-03],\n         [-7.66986161e-02],\n         [ 8.47189128e-02],\n         [-4.61614393e-02],\n         [-1.92526430e-02],\n         [-4.99674790e-02],\n         [-8.35281610e-03],\n         [ 6.05230927e-02],\n         [-7.74278194e-02],\n         [ 1.09563470e-02],\n         [-1.88838542e-02],\n         [-4.70326655e-02],\n         [-7.36595839e-02],\n         [ 7.03992248e-02],\n         [-2.52420083e-02],\n         [ 1.22846514e-02],\n         [ 9.28302109e-03],\n         [-2.35136151e-02],\n         [-2.12027803e-02],\n         [ 4.91269529e-02],\n         [-4.93613072e-02],\n         [ 8.70334506e-02],\n         [ 5.38759977e-02],\n         [ 1.61503255e-03],\n         [ 7.19045848e-02],\n         [ 5.93692064e-04],\n         [-3.81325334e-02],\n         [-7.59326816e-02],\n         [ 6.08555824e-02],\n         [-4.83956896e-02],\n         [ 1.84372216e-02],\n         [-5.03374152e-02],\n         [ 1.54759288e-02],\n         [-6.91940114e-02],\n         [ 2.47452185e-02],\n         [ 9.21648741e-03],\n         [-5.11176214e-02],\n         [-7.45331496e-02],\n         [ 8.26091617e-02],\n         [ 8.18341970e-02],\n         [-9.69479233e-03],\n         [ 4.89368290e-02],\n         [-4.26991396e-02],\n         [-8.83801877e-02],\n         [-7.21906647e-02],\n         [-3.15944143e-02],\n         [ 3.29303369e-02],\n         [-4.94467467e-03],\n         [-5.60007803e-02],\n         [-6.22394793e-02],\n         [-2.54822969e-02],\n         [ 6.30139560e-02],\n         [-4.89213765e-02],\n         [-6.31441623e-02],\n         [-6.62634373e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.09371144,  0.01702544, -0.16216326, ...,  0.01751067,\n           0.089059  ,  0.12657186],\n         [ 0.06208219, -0.13116959,  0.08507419, ..., -0.03308654,\n           0.02695207, -0.07929277],\n         [ 0.08479275, -0.02944072, -0.07979303, ..., -0.08352866,\n           0.06724301, -0.00620721],\n         ...,\n         [-0.07248236,  0.04174983,  0.13346577, ...,  0.10324635,\n          -0.13842711,  0.08201385],\n         [-0.17224312, -0.02182788, -0.06647483, ..., -0.11327539,\n           0.00880406, -0.15378556],\n         [-0.113997  , -0.08554917, -0.03147063, ...,  0.12497499,\n          -0.03437201,  0.04979843]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/moving_variance:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_838/kernel:0' shape=(1, 1, 16, 24) dtype=float32, numpy=\narray([[[[ 3.20742652e-02,  1.40116811e-01, -1.04097873e-01,\n          -2.95556009e-01,  9.91084203e-02, -1.62456483e-01,\n           4.35056418e-01,  1.10671699e-01, -3.83112803e-02,\n           1.98375210e-01,  6.06018156e-02, -4.29946244e-01,\n          -2.96375841e-01,  5.33206649e-02,  1.35120735e-01,\n           3.47470790e-01, -5.57247996e-01, -3.27257335e-01,\n          -4.40364450e-01,  2.72034109e-01,  3.04733664e-01,\n          -1.52809694e-01,  2.05128863e-01,  3.23439986e-01],\n         [-5.38545430e-01, -4.37696278e-01, -3.19173262e-02,\n           1.94255129e-01,  2.59733528e-01, -5.90851791e-02,\n          -1.07112803e-01, -2.98183173e-01,  1.92420051e-01,\n           1.76415220e-01, -3.37192774e-01, -3.64960432e-02,\n          -1.30132169e-01,  2.80971467e-01, -1.53224379e-01,\n           5.82320802e-02,  9.96667519e-02,  1.89746633e-01,\n           1.88022316e-01,  2.22979352e-01, -2.35726535e-02,\n           3.79733741e-01, -6.80858791e-02,  7.81807452e-02],\n         [ 2.68220454e-01, -4.98809844e-01, -1.01698689e-01,\n          -1.67037293e-01,  2.66369492e-01,  3.44779909e-01,\n           4.64066952e-01, -1.70290440e-01, -3.68132889e-01,\n          -3.48931104e-01, -3.66430104e-01, -3.23819280e-01,\n           6.43159673e-02, -4.15949151e-02, -1.40014365e-01,\n           2.14494944e-01, -1.64120018e-01,  4.26626891e-01,\n           1.02399357e-01,  1.06369622e-01,  1.82073504e-01,\n           3.91915530e-01,  3.86553444e-02, -3.67349565e-01],\n         [-3.25381666e-01,  3.26236635e-01,  4.42693502e-01,\n          -1.03761390e-01,  6.57147095e-02, -1.55175582e-01,\n           2.18856022e-01, -1.22157231e-01,  2.48216074e-02,\n          -3.47695619e-01,  7.24261850e-02,  1.10647187e-01,\n           3.30723792e-01,  2.40607962e-01, -1.93591043e-02,\n          -4.32085752e-01, -5.17130971e-01,  2.19161764e-01,\n           1.92945868e-01,  3.06347728e-01, -1.41972378e-01,\n           4.49643314e-01,  3.82418990e-01, -5.63059568e-01],\n         [-8.26441422e-02, -1.83466882e-01,  2.94966102e-02,\n           7.63941333e-02,  3.96017218e-03, -1.41985938e-01,\n          -9.87754110e-03,  2.14219347e-01,  4.78315959e-03,\n           2.53038794e-01,  2.27178987e-02, -1.68142766e-01,\n          -4.12206143e-01, -1.12982191e-01,  6.28182814e-02,\n          -2.44454637e-01,  4.66257900e-01,  1.67200640e-02,\n          -7.78398812e-02,  2.68713236e-01,  1.41591832e-01,\n           3.02275836e-01, -3.01685780e-01, -5.34852110e-02],\n         [ 2.51802862e-01, -4.33654375e-02,  6.14571981e-02,\n           3.10976744e-01, -1.51461855e-01, -2.46825889e-02,\n          -3.87763470e-01,  6.89698160e-02, -3.94356251e-01,\n          -4.16167617e-01,  2.72537619e-01,  1.44084524e-02,\n          -5.58034033e-02,  9.04297084e-02, -2.22693896e-03,\n           9.62451994e-02,  1.96298242e-01, -1.62574902e-01,\n          -5.62921584e-01, -5.12550294e-01,  2.30988517e-01,\n           3.35316658e-02,  1.30041584e-01,  2.35608205e-01],\n         [-1.18184194e-01,  2.50726432e-01,  2.24569365e-01,\n           1.87968045e-01, -1.09798796e-02, -2.02431411e-01,\n          -3.77828211e-01,  1.90364942e-02,  3.30349118e-01,\n          -2.14976951e-01, -1.78841352e-02, -1.81239784e-01,\n          -3.75614673e-01,  3.11361551e-01, -1.78824797e-01,\n           9.84678864e-02,  2.89674729e-01, -1.72588199e-01,\n           1.82460710e-01,  5.00624955e-01, -2.01215863e-01,\n           3.94987971e-01,  4.07913029e-01,  4.65680420e-01],\n         [-4.14654650e-02, -2.50445575e-01,  4.54121262e-01,\n           2.17892621e-02,  3.51245433e-01,  2.15857252e-01,\n          -2.91124191e-02,  2.21475437e-02, -2.03680947e-01,\n           7.61622265e-02, -2.67596185e-01,  2.27779374e-01,\n           1.64280578e-01, -5.93019649e-03, -1.61498412e-01,\n           5.15044928e-01,  1.78730458e-01, -1.85980320e-01,\n          -4.27465856e-01, -1.37090653e-01, -1.70269802e-01,\n          -8.65736529e-02, -2.13030223e-02,  9.62876901e-02],\n         [-9.82363001e-02, -1.20442085e-01, -1.52226850e-01,\n           6.22111298e-02, -3.73685509e-01,  3.95911038e-01,\n           1.47304684e-01,  3.12923133e-01, -4.06624913e-01,\n          -2.33076721e-01, -2.58342316e-03, -3.56965870e-01,\n          -5.54875314e-01,  3.24062377e-01,  9.72081199e-02,\n          -9.02160332e-02,  2.26063371e-01, -2.10597783e-01,\n           6.66906461e-02, -5.75837903e-02, -4.52767387e-02,\n           2.25239024e-01, -5.58979154e-01, -3.26332152e-02],\n         [ 1.96830109e-01,  2.90286958e-01,  1.32023796e-01,\n           3.81115437e-01, -2.89077288e-03,  2.27576885e-02,\n          -2.42102578e-01,  3.04634213e-01, -8.80599767e-02,\n          -1.74007475e-01, -2.06517920e-01,  2.59989858e-01,\n          -2.77630687e-01,  2.65008472e-02,  5.27820475e-02,\n           3.82901788e-01, -2.76493102e-01, -2.22222004e-02,\n           1.48414478e-01, -7.38792866e-02,  3.80482450e-02,\n           3.74507725e-01,  1.51741728e-01,  1.46540269e-01],\n         [-4.81638387e-02,  3.78227904e-02, -4.36700940e-01,\n          -2.39944831e-03,  2.68115569e-02,  1.84498549e-01,\n           1.94241583e-01, -1.94284648e-01,  9.61938277e-02,\n           1.55264378e-01, -3.41927171e-01, -1.75364986e-02,\n           3.42636406e-02, -3.21676493e-01, -3.06289090e-04,\n           2.07028776e-01,  7.09906146e-02, -2.58599788e-01,\n           4.13185060e-01,  3.40851068e-01, -1.06735915e-01,\n           2.78774172e-01, -9.09300223e-02, -1.59190923e-01],\n         [-4.90447193e-01,  4.53697354e-01,  2.84442514e-01,\n           2.10976079e-01,  2.21557230e-01, -5.74082807e-02,\n           5.23616552e-01, -3.19564134e-01, -2.68714447e-02,\n          -2.20213369e-01,  5.41305803e-02, -2.76280105e-01,\n          -1.03800166e-02, -4.48626757e-01, -2.76016265e-01,\n           3.14076170e-02, -2.94259131e-01, -5.46005547e-01,\n           1.50340006e-01, -2.46592402e-01, -2.27015167e-01,\n           2.25038007e-01, -2.80583054e-01, -3.34886611e-01],\n         [-1.41355202e-01,  6.33203834e-02, -1.19014382e-01,\n           2.58501209e-02,  1.13422863e-01, -3.64410937e-01,\n          -1.94707721e-01, -2.06906181e-02,  2.13210229e-02,\n          -2.21917316e-01,  1.54166501e-02, -2.46296570e-01,\n           6.57783300e-02, -1.86941326e-01,  1.10764362e-01,\n           3.00527066e-01, -1.47603005e-01, -4.41266567e-01,\n           1.40170261e-01,  5.53006828e-01, -2.15006769e-01,\n          -2.63788968e-01,  4.08848464e-01, -9.88116637e-02],\n         [ 7.12451637e-02, -2.13422447e-01, -1.48364037e-01,\n          -1.37245610e-01,  4.14041132e-02,  1.97828978e-01,\n          -2.29966789e-01,  6.58925176e-02, -1.94535851e-01,\n           3.94769728e-01, -4.53712285e-01,  8.66682306e-02,\n          -5.12570262e-01, -1.43356353e-01,  1.80321813e-01,\n          -3.20620537e-01,  1.87957868e-01, -1.05334789e-01,\n          -2.89559886e-02, -4.52301055e-01, -4.07211930e-01,\n          -1.91833898e-01, -3.13330293e-01, -9.47975963e-02],\n         [-2.14121178e-01, -6.47390112e-02, -4.65805203e-01,\n          -1.38596177e-01,  4.84214067e-01, -1.97526991e-01,\n          -1.77601129e-01,  4.71508503e-01, -5.37741959e-01,\n          -2.74014682e-01,  1.15513496e-01,  1.68194145e-01,\n          -8.44270438e-02, -4.71970320e-01,  4.78395313e-01,\n           9.47609618e-02,  2.18519762e-01,  3.35975587e-01,\n          -2.35171258e-01,  2.71729916e-01,  4.46444303e-01,\n           4.61972266e-01, -1.02468900e-01, -2.61221021e-01],\n         [ 2.81047791e-01, -3.66608173e-01, -5.53363264e-01,\n           1.16853835e-02,  1.09675176e-01, -3.49280149e-01,\n           1.29160464e-01, -7.58240074e-02, -2.64845073e-01,\n          -2.07234487e-01, -1.80736005e-01,  4.21559691e-01,\n           2.93599337e-01,  4.39292267e-02,  4.54771221e-02,\n          -1.17883950e-01, -9.37320851e-03,  4.14337702e-02,\n           2.53982216e-01,  9.96601488e-03, -5.62995791e-01,\n           2.10219756e-01, -8.62147212e-02,  4.33874190e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/gamma:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 240, 8) dtype=float32, numpy=\narray([[[[ 0.06104271, -0.01311505, -0.00995837, ..., -0.03434118,\n           0.07205841,  0.02138954],\n         [-0.12089845,  0.03850525,  0.12168755, ...,  0.05748101,\n          -0.05227271, -0.04151264],\n         [-0.04091245,  0.04412255, -0.10748985, ..., -0.00757462,\n           0.08675947,  0.01536237],\n         ...,\n         [ 0.09855369, -0.0741913 ,  0.02785364, ...,  0.08212776,\n           0.09798527,  0.06455448],\n         [-0.07895781, -0.06015471, -0.01694091, ...,  0.00490924,\n          -0.07673223,  0.02925727],\n         [ 0.01904452,  0.05023354, -0.03918747, ..., -0.0490978 ,\n          -0.0472915 ,  0.05387364]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-1.5563510e-01,  1.1396616e-01,  1.3776618e-01, ...,\n           3.0482208e-02,  7.9718783e-02,  4.0278852e-02],\n         [-7.4498756e-03, -1.4900202e-01,  1.6188942e-02, ...,\n           3.8401913e-02,  8.9911497e-05, -8.9520246e-02],\n         [-4.3397471e-02, -5.7577904e-02,  1.1934477e-01, ...,\n           4.6057168e-02, -1.8963411e-03,  8.7268934e-02],\n         ...,\n         [ 1.5685430e-02,  3.0594312e-03,  3.7001889e-02, ...,\n          -7.0716918e-02,  6.4648420e-02, -1.9758138e-01],\n         [-9.1882087e-02, -5.2700132e-02, -1.3114776e-01, ...,\n           1.1755834e-01,  6.1785430e-02,  4.4620920e-02],\n         [-8.8291682e-02,  1.3106145e-01, -1.6148455e-01, ...,\n          -5.2039161e-02,  1.5217073e-01,  1.9178411e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/moving_mean:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00270695],\n         [-0.02168023],\n         [ 0.01089906],\n         ...,\n         [-0.01085168],\n         [ 0.00518069],\n         [ 0.00527035]],\n\n        [[-0.01328571],\n         [-0.03063876],\n         [ 0.00170411],\n         ...,\n         [ 0.01075541],\n         [ 0.0198218 ],\n         [ 0.01510967]],\n\n        [[-0.00497825],\n         [ 0.0122616 ],\n         [-0.00617395],\n         ...,\n         [ 0.00267287],\n         [ 0.00816623],\n         [-0.00939731]]],\n\n\n       [[[ 0.0294318 ],\n         [-0.0031346 ],\n         [-0.00030231],\n         ...,\n         [ 0.00255183],\n         [ 0.00244552],\n         [ 0.0065986 ]],\n\n        [[ 0.00502799],\n         [-0.00120259],\n         [ 0.02143406],\n         ...,\n         [-0.00200683],\n         [ 0.03377771],\n         [ 0.00450534]],\n\n        [[-0.02103021],\n         [-0.00144803],\n         [-0.00247725],\n         ...,\n         [-0.01430289],\n         [ 0.00970856],\n         [-0.01870752]]],\n\n\n       [[[-0.00901844],\n         [ 0.01069937],\n         [-0.02238306],\n         ...,\n         [ 0.02736621],\n         [ 0.0028149 ],\n         [-0.00029787]],\n\n        [[-0.00956764],\n         [ 0.00499731],\n         [ 0.00251494],\n         ...,\n         [ 0.00238398],\n         [-0.01011284],\n         [ 0.0165183 ]],\n\n        [[ 0.03358697],\n         [ 0.01815953],\n         [ 0.02630089],\n         ...,\n         [ 0.00729081],\n         [-0.00407788],\n         [-0.00640129]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 0.00157504,  0.03570614,  0.01792276, ...,  0.02347786,\n          -0.04321081, -0.00786104],\n         [-0.00133759, -0.00482325,  0.01555731, ..., -0.08232547,\n           0.00277166,  0.01027902],\n         [ 0.0435539 ,  0.0627959 ,  0.0203787 , ...,  0.07726475,\n           0.02704196,  0.021789  ],\n         ...,\n         [-0.01287492,  0.01203676, -0.03161851, ..., -0.01444559,\n          -0.00817202, -0.03424544],\n         [-0.01920425,  0.01116539,  0.00395886, ...,  0.04744068,\n           0.01164416, -0.04198665],\n         [ 0.03488158, -0.06175166,  0.03859141, ...,  0.02949378,\n          -0.05102222, -0.05743229]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_359/depthwise_kernel:0' shape=(3, 3, 40, 1) dtype=float32, numpy=\narray([[[[ 5.84420264e-02],\n         [-3.05774137e-02],\n         [-3.87217551e-02],\n         [ 8.08576345e-02],\n         [-1.25366464e-01],\n         [ 4.04377431e-02],\n         [-2.83118859e-02],\n         [ 6.23314828e-02],\n         [-1.27106309e-02],\n         [-4.89171371e-02],\n         [ 3.05507183e-02],\n         [ 5.35914451e-02],\n         [ 1.18267134e-01],\n         [-8.57217088e-02],\n         [-5.29292896e-02],\n         [-8.17694813e-02],\n         [-5.38919121e-02],\n         [ 4.19949293e-02],\n         [ 8.37137401e-02],\n         [-6.59022927e-02],\n         [-2.83039212e-02],\n         [-4.44772243e-02],\n         [-9.22586322e-02],\n         [ 5.11890203e-02],\n         [-4.58919853e-02],\n         [ 7.59616494e-03],\n         [-8.03175643e-02],\n         [ 3.37432325e-03],\n         [-7.79841542e-02],\n         [ 1.01828098e-01],\n         [-9.03366506e-02],\n         [-7.91627765e-02],\n         [ 1.05145872e-01],\n         [-1.12409614e-01],\n         [-7.73725808e-02],\n         [ 2.12183297e-02],\n         [ 1.19361490e-01],\n         [-6.59781471e-02],\n         [ 9.45381522e-02],\n         [ 9.87377316e-02]],\n\n        [[-4.43492606e-02],\n         [ 2.88999081e-03],\n         [-6.26203045e-02],\n         [-4.79881093e-02],\n         [-3.97244766e-02],\n         [-1.49902329e-02],\n         [-2.77420953e-02],\n         [-7.61671439e-02],\n         [-8.83090496e-03],\n         [-2.87193358e-02],\n         [ 1.08461082e-01],\n         [-1.94247067e-02],\n         [-1.73662156e-02],\n         [-5.10453433e-03],\n         [-5.11097908e-02],\n         [ 4.25506830e-02],\n         [ 2.13284492e-02],\n         [ 1.08171746e-01],\n         [-9.65194404e-02],\n         [-7.84823745e-02],\n         [-6.46590441e-03],\n         [-4.62004095e-02],\n         [ 3.87676656e-02],\n         [-2.35643387e-02],\n         [ 4.02125865e-02],\n         [-1.19840324e-01],\n         [-2.25571766e-02],\n         [ 9.30687785e-03],\n         [ 1.02365166e-02],\n         [-2.07179487e-02],\n         [-5.23784682e-02],\n         [-5.33969030e-02],\n         [ 8.69223773e-02],\n         [-6.12758324e-02],\n         [-6.11115992e-02],\n         [ 1.52042657e-02],\n         [ 4.68569994e-02],\n         [ 4.96439338e-02],\n         [ 1.09003276e-01],\n         [-1.23886526e-01]],\n\n        [[ 1.16525501e-01],\n         [ 1.02913320e-01],\n         [-1.01660915e-01],\n         [ 9.10464078e-02],\n         [ 6.37339056e-02],\n         [ 5.00026643e-02],\n         [-1.08185679e-01],\n         [-9.35241729e-02],\n         [-3.98608893e-02],\n         [ 6.16493523e-02],\n         [ 5.37328422e-03],\n         [ 6.76348507e-02],\n         [ 1.17907211e-01],\n         [ 3.55395079e-02],\n         [ 5.88136017e-02],\n         [ 5.89650124e-02],\n         [-5.14104962e-02],\n         [-8.01192224e-02],\n         [ 8.49080831e-02],\n         [-7.78726041e-02],\n         [-2.54542828e-02],\n         [ 4.16927338e-02],\n         [ 6.04283810e-02],\n         [ 1.16343051e-01],\n         [ 5.12993485e-02],\n         [ 3.13028693e-03],\n         [-9.82185230e-02],\n         [-6.05791435e-02],\n         [ 9.44961905e-02],\n         [-3.57084274e-02],\n         [-6.45935461e-02],\n         [-9.19126272e-02],\n         [-8.95265192e-02],\n         [-1.20102786e-01],\n         [ 1.12838298e-02],\n         [ 1.10697731e-01],\n         [ 1.21677116e-01],\n         [-4.00049612e-02],\n         [-3.08984593e-02],\n         [ 7.05422461e-02]]],\n\n\n       [[[ 9.46465284e-02],\n         [-8.84237811e-02],\n         [ 4.83985692e-02],\n         [ 9.87773389e-02],\n         [-6.42681867e-02],\n         [-1.19731426e-02],\n         [ 1.04284763e-01],\n         [-7.69521222e-02],\n         [ 5.23781925e-02],\n         [-1.63612142e-02],\n         [-9.05799568e-02],\n         [ 5.17198443e-02],\n         [-9.93361920e-02],\n         [ 9.19825137e-02],\n         [-1.15511015e-01],\n         [ 7.82924294e-02],\n         [ 3.66812944e-03],\n         [-6.40455186e-02],\n         [ 1.05936781e-01],\n         [ 8.73716921e-02],\n         [ 3.79988849e-02],\n         [ 1.24873579e-01],\n         [ 6.21967018e-03],\n         [ 8.72010142e-02],\n         [ 7.14607537e-02],\n         [-9.29251909e-02],\n         [ 2.81104147e-02],\n         [-4.08482552e-02],\n         [-1.06461093e-01],\n         [-6.79676235e-02],\n         [ 1.14579126e-01],\n         [-3.44698131e-03],\n         [-6.94258884e-02],\n         [ 2.45999247e-02],\n         [ 1.42939687e-02],\n         [-1.25985578e-01],\n         [-6.03745356e-02],\n         [-3.65603194e-02],\n         [ 8.82102698e-02],\n         [ 1.15857452e-01]],\n\n        [[-5.50933108e-02],\n         [ 8.38647783e-02],\n         [ 9.61752683e-02],\n         [ 2.06865668e-02],\n         [ 1.02063373e-01],\n         [ 1.21637717e-01],\n         [ 8.84062946e-02],\n         [ 4.58164960e-02],\n         [ 8.72072726e-02],\n         [ 1.56838298e-02],\n         [ 1.87835544e-02],\n         [ 1.17395967e-02],\n         [ 1.50529593e-02],\n         [ 1.15535125e-01],\n         [ 8.27411264e-02],\n         [ 3.90405804e-02],\n         [-3.63685787e-02],\n         [-2.61436775e-02],\n         [-4.78384122e-02],\n         [ 1.02655247e-01],\n         [-1.22609675e-01],\n         [ 1.22391418e-01],\n         [ 1.12662897e-01],\n         [-3.13517600e-02],\n         [ 2.06011683e-02],\n         [-7.35425204e-03],\n         [ 3.41457874e-02],\n         [-9.53677893e-02],\n         [ 6.29100353e-02],\n         [-8.63025710e-02],\n         [-1.01253375e-01],\n         [ 5.43985367e-02],\n         [-6.70780316e-02],\n         [ 4.45505530e-02],\n         [-3.00904363e-03],\n         [-3.53460088e-02],\n         [ 7.59314597e-02],\n         [-4.60441783e-02],\n         [ 8.54007900e-03],\n         [ 1.02719337e-01]],\n\n        [[ 3.86208743e-02],\n         [ 5.63320369e-02],\n         [-3.98957282e-02],\n         [-8.40318128e-02],\n         [ 1.23606473e-01],\n         [-3.42995971e-02],\n         [ 8.30029100e-02],\n         [-5.05628437e-03],\n         [ 1.18925497e-01],\n         [ 5.41552156e-02],\n         [-6.10693097e-02],\n         [-2.76740268e-02],\n         [-7.88388401e-02],\n         [-5.03802672e-02],\n         [ 1.17912009e-01],\n         [ 1.95864141e-02],\n         [-2.37672403e-02],\n         [ 6.82919174e-02],\n         [-6.46000206e-02],\n         [-8.31057653e-02],\n         [-4.76290360e-02],\n         [ 6.83069229e-05],\n         [-9.22608227e-02],\n         [-1.04643993e-01],\n         [ 3.97684723e-02],\n         [ 1.24173522e-01],\n         [-1.06648795e-01],\n         [ 2.82082409e-02],\n         [ 1.26065910e-01],\n         [ 1.06089666e-01],\n         [-2.89665014e-02],\n         [ 5.50031960e-02],\n         [-4.25761566e-02],\n         [-3.97935808e-02],\n         [ 3.77426893e-02],\n         [ 1.12010926e-01],\n         [ 6.63828850e-02],\n         [ 1.12367228e-01],\n         [-9.78244543e-02],\n         [-5.36593050e-02]]],\n\n\n       [[[-2.23992094e-02],\n         [-6.35318458e-02],\n         [-3.11326236e-03],\n         [ 1.08099997e-01],\n         [-4.42322418e-02],\n         [-3.49096134e-02],\n         [-1.18542828e-01],\n         [ 6.92158937e-02],\n         [-1.08973011e-02],\n         [-5.58410436e-02],\n         [-1.09360076e-01],\n         [-1.27183229e-01],\n         [ 7.26999789e-02],\n         [ 2.35420763e-02],\n         [-1.06749207e-01],\n         [ 7.03605115e-02],\n         [-1.29048675e-02],\n         [ 1.14574969e-01],\n         [-6.57476038e-02],\n         [ 1.11071438e-01],\n         [ 4.41964865e-02],\n         [ 1.10713542e-02],\n         [ 1.16372734e-01],\n         [ 9.34214145e-02],\n         [-2.73460150e-02],\n         [ 8.43599737e-02],\n         [ 4.60337400e-02],\n         [ 1.11784428e-01],\n         [-4.86762002e-02],\n         [ 3.77844572e-02],\n         [-1.18259057e-01],\n         [ 9.81796682e-02],\n         [ 1.25283897e-01],\n         [-1.21603489e-01],\n         [ 6.10135198e-02],\n         [ 3.80173326e-04],\n         [ 9.82794166e-03],\n         [-7.00090602e-02],\n         [-6.84467256e-02],\n         [-5.06701469e-02]],\n\n        [[-5.58854342e-02],\n         [-1.22981675e-01],\n         [-1.08027399e-01],\n         [-2.36797109e-02],\n         [ 5.47795892e-02],\n         [-1.92969292e-02],\n         [-6.12039343e-02],\n         [ 1.24440759e-01],\n         [-4.10689414e-02],\n         [-5.70808724e-02],\n         [-1.05055876e-01],\n         [-1.67580545e-02],\n         [ 1.03043482e-01],\n         [-1.20457850e-01],\n         [-1.10972084e-01],\n         [-2.95386985e-02],\n         [ 2.89097428e-02],\n         [ 7.19778985e-02],\n         [-9.30856913e-02],\n         [ 3.55580598e-02],\n         [-2.98610851e-02],\n         [-6.80394024e-02],\n         [ 1.45328045e-02],\n         [-7.02136606e-02],\n         [-1.17908180e-01],\n         [ 6.05001003e-02],\n         [-1.05876945e-01],\n         [-1.10496745e-01],\n         [ 7.02235699e-02],\n         [ 5.05477786e-02],\n         [ 3.09474766e-02],\n         [-6.72595054e-02],\n         [ 1.13452196e-01],\n         [ 1.23863101e-01],\n         [ 9.15643424e-02],\n         [-3.96163315e-02],\n         [-1.16513066e-01],\n         [ 3.25706601e-03],\n         [ 1.93021894e-02],\n         [ 1.24712199e-01]],\n\n        [[-2.39874125e-02],\n         [-5.30241430e-03],\n         [-4.16943729e-02],\n         [-8.12925249e-02],\n         [-3.11907455e-02],\n         [-3.67601588e-02],\n         [ 8.11376572e-02],\n         [-4.47151810e-02],\n         [ 2.22942680e-02],\n         [-1.16318099e-01],\n         [ 3.90666723e-02],\n         [-2.90037766e-02],\n         [-7.94845223e-02],\n         [ 7.06908256e-02],\n         [-4.99447584e-02],\n         [-6.33961931e-02],\n         [ 1.20726362e-01],\n         [ 9.50827003e-02],\n         [-1.03158943e-01],\n         [ 1.05735064e-01],\n         [-8.05437863e-02],\n         [ 3.16193551e-02],\n         [ 6.95690215e-02],\n         [-6.58819824e-02],\n         [-8.31112713e-02],\n         [ 5.24496734e-02],\n         [ 1.27278566e-01],\n         [-1.27289027e-01],\n         [-3.90216708e-04],\n         [-8.31420049e-02],\n         [-1.15026832e-01],\n         [-3.51146609e-03],\n         [-5.39738461e-02],\n         [ 1.02403700e-01],\n         [ 2.85909474e-02],\n         [ 6.03629798e-02],\n         [-7.31144696e-02],\n         [ 9.14853811e-02],\n         [ 7.08744824e-02],\n         [-1.88782588e-02]]]], dtype=float32)>, <tf.Variable 'conv2d_854/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.08927765,  0.02310633, -0.15007019, ..., -0.07187398,\n          -0.1575451 , -0.06102789],\n         [-0.01447855,  0.01099591, -0.02975849, ..., -0.038068  ,\n           0.04645854,  0.12191444],\n         [ 0.06299087,  0.02644032,  0.15216291, ..., -0.01469995,\n          -0.02496267,  0.1261727 ],\n         ...,\n         [-0.02617172,  0.05381781,  0.03638356, ...,  0.04493128,\n           0.0426027 , -0.05502084],\n         [ 0.16851349,  0.04509362, -0.01229738, ..., -0.04244415,\n          -0.00393791, -0.02106936],\n         [-0.07568511, -0.01093991,  0.01620227, ...,  0.03543338,\n           0.0591414 , -0.11505126]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[-0.1604081 ,  0.09265926, -0.02806205, ..., -0.19241086,\n           0.16014767,  0.08268873],\n         [ 0.12953569,  0.1602902 ,  0.00827568, ...,  0.05967159,\n           0.03470638, -0.18503106],\n         [-0.11435635,  0.05174587,  0.09613944, ...,  0.17460869,\n           0.10492414,  0.06297076],\n         ...,\n         [ 0.07338991,  0.12658954,  0.11675625, ...,  0.06729905,\n          -0.00999317, -0.0936647 ],\n         [-0.11777614,  0.00880963, -0.09618402, ..., -0.04232139,\n          -0.1817877 , -0.19564846],\n         [ 0.02152024, -0.05189605,  0.02172527, ...,  0.23859856,\n          -0.02769696, -0.11629164]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 144, 4) dtype=float32, numpy=\narray([[[[ 2.32039690e-02, -1.67950206e-02,  8.60020742e-02,\n          -1.09806634e-01],\n         [ 8.54323898e-03,  6.89792484e-02,  1.61746398e-01,\n          -1.12355640e-02],\n         [-6.00562021e-02,  1.61218300e-01,  4.45421711e-02,\n           3.31441276e-02],\n         [-1.10927159e-02, -8.58479589e-02, -8.30828398e-02,\n          -9.03857127e-02],\n         [ 5.03813429e-03,  6.31147102e-02,  7.37641826e-02,\n           2.98156999e-02],\n         [-3.04640774e-02,  2.30375901e-02,  3.17528062e-02,\n           7.14620501e-02],\n         [ 1.22008296e-02, -1.74540114e-02,  6.44322038e-02,\n           1.09247388e-02],\n         [ 9.27562192e-02,  5.83481453e-02, -2.53892280e-02,\n          -9.88096148e-02],\n         [-3.66993584e-02, -3.21856625e-02,  4.18056808e-02,\n           5.85153652e-03],\n         [-1.66954268e-02,  4.83328551e-02,  8.34413990e-02,\n          -1.26409590e-01],\n         [-6.98710885e-03, -1.32808149e-01, -9.67329293e-02,\n           1.56298101e-01],\n         [-3.74568701e-02, -2.29882468e-02,  3.50534543e-02,\n          -1.12085687e-02],\n         [ 3.42793353e-02, -4.68112491e-02,  6.23147599e-02,\n          -2.71762554e-02],\n         [-5.66131100e-02, -3.37956622e-02,  4.66329195e-02,\n          -1.25237539e-01],\n         [ 1.33029558e-02,  7.89156854e-02,  7.45847300e-02,\n           2.86705215e-02],\n         [ 1.87151637e-02, -7.52698211e-03, -1.70538917e-01,\n           4.67548072e-02],\n         [ 9.20384228e-02,  1.51797086e-01, -3.82008888e-02,\n           9.13437922e-03],\n         [-5.58878891e-02, -3.60749289e-02,  1.42546117e-01,\n          -1.10958822e-01],\n         [-8.01577345e-02,  3.59659665e-03,  7.23180175e-03,\n           7.21419826e-02],\n         [-8.49249139e-02,  6.21397272e-02,  1.07876889e-01,\n           1.35272881e-02],\n         [ 3.25091332e-02, -4.39030789e-02,  8.50055143e-02,\n           1.12538032e-01],\n         [-5.49431182e-02, -3.83335240e-02, -1.37099311e-01,\n           2.41757873e-02],\n         [-1.22387987e-02, -1.07813291e-01, -1.01220518e-01,\n           1.56699911e-01],\n         [-1.13809854e-02, -1.02525458e-01, -3.28203589e-02,\n           5.24778804e-03],\n         [ 2.94138882e-02,  6.01680167e-02, -1.00700408e-01,\n          -1.81398720e-01],\n         [ 2.66503040e-02, -7.06382170e-02,  1.69448033e-02,\n          -5.05105369e-02],\n         [-8.37951750e-02, -9.88824815e-02, -7.57500678e-02,\n          -9.08203721e-02],\n         [ 3.55050415e-02,  3.95638309e-02,  8.87266621e-02,\n          -2.37995237e-02],\n         [ 1.31084204e-01,  1.04590923e-01,  1.53266579e-01,\n           1.22553684e-01],\n         [ 2.47423481e-02,  9.93949026e-02,  7.40014613e-02,\n           7.61438757e-02],\n         [-1.27699435e-01,  1.14765309e-01,  2.02232730e-02,\n          -6.47297055e-02],\n         [ 1.23162106e-01,  2.32398063e-02,  7.31307790e-02,\n          -5.44489780e-03],\n         [-3.73315439e-02, -5.12728579e-02,  1.05492003e-01,\n           1.28327245e-02],\n         [ 1.27245123e-02, -7.62887858e-03, -4.48068306e-02,\n          -3.93181965e-02],\n         [-7.07176998e-02,  5.29265543e-03, -1.03549622e-01,\n           1.26691446e-01],\n         [ 3.03000100e-02,  1.66884810e-02,  5.94952554e-02,\n          -1.02508906e-02],\n         [-1.82266980e-01, -8.81214812e-02, -5.68300188e-02,\n           1.79676369e-01],\n         [-1.08829893e-01,  5.60723851e-03, -1.55494109e-01,\n          -1.01597495e-01],\n         [-8.03215504e-02, -9.57228709e-03,  3.55300866e-02,\n          -6.25646561e-02],\n         [ 9.56917554e-02,  1.44034162e-01,  3.19728069e-02,\n          -1.47246057e-02],\n         [ 1.12042025e-01,  8.63221511e-02, -1.22239351e-01,\n           9.98041034e-02],\n         [ 3.46085639e-03,  9.97041538e-02, -2.30768900e-02,\n          -1.98863167e-02],\n         [-4.02678512e-02, -8.07441622e-02,  6.74324036e-02,\n           3.26033123e-02],\n         [ 1.08782575e-01, -6.87756985e-02, -1.61177907e-02,\n           4.09306623e-02],\n         [-9.53942612e-02,  5.30852675e-02,  1.43177167e-01,\n           4.33065705e-02],\n         [ 1.20934486e-01,  9.57549512e-02, -1.02742285e-01,\n          -6.48610219e-02],\n         [-1.01046299e-03, -1.58001468e-01,  8.10680687e-02,\n          -1.04719639e-01],\n         [ 7.31753111e-02, -1.63125806e-02,  3.57170403e-02,\n          -4.53114286e-02],\n         [-3.04795783e-02,  5.61316311e-02, -1.50168940e-01,\n          -2.91790906e-02],\n         [ 6.66745380e-02,  7.66498595e-02,  3.25827375e-02,\n          -6.28206283e-02],\n         [-4.56469283e-02, -1.34376824e-01,  3.11785955e-02,\n          -8.58782977e-02],\n         [ 7.93023966e-03,  9.59705263e-02, -7.20677003e-02,\n          -6.70344802e-03],\n         [ 2.83532143e-02, -2.01694705e-02, -1.05426557e-01,\n           4.18904051e-02],\n         [ 2.59215776e-02, -9.32423994e-02, -4.82248329e-02,\n          -1.02348952e-02],\n         [-1.87132247e-02, -7.20064864e-02,  1.06809288e-01,\n          -3.38555984e-02],\n         [ 1.43188117e-02, -5.82191907e-02,  4.22617942e-02,\n           1.45122081e-01],\n         [-1.81124941e-01, -8.24285764e-03, -9.22991037e-02,\n           7.81742334e-02],\n         [ 1.07095003e-01, -1.48167275e-02,  1.05703309e-01,\n           4.12180126e-02],\n         [ 1.43192173e-03,  3.21526751e-02, -4.44653854e-02,\n           1.15426421e-01],\n         [-7.85329714e-02,  1.79682806e-01, -1.09941401e-01,\n           6.58254027e-02],\n         [-1.63890079e-01,  1.52665108e-01, -3.92826200e-02,\n          -3.03785279e-02],\n         [ 3.90254743e-02,  3.12023293e-02, -3.43946032e-02,\n          -1.25867397e-01],\n         [ 5.73839173e-02,  1.04488015e-01, -4.53505293e-02,\n          -9.76873189e-02],\n         [ 3.71899968e-03, -8.35440028e-03, -1.11207217e-01,\n           1.36384126e-02],\n         [ 7.89987445e-02, -4.29482460e-02, -1.92072000e-02,\n          -1.54440254e-01],\n         [-3.91403474e-02,  1.14596821e-01, -4.53481935e-02,\n          -4.63046394e-02],\n         [-8.94388929e-02, -9.24426541e-02,  3.32194269e-02,\n           1.22363502e-02],\n         [-2.89974790e-02,  3.60664017e-02, -6.97032660e-02,\n           1.04637556e-02],\n         [ 4.08747531e-02, -1.35821581e-01,  1.00770801e-01,\n           5.38505018e-02],\n         [ 1.56850412e-01,  5.28691411e-02,  3.05276681e-02,\n           5.70571609e-03],\n         [ 5.38112130e-03, -1.50750251e-02, -1.57747209e-01,\n          -8.17289203e-02],\n         [-3.58038209e-02, -7.44801238e-02,  9.42011103e-02,\n          -1.05326466e-01],\n         [-4.91310470e-02, -1.24013750e-02,  1.10529035e-01,\n          -3.05791311e-02],\n         [ 1.65678531e-01, -9.47073624e-02, -1.43054361e-02,\n          -3.64813060e-02],\n         [ 5.70595870e-03,  1.39429927e-01,  1.22806855e-01,\n           1.16044305e-01],\n         [-1.61446468e-03, -1.10205591e-01, -1.43830493e-01,\n           2.13228675e-04],\n         [ 4.32302586e-05,  3.82226445e-02,  5.03091849e-02,\n          -5.76266050e-02],\n         [ 4.07750234e-02, -1.23380311e-01,  4.66464534e-02,\n           1.92814097e-02],\n         [-1.18788004e-01,  1.64318904e-01, -7.32733607e-02,\n           2.20727492e-02],\n         [ 3.41420807e-02, -1.04408458e-01, -6.46848306e-02,\n           1.40925199e-02],\n         [-4.53168526e-02,  3.47976834e-02, -9.73215550e-02,\n           1.50235698e-01],\n         [-3.75344865e-02, -7.96238706e-02,  1.85299113e-01,\n           4.40764949e-02],\n         [ 1.24215938e-01,  8.74436572e-02,  2.86027230e-03,\n           5.15091643e-02],\n         [ 1.57914355e-01,  6.73373090e-03,  6.23514019e-02,\n           2.15380732e-02],\n         [-4.92914543e-02,  1.51277077e-03,  8.58472195e-03,\n           6.22164942e-02],\n         [ 8.55982900e-02, -1.19201407e-01, -7.85484463e-02,\n          -6.75909743e-02],\n         [ 9.08132046e-02,  1.05007831e-03, -2.52275635e-02,\n           2.00525504e-02],\n         [-7.26351440e-02,  5.57457656e-02, -6.94813614e-04,\n           1.46966502e-01],\n         [-7.29022399e-02, -7.50631914e-02,  6.19325489e-02,\n          -1.23839729e-01],\n         [-9.42839310e-02,  1.05201676e-02,  4.09759358e-02,\n          -8.51704255e-02],\n         [-1.44583866e-01,  6.36543557e-02, -1.29617199e-01,\n          -9.37773846e-03],\n         [ 1.77494865e-02, -2.13235710e-02, -1.37329519e-01,\n          -4.68456233e-03],\n         [-2.89609861e-02,  2.18387917e-02,  7.88196176e-02,\n           6.47911504e-02],\n         [-1.21250294e-01, -8.60397145e-02, -1.04069591e-01,\n           9.24099162e-02],\n         [-1.36837572e-01,  2.33730860e-03, -2.41260137e-02,\n          -1.03005007e-01],\n         [ 9.53079462e-02, -4.56560776e-02,  3.94328982e-02,\n           8.15901905e-03],\n         [ 8.68844762e-02,  2.41976753e-02,  1.23425666e-02,\n          -9.09224153e-03],\n         [-4.52853888e-02,  6.64553791e-02, -1.60396025e-01,\n          -5.03647476e-02],\n         [ 1.43663093e-01, -1.64743468e-01, -5.02842218e-02,\n          -1.45463809e-01],\n         [ 6.43484518e-02, -1.69897527e-01,  6.32543042e-02,\n          -7.22356588e-02],\n         [ 8.24022666e-03,  7.09612817e-02, -1.99656766e-02,\n          -1.27321571e-01],\n         [-1.47551253e-01, -8.91607106e-02, -4.83417436e-02,\n           1.40199130e-02],\n         [ 3.53745520e-02, -9.28043127e-02,  1.33486195e-02,\n           1.58304781e-01],\n         [ 1.87206984e-01, -4.88259606e-02, -3.57408673e-02,\n          -1.97686423e-02],\n         [ 4.31926884e-02, -2.48868000e-02, -1.95279196e-02,\n           3.52209271e-03],\n         [ 5.03951982e-02,  4.75277845e-03, -1.06131934e-01,\n          -2.09131669e-02],\n         [ 7.44444057e-02,  8.60180259e-02, -1.83157906e-01,\n           4.58924994e-02],\n         [-1.87769681e-01, -3.57087441e-02,  2.13760231e-02,\n           7.96313733e-02],\n         [ 1.49912313e-01,  5.28050996e-02, -1.52681256e-02,\n           6.09828755e-02],\n         [-6.29480705e-02, -3.80108804e-02, -5.32987155e-02,\n           1.44382596e-01],\n         [-8.49804357e-02, -1.33491993e-01,  1.39583051e-01,\n          -8.19478035e-02],\n         [-9.90629494e-02, -7.96142370e-02,  1.07570253e-01,\n          -9.62870643e-02],\n         [-9.13374999e-04,  5.27729804e-04, -4.00676057e-02,\n           1.19616978e-01],\n         [ 1.75227020e-02, -1.13389730e-01,  1.72196329e-01,\n           4.23182808e-02],\n         [ 7.77740777e-02,  3.93962339e-02, -2.77597345e-02,\n          -7.80640468e-02],\n         [ 6.30129054e-02, -5.66142388e-02, -1.09555200e-01,\n           2.72745695e-02],\n         [ 6.28336966e-02, -4.67941957e-03,  4.50431332e-02,\n          -3.94124053e-02],\n         [ 6.12173751e-02, -2.34600473e-02, -1.07446369e-02,\n           4.87900637e-02],\n         [ 1.00663140e-01,  5.10732681e-02, -9.26399380e-02,\n           7.73343444e-02],\n         [ 1.37057543e-01, -7.68993199e-02,  4.85730432e-02,\n           5.95064685e-02],\n         [ 5.85447326e-02,  5.04013076e-02, -1.50410458e-02,\n          -5.78494221e-02],\n         [-7.96432700e-03,  1.04273997e-01,  2.17811819e-02,\n           9.25356597e-02],\n         [ 2.44578011e-02, -6.02282174e-02,  1.77015476e-02,\n           1.18747018e-01],\n         [-1.37136888e-03,  1.68678939e-01,  4.89798263e-02,\n          -2.34737787e-02],\n         [ 1.76901394e-03,  5.47274342e-03,  1.57165229e-01,\n           1.09086476e-01],\n         [ 1.09915130e-01, -2.34477874e-02,  1.53540047e-02,\n          -7.65306875e-02],\n         [-1.97864398e-02,  1.69357419e-01, -1.63470313e-01,\n          -4.54807561e-03],\n         [-5.91897294e-02, -2.96171810e-02, -5.97766787e-02,\n           4.74084169e-02],\n         [ 1.57482158e-02, -2.70292372e-03,  1.43421218e-01,\n           1.19408602e-02],\n         [-3.84460315e-02, -2.81387772e-02, -1.59336045e-01,\n           6.04261346e-02],\n         [ 2.20307615e-03,  1.40398130e-01,  1.28400465e-02,\n           1.52370274e-01],\n         [-3.78771797e-02, -6.95474297e-02, -8.61535072e-02,\n           1.17960833e-01],\n         [ 1.44006699e-01, -1.82743184e-02,  3.14269885e-02,\n          -1.11197367e-01],\n         [-6.68191314e-02,  3.52549255e-02,  2.53247842e-02,\n           8.78826482e-04],\n         [ 2.90407408e-02,  4.71099913e-02, -5.33276871e-02,\n          -9.19872746e-02],\n         [-2.83581968e-02, -8.08664784e-02, -9.62390974e-02,\n          -1.21426634e-01],\n         [-1.02921706e-02, -1.22379558e-02,  3.70367896e-03,\n          -5.58219664e-02],\n         [-5.62939001e-03,  4.00546379e-02,  1.42955333e-01,\n           6.59830719e-02],\n         [-6.25251792e-04,  3.50408033e-02, -1.29423201e-01,\n          -5.64990677e-02],\n         [ 7.95700848e-02, -8.86222869e-02,  2.49033608e-02,\n           5.44947479e-03],\n         [-4.47278433e-02,  6.24642372e-02,  4.46977280e-02,\n          -8.24861676e-02],\n         [ 9.24923196e-02,  1.27423495e-01,  6.44644797e-02,\n           8.14308971e-02],\n         [-1.32837713e-01,  8.53462983e-03, -3.71800773e-02,\n           8.65096003e-02],\n         [-9.31186080e-02,  5.85664622e-02, -1.59089488e-03,\n          -4.31360826e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00594558, -0.00396335, -0.02186738, ...,  0.02754293,\n          -0.02509721, -0.00084529],\n         [ 0.00569535, -0.01393074,  0.07114539, ...,  0.01338242,\n          -0.04704309, -0.00306149],\n         [-0.02383177,  0.01171319, -0.04965599, ...,  0.06913605,\n           0.02784472, -0.00517856],\n         ...,\n         [-0.08232499, -0.03535913, -0.05210387, ...,  0.01173353,\n          -0.0219713 , -0.00989982],\n         [ 0.04245688, -0.0598773 , -0.02837039, ...,  0.04096496,\n           0.05643328, -0.01824093],\n         [ 0.00912231,  0.03616695, -0.01578228, ...,  0.05656989,\n          -0.06415716,  0.00909172]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 0.00647688, -0.0087103 , -0.03474365, ...,  0.01756965,\n          -0.06735557, -0.03243956],\n         [ 0.03777772, -0.02773981, -0.05797124, ..., -0.03325171,\n          -0.05105164,  0.01640751],\n         [ 0.03888813,  0.01243715, -0.06748699, ...,  0.00287368,\n          -0.03928642, -0.01381011],\n         ...,\n         [-0.0352194 ,  0.00258397, -0.04388691, ...,  0.07749242,\n          -0.0416784 , -0.01804771],\n         [-0.04595544,  0.01328602,  0.03966352, ...,  0.01637703,\n          -0.06882746,  0.01448714],\n         [ 0.03018468,  0.07776093,  0.06670325, ..., -0.00090415,\n          -0.00205473,  0.02096124]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00278403],\n         [ 0.00714479],\n         [-0.00851856],\n         ...,\n         [-0.0124376 ],\n         [-0.00349421],\n         [ 0.00535573]],\n\n        [[-0.01108478],\n         [ 0.00969908],\n         [ 0.0099229 ],\n         ...,\n         [ 0.01376243],\n         [ 0.00868853],\n         [-0.01018537]],\n\n        [[-0.006583  ],\n         [ 0.02807542],\n         [-0.00792098],\n         ...,\n         [-0.00828437],\n         [ 0.02432678],\n         [ 0.01999041]]],\n\n\n       [[[-0.00978566],\n         [-0.00123338],\n         [ 0.03423669],\n         ...,\n         [-0.00853852],\n         [-0.02109533],\n         [ 0.00824265]],\n\n        [[-0.01714325],\n         [-0.00771266],\n         [ 0.00853083],\n         ...,\n         [-0.03115862],\n         [-0.00929501],\n         [-0.00450352]],\n\n        [[ 0.00039372],\n         [ 0.02820576],\n         [ 0.00307397],\n         ...,\n         [ 0.01740071],\n         [ 0.00466509],\n         [-0.02758245]]],\n\n\n       [[[-0.01349994],\n         [ 0.00273102],\n         [-0.02854341],\n         ...,\n         [-0.01187812],\n         [-0.01038369],\n         [-0.01251253]],\n\n        [[-0.02923885],\n         [-0.00933978],\n         [ 0.0296658 ],\n         ...,\n         [-0.03068468],\n         [-0.0075779 ],\n         [-0.01229561]],\n\n        [[ 0.0133796 ],\n         [-0.00949907],\n         [-0.01257044],\n         ...,\n         [ 0.00901757],\n         [-0.01188081],\n         [ 0.01936061]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 48, 1) dtype=float32, numpy=\narray([[[[-0.20452431],\n         [-0.24764627],\n         [-0.02291003],\n         [ 0.26807985],\n         [-0.1896921 ],\n         [ 0.08782116],\n         [ 0.17390439],\n         [ 0.03156349],\n         [ 0.20679231],\n         [-0.31079   ],\n         [ 0.01119312],\n         [ 0.06432789],\n         [-0.09114914],\n         [ 0.08604938],\n         [ 0.16241938],\n         [ 0.10320818],\n         [ 0.05796328],\n         [ 0.01005852],\n         [-0.05520332],\n         [-0.16050872],\n         [ 0.25218022],\n         [-0.00867049],\n         [ 0.1160943 ],\n         [ 0.05627656],\n         [ 0.14947554],\n         [-0.30336204],\n         [ 0.08272176],\n         [-0.03906566],\n         [-0.00807666],\n         [ 0.13487007],\n         [ 0.00533551],\n         [ 0.14318928],\n         [ 0.01428361],\n         [ 0.00601714],\n         [ 0.13084696],\n         [-0.14707583],\n         [-0.00483005],\n         [-0.16639385],\n         [-0.23647362],\n         [ 0.09266609],\n         [-0.06807948],\n         [ 0.13821703],\n         [ 0.02837384],\n         [-0.13147762],\n         [ 0.16046478],\n         [-0.29497913],\n         [-0.16454412],\n         [ 0.10789236]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-2.6183311e-02],\n         [-1.2160144e-02],\n         [-6.3104420e-03],\n         ...,\n         [-3.7077093e-04],\n         [ 4.7504938e-05],\n         [-1.7295025e-02]],\n\n        [[-1.4817242e-02],\n         [ 1.0956171e-03],\n         [-5.6892657e-03],\n         ...,\n         [-1.8619318e-02],\n         [-3.1895090e-02],\n         [-2.3701290e-02]],\n\n        [[-8.3203958e-03],\n         [ 1.6419090e-02],\n         [-5.8985618e-03],\n         ...,\n         [-3.8686779e-03],\n         [ 2.8884599e-02],\n         [ 9.8475171e-03]]],\n\n\n       [[[ 1.1574111e-02],\n         [-3.1547617e-02],\n         [-3.6060603e-03],\n         ...,\n         [-2.4135863e-02],\n         [ 1.7948838e-02],\n         [ 4.2826994e-03]],\n\n        [[-3.6202606e-03],\n         [ 2.4351936e-03],\n         [ 1.4609898e-02],\n         ...,\n         [ 2.0362806e-02],\n         [ 1.0807214e-02],\n         [-4.2689233e-03]],\n\n        [[ 2.1754781e-02],\n         [-9.8444223e-03],\n         [-1.1385389e-03],\n         ...,\n         [ 1.0217044e-02],\n         [ 7.1875281e-03],\n         [ 1.0845623e-02]]],\n\n\n       [[[-3.7411619e-03],\n         [-3.9085140e-03],\n         [-1.3038086e-03],\n         ...,\n         [-2.4963936e-03],\n         [-7.9678698e-03],\n         [ 1.1221718e-02]],\n\n        [[-5.8524334e-03],\n         [-1.5788522e-03],\n         [-1.5313556e-02],\n         ...,\n         [ 2.4537707e-02],\n         [-1.2834115e-02],\n         [ 7.0881755e-03]],\n\n        [[-2.3915144e-02],\n         [-1.4745352e-02],\n         [-1.4594946e-03],\n         ...,\n         [-1.7016517e-02],\n         [ 2.4027515e-02],\n         [-1.0733176e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_847/kernel:0' shape=(1, 1, 40, 80) dtype=float32, numpy=\narray([[[[ 0.229332  ,  0.04093602,  0.17267238, ..., -0.11219734,\n          -0.31629854, -0.3311011 ],\n         [ 0.05939723, -0.16683371, -0.01456103, ..., -0.113846  ,\n          -0.09399445, -0.0029161 ],\n         [-0.20164867, -0.0434567 ,  0.30733716, ...,  0.23951754,\n          -0.08874512, -0.24613258],\n         ...,\n         [ 0.04953276,  0.08305011,  0.31508628, ...,  0.03028731,\n           0.3592492 ,  0.16859336],\n         [ 0.19208433, -0.04702635, -0.01239415, ...,  0.1157487 ,\n           0.10809616, -0.33572364],\n         [-0.2044123 , -0.28736696,  0.03287664, ...,  0.10693512,\n           0.00311556, -0.10930848]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_870/kernel:0' shape=(1, 1, 40, 48) dtype=float32, numpy=\narray([[[[ 0.01786763, -0.06756767, -0.06571115, ..., -0.00730964,\n           0.03190067,  0.04929996],\n         [ 0.15582205,  0.04126063, -0.11644242, ...,  0.1778791 ,\n          -0.13108164,  0.10819105],\n         [-0.23720893,  0.27776513,  0.084771  , ..., -0.04624766,\n           0.21206132,  0.07303346],\n         ...,\n         [-0.13782533,  0.13409404,  0.14941959, ..., -0.00400917,\n           0.13004081, -0.09474001],\n         [ 0.05775578, -0.1817601 , -0.10625485, ..., -0.02392761,\n          -0.18189439,  0.11780782],\n         [ 0.0129387 , -0.00960935,  0.01789157, ..., -0.10858694,\n          -0.09426206, -0.05776041]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[ 9.04455483e-02, -2.07184792e-01, -9.92554501e-02, ...,\n           1.14745311e-01,  1.09404944e-01, -7.08919689e-02],\n         [ 4.27216664e-02, -3.43268782e-01,  1.29004762e-01, ...,\n          -4.02653702e-02, -1.55820921e-01,  2.10245699e-01],\n         [ 6.75961301e-02,  1.45427153e-01,  4.89846796e-01, ...,\n           3.67045432e-01, -3.00594211e-01, -1.52926058e-01],\n         ...,\n         [ 2.75346041e-01, -3.11970025e-01, -4.46407646e-02, ...,\n           4.62386698e-01, -1.54344216e-01, -1.98008284e-01],\n         [-4.69537109e-01, -1.80055812e-01, -2.10313588e-01, ...,\n          -3.78822953e-01, -2.55688250e-01, -1.42059296e-01],\n         [-1.88061409e-02,  3.61227285e-04,  4.33175772e-01, ...,\n          -2.52818614e-01, -2.48124629e-01,  7.25146569e-03]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.06218434, -0.02912119,  0.02528213, ..., -0.06105898,\n           0.00827789,  0.01344541],\n         [-0.04778626,  0.07393913,  0.00090825, ...,  0.02585004,\n           0.06451119,  0.0195078 ],\n         [ 0.07892776,  0.05214995, -0.02863943, ..., -0.05960136,\n          -0.04461313, -0.01483198],\n         ...,\n         [-0.00203958,  0.02563635,  0.0337376 , ...,  0.03392703,\n          -0.02019267,  0.00203115],\n         [-0.02177941,  0.02133331,  0.00691758, ...,  0.00056913,\n           0.01574793, -0.06987429],\n         [ 0.02815631, -0.07254051, -0.05622057, ...,  0.05674487,\n          -0.02285005,  0.06077871]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.09860171, -0.11219367,  0.0709422 , ...,  0.08694396,\n           0.18968357,  0.10887267],\n         [-0.01329385,  0.12000927, -0.11050098, ...,  0.11348261,\n          -0.05166499, -0.01582274],\n         [ 0.09126663,  0.20365034,  0.03514957, ..., -0.03547748,\n          -0.00111086, -0.07441013],\n         ...,\n         [ 0.03441123, -0.1054856 , -0.05878557, ..., -0.04722461,\n          -0.04590106, -0.1330409 ],\n         [-0.07849413, -0.15322424, -0.13777962, ...,  0.10463468,\n           0.09271255,  0.14085548],\n         [-0.10808384, -0.16496061,  0.08698642, ...,  0.01723261,\n           0.07496623,  0.09839762]]]], dtype=float32)>, <tf.Variable 'conv2d_845/kernel:0' shape=(1, 1, 80, 40) dtype=float32, numpy=\narray([[[[-0.19312444,  0.0357251 ,  0.01952331, ..., -0.01949608,\n          -0.12020243,  0.0675675 ],\n         [-0.09228604, -0.12264537,  0.15288417, ..., -0.10980439,\n          -0.00611857,  0.02119552],\n         [-0.11897351, -0.06030397,  0.17962353, ..., -0.00189233,\n           0.22617678,  0.11639097],\n         ...,\n         [-0.06119209,  0.13107713, -0.00023754, ..., -0.11844175,\n          -0.0159166 , -0.0230818 ],\n         [ 0.11544303, -0.0404611 ,  0.10752261, ...,  0.04909577,\n          -0.08193842, -0.19968154],\n         [ 0.03710693,  0.13424017, -0.03987942, ...,  0.04734444,\n          -0.05461815, -0.14645886]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 3, 96) dtype=float32, numpy=\narray([[[[-0.8593429 , -0.6109924 ,  0.36287078,  0.45430574,\n           0.14662363, -0.46694908,  0.44328102,  0.40329054,\n           0.36155355,  0.18604578, -0.94025755,  0.95838004,\n          -0.76577735,  1.213723  , -0.68889666, -0.16700104,\n          -0.74892443, -1.1795899 , -0.8641835 , -0.30184627,\n           0.63804334, -0.32673252, -0.3049658 , -0.22566764,\n           0.91246814,  0.50334316, -0.5088513 , -0.437984  ,\n          -0.65780735,  0.0071061 ,  0.50954175, -0.26528206,\n           0.7372988 , -0.75061214,  0.3759602 ,  0.2658918 ,\n          -0.06775504, -0.7239791 , -0.5217252 ,  0.47276732,\n          -0.5091465 ,  0.21450779,  0.34305522, -0.6261916 ,\n           0.29846773,  0.7305226 ,  1.1869324 , -0.75986063,\n           0.7797713 ,  0.13992728, -0.07813749,  0.10864262,\n           0.7253289 , -0.36918446, -1.2462404 ,  0.29151687,\n           0.95042956, -0.43650752, -0.60653543,  0.04379154,\n           0.12984595,  0.71820587,  0.69131374,  0.12424265,\n          -0.30545488, -0.4368651 , -0.7535283 ,  0.48615748,\n           0.72840834,  1.0319091 ,  0.859103  ,  0.64009833,\n           0.49592033, -0.04839873, -0.21526663, -0.18156706,\n          -0.23926209, -0.78757334,  0.4112407 ,  0.6257132 ,\n           0.8758807 ,  0.67707735, -0.03155694, -0.36504424,\n          -0.4371244 ,  0.67949617,  0.66544366, -0.11875213,\n           0.75677997,  0.824948  ,  0.05948771, -0.51029384,\n          -0.32522076,  0.16038771,  0.9327282 ,  0.30767703],\n         [-0.5149336 , -0.16470696,  0.31653985, -0.16991876,\n          -0.0901171 ,  0.842091  , -0.9595922 ,  0.4612894 ,\n           1.0868502 ,  0.9509355 , -0.04431336, -0.2887685 ,\n          -0.14857617, -0.27049974,  0.3779367 ,  0.5350244 ,\n           0.21228361,  0.5017787 , -0.03958563,  0.5398204 ,\n           0.7143424 ,  0.46369573, -0.57510746,  0.6716289 ,\n          -0.85309744,  0.18525329, -0.20368175,  0.09259929,\n           0.27726224, -0.66497225,  0.38098735,  0.22189927,\n          -0.42487353, -0.25962558,  0.4879799 ,  0.06922325,\n          -0.2949499 ,  0.38467517,  0.4912171 , -0.3304667 ,\n          -0.08945231, -1.3060173 , -0.4923653 ,  0.01481713,\n           0.6855385 , -0.131608  ,  0.29371914,  0.617395  ,\n           0.4626659 , -0.05616185,  0.15508533, -0.3404533 ,\n           0.152904  , -0.22411352,  0.36773992,  0.19951057,\n           0.4924971 , -0.11172747,  0.09707072, -0.19990876,\n          -0.12556368,  1.1386222 , -0.34875035,  0.03312385,\n          -0.20032091, -0.11300383,  0.84240663,  0.1291132 ,\n          -0.7391954 , -1.1676342 ,  0.33909613, -0.40474394,\n          -0.22760735,  0.27282873, -0.38112888, -0.37546006,\n           0.7538182 ,  0.5045261 ,  1.1025451 , -0.30221808,\n          -0.80742127, -0.2066607 , -0.24623291,  0.1884451 ,\n           0.044443  ,  0.66836005,  0.9218799 ,  0.34738305,\n          -0.7384581 ,  0.8018028 ,  0.26269802, -0.50505793,\n          -0.5469436 , -0.41108543,  1.0984261 ,  0.3808754 ],\n         [-0.3181677 ,  0.3926193 , -0.24732952,  0.7514955 ,\n          -0.37740493,  0.60732955,  0.22855878, -0.36008295,\n          -0.94813   ,  0.16374506, -0.80468255,  0.11867169,\n          -0.22354127, -0.1988464 , -0.17168859, -0.1275264 ,\n          -0.17421068,  0.5361863 , -0.39278293,  0.21524292,\n          -0.8568358 , -0.36071274, -0.22772855, -0.25146058,\n          -0.21862538,  0.4152325 , -0.5275163 ,  0.5676322 ,\n          -0.8980084 , -0.3808319 ,  0.01031865,  1.1934484 ,\n           0.13256325,  0.94505733, -0.47729507, -0.8778686 ,\n          -0.79745376,  1.2455444 , -0.12721737,  0.38777995,\n          -0.12185254, -0.54620564,  0.4413523 , -0.00657901,\n          -0.18665062,  0.05991966, -0.03109413, -0.8999574 ,\n          -0.42473194,  0.6517911 ,  1.0288966 ,  0.24611346,\n           0.8151978 ,  0.18124261, -0.3569229 , -0.22670203,\n          -0.264546  ,  0.33624667, -0.9034328 , -0.5437337 ,\n          -1.2012364 , -0.0924942 , -0.40718198,  0.41623724,\n          -0.79206127, -0.6891899 ,  0.19105347,  1.2648487 ,\n          -0.331584  ,  1.1567346 ,  0.47548437,  0.3004957 ,\n          -0.6069525 , -0.82851535, -0.1622208 ,  0.2856439 ,\n          -0.06693541, -0.8659546 , -0.3870505 ,  0.45674446,\n           0.21934836, -0.0392806 ,  0.41481543, -0.5834661 ,\n          -1.159805  ,  0.3857798 ,  1.0796093 , -1.0500197 ,\n          -0.5846484 ,  0.6644391 ,  0.19117105,  0.6010996 ,\n          -0.2686303 ,  0.5102761 ,  0.02802917,  0.14588255]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/conv2d/kernel:0' shape=(1, 1, 40, 240) dtype=float32, numpy=\narray([[[[-0.03580589, -0.03718453,  0.09063021, ...,  0.2840908 ,\n           0.0600919 ,  0.12841374],\n         [ 0.12966247, -0.04607128, -0.05790869, ..., -0.31139356,\n          -0.13142434,  0.14053947],\n         [-0.12613043, -0.11303505,  0.13390559, ..., -0.01209663,\n           0.15497226,  0.22257319],\n         ...,\n         [ 0.1730419 ,  0.12086028, -0.04780838, ...,  0.04298738,\n           0.16725871, -0.32186684],\n         [ 0.1727904 ,  0.1389913 , -0.14906678, ...,  0.08908752,\n          -0.13282941,  0.04531224],\n         [ 0.3381272 , -0.05858222,  0.05869281, ...,  0.21563582,\n          -0.00696808, -0.10495767]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.04094838, -0.01697714, -0.02476349, ..., -0.01517121,\n          -0.05534598, -0.0133063 ],\n         [-0.01546451,  0.08713336,  0.03070217, ...,  0.03287918,\n           0.0441424 ,  0.0240233 ],\n         [-0.06429084,  0.0282733 ,  0.07640268, ...,  0.0755832 ,\n          -0.06094262, -0.03022468],\n         ...,\n         [-0.05749188,  0.00406919, -0.04209737, ...,  0.01730248,\n           0.0636812 , -0.0345047 ],\n         [-0.004345  ,  0.03219265, -0.00685621, ..., -0.07859609,\n           0.06323933, -0.05358142],\n         [ 0.02457728,  0.0408018 , -0.00118632, ..., -0.03826384,\n           0.07124622, -0.05614092]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/gamma:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 7.5099856e-02, -8.9831585e-03, -1.7786924e-02, ...,\n           8.0594085e-02, -8.1487805e-02,  3.0029789e-02],\n         [ 1.7842339e-02,  2.9523984e-02, -8.1233755e-03, ...,\n           1.9957755e-02, -5.6560870e-02, -2.5081730e-05],\n         [-1.5797760e-02, -2.6927613e-02,  2.2581900e-02, ...,\n          -9.3783578e-03, -6.0688374e-03, -2.5263911e-02],\n         ...,\n         [-3.8226977e-02,  2.5025753e-02,  1.4250455e-02, ...,\n          -6.4321011e-02, -3.0882681e-02, -3.3604253e-02],\n         [ 7.7694997e-02, -4.3030303e-02,  4.2262655e-02, ...,\n           2.2949072e-02, -7.2324507e-02,  2.7398553e-03],\n         [-3.1653494e-02,  1.0344838e-02, -2.9931890e-02, ...,\n           5.8528718e-02, -3.8647234e-02, -1.0123580e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_353/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.13849488],\n         [ 0.02897866],\n         [-0.07185471],\n         [-0.16313478],\n         [-0.06370933],\n         [ 0.08449882],\n         [-0.09591664],\n         [ 0.13218993],\n         [ 0.03371559],\n         [ 0.14078301],\n         [ 0.05277188],\n         [-0.04513314],\n         [-0.10746551],\n         [ 0.1301198 ],\n         [-0.12517352],\n         [-0.00607796],\n         [-0.04420073],\n         [-0.01560271],\n         [-0.10181466],\n         [-0.12030029],\n         [ 0.03560224],\n         [ 0.10298756],\n         [ 0.09315181],\n         [ 0.06096803]],\n\n        [[ 0.1289083 ],\n         [-0.13086674],\n         [-0.00188552],\n         [ 0.13375822],\n         [-0.05067164],\n         [ 0.06413913],\n         [-0.03335604],\n         [-0.08779264],\n         [-0.07066435],\n         [ 0.03209385],\n         [-0.00485015],\n         [-0.06488166],\n         [ 0.01330392],\n         [ 0.01405156],\n         [-0.12815717],\n         [-0.10817936],\n         [-0.05917124],\n         [-0.12819333],\n         [-0.09434272],\n         [-0.04462093],\n         [-0.03463961],\n         [ 0.08506422],\n         [-0.07328302],\n         [ 0.11587828]],\n\n        [[ 0.10083047],\n         [ 0.09766015],\n         [ 0.00050169],\n         [-0.12740344],\n         [-0.08339427],\n         [-0.11373359],\n         [-0.01170456],\n         [-0.07792348],\n         [-0.02138443],\n         [ 0.14089778],\n         [ 0.10965672],\n         [-0.04187164],\n         [-0.07663396],\n         [-0.01406012],\n         [ 0.16258112],\n         [ 0.12789953],\n         [-0.09293009],\n         [ 0.09892866],\n         [-0.00890462],\n         [-0.08325501],\n         [-0.11338755],\n         [ 0.00055796],\n         [ 0.15617815],\n         [ 0.16254085]]],\n\n\n       [[[ 0.05785306],\n         [-0.02455457],\n         [-0.14726865],\n         [-0.01772518],\n         [-0.08700296],\n         [-0.1356391 ],\n         [ 0.1537045 ],\n         [-0.14312136],\n         [-0.16197842],\n         [ 0.13620618],\n         [ 0.04348142],\n         [-0.1349677 ],\n         [ 0.10783952],\n         [ 0.11449111],\n         [-0.05310293],\n         [-0.00686146],\n         [ 0.03816858],\n         [-0.0661655 ],\n         [-0.02866369],\n         [ 0.13562939],\n         [ 0.11119592],\n         [ 0.09225491],\n         [-0.11073255],\n         [-0.04627149]],\n\n        [[-0.09527521],\n         [ 0.0263105 ],\n         [ 0.12082401],\n         [ 0.16120282],\n         [ 0.12034109],\n         [-0.02056006],\n         [ 0.10700285],\n         [-0.0173223 ],\n         [-0.0571215 ],\n         [-0.04807582],\n         [ 0.11205998],\n         [-0.10625277],\n         [ 0.12528017],\n         [ 0.1247215 ],\n         [-0.11606404],\n         [ 0.0836274 ],\n         [ 0.08162206],\n         [ 0.09087798],\n         [-0.01115549],\n         [ 0.02544217],\n         [-0.07372694],\n         [ 0.00969583],\n         [-0.10373724],\n         [-0.09142876]],\n\n        [[-0.01747854],\n         [-0.09289146],\n         [ 0.13116187],\n         [ 0.00941414],\n         [-0.16147485],\n         [-0.05920437],\n         [ 0.14826769],\n         [ 0.12216702],\n         [-0.04528728],\n         [-0.13535933],\n         [-0.03953617],\n         [-0.13990627],\n         [ 0.02382432],\n         [-0.10780552],\n         [ 0.07998529],\n         [ 0.13866073],\n         [ 0.09606892],\n         [-0.01306958],\n         [-0.02496515],\n         [-0.02547172],\n         [-0.00026315],\n         [-0.08821733],\n         [ 0.06392771],\n         [-0.14167696]]],\n\n\n       [[[-0.0934789 ],\n         [ 0.10967278],\n         [-0.02268095],\n         [-0.03492032],\n         [ 0.11339512],\n         [ 0.07917415],\n         [-0.16083245],\n         [ 0.04575776],\n         [ 0.04448517],\n         [ 0.08861175],\n         [ 0.00100951],\n         [-0.1622566 ],\n         [ 0.05607858],\n         [ 0.07968107],\n         [-0.09459761],\n         [-0.13017619],\n         [ 0.16299564],\n         [ 0.12090075],\n         [-0.12790655],\n         [-0.09997084],\n         [-0.04945968],\n         [-0.09769723],\n         [ 0.15370592],\n         [-0.01436058]],\n\n        [[ 0.00155622],\n         [-0.02179335],\n         [ 0.07990396],\n         [ 0.1631676 ],\n         [-0.13359179],\n         [-0.04661316],\n         [ 0.1425178 ],\n         [ 0.11671162],\n         [-0.1062787 ],\n         [ 0.07332212],\n         [ 0.05208018],\n         [ 0.06097203],\n         [-0.05572534],\n         [ 0.01191519],\n         [ 0.01859282],\n         [-0.08418649],\n         [-0.07508659],\n         [-0.06353476],\n         [-0.08970284],\n         [ 0.10558009],\n         [-0.08706338],\n         [-0.1299974 ],\n         [ 0.06256886],\n         [ 0.01166372]],\n\n        [[-0.00765508],\n         [-0.14113945],\n         [ 0.08079234],\n         [-0.10584214],\n         [-0.02799076],\n         [-0.08138246],\n         [ 0.02568609],\n         [-0.06525726],\n         [-0.08336831],\n         [-0.04966214],\n         [-0.05686022],\n         [ 0.04603559],\n         [ 0.03964721],\n         [ 0.13066441],\n         [-0.02188641],\n         [ 0.0215814 ],\n         [-0.06033399],\n         [ 0.03386502],\n         [-0.05600457],\n         [ 0.04908063],\n         [-0.02449323],\n         [ 0.09225911],\n         [-0.12986058],\n         [ 0.01486866]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 240, 8) dtype=float32, numpy=\narray([[[[ 3.4974236e-02,  4.0096171e-02, -1.8591153e-02, ...,\n          -3.2003436e-02, -7.9247683e-02,  8.4725231e-02],\n         [-7.8437433e-02, -2.3399906e-02,  9.0212069e-02, ...,\n          -3.8341627e-02, -3.0448733e-02, -1.3374437e-02],\n         [-6.9455549e-02, -1.6197116e-03,  1.4379847e-02, ...,\n           2.1526795e-02, -1.2121414e-01,  9.6624739e-02],\n         ...,\n         [-1.5014499e-02,  2.7963048e-05,  2.6916457e-02, ...,\n          -3.9851893e-02, -5.5315755e-02, -7.9558380e-02],\n         [ 5.3736931e-03,  9.1576524e-02, -4.8750237e-02, ...,\n          -3.8119044e-02,  9.3422614e-02,  3.1993296e-02],\n         [-1.1105114e-01,  9.2410639e-02, -1.3369443e-01, ...,\n          -3.4973089e-02, -3.0608911e-02,  1.3594982e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/moving_variance:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.02017228],\n         [-0.01151623],\n         [-0.00789383],\n         ...,\n         [ 0.00484896],\n         [ 0.01367104],\n         [ 0.00623519]],\n\n        [[ 0.00044052],\n         [ 0.02443755],\n         [-0.00860939],\n         ...,\n         [-0.00219958],\n         [ 0.00124043],\n         [ 0.00480329]],\n\n        [[ 0.01082526],\n         [ 0.0115036 ],\n         [-0.02170265],\n         ...,\n         [ 0.02083252],\n         [ 0.00915166],\n         [ 0.0230524 ]]],\n\n\n       [[[-0.01161856],\n         [ 0.02521697],\n         [ 0.0076262 ],\n         ...,\n         [ 0.00082509],\n         [-0.00126224],\n         [ 0.00825271]],\n\n        [[-0.01537788],\n         [ 0.0225614 ],\n         [ 0.01172892],\n         ...,\n         [-0.00044733],\n         [ 0.00332063],\n         [ 0.01808693]],\n\n        [[-0.01314352],\n         [-0.003966  ],\n         [-0.02428772],\n         ...,\n         [ 0.01708915],\n         [-0.01331055],\n         [-0.00778214]]],\n\n\n       [[[ 0.00837127],\n         [-0.01023646],\n         [-0.0141609 ],\n         ...,\n         [-0.01595775],\n         [-0.02467681],\n         [ 0.01089629]],\n\n        [[-0.0003353 ],\n         [-0.01173409],\n         [-0.01102669],\n         ...,\n         [-0.02343264],\n         [-0.02184847],\n         [ 0.01711092]],\n\n        [[-0.00066283],\n         [-0.01914847],\n         [-0.01192349],\n         ...,\n         [ 0.00704022],\n         [ 0.00017623],\n         [ 0.01328891]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_355/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.09269446],\n         [-0.01288679],\n         [ 0.06708951],\n         [-0.06255546],\n         [ 0.12168574],\n         [ 0.10496387],\n         [ 0.04545474],\n         [-0.10202396],\n         [-0.13733108],\n         [ 0.13268262],\n         [-0.13912818],\n         [-0.1320993 ],\n         [ 0.01688986],\n         [ 0.03911191],\n         [ 0.01015015],\n         [-0.12454732],\n         [ 0.07805601],\n         [-0.06554677],\n         [-0.05939475],\n         [ 0.13075036],\n         [-0.04195975],\n         [-0.06328613],\n         [-0.02970126],\n         [ 0.12993541]],\n\n        [[ 0.08413389],\n         [-0.11934552],\n         [ 0.01912406],\n         [-0.160735  ],\n         [-0.0731503 ],\n         [ 0.07060362],\n         [ 0.11601949],\n         [ 0.15515578],\n         [-0.10723001],\n         [ 0.00271535],\n         [-0.05833214],\n         [ 0.08732694],\n         [-0.12123305],\n         [-0.1452452 ],\n         [-0.00541991],\n         [ 0.10782027],\n         [-0.0072756 ],\n         [ 0.13823882],\n         [ 0.09904993],\n         [ 0.01572809],\n         [-0.12993568],\n         [-0.11935167],\n         [ 0.10636064],\n         [-0.0721047 ]],\n\n        [[-0.03184289],\n         [-0.03854185],\n         [ 0.07815008],\n         [-0.08041282],\n         [ 0.1288842 ],\n         [ 0.09504798],\n         [ 0.03231831],\n         [-0.0126072 ],\n         [-0.13856263],\n         [ 0.03962275],\n         [-0.10303631],\n         [ 0.04475491],\n         [-0.01651007],\n         [-0.03154221],\n         [-0.1412346 ],\n         [ 0.13627812],\n         [-0.0795557 ],\n         [-0.11119356],\n         [ 0.04392433],\n         [ 0.06009938],\n         [-0.11693202],\n         [-0.14295442],\n         [ 0.03680097],\n         [-0.12765804]]],\n\n\n       [[[ 0.0483074 ],\n         [-0.11818016],\n         [-0.00753559],\n         [-0.06340686],\n         [ 0.06363264],\n         [ 0.11563954],\n         [-0.0348106 ],\n         [ 0.04858722],\n         [ 0.13422772],\n         [-0.043624  ],\n         [-0.1470414 ],\n         [ 0.06906699],\n         [ 0.06273821],\n         [ 0.03705294],\n         [-0.10490952],\n         [-0.03354752],\n         [-0.09529826],\n         [-0.0415912 ],\n         [-0.04517835],\n         [ 0.04118162],\n         [-0.0210961 ],\n         [-0.04940587],\n         [ 0.02069998],\n         [ 0.09116167]],\n\n        [[-0.13297118],\n         [ 0.15001136],\n         [-0.02755992],\n         [-0.12241368],\n         [ 0.01992279],\n         [ 0.06407948],\n         [-0.06437288],\n         [ 0.00943065],\n         [ 0.14539641],\n         [ 0.1001541 ],\n         [-0.07872342],\n         [-0.14381614],\n         [-0.08720973],\n         [-0.041499  ],\n         [-0.00571515],\n         [ 0.01406628],\n         [-0.05493507],\n         [-0.00952733],\n         [-0.15234894],\n         [-0.06869525],\n         [ 0.04272585],\n         [-0.1039326 ],\n         [ 0.10173959],\n         [ 0.0951407 ]],\n\n        [[-0.01209678],\n         [-0.10130338],\n         [-0.02303934],\n         [-0.139551  ],\n         [ 0.13466263],\n         [ 0.05279757],\n         [-0.02733119],\n         [ 0.14191648],\n         [ 0.0677093 ],\n         [-0.06976175],\n         [ 0.07574196],\n         [-0.04425963],\n         [ 0.12402746],\n         [-0.1598713 ],\n         [-0.00876325],\n         [ 0.0572045 ],\n         [ 0.08567087],\n         [ 0.06938547],\n         [-0.15256217],\n         [-0.15812738],\n         [ 0.07876873],\n         [-0.1316569 ],\n         [ 0.06263675],\n         [-0.03180766]]],\n\n\n       [[[ 0.07397492],\n         [ 0.10051706],\n         [-0.03205508],\n         [-0.04766098],\n         [ 0.01373401],\n         [ 0.16122478],\n         [-0.0163205 ],\n         [-0.05664468],\n         [ 0.0171812 ],\n         [ 0.10179979],\n         [ 0.0593221 ],\n         [-0.14177173],\n         [ 0.08279306],\n         [-0.1401204 ],\n         [-0.0993349 ],\n         [-0.1573097 ],\n         [ 0.03865817],\n         [ 0.09140867],\n         [-0.10799669],\n         [-0.04494482],\n         [-0.07470375],\n         [-0.14041622],\n         [ 0.10016131],\n         [-0.15711935]],\n\n        [[ 0.14849514],\n         [-0.13938491],\n         [ 0.04092151],\n         [-0.14479437],\n         [-0.13778949],\n         [ 0.03896116],\n         [ 0.09166905],\n         [ 0.03831318],\n         [-0.01095051],\n         [ 0.13168657],\n         [ 0.00416721],\n         [ 0.13576624],\n         [-0.05778259],\n         [-0.06010428],\n         [-0.04157282],\n         [ 0.08086531],\n         [-0.11566941],\n         [-0.1401071 ],\n         [ 0.11043647],\n         [-0.02235334],\n         [ 0.05919752],\n         [-0.02376911],\n         [ 0.03531316],\n         [ 0.00431439]],\n\n        [[-0.01478989],\n         [-0.0404054 ],\n         [ 0.01434259],\n         [ 0.11781424],\n         [-0.12623766],\n         [ 0.10526732],\n         [-0.13766132],\n         [ 0.15785667],\n         [-0.14722706],\n         [-0.06357684],\n         [-0.02407852],\n         [ 0.12087491],\n         [-0.15142843],\n         [ 0.00590762],\n         [-0.1347552 ],\n         [-0.00799976],\n         [ 0.15857908],\n         [ 0.02078167],\n         [ 0.00017855],\n         [ 0.00757048],\n         [ 0.00604378],\n         [ 0.0099538 ],\n         [ 0.02369763],\n         [-0.04869989]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_3/bias:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_869/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.10592639, -0.17026709, -0.07162118, ...,  0.02469771,\n          -0.156245  , -0.09833174],\n         [ 0.09968647,  0.21304305, -0.03984497, ..., -0.07341669,\n          -0.20432045,  0.11369864],\n         [-0.15301932, -0.10845814, -0.04094265, ...,  0.19014755,\n           0.07070048,  0.05079155],\n         ...,\n         [ 0.03690203,  0.02658478,  0.06377494, ..., -0.0372372 ,\n          -0.01185   , -0.16090263],\n         [-0.12691054,  0.03265052,  0.1367361 , ..., -0.01871606,\n          -0.07647292,  0.16047268],\n         [-0.05541273,  0.03420696,  0.00142948, ...,  0.12095267,\n          -0.07917752,  0.16956376]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.01155742, -0.00524791, -0.04753219, ..., -0.03320216,\n           0.03468966,  0.02906549],\n         [ 0.00650545,  0.0076134 , -0.02321688, ...,  0.02695363,\n          -0.04825719, -0.01543849],\n         [ 0.07276434, -0.03177005,  0.05419445, ...,  0.07522202,\n           0.05643095, -0.00412206],\n         ...,\n         [-0.01949945, -0.04551144,  0.03964258, ..., -0.02649692,\n           0.00759518,  0.0207909 ],\n         [-0.03894961,  0.01449677, -0.01115661, ...,  0.05769029,\n           0.03066368, -0.00863155],\n         [ 0.01153878,  0.00901201, -0.02214593, ...,  0.06698662,\n          -0.02741809, -0.04417448]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.16193387, -0.37508973,  0.08705277, ...,  0.01701975,\n           0.15192893, -0.04754537],\n         [ 0.02943505,  0.19256023,  0.2590664 , ...,  0.35520983,\n          -0.00518594, -0.00350543],\n         [ 0.4648605 , -0.2680278 ,  0.22158462, ..., -0.11250801,\n           0.21562612,  0.10423541],\n         ...,\n         [-0.31060377, -0.17255054,  0.20477678, ...,  0.12670554,\n           0.08347422, -0.16853902],\n         [ 0.37753522, -0.10106166,  0.21652375, ..., -0.14339328,\n           0.05991311, -0.31484053],\n         [ 0.17065421, -0.0329602 ,  0.07007157, ...,  0.13431372,\n          -0.10313313, -0.05288402]]]], dtype=float32)>, <tf.Variable 'conv2d_849/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.0351841 ,  0.23216508, -0.11201655, ..., -0.09371081,\n           0.07142515,  0.11072045],\n         [ 0.06653243, -0.12167284,  0.02268673, ..., -0.11387742,\n          -0.21050474, -0.06499572],\n         [ 0.17949948, -0.1845357 ,  0.21261455, ...,  0.03640857,\n           0.13286114, -0.06381626],\n         ...,\n         [ 0.04578014, -0.10260485,  0.07663377, ...,  0.11811225,\n           0.03447432,  0.00667574],\n         [ 0.01730198, -0.13425732,  0.00642166, ...,  0.16024661,\n          -0.05570469,  0.04722622],\n         [ 0.08311965, -0.07642876,  0.15479963, ...,  0.17699969,\n           0.08706012,  0.01549458]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[ 0.01865456,  0.02448711,  0.06336626, ...,  0.01863312,\n           0.06645602, -0.01027271],\n         [-0.05046976, -0.07778978,  0.0923899 , ...,  0.07419171,\n          -0.08859947,  0.00970246],\n         [ 0.06254003,  0.02266415, -0.04971264, ...,  0.05631211,\n          -0.09927698,  0.04001227],\n         ...,\n         [-0.0252409 , -0.05158851, -0.06827082, ..., -0.0460006 ,\n           0.05745228,  0.06582876],\n         [-0.02060892, -0.04300323, -0.00547198, ...,  0.03776245,\n          -0.05827299,  0.03000936],\n         [ 0.00457463, -0.06207519,  0.042109  , ..., -0.02820795,\n           0.07345182, -0.06322144]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_351/depthwise_kernel:0' shape=(3, 3, 16, 1) dtype=float32, numpy=\narray([[[[-0.18156898],\n         [ 0.19505154],\n         [ 0.12156393],\n         [ 0.02849521],\n         [-0.13632303],\n         [-0.0960763 ],\n         [ 0.05003363],\n         [ 0.10355498],\n         [ 0.01060599],\n         [-0.04266867],\n         [-0.13654622],\n         [ 0.18727376],\n         [ 0.02451327],\n         [ 0.17977022],\n         [ 0.13572358],\n         [ 0.00656609]],\n\n        [[-0.16418095],\n         [-0.04750711],\n         [-0.05908103],\n         [ 0.12219118],\n         [ 0.05839451],\n         [-0.00379916],\n         [ 0.06902014],\n         [-0.01142336],\n         [-0.09227902],\n         [ 0.12532367],\n         [ 0.02946818],\n         [ 0.01296528],\n         [ 0.01123323],\n         [-0.05944246],\n         [-0.07007948],\n         [ 0.03112119]],\n\n        [[-0.00334752],\n         [-0.04870947],\n         [ 0.12945266],\n         [ 0.03037643],\n         [ 0.05273323],\n         [ 0.1808352 ],\n         [ 0.13996442],\n         [-0.19378418],\n         [ 0.08197828],\n         [ 0.18762355],\n         [ 0.13652964],\n         [-0.18967997],\n         [ 0.14133559],\n         [ 0.13443165],\n         [-0.07212397],\n         [ 0.12348302]]],\n\n\n       [[[-0.15704367],\n         [-0.17987463],\n         [-0.14626706],\n         [ 0.06493117],\n         [-0.10852023],\n         [ 0.08941413],\n         [ 0.02448201],\n         [ 0.07179783],\n         [ 0.10626198],\n         [ 0.10289763],\n         [-0.0161633 ],\n         [-0.15579174],\n         [ 0.10292868],\n         [ 0.05571733],\n         [-0.03318594],\n         [ 0.19201557]],\n\n        [[-0.10133867],\n         [-0.04271537],\n         [-0.12265202],\n         [-0.11693847],\n         [ 0.16743277],\n         [ 0.01850998],\n         [ 0.13967718],\n         [-0.00180532],\n         [-0.10186317],\n         [-0.10008807],\n         [-0.00190352],\n         [-0.1433066 ],\n         [-0.08448618],\n         [ 0.18880527],\n         [ 0.00458187],\n         [ 0.15746965]],\n\n        [[ 0.09598999],\n         [-0.11429355],\n         [ 0.09206222],\n         [ 0.03717443],\n         [ 0.17919262],\n         [ 0.16423129],\n         [-0.09106095],\n         [ 0.17646314],\n         [ 0.13589911],\n         [-0.05981819],\n         [-0.15076658],\n         [ 0.07567169],\n         [-0.07332292],\n         [-0.01439539],\n         [-0.19669236],\n         [ 0.0540788 ]]],\n\n\n       [[[-0.0592943 ],\n         [-0.05214687],\n         [ 0.1332853 ],\n         [-0.11282038],\n         [ 0.13121663],\n         [-0.03615089],\n         [-0.02158625],\n         [ 0.04025388],\n         [ 0.06182109],\n         [ 0.01381116],\n         [-0.10889266],\n         [ 0.12934671],\n         [-0.180569  ],\n         [-0.16137668],\n         [-0.0137952 ],\n         [ 0.00117974]],\n\n        [[ 0.13385583],\n         [ 0.14412688],\n         [ 0.16242118],\n         [-0.03222406],\n         [ 0.0567355 ],\n         [-0.10840352],\n         [-0.01351918],\n         [ 0.03361957],\n         [ 0.18568628],\n         [ 0.172716  ],\n         [ 0.05416353],\n         [-0.19283177],\n         [ 0.07712828],\n         [-0.01229554],\n         [-0.03825763],\n         [-0.15312935]],\n\n        [[-0.16509143],\n         [-0.07275805],\n         [-0.11268309],\n         [-0.11943939],\n         [ 0.07618068],\n         [-0.12953746],\n         [ 0.17552923],\n         [-0.08020052],\n         [-0.07263733],\n         [-0.00589035],\n         [ 0.05329488],\n         [-0.16969611],\n         [-0.16413625],\n         [ 0.11075388],\n         [ 0.06341593],\n         [ 0.08046152]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 0.00837232],\n         [-0.01258322],\n         [ 0.02133762],\n         ...,\n         [-0.00911685],\n         [-0.00111898],\n         [ 0.00674527]],\n\n        [[ 0.00736733],\n         [ 0.00937208],\n         [ 0.00607242],\n         ...,\n         [ 0.01452898],\n         [ 0.01414894],\n         [-0.00861313]],\n\n        [[-0.02222398],\n         [ 0.0035272 ],\n         [-0.00516614],\n         ...,\n         [ 0.00895134],\n         [-0.01209036],\n         [-0.00396691]]],\n\n\n       [[[-0.01443637],\n         [-0.02711247],\n         [-0.01229688],\n         ...,\n         [ 0.0080577 ],\n         [ 0.01007586],\n         [ 0.00142359]],\n\n        [[ 0.02332135],\n         [-0.01557416],\n         [ 0.01482667],\n         ...,\n         [-0.01860106],\n         [ 0.00421439],\n         [ 0.00445065]],\n\n        [[-0.00238347],\n         [-0.01076152],\n         [ 0.01432462],\n         ...,\n         [ 0.00475441],\n         [-0.01577962],\n         [ 0.00436   ]]],\n\n\n       [[[ 0.0114054 ],\n         [-0.00764033],\n         [ 0.01824616],\n         ...,\n         [-0.01345986],\n         [ 0.00701949],\n         [ 0.00367641]],\n\n        [[-0.01555288],\n         [-0.0027579 ],\n         [-0.01109826],\n         ...,\n         [ 0.00948778],\n         [ 0.01328037],\n         [-0.00083532]],\n\n        [[-0.01391051],\n         [ 0.01242126],\n         [ 0.00957648],\n         ...,\n         [ 0.00082009],\n         [ 0.00107349],\n         [-0.013445  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_370/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-8.66720080e-03],\n         [-2.13127434e-02],\n         [-3.88052203e-02],\n         [ 6.42649382e-02],\n         [ 2.13145837e-02],\n         [-7.64561668e-02],\n         [-2.55294666e-02],\n         [ 1.10324845e-02],\n         [ 7.67508894e-02],\n         [-1.66203156e-02],\n         [ 8.97821337e-02],\n         [ 6.52015507e-02],\n         [-1.56597048e-03],\n         [ 3.13886926e-02],\n         [ 8.50393325e-02],\n         [-6.98380843e-02],\n         [ 3.20993811e-02],\n         [ 7.83130825e-02],\n         [-6.84964359e-02],\n         [-8.25381130e-02],\n         [-6.51107654e-02],\n         [ 8.35671723e-02],\n         [-6.77240342e-02],\n         [ 2.44721621e-02],\n         [-3.56141999e-02],\n         [-4.14163657e-02],\n         [-2.73776725e-02],\n         [ 1.09216273e-02],\n         [ 4.56602126e-02],\n         [-1.84890628e-02],\n         [-5.03567941e-02],\n         [-4.56571653e-02],\n         [-5.66402227e-02],\n         [-8.36497992e-02],\n         [-3.46601754e-02],\n         [ 6.80498481e-02],\n         [ 5.13101071e-02],\n         [-2.14021876e-02],\n         [-1.45603195e-02],\n         [ 6.17103130e-02],\n         [ 2.89156735e-02],\n         [-4.56256941e-02],\n         [-4.21318561e-02],\n         [-2.10093036e-02],\n         [-4.20958884e-02],\n         [ 8.80889595e-02],\n         [ 1.41220540e-03],\n         [-9.16565955e-03],\n         [ 8.33628178e-02],\n         [-7.29865134e-02],\n         [ 5.81384450e-02],\n         [ 1.13113150e-02],\n         [ 7.91448802e-02],\n         [-5.23621775e-02],\n         [-5.46597131e-02],\n         [ 6.22289032e-02],\n         [ 4.04786319e-03],\n         [-8.81686881e-02],\n         [ 6.32246435e-02],\n         [-8.68914947e-02],\n         [ 8.99612159e-02],\n         [-1.16892457e-02],\n         [ 2.23822072e-02],\n         [ 1.83739513e-02],\n         [ 6.49124682e-02],\n         [-8.25013816e-02],\n         [ 3.63224447e-02],\n         [-2.91193873e-02],\n         [-1.20958462e-02],\n         [ 6.74212724e-03],\n         [ 5.02381325e-02],\n         [-6.02036640e-02],\n         [-7.70059302e-02],\n         [ 4.70729768e-02],\n         [-5.99477366e-02],\n         [-1.78149343e-03],\n         [-5.38734943e-02],\n         [ 7.98156410e-02],\n         [ 6.51998371e-02],\n         [-6.06267825e-02]],\n\n        [[ 6.47040009e-02],\n         [ 2.41721347e-02],\n         [-9.01182443e-02],\n         [ 3.78489047e-02],\n         [-7.39553347e-02],\n         [-4.28463332e-02],\n         [-7.30725378e-02],\n         [-7.35043734e-02],\n         [-5.07073253e-02],\n         [-7.64100328e-02],\n         [-7.78117776e-03],\n         [ 7.64816850e-02],\n         [-6.89681992e-02],\n         [-2.94656344e-02],\n         [ 9.32216644e-05],\n         [ 8.39487463e-02],\n         [ 7.81932920e-02],\n         [ 6.78214431e-03],\n         [ 2.61025503e-02],\n         [-1.91596076e-02],\n         [-5.31842373e-02],\n         [-2.68305913e-02],\n         [-3.72442193e-02],\n         [-1.96978673e-02],\n         [-6.92160949e-02],\n         [-6.39034584e-02],\n         [ 3.76998931e-02],\n         [-3.12017277e-02],\n         [-6.85716122e-02],\n         [-3.38711217e-02],\n         [ 3.92690301e-02],\n         [-3.20080630e-02],\n         [ 3.57076228e-02],\n         [-2.59323418e-03],\n         [-1.91018805e-02],\n         [ 4.37287241e-02],\n         [ 4.36018109e-02],\n         [ 6.54489845e-02],\n         [-8.73395801e-02],\n         [-5.60364500e-02],\n         [-7.06417784e-02],\n         [-5.42678460e-02],\n         [ 2.85325944e-02],\n         [-7.92771429e-02],\n         [-5.25924712e-02],\n         [ 4.68801260e-02],\n         [ 1.49652362e-03],\n         [-1.91350579e-02],\n         [ 2.92248949e-02],\n         [ 6.26503527e-02],\n         [-4.60788161e-02],\n         [ 4.27370220e-02],\n         [ 7.56458789e-02],\n         [ 1.96570754e-02],\n         [ 2.63850540e-02],\n         [-3.72863337e-02],\n         [-6.19825386e-02],\n         [-2.67465115e-02],\n         [-1.62728801e-02],\n         [-6.86519295e-02],\n         [ 5.59081584e-02],\n         [ 3.00952047e-03],\n         [-1.70502737e-02],\n         [-1.53839812e-02],\n         [ 5.41786849e-02],\n         [ 5.23826629e-02],\n         [-4.25865166e-02],\n         [-1.21858269e-02],\n         [ 8.34462345e-02],\n         [-2.97904760e-03],\n         [ 4.49511409e-02],\n         [-8.17865133e-03],\n         [ 7.34964311e-02],\n         [ 7.08657801e-02],\n         [ 1.48458779e-02],\n         [ 3.38373333e-02],\n         [ 9.36627388e-03],\n         [ 2.34712660e-02],\n         [-6.37596846e-02],\n         [-3.82735170e-02]],\n\n        [[ 6.70440495e-03],\n         [-2.78624147e-02],\n         [-3.78119797e-02],\n         [ 8.39920640e-02],\n         [ 8.46782476e-02],\n         [ 7.44766146e-02],\n         [-4.61067185e-02],\n         [ 4.00467068e-02],\n         [-8.80319029e-02],\n         [-2.35529169e-02],\n         [ 8.82621706e-02],\n         [ 5.57739139e-02],\n         [ 4.27132398e-02],\n         [-6.93430230e-02],\n         [-4.26840670e-02],\n         [ 7.11494684e-02],\n         [ 3.49609107e-02],\n         [-3.71913798e-02],\n         [-5.37971407e-02],\n         [-8.60427171e-02],\n         [-3.08213681e-02],\n         [ 3.98330390e-04],\n         [ 5.73825985e-02],\n         [-6.33095279e-02],\n         [ 5.16120791e-02],\n         [-5.87291382e-02],\n         [-3.72196473e-02],\n         [ 1.28205717e-02],\n         [-2.67023593e-03],\n         [ 6.51233941e-02],\n         [ 4.88470346e-02],\n         [-2.30490789e-02],\n         [ 6.21873438e-02],\n         [-8.99210498e-02],\n         [ 3.04477811e-02],\n         [-8.57212767e-02],\n         [ 7.05604255e-02],\n         [-1.12945512e-02],\n         [ 6.36809915e-02],\n         [ 4.67116833e-02],\n         [-6.41801432e-02],\n         [-8.89959633e-02],\n         [ 6.47775084e-03],\n         [ 3.91512811e-02],\n         [ 3.88940275e-02],\n         [ 5.86843193e-02],\n         [-8.83258060e-02],\n         [-1.30565986e-02],\n         [-8.97243693e-02],\n         [-6.85198605e-03],\n         [ 5.94256222e-02],\n         [-8.82890150e-02],\n         [-5.27570732e-02],\n         [-6.50582910e-02],\n         [ 4.02529240e-02],\n         [-3.15060578e-02],\n         [ 1.94649547e-02],\n         [-3.47958617e-02],\n         [-3.88528034e-02],\n         [-8.61146599e-02],\n         [-5.52012809e-02],\n         [-2.53325328e-02],\n         [-4.06550206e-02],\n         [-9.01605114e-02],\n         [-7.11788088e-02],\n         [-5.25964499e-02],\n         [-2.08720192e-02],\n         [-6.18887953e-02],\n         [ 7.64862895e-02],\n         [-2.75530890e-02],\n         [ 3.88170779e-02],\n         [ 5.13875484e-03],\n         [-1.01784766e-02],\n         [ 4.67309505e-02],\n         [-6.01326749e-02],\n         [ 3.59575301e-02],\n         [-2.75589898e-02],\n         [-7.17716143e-02],\n         [ 1.73699632e-02],\n         [-7.21093863e-02]]],\n\n\n       [[[ 2.62801498e-02],\n         [ 8.14863890e-02],\n         [ 1.97267234e-02],\n         [-1.10455230e-02],\n         [-8.82565975e-03],\n         [-4.84527275e-02],\n         [-6.60223290e-02],\n         [-7.19866306e-02],\n         [-3.92277539e-03],\n         [-2.95662768e-02],\n         [-5.99202067e-02],\n         [-7.16961697e-02],\n         [-2.46731192e-03],\n         [ 1.65557340e-02],\n         [-1.12281665e-02],\n         [ 4.22407687e-03],\n         [-5.29213510e-02],\n         [ 5.10078073e-02],\n         [ 1.28445849e-02],\n         [ 8.17214996e-02],\n         [-5.48714474e-02],\n         [ 4.11119461e-02],\n         [ 8.35301578e-02],\n         [ 6.87580705e-02],\n         [ 1.83091462e-02],\n         [ 5.74252903e-02],\n         [-6.76059723e-02],\n         [ 2.96606272e-02],\n         [ 6.39719814e-02],\n         [ 1.87493786e-02],\n         [-8.30230862e-03],\n         [-6.16641343e-03],\n         [-4.12242487e-02],\n         [ 5.60820401e-02],\n         [ 4.29547131e-02],\n         [-3.97115946e-02],\n         [-6.34776354e-02],\n         [-2.74640769e-02],\n         [-6.98899925e-02],\n         [-1.63113549e-02],\n         [ 6.29158914e-02],\n         [ 8.96175206e-02],\n         [-3.01576592e-02],\n         [ 3.95234376e-02],\n         [ 8.50173831e-02],\n         [ 8.19786638e-02],\n         [ 3.79800498e-02],\n         [ 1.08044147e-02],\n         [-6.03665337e-02],\n         [-2.97432095e-02],\n         [ 7.58797824e-02],\n         [ 1.85215995e-02],\n         [ 7.20996410e-03],\n         [ 2.74261013e-02],\n         [-6.63442016e-02],\n         [ 7.90797770e-02],\n         [-3.90939340e-02],\n         [ 3.54459435e-02],\n         [-6.87695295e-02],\n         [ 8.47561359e-02],\n         [ 6.15354031e-02],\n         [ 1.00995228e-02],\n         [-5.05422279e-02],\n         [ 8.34452063e-02],\n         [-8.00335109e-02],\n         [-5.60612157e-02],\n         [-5.63906804e-02],\n         [-7.36494437e-02],\n         [ 7.85864145e-02],\n         [-7.99106583e-02],\n         [ 6.56358749e-02],\n         [-4.90115955e-02],\n         [-2.13449523e-02],\n         [-6.94891065e-02],\n         [-1.99389085e-02],\n         [ 2.17362121e-02],\n         [ 5.39780259e-02],\n         [ 2.23629177e-02],\n         [ 6.14463985e-02],\n         [-5.22234663e-02]],\n\n        [[-1.04146525e-02],\n         [ 7.11427331e-02],\n         [-8.13935325e-02],\n         [-1.18601248e-02],\n         [ 2.30892003e-02],\n         [ 1.56975016e-02],\n         [ 2.81500444e-02],\n         [-2.83871740e-02],\n         [-4.78716940e-03],\n         [ 7.75989294e-02],\n         [ 1.76681504e-02],\n         [ 3.21879834e-02],\n         [-5.42909466e-02],\n         [ 6.63600117e-02],\n         [-1.19371265e-02],\n         [ 7.57897496e-02],\n         [ 4.53603864e-02],\n         [ 6.93211108e-02],\n         [-7.00327009e-03],\n         [ 8.04007947e-02],\n         [ 1.18009001e-02],\n         [ 9.22209024e-03],\n         [ 1.60848051e-02],\n         [ 6.18357658e-02],\n         [ 5.26638031e-02],\n         [-7.56375864e-02],\n         [-3.53368223e-02],\n         [-5.06006926e-03],\n         [-8.54081213e-02],\n         [-6.75970912e-02],\n         [ 4.01512682e-02],\n         [ 3.20250019e-02],\n         [-5.59895486e-03],\n         [ 2.00522095e-02],\n         [ 6.71331584e-03],\n         [ 1.01447776e-02],\n         [ 3.89200896e-02],\n         [ 6.42025471e-03],\n         [-8.66741985e-02],\n         [-1.15655065e-02],\n         [-7.17285424e-02],\n         [ 8.74520242e-02],\n         [-6.56224862e-02],\n         [ 6.16853833e-02],\n         [ 6.89223260e-02],\n         [ 3.94560844e-02],\n         [ 9.89958644e-05],\n         [-2.37218291e-03],\n         [ 8.11796933e-02],\n         [ 2.53639370e-03],\n         [-2.99520008e-02],\n         [ 1.20805502e-02],\n         [ 2.47909650e-02],\n         [ 4.72950786e-02],\n         [-4.27586026e-02],\n         [-2.00201944e-02],\n         [ 6.35461807e-02],\n         [-7.65774250e-02],\n         [ 2.09345892e-02],\n         [-4.54149954e-02],\n         [ 4.98757660e-02],\n         [ 4.38040346e-02],\n         [-1.42264888e-02],\n         [-3.55059206e-02],\n         [-3.48351896e-03],\n         [-5.52938767e-02],\n         [ 7.22648948e-02],\n         [-2.87522413e-02],\n         [-6.95469007e-02],\n         [-4.81623039e-02],\n         [-8.01663250e-02],\n         [ 7.57557154e-03],\n         [ 9.06218290e-02],\n         [-1.90361589e-03],\n         [-2.11788565e-02],\n         [-6.09034747e-02],\n         [-9.00204331e-02],\n         [ 1.20628849e-02],\n         [ 3.04240063e-02],\n         [-5.60291372e-02]],\n\n        [[ 7.78300464e-02],\n         [-7.32453763e-02],\n         [-7.69731402e-02],\n         [ 6.59853220e-02],\n         [-2.76882052e-02],\n         [ 3.64506692e-02],\n         [ 5.73763102e-02],\n         [-6.18058220e-02],\n         [-9.05239731e-02],\n         [-5.33724837e-02],\n         [-7.94109479e-02],\n         [-1.89898387e-02],\n         [-5.41004762e-02],\n         [ 5.44473529e-02],\n         [ 3.29278484e-02],\n         [ 1.01084784e-02],\n         [ 1.67916939e-02],\n         [-8.15748721e-02],\n         [-3.90254334e-02],\n         [ 1.74498186e-02],\n         [-1.37196779e-02],\n         [-3.01492661e-02],\n         [ 3.83973122e-04],\n         [ 3.29140276e-02],\n         [ 7.97250718e-02],\n         [-4.72386889e-02],\n         [ 9.02785659e-02],\n         [-5.27401268e-03],\n         [-6.18153214e-02],\n         [-3.51565592e-02],\n         [-5.38068525e-02],\n         [-2.06493810e-02],\n         [-6.84127882e-02],\n         [ 7.55287260e-02],\n         [ 2.98400223e-03],\n         [ 4.62450236e-02],\n         [-6.29361719e-03],\n         [-4.17920761e-02],\n         [ 4.58817184e-02],\n         [ 5.82863092e-02],\n         [-5.95807247e-02],\n         [ 4.67566252e-02],\n         [ 7.59347528e-03],\n         [ 7.82608688e-02],\n         [-2.54447237e-02],\n         [ 8.13296735e-02],\n         [-3.60343792e-02],\n         [ 1.95392966e-02],\n         [-6.30896613e-02],\n         [ 7.00883418e-02],\n         [-1.74168348e-02],\n         [-4.18131426e-02],\n         [ 6.85076565e-02],\n         [-4.59557399e-02],\n         [-2.83844769e-04],\n         [ 3.47904712e-02],\n         [-5.75928837e-02],\n         [-1.45003945e-03],\n         [-3.74742597e-03],\n         [-8.23443383e-03],\n         [-8.04779008e-02],\n         [ 4.20557857e-02],\n         [-8.86777863e-02],\n         [-2.87189111e-02],\n         [-3.11012343e-02],\n         [-7.09311888e-02],\n         [-3.93627286e-02],\n         [ 4.72665876e-02],\n         [-8.03857595e-02],\n         [ 7.24331439e-02],\n         [ 6.89113736e-02],\n         [-6.34625107e-02],\n         [ 6.78108335e-02],\n         [ 8.46767575e-02],\n         [-2.24580616e-02],\n         [-6.13560304e-02],\n         [-3.30255479e-02],\n         [ 2.74264887e-02],\n         [ 7.65512288e-02],\n         [ 1.24840438e-03]]],\n\n\n       [[[-4.15212698e-02],\n         [-1.65857747e-02],\n         [-4.18476835e-02],\n         [ 5.97543269e-02],\n         [-5.01129180e-02],\n         [-4.46611792e-02],\n         [-7.71042705e-03],\n         [-8.98741186e-03],\n         [ 6.35068715e-02],\n         [-7.22834393e-02],\n         [ 2.92851105e-02],\n         [ 3.65661681e-02],\n         [ 8.21505040e-02],\n         [-4.67923395e-02],\n         [-5.21486066e-02],\n         [ 5.00400662e-02],\n         [-3.45263965e-02],\n         [ 6.91485405e-02],\n         [-6.49325848e-02],\n         [ 6.56836331e-02],\n         [ 2.71371752e-03],\n         [-3.84243615e-02],\n         [ 4.34292257e-02],\n         [ 6.21979684e-02],\n         [-3.09776850e-02],\n         [ 2.36947015e-02],\n         [-7.10669756e-02],\n         [-9.62924957e-03],\n         [-3.31154205e-02],\n         [ 1.27258971e-02],\n         [ 8.01828504e-02],\n         [-6.33612201e-02],\n         [-3.32447886e-02],\n         [-7.48300627e-02],\n         [-9.97699052e-03],\n         [ 1.13431513e-02],\n         [-3.38890329e-02],\n         [-4.57420610e-02],\n         [-3.79354879e-02],\n         [ 1.54659152e-03],\n         [-7.01940656e-02],\n         [ 7.71742314e-02],\n         [-2.50237435e-02],\n         [ 6.79738820e-04],\n         [ 1.99558586e-03],\n         [ 3.96522135e-02],\n         [-2.54567713e-02],\n         [-1.01723298e-02],\n         [-2.37911940e-02],\n         [-7.94683695e-02],\n         [-3.62368785e-02],\n         [ 7.14154541e-02],\n         [ 7.25253820e-02],\n         [ 8.91425461e-03],\n         [-1.09159872e-02],\n         [ 4.30653989e-02],\n         [ 4.45811450e-02],\n         [-1.75290480e-02],\n         [-8.96497816e-03],\n         [ 5.21661937e-02],\n         [ 6.61091357e-02],\n         [-6.40156716e-02],\n         [-6.33788928e-02],\n         [ 4.55363095e-03],\n         [-2.65718922e-02],\n         [ 2.57802755e-03],\n         [-2.03699023e-02],\n         [ 5.40879667e-02],\n         [-2.48151273e-02],\n         [ 9.05132294e-03],\n         [ 5.81189692e-02],\n         [ 1.64462626e-02],\n         [-9.08786058e-03],\n         [-1.23984367e-03],\n         [-7.96884298e-03],\n         [ 1.69560313e-02],\n         [-4.03613299e-02],\n         [-2.38711163e-02],\n         [ 5.21084666e-02],\n         [-8.39432478e-02]],\n\n        [[-5.32533973e-03],\n         [ 6.94005340e-02],\n         [ 6.39073998e-02],\n         [-9.16613638e-03],\n         [ 1.18176863e-02],\n         [-3.56114954e-02],\n         [-7.90868476e-02],\n         [-6.23369217e-02],\n         [ 2.46274620e-02],\n         [ 1.27945542e-02],\n         [ 3.14159915e-02],\n         [-8.07454586e-02],\n         [ 6.77292198e-02],\n         [ 6.31783009e-02],\n         [-4.53442894e-02],\n         [-2.61754617e-02],\n         [ 3.67901176e-02],\n         [ 1.94124877e-03],\n         [-4.13189679e-02],\n         [-1.43459439e-03],\n         [-4.92663719e-02],\n         [-7.83275291e-02],\n         [ 7.79393166e-02],\n         [-3.10968868e-02],\n         [-7.51439780e-02],\n         [ 6.48184121e-02],\n         [-5.09805754e-02],\n         [-1.77309662e-02],\n         [-8.58000144e-02],\n         [ 7.90582895e-02],\n         [ 3.64466459e-02],\n         [ 8.79381150e-02],\n         [-1.77353770e-02],\n         [-3.68133187e-05],\n         [-4.56023552e-02],\n         [ 6.35572076e-02],\n         [ 3.30103412e-02],\n         [ 6.78781420e-02],\n         [ 5.79086840e-02],\n         [ 7.33441114e-02],\n         [-3.86655331e-02],\n         [ 1.08553767e-02],\n         [-4.71937656e-03],\n         [-4.86585125e-02],\n         [ 8.16603154e-02],\n         [-3.35063152e-02],\n         [-5.80220856e-02],\n         [-1.65647268e-03],\n         [ 1.33805647e-02],\n         [-5.82382530e-02],\n         [-8.74474421e-02],\n         [ 1.01281181e-02],\n         [ 2.32846886e-02],\n         [ 7.57527500e-02],\n         [-4.13189083e-03],\n         [ 7.88294524e-02],\n         [-7.79333711e-02],\n         [-3.82337607e-02],\n         [-3.32482271e-02],\n         [-7.03862011e-02],\n         [ 6.96699917e-02],\n         [-7.34459907e-02],\n         [-9.04230550e-02],\n         [ 7.82419145e-02],\n         [-5.93036041e-02],\n         [ 2.81842798e-03],\n         [ 6.29189312e-02],\n         [-1.84516460e-02],\n         [ 7.74733126e-02],\n         [-4.75304537e-02],\n         [ 4.53350097e-02],\n         [-8.24960843e-02],\n         [-3.36195044e-02],\n         [-6.06605262e-02],\n         [-7.95032606e-02],\n         [ 5.45232296e-02],\n         [ 7.84163475e-02],\n         [ 4.95704710e-02],\n         [ 6.70588017e-03],\n         [ 2.43533701e-02]],\n\n        [[-6.02158159e-02],\n         [ 6.55934513e-02],\n         [ 2.42115036e-02],\n         [ 5.58568984e-02],\n         [-1.18216425e-02],\n         [-3.87412608e-02],\n         [-1.32587478e-02],\n         [-1.38917863e-02],\n         [ 2.72165313e-02],\n         [-6.54928535e-02],\n         [-6.87674955e-02],\n         [-2.03985199e-02],\n         [ 6.37516379e-02],\n         [-4.24799249e-02],\n         [ 7.47797489e-02],\n         [ 3.70633900e-02],\n         [-3.59726511e-02],\n         [ 4.05049324e-02],\n         [ 5.96642345e-02],\n         [ 1.37628540e-02],\n         [-5.11466265e-02],\n         [-6.47759363e-02],\n         [-1.28356069e-02],\n         [ 7.03348219e-03],\n         [ 3.61459404e-02],\n         [ 1.68216899e-02],\n         [ 9.48987156e-03],\n         [-1.83533132e-03],\n         [ 3.20909470e-02],\n         [ 7.49292970e-02],\n         [ 3.72575819e-02],\n         [-6.52565509e-02],\n         [ 5.67191988e-02],\n         [-6.35091215e-03],\n         [ 7.49246031e-02],\n         [-1.70183480e-02],\n         [-8.14317465e-02],\n         [-5.93253411e-02],\n         [ 8.10084790e-02],\n         [-3.56769040e-02],\n         [ 7.36415535e-02],\n         [ 1.45708993e-02],\n         [ 7.53114820e-02],\n         [-6.20543733e-02],\n         [ 4.27161902e-03],\n         [-1.40484050e-02],\n         [ 4.82401848e-02],\n         [ 1.56359226e-02],\n         [-4.18757834e-02],\n         [-4.63947169e-02],\n         [-6.13191128e-02],\n         [-8.71411636e-02],\n         [-1.40616447e-02],\n         [ 7.46802241e-03],\n         [-7.99229667e-02],\n         [-5.89055717e-02],\n         [ 1.93427503e-02],\n         [ 2.65355781e-02],\n         [ 6.00865334e-02],\n         [-3.03183235e-02],\n         [ 9.06062275e-02],\n         [-6.92652166e-03],\n         [ 2.95820236e-02],\n         [-7.95759261e-03],\n         [ 3.83987725e-02],\n         [ 4.73548472e-02],\n         [ 7.44029880e-02],\n         [-4.79479507e-02],\n         [ 3.91598791e-02],\n         [-7.95012712e-02],\n         [-6.58729151e-02],\n         [-2.51954868e-02],\n         [ 2.63304412e-02],\n         [ 3.73968333e-02],\n         [ 7.90280402e-02],\n         [ 7.94202089e-02],\n         [-5.42753302e-02],\n         [-6.16169088e-02],\n         [-2.83450410e-02],\n         [ 6.40583336e-02]]]], dtype=float32)>, <tf.Variable 'conv2d_859/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.10411051, -0.09993905,  0.10945921, ...,  0.0138134 ,\n          -0.09568352, -0.01320909],\n         [ 0.13120577,  0.10361341,  0.01597022, ..., -0.09409473,\n           0.11399805, -0.12183334],\n         [ 0.00971108,  0.10353881, -0.0794847 , ..., -0.08021943,\n           0.19035943,  0.01096168],\n         ...,\n         [-0.14632568,  0.11939848, -0.12212426, ...,  0.02531959,\n          -0.17951569, -0.13103734],\n         [-0.11415138, -0.18519133,  0.11686815, ...,  0.15166123,\n           0.11571956,  0.08748915],\n         [ 0.01324788, -0.00819887, -0.2116318 , ..., -0.02114077,\n           0.00374202,  0.08554063]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_837/kernel:0' shape=(3, 3, 3, 8) dtype=float32, numpy=\narray([[[[ 4.34860617e-01, -6.12443872e-02, -2.34070227e-01,\n          -6.79554269e-02,  3.35900247e-01, -1.01141036e-02,\n          -1.08897328e-01, -4.19404469e-02],\n         [ 4.18321043e-02, -6.16611950e-02,  1.59482077e-01,\n          -1.26871407e-01, -2.95461833e-01, -1.52698517e-01,\n           2.78214574e-01,  4.36488509e-01],\n         [ 1.37099147e-01, -1.17949862e-02, -1.08235322e-01,\n           2.34664115e-03,  1.69618309e-01, -7.34768137e-02,\n          -5.35418093e-02,  4.46267985e-02]],\n\n        [[-3.52367647e-02,  1.74914859e-02, -1.94057181e-01,\n          -2.17091754e-01, -1.77843153e-01,  1.08397566e-02,\n          -4.77415919e-02,  3.65599245e-01],\n         [-1.05641685e-01,  8.71259440e-03,  2.00579241e-02,\n           7.68682137e-02, -7.84347877e-02, -1.21652402e-01,\n           4.08379696e-02, -2.69199878e-01],\n         [ 5.96811771e-02, -7.08556473e-02,  1.80879999e-02,\n          -8.25090334e-02, -1.43719614e-01,  2.51296401e-01,\n          -2.75461942e-01,  1.52257442e-01]],\n\n        [[ 9.62612629e-02, -2.78844982e-01, -7.05683678e-02,\n           1.93157479e-01, -1.74849629e-01, -2.91720349e-02,\n          -2.90387031e-02, -1.32201582e-01],\n         [ 7.43680671e-02,  5.26263788e-02, -6.56763390e-02,\n          -5.09885699e-02,  4.71500978e-02,  1.28422743e-02,\n          -6.89756870e-02, -3.64297390e-01],\n         [ 1.06877729e-01,  2.85665747e-02,  2.92315464e-02,\n           1.32722288e-01,  5.98155074e-02,  9.30707082e-02,\n           1.04779646e-01, -3.04968417e-01]]],\n\n\n       [[[-3.73448908e-01, -4.44144122e-02,  1.24600559e-01,\n           2.76192483e-02, -4.64274958e-02, -1.49158865e-01,\n           1.92302361e-01,  3.15826297e-01],\n         [-2.51975268e-01, -1.93237916e-01, -1.82171896e-01,\n           2.53471375e-01, -1.31441236e-01,  3.64394099e-01,\n           1.09096549e-01,  3.60211372e-01],\n         [-1.94265336e-01, -3.88557017e-01, -1.17687561e-01,\n           2.96913058e-01, -1.85678527e-02,  1.21498958e-03,\n           3.95804554e-01,  1.58660769e-01]],\n\n        [[ 2.22440250e-02,  3.85935336e-01, -1.59623802e-01,\n          -6.19686618e-02, -1.35481641e-01, -1.06442370e-01,\n           1.97795272e-01, -1.00649916e-01],\n         [ 1.16978303e-01, -2.13973135e-01, -8.31322372e-02,\n           1.45909384e-01,  1.57183826e-01, -8.19479972e-02,\n           3.44110906e-01, -1.28656447e-01],\n         [-3.02926451e-01,  1.35517642e-01, -1.72126278e-01,\n          -4.61478271e-02,  1.47228554e-01,  1.08457848e-01,\n           1.53731465e-01,  1.21956535e-01]],\n\n        [[ 3.67071219e-02,  8.91752541e-02, -1.02156341e-01,\n           1.13416314e-02,  1.98783097e-03, -9.64439437e-02,\n           4.89879325e-02, -2.09098727e-01],\n         [ 2.83310592e-01,  1.16454080e-01, -3.93767953e-02,\n          -4.38202880e-02, -3.15381676e-01, -6.14104569e-02,\n          -3.83391738e-01, -1.44625410e-01],\n         [ 2.11003423e-01,  4.34468995e-04,  2.73406431e-02,\n          -5.92781343e-02, -3.75086784e-01,  7.01255500e-02,\n          -1.94294408e-01, -1.92789122e-01]]],\n\n\n       [[[ 1.40643612e-01, -1.64493680e-01,  2.79116511e-01,\n          -9.80716497e-02, -3.82111520e-02,  2.36558586e-01,\n          -1.01421215e-01, -3.15519385e-02],\n         [-1.44459143e-01,  8.53005126e-02, -1.98771074e-01,\n          -5.45773581e-02, -1.12990923e-01, -2.18943313e-01,\n          -2.04592466e-01,  6.73497021e-02],\n         [ 2.82178223e-01, -3.14117610e-01,  1.75205678e-01,\n           1.69952735e-01,  2.98341364e-01, -4.09468710e-02,\n           2.71549135e-01,  1.89843521e-01]],\n\n        [[-2.68893778e-01,  3.75231206e-02,  1.79400995e-01,\n          -2.13881597e-01, -1.68604493e-01, -1.04828462e-01,\n          -1.17957257e-01, -9.95254517e-02],\n         [-3.20701867e-01,  1.36785597e-01,  5.50708957e-02,\n           8.46281424e-02, -2.01541279e-02,  1.62159428e-01,\n          -2.35586807e-01,  2.56881684e-01],\n         [-2.25200191e-01,  3.51056308e-02, -8.72928798e-02,\n           2.27396891e-01,  3.85151617e-02,  3.09475422e-01,\n           1.04107819e-01,  1.51687354e-01]],\n\n        [[ 7.02244043e-02, -8.67525935e-02,  2.86658198e-01,\n           3.96883428e-01,  3.12807225e-02, -5.19500002e-02,\n           5.98939881e-02, -2.22012341e-01],\n         [ 2.73790926e-01,  2.84305841e-01,  7.07704201e-02,\n           2.06513658e-01, -1.50258556e-01,  3.22034270e-01,\n          -1.79023236e-01, -2.95934439e-01],\n         [-3.89295399e-01,  2.20175534e-01,  1.07977375e-01,\n           2.89510638e-02, -2.25162596e-01, -3.94590020e-01,\n          -3.11882794e-01, -1.61674961e-01]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.2479917 , -0.23689294, -0.14518796, ...,  0.39041418,\n          -0.12793861,  0.39641052],\n         [ 0.3597114 ,  0.18744245,  0.2737869 , ...,  0.08534814,\n           0.05556985, -0.0025951 ],\n         [-0.2385604 , -0.271404  ,  0.28244513, ..., -0.29290363,\n          -0.04824167,  0.14886163],\n         ...,\n         [ 0.23674822, -0.22173344, -0.30637556, ..., -0.28418595,\n          -0.09394607,  0.2505591 ],\n         [ 0.08151749, -0.03971544,  0.0468292 , ...,  0.14265789,\n          -0.3311238 ,  0.22740376],\n         [ 0.27640203, -0.01170183, -0.32826698, ...,  0.13623905,\n          -0.09182345, -0.14845005]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_855/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.05691873, -0.08178847,  0.10209659, ...,  0.05336939,\n           0.04119298,  0.16145097],\n         [-0.07454727, -0.04499779, -0.14113724, ...,  0.08217024,\n          -0.01950422, -0.04713718],\n         [ 0.16121182,  0.04491493, -0.0777458 , ..., -0.11923408,\n           0.0611771 ,  0.13828753],\n         ...,\n         [-0.08755382, -0.08692743, -0.04167262, ...,  0.12630141,\n          -0.13755977, -0.07483485],\n         [-0.0057496 , -0.08392468, -0.08055364, ..., -0.02204002,\n          -0.1026118 , -0.03875181],\n         [-0.03894832,  0.11955823, -0.04138163, ...,  0.07989595,\n           0.00929255,  0.1405722 ]]]], dtype=float32)>, <tf.Variable 'conv2d_850/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[-0.17312704,  0.16594543,  0.03478403, ...,  0.02367057,\n           0.10055587,  0.23386765],\n         [ 0.05774681, -0.0216629 , -0.19633013, ..., -0.18767416,\n          -0.18666461, -0.10115756],\n         [ 0.11902137, -0.19842215, -0.06245279, ..., -0.2516125 ,\n           0.1320161 , -0.06040335],\n         ...,\n         [-0.08664814,  0.06752764, -0.07373308, ..., -0.16511129,\n          -0.00979579,  0.04597995],\n         [ 0.04794793,  0.13216718,  0.01690847, ..., -0.07301548,\n           0.02930633,  0.18098101],\n         [ 0.13800204,  0.00230392,  0.17418192, ..., -0.10249943,\n           0.02288403,  0.04760702]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[ 0.23353304, -0.20531552,  0.12357561, ...,  0.06063399,\n          -0.21159081,  0.03818657],\n         [ 0.29464367, -0.0783284 ,  0.06509706, ...,  0.22956146,\n           0.03700827, -0.34284928],\n         [-0.20444453,  0.5052561 ,  0.540054  , ..., -0.2820317 ,\n           0.19628468, -0.2687783 ],\n         ...,\n         [ 0.11366351, -0.2197347 , -0.19798149, ..., -0.08464143,\n           0.2715783 , -0.10311449],\n         [-0.5323078 ,  0.3015175 , -0.20705988, ..., -0.05869035,\n           0.19765744, -0.4617885 ],\n         [-0.00256486, -0.40370452,  0.02302782, ..., -0.3269101 ,\n           0.09300213,  0.28129053]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/conv2d_1/kernel:0' shape=(1, 1, 240, 40) dtype=float32, numpy=\narray([[[[-0.05071502, -0.00046771, -0.07373971, ...,  0.09413058,\n           0.01781907, -0.04042453],\n         [-0.09543748, -0.12304069, -0.06205228, ...,  0.02624068,\n           0.02881169,  0.00810569],\n         [-0.1163765 , -0.02997088,  0.01742249, ...,  0.02339732,\n           0.036571  , -0.01657863],\n         ...,\n         [-0.01074709,  0.13512889,  0.10065539, ...,  0.11613697,\n          -0.00763821, -0.02962824],\n         [-0.00809216,  0.06155474, -0.05628331, ..., -0.07483778,\n          -0.08880164, -0.0541205 ],\n         [-0.04729754, -0.09207111, -0.02092353, ..., -0.03724654,\n           0.05418466, -0.09004581]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/moving_mean:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_367/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.05658032],\n         [ 0.04513918],\n         [-0.06506998],\n         ...,\n         [ 0.03815841],\n         [ 0.02281986],\n         [ 0.02134433]],\n\n        [[ 0.07209826],\n         [-0.04146219],\n         [-0.03197265],\n         ...,\n         [ 0.01712053],\n         [ 0.02636585],\n         [-0.06394023]],\n\n        [[ 0.00481731],\n         [ 0.00850389],\n         [ 0.03421478],\n         ...,\n         [-0.03269311],\n         [-0.07010403],\n         [-0.03387936]]],\n\n\n       [[[-0.00750106],\n         [-0.02072125],\n         [-0.03230726],\n         ...,\n         [-0.06100129],\n         [-0.00659133],\n         [-0.04323304]],\n\n        [[-0.00846768],\n         [-0.07259206],\n         [ 0.0481456 ],\n         ...,\n         [-0.0550942 ],\n         [-0.01256686],\n         [-0.05775381]],\n\n        [[-0.02718295],\n         [-0.03214045],\n         [ 0.01380256],\n         ...,\n         [-0.07038531],\n         [-0.04531629],\n         [ 0.03864978]]],\n\n\n       [[[ 0.02549809],\n         [ 0.06117572],\n         [ 0.03622878],\n         ...,\n         [ 0.0331825 ],\n         [-0.0315299 ],\n         [ 0.0415382 ]],\n\n        [[-0.04904476],\n         [-0.01267374],\n         [-0.07439227],\n         ...,\n         [-0.02343307],\n         [ 0.05014357],\n         [ 0.04373406]],\n\n        [[-0.02252823],\n         [-0.02713235],\n         [-0.01811955],\n         ...,\n         [-0.02345107],\n         [ 0.07354911],\n         [ 0.01964509]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/moving_variance:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.05322937,  0.00419696,  0.14083974, ...,  0.05964502,\n          -0.07552427,  0.03780741],\n         [ 0.04103354, -0.07011916, -0.09230108, ...,  0.10921484,\n           0.05243674,  0.07273926],\n         [ 0.10637338, -0.01923977, -0.01467316, ...,  0.07515216,\n           0.07851442, -0.06054208],\n         ...,\n         [ 0.08629661, -0.11335976,  0.11231662, ...,  0.04661131,\n           0.08741467, -0.10036431],\n         [ 0.00919535, -0.03788225,  0.06047742, ...,  0.18185467,\n           0.16720587,  0.14260915],\n         [ 0.0395638 , -0.08249996, -0.0670304 , ..., -0.09548555,\n           0.1436232 ,  0.00969846]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00198248],\n         [ 0.01609984],\n         [ 0.00836946],\n         ...,\n         [-0.01657758],\n         [-0.01932586],\n         [ 0.02946362]],\n\n        [[ 0.00518826],\n         [-0.0136152 ],\n         [-0.00768054],\n         ...,\n         [-0.00923684],\n         [ 0.01206317],\n         [-0.01039699]],\n\n        [[-0.00512563],\n         [ 0.01070204],\n         [ 0.00834193],\n         ...,\n         [-0.0032751 ],\n         [ 0.02260692],\n         [-0.02298075]]],\n\n\n       [[[ 0.00206978],\n         [-0.00096237],\n         [ 0.02283854],\n         ...,\n         [-0.00640933],\n         [-0.01373974],\n         [-0.02142998]],\n\n        [[-0.01529582],\n         [ 0.00130071],\n         [-0.0158083 ],\n         ...,\n         [-0.01130382],\n         [ 0.0061287 ],\n         [-0.02285107]],\n\n        [[ 0.00127067],\n         [-0.00029359],\n         [-0.0321688 ],\n         ...,\n         [ 0.00509909],\n         [ 0.00728624],\n         [-0.00528747]]],\n\n\n       [[[-0.01982355],\n         [ 0.00784959],\n         [ 0.00336699],\n         ...,\n         [-0.00233218],\n         [-0.01549122],\n         [ 0.01841665]],\n\n        [[-0.01651531],\n         [-0.01242766],\n         [-0.01246268],\n         ...,\n         [-0.01459251],\n         [-0.00059355],\n         [-0.00593053]],\n\n        [[-0.02197322],\n         [ 0.03255267],\n         [ 0.00084239],\n         ...,\n         [ 0.01762703],\n         [ 0.0056902 ],\n         [-0.01367214]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/conv2d/kernel:0' shape=(1, 1, 16, 96) dtype=float32, numpy=\narray([[[[ 2.5876215e-01,  2.2885117e-01, -3.7943393e-02, ...,\n          -7.0458680e-02, -9.0687610e-02, -2.9245937e-01],\n         [ 1.9379990e-01, -1.4698873e-01, -3.6464572e-02, ...,\n           4.1912407e-01,  1.6572762e-01, -3.3918551e-01],\n         [ 2.7932101e-01, -3.4450549e-01, -2.6956692e-01, ...,\n           2.1920848e-01, -1.6603917e-01,  9.3559630e-02],\n         ...,\n         [ 1.8810408e-02,  2.1550113e-01,  1.1200634e-01, ...,\n           5.1735640e-01, -3.8649648e-01, -1.7318353e-03],\n         [ 4.4375995e-01, -2.4426644e-01,  4.0689960e-01, ...,\n           2.0198093e-01, -8.0465831e-02,  4.4801924e-02],\n         [ 3.4991312e-01,  3.9740109e-01, -5.2391659e-03, ...,\n           1.5180360e-01, -3.9457161e-02,  3.1451267e-04]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[-0.28877535,  0.08674186,  0.00533257, ...,  0.05692507,\n           0.53369904,  0.38847327],\n         [-0.3101322 ,  0.0353773 ,  0.0509994 , ..., -0.13558097,\n          -0.18690796,  0.54423714],\n         [ 0.15576588,  0.10971843, -0.21223341, ...,  0.16388036,\n           0.13791399, -0.50099695],\n         ...,\n         [ 0.21520627, -0.05457871, -0.1527293 , ...,  0.29818162,\n          -0.18155313,  0.04517001],\n         [ 0.4248039 , -0.3429481 , -0.23517631, ..., -0.24873146,\n           0.02962397, -0.42239076],\n         [-0.38152325, -0.30858228, -0.03382488, ...,  0.387512  ,\n          -0.29318768,  0.21084514]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/beta:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_874/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[ 0.04510472,  0.20648754,  0.1176513 , ...,  0.2049702 ,\n           0.02841216, -0.14003591],\n         [ 0.02559275,  0.0421253 ,  0.00520388, ...,  0.02768417,\n          -0.00510083,  0.1624502 ],\n         [-0.01072824,  0.05431699, -0.12903199, ..., -0.04933112,\n          -0.09183082,  0.10126495],\n         ...,\n         [-0.05445305,  0.18244241,  0.13566735, ...,  0.03528935,\n           0.12248649,  0.14743344],\n         [-0.08861005, -0.14864802,  0.2048285 , ...,  0.01239545,\n          -0.05569541,  0.00600726],\n         [-0.13778675,  0.17862606, -0.01290794, ...,  0.06893931,\n          -0.09094699, -0.05378803]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_867/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.15957758, -0.11312751, -0.15851146, ..., -0.12608384,\n           0.09525088, -0.08314826],\n         [-0.02660082,  0.05745919, -0.09143284, ...,  0.02496169,\n          -0.12793098, -0.00145942],\n         [-0.18886368, -0.16361073,  0.01116989, ..., -0.09486587,\n          -0.05889914,  0.1590093 ],\n         ...,\n         [ 0.04246343,  0.05698205, -0.07096339, ...,  0.06296895,\n          -0.03187802, -0.18009189],\n         [ 0.01452543, -0.01232398, -0.08866816, ...,  0.04642151,\n          -0.11985493, -0.03702703],\n         [ 0.04189466, -0.01042653,  0.08280015, ...,  0.12869924,\n          -0.09729425, -0.15023673]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 4, 144) dtype=float32, numpy=\narray([[[[-0.16776745, -0.01107461,  0.83408785, -0.6419895 ,\n          -0.03528202,  0.64626026, -0.67606574,  0.13160484,\n          -0.29657876,  0.82573146,  0.1914607 , -0.00961619,\n          -0.47519082,  0.00666555,  0.7396214 , -0.14327317,\n           0.3349916 , -0.26881358, -0.29431713, -0.83039266,\n          -0.28265402,  0.3137494 ,  0.10342664,  0.19247799,\n           0.30707455,  0.6808928 ,  0.35664588, -0.9909029 ,\n           0.56933737,  0.41333726, -0.9657033 ,  1.0132818 ,\n          -0.09256936, -0.5227127 ,  1.0718073 , -0.05185861,\n          -0.05041257,  0.17077975, -0.6845666 ,  0.24249968,\n           0.0569461 , -0.16302364,  0.8806042 , -0.99391323,\n          -0.09921478,  0.6818946 ,  0.5285469 , -0.0279187 ,\n          -0.25445908, -0.33157763, -0.00393659, -0.6409969 ,\n          -0.09395363,  0.54187053, -0.32372445, -0.11142825,\n           0.19199812, -0.17920262, -0.4946462 , -0.01743084,\n          -0.2601722 ,  0.40456846, -0.9047628 , -0.65478045,\n          -0.06986048,  0.31659806,  0.11275043, -0.30804428,\n          -1.0519745 , -0.02870833,  0.66114515,  0.21226135,\n          -0.39647344,  0.3002576 , -0.18979299, -0.4999055 ,\n          -0.73667544,  0.09276333, -1.1361312 ,  1.0816007 ,\n          -0.65233743, -0.5979163 , -0.712924  ,  0.36949113,\n          -0.5170336 ,  0.36557817, -0.51443595, -0.7022156 ,\n           0.02008307,  0.3340164 ,  0.43797365, -0.5489855 ,\n          -0.17064345,  0.55959755, -0.122706  ,  0.13699171,\n          -0.10662575,  0.27799806, -0.2464436 ,  0.81737345,\n          -0.8665495 , -0.5111603 , -0.40959263, -0.7692196 ,\n           0.29745805,  0.71748877, -0.4497995 ,  0.38830143,\n           0.05356326, -0.33564323,  0.19943495,  0.61193085,\n          -0.8530397 , -0.10197708, -0.72405595,  0.62300456,\n           0.24674514,  0.27955812,  0.38849142, -0.05993968,\n          -0.5073567 ,  0.39661697,  0.39411092,  0.157851  ,\n          -0.75409806,  0.33312374, -0.31899762,  0.09761707,\n           0.56409353,  0.64576536,  0.32380137,  0.18089986,\n          -0.77493066, -0.23393588, -0.05034808, -0.8058799 ,\n          -0.8371362 ,  0.21467723,  0.17819731,  0.6864316 ,\n           0.40611446, -0.26745972, -0.14092351,  0.11800583],\n         [-0.39469   ,  0.30300498,  0.53789955, -0.52856624,\n          -1.0521023 , -0.39769587,  0.26218626,  0.48027346,\n          -0.42317685,  0.07384458,  0.02196375,  0.42948914,\n          -0.1745447 , -0.42808214, -0.02662465, -0.90202034,\n          -0.30277604,  0.9371252 ,  0.524054  ,  1.056957  ,\n           0.58215135, -0.975589  , -0.5591015 ,  0.48841473,\n           0.20607665,  0.9382853 ,  1.1080399 , -0.86645097,\n          -0.41629606,  0.6389021 ,  0.12614216,  1.0538548 ,\n          -0.19141994, -0.57476276,  0.00735889,  0.34256047,\n           0.04511756,  0.502965  , -0.97229046,  0.586565  ,\n          -0.9448496 ,  0.16441298,  0.664086  , -0.3116942 ,\n           0.3827091 ,  0.10757452,  0.22329819, -0.36200747,\n          -0.34872165, -1.1089379 , -0.11258741, -0.6987143 ,\n          -0.39123395,  0.79118615, -0.6871437 ,  0.98652273,\n           0.45614192, -0.8000015 ,  0.48945192, -0.5666781 ,\n           0.03681678,  0.47129726, -0.24828257,  0.02689931,\n           0.10958332, -0.329704  , -0.6835226 ,  0.28747895,\n           0.04841892,  0.04434224, -0.56140655,  0.6084956 ,\n          -0.6982782 , -0.8603141 , -0.9699785 ,  0.72398233,\n           0.64600843,  0.2879384 ,  0.29492298,  1.1124154 ,\n          -0.19271912,  0.6591149 ,  0.57711303, -1.0100758 ,\n          -0.1111366 ,  0.77275485, -0.22868526, -0.5988182 ,\n          -0.11498249, -0.27344736,  0.2709899 , -0.26077777,\n          -0.33749226,  0.8111305 , -0.18575278, -0.04168475,\n          -0.04411848, -1.0682193 ,  0.5733207 ,  0.774866  ,\n           0.538991  , -0.38923022,  0.05205485, -0.1860995 ,\n          -0.9577869 , -0.36246422,  0.26046517, -0.7757237 ,\n           0.60591906,  0.1543424 , -0.4295256 , -0.02982505,\n           0.26756245,  0.32862052,  0.2425808 ,  0.20770375,\n           0.54039216, -0.8881532 , -0.0658545 ,  0.1212695 ,\n          -0.0795048 ,  0.5900311 ,  0.11333069,  0.27838373,\n          -0.09550293, -0.68276167, -0.1973688 ,  0.9723001 ,\n           0.25163275, -0.63432914,  0.63903147, -0.62233347,\n          -0.17469533,  0.18646888, -0.7063749 , -0.2633393 ,\n          -0.16341127,  0.43954936, -0.3643338 , -0.6634698 ,\n           0.45505443, -0.21446237, -0.68083745,  0.3955437 ],\n         [ 0.9754646 , -0.00438527, -0.35573214,  0.34832147,\n           0.5408223 ,  0.46897078, -0.08874272,  0.14692575,\n           0.16078435,  0.0389923 , -0.44496182, -0.23117025,\n          -0.4639831 , -0.52893287,  0.23210871, -0.6741205 ,\n          -0.8130221 ,  0.1739061 , -0.21381497,  0.6114615 ,\n           0.5018714 , -0.5131973 , -0.05490024,  0.44681096,\n           0.42288497, -0.19716763,  0.14599109,  0.6564013 ,\n           0.4676522 ,  0.24036585,  0.11850829, -0.7254172 ,\n          -1.0944178 , -0.10014945,  0.6750436 ,  0.14813387,\n          -1.045056  ,  0.50445986, -0.04623822,  0.09868938,\n          -0.41627884, -0.16237122,  1.1205145 , -0.34445724,\n           0.05962926, -0.6128795 ,  0.83766705, -0.22920242,\n           0.56529564,  0.49025205, -0.15284525, -0.00703803,\n           0.06588357, -0.48238137, -0.8113619 ,  0.41264638,\n          -0.2875805 ,  0.1166129 , -0.20996325, -0.07270594,\n          -0.58980566, -0.831582  ,  0.6943867 , -0.08046342,\n          -0.12935568,  0.34449622, -0.6762317 , -0.6754419 ,\n           0.88747746, -0.58709174, -0.37066662,  0.06890481,\n           0.25350207, -0.38977683,  0.44481575, -0.74258065,\n           0.10313553, -0.9746051 , -0.42320952,  0.38481987,\n          -0.15555532, -0.80368644, -0.01303876,  0.42803398,\n           0.21563873,  0.4039424 , -0.04059639,  0.26639232,\n          -0.08367503,  0.3938428 , -0.46830386, -0.1440706 ,\n          -0.17425267, -0.04523797, -0.67745745, -0.6934136 ,\n           0.782805  ,  0.06349245,  0.7873974 , -0.49040392,\n           0.4589856 , -0.23889068,  0.28198406, -0.24196243,\n          -0.3547125 , -0.80859405,  0.5006063 ,  0.36697018,\n          -0.30710855, -1.1278713 , -0.09068426, -0.90145075,\n          -0.28888053, -0.45720378, -0.23874857,  0.624876  ,\n           0.60238147, -0.21903844, -0.1719479 , -0.3206194 ,\n           0.6145958 , -0.5016537 , -0.3736362 , -0.9036106 ,\n           0.42266077,  0.48498815,  0.7751404 , -0.38286912,\n          -0.20760374, -0.08962531,  0.15637088, -0.52028143,\n           0.11103437,  0.2873182 ,  0.7245172 ,  0.01077716,\n           0.2696031 , -1.1249957 , -0.7402211 , -0.9082132 ,\n           0.3822948 , -0.01565916,  0.3292175 ,  0.63007253],\n         [ 0.20066158, -0.39986926,  0.70086503,  0.25450036,\n          -0.42714983, -0.4481472 ,  0.58430934, -0.34443662,\n          -0.998419  , -0.6954459 ,  0.5982778 ,  0.15596342,\n           0.8363044 ,  0.40619704,  0.49438566,  0.21595173,\n          -0.41770044,  0.5155262 ,  0.31941435,  0.5943516 ,\n          -0.4207089 , -0.22839516, -0.2850254 , -0.48265067,\n          -0.3857148 ,  0.1600421 ,  0.5635464 ,  0.54957885,\n           0.00668295, -0.6173806 ,  0.1906684 ,  0.3727613 ,\n           0.3042391 ,  0.38187587,  0.08821028,  0.7179519 ,\n          -0.60850495,  0.38117087,  0.10388664,  0.07209044,\n           0.4224496 ,  0.30955866,  0.282565  ,  0.7405576 ,\n          -0.53897065, -0.44276372, -0.8774886 , -0.8751283 ,\n          -0.31016666, -0.13271686, -0.40718403,  0.5345011 ,\n          -0.44278276,  0.89124227, -0.6074596 ,  0.3430309 ,\n           0.2842252 , -0.64881885, -0.3956869 , -0.30742168,\n          -0.10451504,  0.2389749 ,  1.0267768 ,  0.6741248 ,\n           0.34706685, -0.83305746, -0.41279048, -0.07871567,\n          -0.2843145 , -0.14377773,  1.0640689 , -0.07497586,\n           0.4705423 , -1.0031061 , -0.36948532, -0.1916939 ,\n          -0.54547554,  0.67887676, -0.23877418,  0.33397022,\n           0.10341568,  0.40265772,  0.3355503 ,  0.48349556,\n          -0.2785468 ,  0.41726178, -0.48996758, -0.14610444,\n          -0.8965524 ,  0.53374225, -0.6285892 ,  0.17857426,\n          -0.73508686, -0.08894856, -0.52788913,  0.78603166,\n           0.6993428 ,  0.27794513, -0.8726327 , -0.07149154,\n           0.03367646, -0.40194854, -0.21028782, -0.12961254,\n          -0.7025133 , -0.5894277 ,  0.932474  ,  0.7977343 ,\n          -0.23513924,  0.9309386 , -0.5782518 ,  0.58637077,\n          -0.34770703,  0.65729386, -0.5561754 ,  0.04164503,\n          -0.9982304 ,  0.2352612 , -0.2568104 , -0.2858503 ,\n           0.6451764 ,  0.7721339 , -0.07506826,  0.32429686,\n          -0.39532852, -0.07099956,  1.1071563 , -0.2077619 ,\n          -0.02654623,  0.7633865 ,  1.1225549 , -0.25271323,\n           0.16528678, -0.740723  , -0.38473913,  0.5335051 ,\n          -0.7202439 , -0.95562524,  0.5452918 , -0.8490771 ,\n          -0.50285286, -0.13346614,  0.44031847, -0.51493686]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_851/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[ 0.14176348, -0.18495345,  0.21216701, ..., -0.08082036,\n           0.00323492, -0.09561373],\n         [-0.03675757,  0.04443929, -0.03111906, ..., -0.18890283,\n           0.00630859, -0.11341402],\n         [-0.06600282, -0.11612254,  0.19817844, ...,  0.24137457,\n           0.03846955,  0.2028332 ],\n         ...,\n         [ 0.06127869,  0.19625293, -0.01395706, ...,  0.149263  ,\n          -0.25050923, -0.21167158],\n         [-0.02569345,  0.08823421,  0.07141477, ..., -0.06534476,\n          -0.20569034, -0.14028575],\n         [ 0.01713383,  0.02133022, -0.13792536, ..., -0.21138842,\n          -0.07604994, -0.06765077]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_3/bias:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[-0.01230802, -0.04724625,  0.04502202, ...,  0.03112269,\n          -0.02959301,  0.09607556],\n         [-0.03805686,  0.09795295,  0.00647715, ..., -0.01783718,\n           0.00159166,  0.0407985 ],\n         [ 0.05649356,  0.04052271,  0.06199136, ...,  0.02262933,\n           0.0109346 , -0.09812878],\n         ...,\n         [-0.02682485,  0.01743664, -0.02204785, ...,  0.0453328 ,\n           0.04073798, -0.066413  ],\n         [ 0.06118085, -0.0336022 , -0.06813037, ...,  0.04083523,\n           0.03830257,  0.01283902],\n         [ 0.0461296 , -0.00201737, -0.01553704, ..., -0.08509237,\n          -0.04542306, -0.02710045]]]], dtype=float32)>, <tf.Variable 'conv2d_856/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.01843976, -0.03098864,  0.05574783, ..., -0.13279253,\n           0.16101842, -0.05144629],\n         [ 0.14971836, -0.08997049, -0.1220033 , ..., -0.06152144,\n          -0.03506518, -0.0560917 ],\n         [ 0.07375477, -0.01566198,  0.10971449, ...,  0.17921707,\n          -0.14212574,  0.04531173],\n         ...,\n         [-0.06201873,  0.09663314,  0.0133636 , ..., -0.08341017,\n           0.0265577 , -0.0024548 ],\n         [ 0.0222892 , -0.13300845,  0.02199313, ...,  0.00113345,\n          -0.10096229,  0.12386192],\n         [-0.1473402 ,  0.05544004, -0.01258931, ...,  0.09006105,\n          -0.03448061,  0.02653985]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/moving_variance:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 240, 1) dtype=float32, numpy=\narray([[[[ 0.00603853],\n         [-0.00661407],\n         [ 0.01694463],\n         ...,\n         [-0.02450655],\n         [-0.00253637],\n         [-0.02337872]],\n\n        [[ 0.00250033],\n         [ 0.03330577],\n         [-0.01773065],\n         ...,\n         [ 0.02821982],\n         [-0.03204954],\n         [ 0.01769499]],\n\n        [[ 0.00617511],\n         [-0.00010343],\n         [ 0.03215319],\n         ...,\n         [ 0.00722378],\n         [-0.00159786],\n         [ 0.00946158]]],\n\n\n       [[[ 0.02254423],\n         [ 0.02320418],\n         [-0.01153665],\n         ...,\n         [-0.00807771],\n         [ 0.0385689 ],\n         [-0.01325462]],\n\n        [[-0.02658791],\n         [ 0.04491263],\n         [ 0.01900977],\n         ...,\n         [-0.00925941],\n         [ 0.04067061],\n         [-0.03203978]],\n\n        [[-0.02860303],\n         [ 0.00088431],\n         [-0.03354765],\n         ...,\n         [-0.02702828],\n         [-0.0178824 ],\n         [ 0.0075737 ]]],\n\n\n       [[[ 0.03257695],\n         [ 0.00523627],\n         [ 0.01086204],\n         ...,\n         [-0.01027123],\n         [-0.01318854],\n         [-0.0080928 ]],\n\n        [[ 0.01711234],\n         [-0.00469417],\n         [-0.02240466],\n         ...,\n         [ 0.0386394 ],\n         [-0.03802041],\n         [-0.0040078 ]],\n\n        [[-0.00369647],\n         [ 0.01324173],\n         [-0.03341268],\n         ...,\n         [ 0.01164204],\n         [ 0.01389095],\n         [-0.03039853]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00266667,  0.03014395,  0.02668047, ..., -0.0314961 ,\n          -0.03319273, -0.00969079],\n         [ 0.07900628,  0.03745876, -0.01490635, ...,  0.02624054,\n          -0.01047033, -0.07650313],\n         [ 0.02356237, -0.03130692,  0.03067523, ..., -0.06359611,\n           0.04184388,  0.03455317],\n         ...,\n         [ 0.04103096,  0.01069454,  0.06131755, ...,  0.04147609,\n           0.02061796,  0.01619933],\n         [ 0.02983697, -0.07677518, -0.03068724, ..., -0.03915524,\n          -0.05607092,  0.02268139],\n         [-0.00462203,  0.05226349,  0.08682993, ..., -0.02759304,\n          -0.05311427,  0.01523298]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.18786344,  0.12604521, -0.04501265, ...,  0.07109242,\n          -0.47982773, -0.0677612 ],\n         [ 0.2618899 , -0.3980752 , -0.30758515, ..., -0.06631817,\n          -0.08941885, -0.15816832],\n         [-0.11506429, -0.00277571,  0.13713962, ..., -0.0566028 ,\n           0.27663597, -0.09413323],\n         ...,\n         [-0.15575771, -0.15221483,  0.14853598, ..., -0.4634371 ,\n          -0.02095373, -0.09162367],\n         [-0.14941089,  0.3243132 ,  0.00394255, ...,  0.0455074 ,\n          -0.15589875,  0.23712142],\n         [-0.18219858, -0.3280798 ,  0.14526923, ..., -0.22644341,\n          -0.31533128, -0.06355378]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/conv2d_1/kernel:0' shape=(1, 1, 48, 16) dtype=float32, numpy=\narray([[[[-1.02181524e-01, -7.25777596e-02,  8.90106559e-02,\n          -1.86004907e-01,  3.00907761e-01,  1.48552343e-01,\n           1.39019474e-01,  2.88058668e-01,  2.10673902e-02,\n           6.88962862e-02, -8.51926580e-02,  6.53823167e-02,\n          -1.45136029e-01, -7.85291642e-02, -7.25867748e-02,\n           1.43174782e-01],\n         [-2.24682406e-01,  3.22753221e-01, -7.08048493e-02,\n          -1.45695597e-01, -7.21457079e-02,  4.24870341e-05,\n           3.03617232e-02,  1.96206316e-01,  1.14046913e-02,\n           2.52127089e-02,  6.18198179e-02,  2.98034642e-02,\n          -8.43900163e-03,  9.62586105e-02, -7.30514824e-02,\n          -2.18906458e-02],\n         [ 2.34150097e-01,  1.07950263e-01,  1.79907173e-01,\n          -5.66559024e-02, -4.23578881e-02,  2.81627208e-01,\n          -2.13104650e-01,  2.06335634e-01,  1.24032654e-01,\n          -8.56553018e-02, -1.46149606e-01, -7.23259971e-02,\n          -1.16082333e-01, -1.14865407e-01,  2.63576269e-01,\n          -8.24334621e-02],\n         [-1.45542622e-01,  1.78907692e-01,  2.66639769e-01,\n           2.89792955e-01,  9.97686014e-02, -2.76628067e-03,\n           2.23187730e-01,  6.13700449e-02, -5.67456074e-02,\n          -3.86756659e-02,  9.64571759e-02,  3.98134328e-02,\n           1.04198404e-01, -4.98739928e-02, -1.59259260e-01,\n          -2.66742676e-01],\n         [-1.18493266e-01, -7.02051222e-02, -6.59645349e-02,\n           3.38049755e-02, -1.47867560e-01,  7.02824965e-02,\n          -1.11968569e-01, -8.70006606e-02, -4.94164042e-02,\n           2.51324032e-03,  2.62915753e-02, -8.96383300e-02,\n           1.51135623e-01, -3.12440507e-02,  2.36292910e-02,\n           1.65162478e-02],\n         [ 1.57954067e-01, -2.94619471e-01,  1.96081097e-03,\n          -1.03333600e-01, -3.27900261e-01,  2.21132159e-01,\n           2.66339853e-02, -2.32908860e-01,  1.36533543e-01,\n          -7.41727203e-02,  4.98304330e-02,  2.18312502e-01,\n          -3.13802212e-01,  8.79045278e-02,  1.25991076e-01,\n          -2.50706524e-01],\n         [-3.24532464e-02, -2.65887558e-01,  5.73137403e-02,\n          -1.34154081e-01,  3.15417955e-03,  4.95391898e-02,\n          -1.13012120e-01,  1.82941690e-01, -1.01797050e-02,\n          -1.74275801e-01,  1.98419928e-03, -9.65388194e-02,\n          -3.27803999e-01, -2.52139084e-02,  8.77076164e-02,\n           9.16032307e-03],\n         [ 1.58155132e-02, -2.43053406e-01,  2.11689353e-01,\n           1.99067090e-02, -2.16767602e-02, -1.84347257e-01,\n          -1.48267925e-01,  1.27169728e-01, -9.10081938e-02,\n           2.47795582e-01,  2.41188314e-02,  2.45306417e-01,\n           3.35509167e-03,  2.88400143e-01,  5.10288030e-02,\n          -1.09803133e-01],\n         [ 1.30566165e-01, -1.11069545e-01, -2.45236121e-02,\n           6.36465475e-02, -9.49181914e-02,  1.42550290e-01,\n          -1.62568361e-01, -1.56498358e-01,  8.97106081e-02,\n          -2.99477391e-02,  1.59102216e-01,  4.52981591e-02,\n          -1.56800807e-01,  4.24487256e-02, -2.40603969e-01,\n           8.72158036e-02],\n         [ 3.25359590e-02,  1.00344390e-01,  1.18712731e-01,\n          -1.10225484e-01,  1.34726658e-01, -4.22361642e-02,\n           2.78295577e-01,  9.33252946e-02,  8.67340565e-02,\n           4.10922132e-02, -2.91002523e-02,  8.76883566e-02,\n          -1.20117262e-01,  1.93860456e-01,  5.09554483e-02,\n           1.69934273e-01],\n         [-2.64407061e-02, -2.43461058e-02, -1.11113265e-01,\n          -2.92662323e-01,  2.00214267e-01,  6.42837584e-02,\n           8.26920494e-02,  1.18289873e-01, -1.08833961e-01,\n          -8.54469091e-03,  1.98734090e-01,  1.04158401e-01,\n           1.05692248e-03,  1.59713015e-01, -1.24541976e-01,\n          -4.95548313e-03],\n         [ 8.57236087e-02, -1.82414078e-04,  6.72515780e-02,\n          -1.83787152e-01,  2.76540667e-02, -7.11885318e-02,\n           6.62677409e-03, -7.98571929e-02, -1.85721040e-01,\n           2.97254622e-01,  2.09907070e-01,  1.14811979e-01,\n          -7.12441653e-02, -2.12579090e-02, -1.22004353e-01,\n          -7.18095377e-02],\n         [ 7.74764493e-02, -8.07218179e-02, -6.34014010e-02,\n           1.46065578e-01, -1.12367524e-02,  3.08802873e-02,\n           8.15941840e-02,  1.97391003e-01,  1.47138536e-01,\n           6.80283457e-02, -1.42199159e-01,  9.17010605e-02,\n           1.95323110e-01, -6.29295781e-02, -1.09015472e-01,\n           1.22423016e-01],\n         [ 3.36311720e-02,  7.94820189e-02, -1.55627057e-01,\n           2.49369070e-01, -3.18250626e-01,  1.33801103e-01,\n           1.24305658e-01, -8.40935484e-02, -6.46493882e-02,\n          -1.89908937e-01, -1.50145084e-01, -1.21420972e-01,\n           2.13825062e-01,  1.14537135e-01, -1.08218752e-01,\n           6.87922314e-02],\n         [ 1.33074284e-01, -1.18591987e-01, -5.25621660e-02,\n          -5.02595007e-02,  4.52356646e-03,  1.24821030e-01,\n          -3.27542424e-02, -2.02210504e-03,  8.90989788e-03,\n           2.82372534e-01, -4.53988686e-02,  1.47531062e-01,\n          -7.41540566e-02,  6.54057413e-02,  1.59883536e-02,\n           1.37441322e-01],\n         [ 1.01780362e-01, -3.11982329e-03,  3.23392376e-02,\n          -1.50009841e-01, -1.68700755e-01,  3.46118063e-02,\n           1.29430935e-01, -7.40154386e-02, -1.94036499e-01,\n          -1.52886033e-01,  2.40291879e-01,  3.24320406e-01,\n          -1.15377896e-01, -7.74510652e-02, -1.47420123e-01,\n          -4.02958989e-02],\n         [-3.82325277e-02,  2.32930750e-01, -2.28026465e-01,\n           5.03906198e-02, -5.62171079e-02,  4.12754752e-02,\n          -2.38826293e-02, -6.89155608e-02, -8.18880349e-02,\n           4.42061061e-03, -1.13892987e-01, -3.97676378e-02,\n           4.21150438e-02,  9.08962712e-02,  3.07603270e-01,\n          -4.75876890e-02],\n         [ 2.25391343e-01,  5.63282408e-02,  7.41237728e-03,\n           1.23824105e-01,  6.29147440e-02, -1.28068149e-01,\n           1.47795275e-01, -2.41845883e-02,  2.00235531e-01,\n          -1.06524386e-01, -2.74975210e-01, -1.93612754e-01,\n          -3.13928723e-01,  6.29700199e-02, -3.06633450e-02,\n           9.24778059e-02],\n         [-1.89643294e-01, -1.58751546e-03,  2.84088384e-02,\n          -2.97337115e-01,  1.72584325e-01, -1.55372918e-01,\n           1.28265530e-01, -1.32720489e-02,  1.08151361e-01,\n           1.69150084e-01,  1.70283616e-01, -2.14693382e-01,\n          -3.55941541e-02, -1.01406336e-01, -1.51374996e-01,\n          -1.00705154e-01],\n         [ 2.14555457e-01, -1.27922930e-02, -4.87317108e-02,\n          -1.91085979e-01, -8.85218754e-03, -2.12998569e-01,\n           1.61059603e-01,  2.14747444e-01, -8.53616744e-02,\n          -5.25604934e-02,  2.36451596e-01, -6.25107139e-02,\n          -1.59164481e-02, -2.91219831e-01,  1.55970827e-01,\n          -1.14534318e-01],\n         [ 1.73278913e-01,  9.88745131e-04,  2.70399332e-01,\n          -2.49358296e-01,  3.17873061e-02,  1.27640646e-02,\n          -8.49547461e-02, -5.36032878e-02,  4.84497100e-02,\n           7.64451921e-02, -1.76088177e-02, -1.08589411e-01,\n           3.53286345e-03,  6.78457320e-02,  1.03090495e-01,\n           6.02727942e-02],\n         [-1.86414480e-01, -5.57431839e-02, -3.84370722e-02,\n           1.21744864e-01,  7.30370730e-02,  1.01285741e-01,\n           3.93401347e-02,  5.85956313e-03, -1.38463110e-01,\n           1.28210843e-01,  2.21437380e-01,  1.41965196e-01,\n           2.15172172e-01, -2.73327027e-02, -1.75234050e-01,\n          -9.61982924e-03],\n         [ 2.38107637e-01, -3.53073664e-02,  1.68440744e-01,\n           2.96526644e-02,  1.21617101e-01,  2.21708447e-01,\n           7.18526244e-02, -1.11687444e-01, -4.19403203e-02,\n           4.43263426e-02,  5.94520867e-02, -7.71521777e-02,\n          -4.82642651e-02,  3.08729261e-01, -7.03656301e-02,\n           1.98290542e-01],\n         [ 5.99126369e-02,  2.05281049e-01,  5.15868664e-02,\n          -3.52837965e-02, -8.69954601e-02,  6.91513047e-02,\n           9.27370861e-02, -2.25239679e-01, -1.60201974e-02,\n          -1.05777249e-01,  1.10523298e-01,  1.09623961e-01,\n           7.89763406e-02,  1.42659664e-01,  1.58130631e-01,\n          -9.13958848e-02],\n         [ 3.56138200e-02,  3.25297415e-02,  1.07691579e-01,\n           1.76336542e-01, -1.33302942e-01,  3.27597931e-02,\n           2.93018669e-01,  8.23027194e-02, -2.54388243e-01,\n          -2.44387046e-01,  1.56651139e-01, -2.83729255e-01,\n           5.83191216e-02,  8.30602646e-02, -1.85414448e-01,\n          -7.65476674e-02],\n         [-2.39664271e-01,  2.61359751e-01,  2.22969040e-01,\n          -2.92681813e-01,  3.34077328e-02,  9.23342109e-02,\n          -3.05619210e-01, -3.80843952e-02, -7.14975819e-02,\n           1.12608612e-01,  1.01626419e-01,  1.71271130e-01,\n           9.52569768e-02,  6.74543343e-03, -4.49980162e-02,\n          -3.05042230e-02],\n         [ 4.56222259e-02,  1.36861712e-01, -2.84185946e-01,\n          -8.54362249e-02, -4.35483754e-02,  8.63322616e-02,\n           1.80963650e-01,  7.72910425e-03, -2.26032570e-01,\n           1.35270804e-01,  1.47955166e-02,  2.82299370e-01,\n          -7.48860091e-02, -1.34217203e-01,  7.32719600e-02,\n          -7.65958726e-02],\n         [ 2.17576653e-01,  5.17210737e-03,  5.50453216e-02,\n          -3.38355033e-03, -8.10837895e-02, -1.42146409e-01,\n          -1.66495234e-01,  7.87371099e-02,  9.20132361e-03,\n           1.77631274e-01, -3.75026949e-02, -1.43959031e-01,\n           1.84399232e-01,  1.23184867e-01,  1.47548810e-01,\n           1.28731102e-01],\n         [ 2.30618581e-01,  1.84325278e-01,  2.68379390e-01,\n           2.50827044e-01,  1.96538925e-01,  2.73314625e-01,\n          -1.60220433e-02,  1.80634558e-01,  1.17443822e-01,\n           1.88180059e-02, -1.01446703e-01,  1.96876720e-01,\n           1.74266115e-01,  3.60445678e-02,  1.21307746e-02,\n          -1.11937791e-01],\n         [-1.91131365e-02, -4.53058481e-02, -1.15102626e-01,\n           4.95938286e-02, -7.81944096e-02, -4.97212000e-02,\n           1.92438856e-01, -2.39768162e-01, -1.63508281e-01,\n          -3.30265961e-04,  1.26804352e-01, -1.82086140e-01,\n          -5.62040973e-03, -2.17691690e-01,  2.76131004e-01,\n           1.84075549e-01],\n         [-1.10748328e-01,  6.51763454e-02,  2.29822338e-01,\n           1.67506576e-01, -4.07474115e-02, -5.39673120e-02,\n          -2.27724448e-01, -6.65826574e-02,  2.79039532e-01,\n           3.28486995e-03, -9.92082879e-02, -5.25546409e-02,\n          -1.04851097e-01,  2.50993595e-02,  8.60331357e-02,\n          -3.08229923e-02],\n         [-3.55478562e-02, -4.16829437e-02,  1.03898264e-01,\n           2.36273721e-01, -1.38596063e-02, -2.31124789e-01,\n           1.04059204e-01, -2.83180743e-01, -9.62332077e-03,\n          -1.47309005e-01,  1.05392158e-01,  5.36897853e-02,\n          -2.50509307e-02, -7.95836896e-02,  4.15101871e-02,\n          -2.75264859e-01],\n         [ 2.10245803e-01, -3.98529172e-02, -2.64765590e-01,\n           1.07619330e-01,  1.79662243e-01, -1.74933285e-01,\n          -1.71799675e-01, -1.41173258e-01, -3.84134017e-02,\n          -1.96545906e-02,  1.47436917e-01, -1.49164245e-01,\n           7.49868676e-02, -9.84556079e-02,  2.12001249e-01,\n          -5.78430817e-02],\n         [-8.97223800e-02,  2.86912173e-01, -2.62841787e-02,\n          -2.56170660e-01, -9.64613352e-03,  2.69677285e-02,\n          -5.41694579e-04,  2.34047547e-01,  3.34745320e-03,\n           6.37298748e-02,  1.46696419e-01, -2.53614128e-01,\n           4.58766669e-02, -1.11500196e-01, -1.74091198e-02,\n           7.75560364e-02],\n         [-1.71826091e-02, -2.10667387e-01,  1.37687966e-01,\n          -1.19939111e-01, -7.41712824e-02, -6.40208200e-02,\n          -1.67886000e-02,  1.39687777e-01,  4.21378836e-02,\n           3.89180668e-02,  1.74796417e-01, -1.99876532e-01,\n          -2.99249589e-01,  7.10245296e-02, -9.38150659e-02,\n           5.01777139e-03],\n         [-1.13493584e-01, -1.09270714e-01,  3.28636058e-02,\n           4.92055640e-02, -1.46066859e-01,  1.91645488e-01,\n          -5.97882979e-02,  3.00473511e-01,  1.90640986e-02,\n           3.11508887e-02, -1.43666938e-01, -2.18929276e-01,\n           2.31208906e-01, -3.36096622e-02, -1.67405102e-02,\n           1.22818239e-01],\n         [-1.45999864e-01,  7.32734352e-02,  2.54455954e-01,\n           1.92452028e-01, -4.89150956e-02, -7.94497356e-02,\n           9.09663737e-02,  1.15875915e-01,  1.83012649e-01,\n          -8.38058963e-02, -6.29356652e-02,  7.82416388e-02,\n           2.92102575e-01, -2.64993876e-01,  6.84432760e-02,\n           4.14422713e-02],\n         [ 1.37558043e-01, -6.48783054e-03,  1.33791342e-02,\n           5.58794253e-02, -1.12529777e-01, -1.61715299e-01,\n           9.51136574e-02, -1.47645086e-01,  9.76647139e-02,\n           1.34419456e-01,  6.70032750e-04,  1.80288628e-02,\n           2.04077557e-01,  6.98165745e-02, -4.42982838e-02,\n          -2.10351869e-01],\n         [-5.06078042e-02,  2.24750131e-01, -3.49927694e-02,\n           4.29473333e-02, -2.20072329e-01,  1.82456225e-01,\n           9.55630466e-02,  1.69595510e-01, -1.00732967e-01,\n          -1.73102200e-01, -5.59920967e-02, -1.48348108e-01,\n           5.40265888e-02, -1.93006486e-01,  1.17594130e-01,\n          -7.79562071e-02],\n         [-6.01457953e-02,  2.99031317e-01, -5.18117212e-02,\n          -2.80229956e-01, -1.11987256e-01,  1.35468200e-01,\n          -9.81529057e-02, -5.28691895e-02,  1.24282166e-01,\n          -5.77128865e-02,  8.37636068e-02, -1.27593100e-01,\n          -2.16098428e-01, -1.09928995e-02, -4.94445600e-02,\n           2.47993737e-01],\n         [ 2.05893114e-01,  4.09197398e-02,  2.46151671e-01,\n          -2.72073783e-02, -2.68758178e-01, -2.99959958e-01,\n          -1.04729973e-01,  1.64711162e-01, -2.20185012e-01,\n           3.30054425e-02, -9.62202176e-02,  2.28863955e-01,\n          -1.75233960e-01, -6.57974109e-02, -9.78763551e-02,\n           3.98478508e-02],\n         [-8.92820209e-02,  8.28092918e-02, -1.22760050e-01,\n           5.92688681e-04, -1.35606572e-01, -3.15818638e-02,\n          -2.29801431e-01, -9.98021066e-02, -1.80383578e-01,\n          -3.47576216e-02, -1.23595476e-01,  1.35637328e-01,\n           1.70570984e-02,  1.37430981e-01,  1.38109267e-01,\n          -2.65610665e-01],\n         [-7.37612769e-02, -1.16773784e-01,  5.43266684e-02,\n           2.11834937e-01,  2.91099280e-01,  1.79449245e-01,\n           1.35207614e-02, -9.66300082e-04, -1.23524241e-01,\n           1.10784717e-01, -1.25249609e-01,  1.70965753e-02,\n          -5.92054650e-02, -8.25566798e-02, -3.71096618e-02,\n          -3.02544355e-01],\n         [-1.44560695e-01,  1.17624514e-01, -6.80882931e-02,\n          -2.18734075e-03,  7.92770386e-02, -6.66104332e-02,\n          -5.99203296e-02,  2.71038651e-01,  1.10681474e-01,\n           5.78726381e-02,  2.00314801e-02, -2.24641219e-01,\n          -8.10881704e-02, -2.86036611e-01, -1.02746487e-01,\n          -1.77701876e-01],\n         [ 1.17489479e-01,  1.07996063e-02, -4.15525027e-02,\n          -2.91466918e-02,  3.07904202e-02, -1.04048001e-02,\n           6.87485337e-02, -2.45118737e-01,  8.25035200e-03,\n          -1.28545919e-02,  1.24011412e-01,  1.52969494e-01,\n          -2.43195996e-01,  8.16511512e-02,  1.31879270e-01,\n          -8.99414718e-03],\n         [-2.58023441e-01,  5.46123162e-02,  2.76821945e-02,\n          -9.41413566e-02, -5.22293635e-02, -3.28014433e-01,\n           2.70314872e-01, -1.94480389e-01,  1.15801260e-01,\n          -1.11605279e-01,  3.01359519e-02, -2.47813053e-02,\n           2.07918193e-02, -2.12495979e-02,  2.27290541e-01,\n           8.60297605e-02],\n         [ 1.91424325e-01,  1.29608423e-01,  2.65128780e-02,\n          -9.84849259e-02,  1.33727938e-01, -1.89162463e-01,\n          -2.21847117e-01,  4.89297211e-02,  1.06917962e-01,\n          -1.06698759e-01, -4.88257036e-02,  1.37369588e-01,\n          -1.72220275e-01,  1.38163000e-01, -1.02464557e-01,\n          -9.28356126e-02],\n         [-3.33271734e-02,  1.12439118e-01, -5.66471368e-02,\n           8.81095454e-02,  1.42193526e-01,  2.24082530e-01,\n          -2.61987895e-02, -3.26926336e-02, -1.26960486e-01,\n           2.93076605e-01, -1.89460814e-01, -5.85879311e-02,\n          -2.26266265e-01, -3.90795618e-02,  2.25898791e-02,\n          -7.29364753e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_374/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.03971641],\n         [ 0.02154293],\n         [ 0.06626424],\n         ...,\n         [-0.07487623],\n         [ 0.06870477],\n         [-0.07227591]],\n\n        [[ 0.07187608],\n         [ 0.05755942],\n         [ 0.04431364],\n         ...,\n         [ 0.0232104 ],\n         [-0.04937269],\n         [-0.00543904]],\n\n        [[ 0.02613164],\n         [ 0.04544594],\n         [ 0.06915727],\n         ...,\n         [ 0.03430823],\n         [ 0.00054798],\n         [ 0.00852149]]],\n\n\n       [[[ 0.05902345],\n         [ 0.06464124],\n         [ 0.0472585 ],\n         ...,\n         [ 0.02441438],\n         [ 0.05487467],\n         [ 0.04975504]],\n\n        [[-0.04066389],\n         [ 0.03292453],\n         [-0.06758874],\n         ...,\n         [ 0.07410011],\n         [-0.05377408],\n         [ 0.0054394 ]],\n\n        [[ 0.002588  ],\n         [-0.04081379],\n         [ 0.06389795],\n         ...,\n         [-0.00103398],\n         [ 0.07333204],\n         [-0.06200524]]],\n\n\n       [[[-0.00235611],\n         [ 0.00851078],\n         [-0.05419039],\n         ...,\n         [-0.02631247],\n         [ 0.07017735],\n         [ 0.052789  ]],\n\n        [[ 0.00757284],\n         [ 0.02946821],\n         [ 0.02877439],\n         ...,\n         [ 0.00752001],\n         [ 0.03604785],\n         [ 0.07542095]],\n\n        [[-0.04866141],\n         [ 0.04339413],\n         [-0.04499489],\n         ...,\n         [-0.02147651],\n         [ 0.05177794],\n         [ 0.06711251]]]], dtype=float32)>, <tf.Variable 'conv2d_873/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[-0.08228299, -0.10042142, -0.14646548, ..., -0.06682579,\n          -0.12935759,  0.06716952],\n         [ 0.12372063, -0.08948938, -0.12282396, ..., -0.04901413,\n          -0.03705778,  0.18005234],\n         [ 0.14789614, -0.03093061, -0.14247869, ...,  0.03753457,\n          -0.10338383, -0.00158537],\n         ...,\n         [-0.09937522, -0.04977391,  0.09749693, ...,  0.00172218,\n          -0.12187161,  0.09031255],\n         [-0.00452282, -0.16338657, -0.11814156, ...,  0.09473725,\n           0.03825827,  0.0155141 ],\n         [-0.1459344 , -0.05121383,  0.11358248, ..., -0.05892809,\n           0.0844176 ,  0.10785883]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[ 0.06176353, -0.01652106, -0.01412831, ...,  0.01955262,\n           0.09287293, -0.02693438],\n         [ 0.00824071, -0.00586807,  0.08832687, ..., -0.02067577,\n          -0.05568636, -0.0871231 ],\n         [-0.04435338,  0.0541266 , -0.00054808, ...,  0.01516627,\n          -0.02366685, -0.07100553],\n         ...,\n         [ 0.07872646,  0.00419506,  0.03426314, ..., -0.08489309,\n          -0.04017992,  0.0593922 ],\n         [ 0.00327188, -0.00678592, -0.04918166, ..., -0.01181698,\n           0.00403947,  0.03008547],\n         [ 0.0136309 , -0.04501588, -0.01774996, ..., -0.03336721,\n          -0.02977681,  0.0736668 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 8, 240) dtype=float32, numpy=\narray([[[[ 0.19422825, -0.05745029, -0.01499916, ...,  0.517576  ,\n           0.10424303, -0.01301186],\n         [-0.11046448, -0.29540455,  0.1400048 , ..., -0.40834996,\n           0.27793723, -0.06076267],\n         [-0.37831515, -0.1006196 ,  0.5182175 , ..., -0.49494174,\n           0.04465031,  0.27039543],\n         ...,\n         [ 0.15394491,  0.01537794, -0.37696788, ...,  0.04789364,\n           0.47758695,  0.07914821],\n         [-0.22362801, -0.24872197,  0.42814654, ..., -0.18299043,\n           0.16262025,  0.12342016],\n         [-0.77522725,  0.18929759,  0.07792163, ..., -0.52205354,\n          -0.4897011 , -0.04682273]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_376/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-7.54119456e-02],\n         [ 4.35901135e-02],\n         [-1.56401843e-02],\n         [-6.54867589e-02],\n         [ 7.67492950e-02],\n         [ 4.23647016e-02],\n         [-8.69500265e-02],\n         [-1.82650238e-02],\n         [ 5.17879277e-02],\n         [-1.35912597e-02],\n         [-2.25840509e-03],\n         [-3.96893136e-02],\n         [ 3.28698754e-03],\n         [-5.64172417e-02],\n         [ 3.91502827e-02],\n         [ 3.59694660e-03],\n         [ 8.13923776e-02],\n         [-3.53698283e-02],\n         [-6.39253110e-03],\n         [ 6.44260347e-02],\n         [-5.92353195e-02],\n         [ 4.34220880e-02],\n         [-3.61393504e-02],\n         [-2.70348340e-02],\n         [ 5.60555905e-02],\n         [ 8.85745883e-03],\n         [-8.93270746e-02],\n         [ 7.36064017e-02],\n         [ 3.74496132e-02],\n         [ 5.99114597e-02],\n         [-5.98261356e-02],\n         [-7.08203167e-02],\n         [-5.12632988e-02],\n         [ 4.85774279e-02],\n         [-4.03982103e-02],\n         [ 9.84951854e-04],\n         [-4.07257266e-02],\n         [-4.96313311e-02],\n         [-2.37129554e-02],\n         [ 7.44497031e-02],\n         [ 2.98440233e-02],\n         [-5.14727198e-02],\n         [-7.16835558e-02],\n         [ 7.04396516e-02],\n         [-7.32333958e-02],\n         [-4.76629809e-02],\n         [-6.45708218e-02],\n         [-7.50364736e-02],\n         [-8.82310271e-02],\n         [ 8.57872516e-02],\n         [ 4.08156812e-02],\n         [-7.69297779e-03],\n         [-3.03034000e-02],\n         [ 5.38863689e-02],\n         [ 7.10701793e-02],\n         [-8.30060318e-02],\n         [ 5.83906919e-02],\n         [ 5.42241335e-03],\n         [ 8.59430730e-02],\n         [-6.49167448e-02],\n         [ 7.64623284e-03],\n         [ 3.19572985e-02],\n         [ 2.73965299e-02],\n         [ 5.62180281e-02],\n         [ 6.87173158e-02],\n         [-2.93542407e-02],\n         [ 6.68308288e-02],\n         [ 4.19791788e-02],\n         [ 3.95928174e-02],\n         [-4.38746326e-02],\n         [ 6.07686043e-02],\n         [-6.77663609e-02],\n         [-1.86048523e-02],\n         [-5.30321151e-03],\n         [ 5.28227240e-02],\n         [-4.06262726e-02],\n         [-5.43178990e-02],\n         [ 6.49656504e-02],\n         [-4.05533612e-02],\n         [ 6.90804571e-02]],\n\n        [[ 5.72535843e-02],\n         [-5.54751568e-02],\n         [ 4.13765311e-02],\n         [-7.56911188e-02],\n         [ 2.15933919e-02],\n         [ 5.49217165e-02],\n         [-8.08221176e-02],\n         [ 7.95510858e-02],\n         [ 7.74058402e-02],\n         [-7.44868219e-02],\n         [ 5.91836721e-02],\n         [ 6.47287220e-02],\n         [ 8.20962340e-02],\n         [-8.57135355e-02],\n         [ 1.17464140e-02],\n         [ 5.54461926e-02],\n         [-3.93197276e-02],\n         [-2.38975883e-02],\n         [ 3.91321927e-02],\n         [-1.58593580e-02],\n         [-4.27885577e-02],\n         [ 7.74641931e-02],\n         [ 8.28367770e-02],\n         [ 8.44681859e-02],\n         [ 7.99739957e-02],\n         [ 7.27482140e-02],\n         [-6.67780787e-02],\n         [-6.94502369e-02],\n         [ 3.25453654e-02],\n         [ 6.40894324e-02],\n         [ 3.41777205e-02],\n         [-7.27396533e-02],\n         [-5.77187054e-02],\n         [ 7.22127408e-03],\n         [ 2.84705982e-02],\n         [-2.93121934e-02],\n         [ 1.44367889e-02],\n         [-7.52701387e-02],\n         [-2.44244933e-04],\n         [ 4.01310325e-02],\n         [ 3.17976028e-02],\n         [ 1.95085406e-02],\n         [-6.42912835e-03],\n         [ 3.41976881e-02],\n         [ 8.25452656e-02],\n         [ 8.32222551e-02],\n         [ 1.14671141e-02],\n         [-3.17213833e-02],\n         [-2.28364766e-02],\n         [ 8.07520747e-02],\n         [ 2.58139670e-02],\n         [-3.49797569e-02],\n         [ 2.95975730e-02],\n         [ 5.67703545e-02],\n         [ 3.17150205e-02],\n         [-3.10653932e-02],\n         [ 6.08955920e-02],\n         [ 4.40307558e-02],\n         [ 6.77395910e-02],\n         [-2.28326023e-03],\n         [ 6.36583418e-02],\n         [ 3.98417413e-02],\n         [ 5.18492311e-02],\n         [-3.65202054e-02],\n         [ 7.15821981e-03],\n         [ 3.04634571e-02],\n         [ 1.22026131e-02],\n         [-2.46368945e-02],\n         [-5.31151108e-02],\n         [-8.70133117e-02],\n         [-1.54497549e-02],\n         [-5.12846038e-02],\n         [ 4.39778715e-03],\n         [-6.43447042e-03],\n         [-4.65566590e-02],\n         [ 5.70022464e-02],\n         [ 7.15953857e-03],\n         [-7.95828179e-02],\n         [ 1.54453665e-02],\n         [-3.50460745e-02]],\n\n        [[ 2.77394727e-02],\n         [-2.58966163e-02],\n         [-1.66886449e-02],\n         [ 4.86398190e-02],\n         [ 7.33190328e-02],\n         [ 1.42366514e-02],\n         [ 4.08184826e-02],\n         [ 4.73294407e-03],\n         [-1.73185468e-02],\n         [ 5.09149581e-03],\n         [ 8.98689628e-02],\n         [ 3.43587697e-02],\n         [ 2.32455358e-02],\n         [-1.31728128e-02],\n         [-4.32538167e-02],\n         [ 3.86973321e-02],\n         [ 7.14071989e-02],\n         [ 6.28632307e-02],\n         [-6.61212876e-02],\n         [-7.52777085e-02],\n         [-1.90151259e-02],\n         [-8.97690728e-02],\n         [ 5.31234741e-02],\n         [ 5.40803969e-02],\n         [-8.41703564e-02],\n         [ 7.28517771e-05],\n         [ 3.60610932e-02],\n         [ 3.57715338e-02],\n         [ 4.11098748e-02],\n         [-4.83782589e-03],\n         [ 3.55465710e-03],\n         [-7.91186839e-03],\n         [-1.03218332e-02],\n         [ 5.51280826e-02],\n         [ 2.87270248e-02],\n         [ 4.55874950e-02],\n         [ 6.97382838e-02],\n         [-2.90578045e-02],\n         [-4.26749587e-02],\n         [-3.41850780e-02],\n         [ 7.10358322e-02],\n         [ 3.52026224e-02],\n         [-4.95918803e-02],\n         [ 8.34358186e-02],\n         [ 4.77175564e-02],\n         [ 7.21576065e-03],\n         [ 6.23911023e-02],\n         [ 8.79271477e-02],\n         [ 7.99205005e-02],\n         [ 8.46968740e-02],\n         [-2.15377584e-02],\n         [ 3.15198153e-02],\n         [ 8.96793604e-02],\n         [ 5.97443581e-02],\n         [ 7.38078356e-02],\n         [-5.77374361e-02],\n         [ 4.46983427e-03],\n         [ 2.87043303e-02],\n         [ 5.88855296e-02],\n         [-8.09071660e-02],\n         [-8.23021084e-02],\n         [-5.89700751e-02],\n         [-6.90551847e-03],\n         [ 3.82395089e-03],\n         [-7.72838295e-03],\n         [ 1.76490098e-03],\n         [-2.36759931e-02],\n         [-5.43821827e-02],\n         [ 2.58054212e-02],\n         [ 1.64693445e-02],\n         [-3.86437736e-02],\n         [ 3.78810018e-02],\n         [ 4.91713136e-02],\n         [-4.72817123e-02],\n         [-9.72598046e-03],\n         [ 8.03824067e-02],\n         [-7.08978102e-02],\n         [-5.27104400e-02],\n         [-4.05620113e-02],\n         [ 2.76838392e-02]]],\n\n\n       [[[-4.85326461e-02],\n         [ 4.39600050e-02],\n         [-5.95268235e-02],\n         [ 3.71420234e-02],\n         [-6.09204546e-02],\n         [ 2.76806951e-03],\n         [-4.10207808e-02],\n         [ 2.48205960e-02],\n         [-1.76252797e-02],\n         [-5.30926138e-02],\n         [-8.63287076e-02],\n         [ 8.56080502e-02],\n         [-6.08716533e-02],\n         [-5.60354739e-02],\n         [ 1.54790208e-02],\n         [ 6.68514073e-02],\n         [ 3.98461521e-03],\n         [ 4.14566249e-02],\n         [ 7.88684040e-02],\n         [-4.81401980e-02],\n         [-8.16377923e-02],\n         [-6.90909252e-02],\n         [ 3.32543924e-02],\n         [ 1.72690377e-02],\n         [ 7.26426840e-02],\n         [ 3.09421942e-02],\n         [-4.61755209e-02],\n         [ 2.53612101e-02],\n         [ 2.51372978e-02],\n         [-1.04279742e-02],\n         [ 8.02167356e-02],\n         [ 8.52757245e-02],\n         [-2.88596340e-02],\n         [-5.40694594e-03],\n         [ 8.91544819e-02],\n         [-6.70565367e-02],\n         [ 6.17378205e-02],\n         [-6.25343323e-02],\n         [ 1.67820677e-02],\n         [ 4.90984023e-02],\n         [ 6.57731742e-02],\n         [-7.30120167e-02],\n         [-6.64066970e-02],\n         [-4.40580547e-02],\n         [-2.23393142e-02],\n         [-6.70069158e-02],\n         [ 8.76470655e-02],\n         [-8.35113898e-02],\n         [-6.83190003e-02],\n         [ 4.06610519e-02],\n         [-5.38447239e-02],\n         [ 9.35472548e-03],\n         [ 7.03892708e-02],\n         [ 3.75416577e-02],\n         [-8.53907317e-02],\n         [-9.01272893e-02],\n         [-1.94965154e-02],\n         [-1.20610446e-02],\n         [ 3.00763920e-02],\n         [ 2.98872218e-02],\n         [-8.15392509e-02],\n         [-8.28994587e-02],\n         [ 1.31528303e-02],\n         [ 7.25422949e-02],\n         [-3.66053730e-03],\n         [-6.93501160e-02],\n         [ 2.78297737e-02],\n         [-2.78673470e-02],\n         [-5.69179058e-02],\n         [-8.00205767e-02],\n         [ 1.46418884e-02],\n         [-2.18716189e-02],\n         [ 4.04654145e-02],\n         [ 2.49038935e-02],\n         [-4.65729907e-02],\n         [-3.62633094e-02],\n         [-4.67263684e-02],\n         [ 7.71150291e-02],\n         [ 9.03513134e-02],\n         [-6.82108775e-02]],\n\n        [[-6.86773658e-03],\n         [ 2.84425169e-03],\n         [ 1.60290897e-02],\n         [-5.76147959e-02],\n         [ 5.59065789e-02],\n         [ 8.72246921e-03],\n         [-3.86033207e-03],\n         [ 5.89344501e-02],\n         [ 6.35267794e-02],\n         [ 6.69771284e-02],\n         [-2.06507668e-02],\n         [ 8.59850645e-03],\n         [-3.59203257e-02],\n         [-6.88398033e-02],\n         [ 4.79807258e-02],\n         [ 2.70279348e-02],\n         [ 2.09501684e-02],\n         [-6.67875037e-02],\n         [-2.23895907e-03],\n         [-6.07346743e-03],\n         [-8.38409811e-02],\n         [-1.76290423e-02],\n         [ 8.59877765e-02],\n         [-1.54868290e-02],\n         [ 2.40212902e-02],\n         [-3.28111127e-02],\n         [-1.77472532e-02],\n         [ 3.92719060e-02],\n         [-4.82305139e-03],\n         [ 4.73845452e-02],\n         [-6.26439601e-03],\n         [ 8.44971836e-02],\n         [ 8.92895907e-02],\n         [-6.10536039e-02],\n         [-5.08295000e-03],\n         [ 6.68126643e-02],\n         [ 5.00462800e-02],\n         [ 8.63014907e-03],\n         [-9.65531170e-03],\n         [ 4.73418236e-02],\n         [-7.01506957e-02],\n         [ 3.93184572e-02],\n         [-5.71880601e-02],\n         [ 6.40861690e-02],\n         [-6.55363798e-02],\n         [ 1.01189464e-02],\n         [-9.00772139e-02],\n         [-6.91317767e-03],\n         [ 4.52731550e-02],\n         [-8.97936448e-02],\n         [-7.39973560e-02],\n         [-1.29010528e-03],\n         [-3.18109095e-02],\n         [ 2.75859013e-02],\n         [ 2.88908258e-02],\n         [-7.13028312e-02],\n         [ 4.53336835e-02],\n         [ 2.08915696e-02],\n         [-6.74519092e-02],\n         [-5.10602593e-02],\n         [-1.28109008e-02],\n         [-3.69329900e-02],\n         [-2.38917693e-02],\n         [-5.60949147e-02],\n         [-8.21346343e-02],\n         [ 1.28431767e-02],\n         [-1.23234093e-02],\n         [ 5.99144995e-02],\n         [ 3.80396992e-02],\n         [-2.93520093e-03],\n         [-2.87279747e-02],\n         [-3.92357185e-02],\n         [ 4.94959503e-02],\n         [ 6.81902766e-02],\n         [-7.47677237e-02],\n         [-4.52791639e-02],\n         [ 5.59632033e-02],\n         [-7.65921324e-02],\n         [-8.07574838e-02],\n         [-5.48767671e-02]],\n\n        [[-6.12904504e-02],\n         [ 6.41111284e-02],\n         [-1.51006132e-03],\n         [ 7.54247755e-02],\n         [-6.87352717e-02],\n         [-3.54361460e-02],\n         [-3.48017439e-02],\n         [ 1.80127770e-02],\n         [-1.16605461e-02],\n         [-8.91515911e-02],\n         [ 5.24214059e-02],\n         [-3.52071933e-02],\n         [ 8.41010213e-02],\n         [ 2.60445625e-02],\n         [-8.77312571e-03],\n         [-7.71957636e-03],\n         [-9.04813856e-02],\n         [ 5.47045916e-02],\n         [ 2.36725509e-02],\n         [-7.17540458e-02],\n         [ 8.89526606e-02],\n         [-2.98593603e-02],\n         [-5.99487796e-02],\n         [ 4.22368050e-02],\n         [ 8.83581638e-02],\n         [ 3.24770808e-04],\n         [-3.22478525e-02],\n         [ 2.87808552e-02],\n         [ 6.92919493e-02],\n         [ 1.00817233e-02],\n         [ 2.61961669e-02],\n         [ 8.11803192e-02],\n         [ 1.15083605e-02],\n         [ 1.64433569e-03],\n         [ 3.29069570e-02],\n         [ 5.50898463e-02],\n         [ 7.63210654e-03],\n         [-3.37506831e-03],\n         [ 7.86510706e-02],\n         [ 1.18321180e-03],\n         [ 6.92457110e-02],\n         [-8.94948319e-02],\n         [-5.85604496e-02],\n         [ 4.63472456e-02],\n         [-6.96153939e-03],\n         [-8.78670588e-02],\n         [-4.63373959e-04],\n         [ 8.69005322e-02],\n         [ 1.90617591e-02],\n         [-6.78759590e-02],\n         [ 6.38314784e-02],\n         [-5.95875084e-04],\n         [-7.52058327e-02],\n         [ 2.32845172e-02],\n         [ 6.45345896e-02],\n         [-8.37997347e-02],\n         [-3.92290205e-03],\n         [-5.53201139e-03],\n         [-2.36374512e-02],\n         [-6.25461638e-02],\n         [-8.00660029e-02],\n         [ 1.64624304e-03],\n         [-8.52125660e-02],\n         [-6.83658943e-02],\n         [-5.88944331e-02],\n         [-5.19454144e-02],\n         [ 1.98286176e-02],\n         [ 4.45530564e-02],\n         [ 3.18888426e-02],\n         [ 5.38064837e-02],\n         [-8.52606297e-02],\n         [-1.66572854e-02],\n         [-5.55831529e-02],\n         [ 2.91081369e-02],\n         [ 4.71771806e-02],\n         [-3.00210640e-02],\n         [-4.62510735e-02],\n         [ 1.56757683e-02],\n         [ 8.45512599e-02],\n         [-3.24767083e-03]]],\n\n\n       [[[ 7.70245045e-02],\n         [ 5.20891249e-02],\n         [-7.88103715e-02],\n         [-1.50790662e-02],\n         [ 4.06879038e-02],\n         [-8.47895443e-03],\n         [-5.21993637e-03],\n         [-5.86379468e-02],\n         [-7.13074133e-02],\n         [-4.54593152e-02],\n         [ 4.28686738e-02],\n         [-4.68212143e-02],\n         [ 2.88642868e-02],\n         [ 6.15573376e-02],\n         [ 5.01982868e-04],\n         [-2.05515698e-02],\n         [ 2.90653557e-02],\n         [-4.02364172e-02],\n         [ 8.95099044e-02],\n         [-7.75196999e-02],\n         [ 1.93311349e-02],\n         [ 1.86079666e-02],\n         [ 3.49725783e-02],\n         [ 3.07957828e-02],\n         [-3.69704291e-02],\n         [ 6.35100156e-02],\n         [-3.71705070e-02],\n         [-1.53027624e-02],\n         [-7.95486569e-03],\n         [-3.58980037e-02],\n         [ 3.20954919e-02],\n         [ 8.60620588e-02],\n         [-8.27630162e-02],\n         [ 1.72983706e-02],\n         [-5.33646531e-02],\n         [ 6.85070306e-02],\n         [-1.96834430e-02],\n         [ 4.95140702e-02],\n         [-4.83306497e-03],\n         [ 5.60732633e-02],\n         [-9.01016593e-03],\n         [-2.80307606e-02],\n         [ 2.53148377e-03],\n         [-7.50318170e-04],\n         [-3.84659767e-02],\n         [ 2.58073881e-02],\n         [ 1.96034089e-02],\n         [-6.89935684e-02],\n         [-8.82329941e-02],\n         [-2.50657275e-02],\n         [ 8.04955512e-02],\n         [ 7.42507279e-02],\n         [ 2.37861574e-02],\n         [-3.23145352e-02],\n         [-8.71522650e-02],\n         [-5.56358658e-02],\n         [-5.36520891e-02],\n         [ 7.43738413e-02],\n         [ 3.78282070e-02],\n         [-2.05851421e-02],\n         [-3.29628028e-02],\n         [ 8.96409005e-02],\n         [-1.77031904e-02],\n         [-2.29756460e-02],\n         [-7.85612836e-02],\n         [-5.95954135e-02],\n         [-2.77704895e-02],\n         [-8.00159052e-02],\n         [ 7.17392713e-02],\n         [ 4.61034328e-02],\n         [-2.80745625e-02],\n         [-4.22720835e-02],\n         [-1.98911056e-02],\n         [ 1.80563405e-02],\n         [-1.92397907e-02],\n         [-6.23371154e-02],\n         [-1.32834911e-02],\n         [-4.66507263e-02],\n         [-1.36140808e-02],\n         [-8.40737596e-02]],\n\n        [[-3.34782824e-02],\n         [ 4.49158847e-02],\n         [-2.88777053e-03],\n         [ 1.62878036e-02],\n         [ 7.54041970e-03],\n         [ 1.03477687e-02],\n         [ 2.95691341e-02],\n         [-3.32284793e-02],\n         [-4.12497073e-02],\n         [ 8.22490901e-02],\n         [-2.88310163e-02],\n         [ 4.19954211e-02],\n         [ 8.43392015e-02],\n         [-2.58238539e-02],\n         [ 4.67277914e-02],\n         [ 8.06306750e-02],\n         [ 8.16586614e-03],\n         [ 1.16798431e-02],\n         [-3.78326587e-02],\n         [-7.51038045e-02],\n         [ 5.19819707e-02],\n         [ 6.24464154e-02],\n         [ 4.45526987e-02],\n         [-3.11202258e-02],\n         [ 6.23544604e-02],\n         [-1.31400228e-02],\n         [-8.86063874e-02],\n         [-8.37758183e-03],\n         [ 5.87020814e-02],\n         [-5.78902066e-02],\n         [ 5.38229197e-02],\n         [ 1.55037045e-02],\n         [-3.97254378e-02],\n         [ 1.71234459e-02],\n         [ 8.11417401e-02],\n         [ 1.33733228e-02],\n         [-6.39583543e-02],\n         [ 6.36905730e-02],\n         [ 6.31818175e-02],\n         [-3.21312435e-02],\n         [ 3.74408066e-02],\n         [ 3.39820385e-02],\n         [ 1.78786069e-02],\n         [-5.06299771e-02],\n         [ 6.70386702e-02],\n         [ 7.02214241e-02],\n         [-8.21430236e-02],\n         [-2.94084027e-02],\n         [ 2.45264322e-02],\n         [ 8.50942582e-02],\n         [ 2.16991603e-02],\n         [-7.98663571e-02],\n         [ 7.88633078e-02],\n         [-3.40039730e-02],\n         [ 5.61790168e-03],\n         [-3.07871066e-02],\n         [ 8.78598392e-02],\n         [-2.82317214e-02],\n         [ 5.07672876e-02],\n         [ 9.04510170e-02],\n         [ 4.04788852e-02],\n         [ 8.09549689e-02],\n         [-2.39593834e-02],\n         [ 5.43897599e-03],\n         [-2.92186663e-02],\n         [ 8.75832289e-02],\n         [-4.19654809e-02],\n         [ 8.89285058e-02],\n         [-5.54370433e-02],\n         [ 7.34764636e-02],\n         [ 1.68509781e-02],\n         [ 1.29503980e-02],\n         [ 1.90058649e-02],\n         [-1.01192519e-02],\n         [ 2.62008607e-02],\n         [ 2.77597606e-02],\n         [ 1.82159916e-02],\n         [-2.32556388e-02],\n         [-4.07052226e-02],\n         [-8.07569623e-02]],\n\n        [[ 5.06176651e-02],\n         [-7.73551241e-02],\n         [ 3.62409055e-02],\n         [-7.33292550e-02],\n         [-5.08749783e-02],\n         [-9.15957987e-03],\n         [-5.54373115e-03],\n         [-4.67265621e-02],\n         [ 3.08878124e-02],\n         [ 7.41918683e-02],\n         [-5.31534366e-02],\n         [-7.18746334e-03],\n         [ 4.92269844e-02],\n         [-4.77470756e-02],\n         [ 7.89286047e-02],\n         [-7.44131282e-02],\n         [-1.37471259e-02],\n         [-2.53833383e-02],\n         [ 4.78912443e-02],\n         [ 4.55887914e-02],\n         [ 7.25449175e-02],\n         [ 6.84077740e-02],\n         [-4.77341413e-02],\n         [ 3.26667354e-02],\n         [-7.66998902e-02],\n         [ 7.12538511e-03],\n         [ 7.10932612e-02],\n         [-7.98799023e-02],\n         [ 4.36253101e-03],\n         [-5.44134602e-02],\n         [-5.25496639e-02],\n         [ 5.49928099e-02],\n         [ 2.81137228e-03],\n         [-2.02295929e-02],\n         [ 3.06400657e-02],\n         [-2.21785009e-02],\n         [ 4.49724793e-02],\n         [ 4.88250852e-02],\n         [-1.07727051e-02],\n         [ 2.94051394e-02],\n         [ 4.38403785e-02],\n         [-7.84317628e-02],\n         [-8.97113457e-02],\n         [-3.64493914e-02],\n         [-3.17702442e-03],\n         [-7.20982850e-02],\n         [ 2.04602629e-03],\n         [ 5.76119870e-03],\n         [-5.25772572e-03],\n         [-5.53819537e-02],\n         [ 5.52791506e-02],\n         [ 1.23902261e-02],\n         [-3.86110693e-03],\n         [ 6.37449920e-02],\n         [-2.72645801e-03],\n         [-1.47141293e-02],\n         [-3.94627005e-02],\n         [-5.98062798e-02],\n         [ 7.54276067e-02],\n         [ 2.93297321e-02],\n         [-4.38237824e-02],\n         [ 2.28748694e-02],\n         [ 3.14440876e-02],\n         [ 5.97440749e-02],\n         [ 2.86214054e-03],\n         [-8.93861651e-02],\n         [ 7.55555034e-02],\n         [-5.64641356e-02],\n         [-8.82589296e-02],\n         [-1.04819983e-03],\n         [-7.61698931e-02],\n         [-8.76631364e-02],\n         [-3.03780884e-02],\n         [-5.85255399e-02],\n         [-7.01234043e-02],\n         [ 8.02656412e-02],\n         [-3.17775533e-02],\n         [ 6.59556240e-02],\n         [ 2.57648677e-02],\n         [ 2.73409635e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_377/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[ 0.05196753],\n         [-0.04946721],\n         [-0.04075183],\n         ...,\n         [-0.03433312],\n         [-0.02869372],\n         [-0.03257717]],\n\n        [[ 0.02662175],\n         [ 0.0266779 ],\n         [ 0.05813749],\n         ...,\n         [-0.05355116],\n         [ 0.02629628],\n         [ 0.00244688]],\n\n        [[ 0.03518628],\n         [ 0.04306196],\n         [ 0.05291317],\n         ...,\n         [ 0.01209816],\n         [ 0.05349943],\n         [-0.05977012]]],\n\n\n       [[[ 0.04053825],\n         [ 0.00969673],\n         [ 0.02626443],\n         ...,\n         [-0.04226689],\n         [-0.04979882],\n         [-0.01517585]],\n\n        [[-0.01728126],\n         [ 0.002227  ],\n         [-0.01256393],\n         ...,\n         [ 0.04798179],\n         [-0.06487456],\n         [-0.04146526]],\n\n        [[ 0.04391406],\n         [-0.02389202],\n         [ 0.01749081],\n         ...,\n         [-0.01623254],\n         [ 0.00468493],\n         [-0.07047215]]],\n\n\n       [[[-0.02832882],\n         [ 0.07033147],\n         [ 0.04166061],\n         ...,\n         [-0.01961127],\n         [-0.00354851],\n         [ 0.03070489]],\n\n        [[-0.05504709],\n         [ 0.0293152 ],\n         [-0.05304461],\n         ...,\n         [-0.0142126 ],\n         [-0.04848078],\n         [-0.0476849 ]],\n\n        [[ 0.01213649],\n         [ 0.03701131],\n         [ 0.06323072],\n         ...,\n         [ 0.06401858],\n         [-0.04995251],\n         [ 0.00824822]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_368/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-2.18102708e-02],\n         [-6.41603544e-02],\n         [ 7.29615241e-03],\n         [ 8.77435058e-02],\n         [-1.88252330e-02],\n         [ 8.87093097e-02],\n         [-4.50338386e-02],\n         [-2.94286907e-02],\n         [-6.16472960e-02],\n         [-1.92121267e-02],\n         [ 7.55837113e-02],\n         [ 4.05267328e-02],\n         [-6.25152141e-03],\n         [ 8.35019499e-02],\n         [ 6.08466268e-02],\n         [-4.38588448e-02],\n         [-6.76913932e-02],\n         [-5.30068316e-02],\n         [ 8.98498446e-02],\n         [ 2.87644640e-02],\n         [-8.09025764e-02],\n         [-5.06592654e-02],\n         [-2.71893144e-02],\n         [-5.19277155e-03],\n         [ 2.34405100e-02],\n         [-4.80502397e-02],\n         [-3.82184051e-02],\n         [-5.35756722e-02],\n         [ 8.12756270e-03],\n         [-7.93830007e-02],\n         [-8.87104273e-02],\n         [ 3.83218378e-02],\n         [ 3.24957073e-03],\n         [ 1.67576224e-02],\n         [ 1.21007785e-02],\n         [ 7.04792291e-02],\n         [ 7.43386894e-03],\n         [ 2.99349353e-02],\n         [-1.09607577e-02],\n         [-2.74258181e-02],\n         [ 2.22629234e-02],\n         [-6.71797842e-02],\n         [-4.82663624e-02],\n         [ 2.16031447e-02],\n         [ 1.42999813e-02],\n         [-6.81215674e-02],\n         [ 5.76147884e-02],\n         [ 1.61182657e-02],\n         [-7.17826188e-02],\n         [-1.32220015e-02],\n         [-8.94065797e-02],\n         [ 3.13203484e-02],\n         [-6.73711225e-02],\n         [ 7.77266175e-03],\n         [-3.29103321e-03],\n         [ 2.14463100e-02],\n         [-1.87514350e-02],\n         [-3.18834744e-02],\n         [-3.86751369e-02],\n         [ 6.74265772e-02],\n         [ 8.98409486e-02],\n         [-6.22067973e-02],\n         [-5.99242486e-02],\n         [ 7.58714527e-02],\n         [-5.72273396e-02],\n         [ 8.40091705e-03],\n         [-3.85930538e-02],\n         [-8.20485875e-02],\n         [ 2.79474631e-02],\n         [ 2.47621983e-02],\n         [-7.63550699e-02],\n         [-6.39753342e-02],\n         [ 4.93818074e-02],\n         [ 8.35829675e-02],\n         [-5.60280792e-02],\n         [-8.45174119e-02],\n         [ 7.27991164e-02],\n         [ 1.66817233e-02],\n         [ 3.75016183e-02],\n         [ 6.92256093e-02]],\n\n        [[-4.20919806e-03],\n         [ 5.51334023e-02],\n         [ 5.26752621e-02],\n         [ 7.43701011e-02],\n         [ 3.21623906e-02],\n         [-7.19796494e-02],\n         [ 3.77919972e-02],\n         [-1.08985305e-02],\n         [ 6.89286739e-03],\n         [-7.46415406e-02],\n         [-8.72995853e-02],\n         [-1.88707411e-02],\n         [-3.76431830e-02],\n         [-5.40231057e-02],\n         [ 7.78765529e-02],\n         [ 1.17334723e-03],\n         [-3.06395926e-02],\n         [ 7.11224526e-02],\n         [-6.75399154e-02],\n         [-4.01493385e-02],\n         [ 8.46541673e-03],\n         [-6.59588054e-02],\n         [-8.62221420e-03],\n         [ 5.29159606e-03],\n         [ 3.57347429e-02],\n         [-2.94847339e-02],\n         [ 3.47555429e-02],\n         [-5.15429080e-02],\n         [-4.96219657e-02],\n         [-1.22503042e-02],\n         [-1.13357976e-02],\n         [ 3.49531472e-02],\n         [ 7.79607296e-02],\n         [-9.30798054e-03],\n         [ 5.64286560e-02],\n         [-7.95902759e-02],\n         [-9.30220634e-03],\n         [ 6.81759715e-02],\n         [-8.76343921e-02],\n         [ 1.51923224e-02],\n         [-2.37704068e-02],\n         [ 6.02407306e-02],\n         [-8.60547274e-03],\n         [ 6.38726801e-02],\n         [-1.28410533e-02],\n         [ 4.89972979e-02],\n         [-6.42421395e-02],\n         [-1.78357139e-02],\n         [-4.03082520e-02],\n         [ 2.28663906e-02],\n         [ 4.87780124e-02],\n         [ 2.92855874e-02],\n         [-7.24780858e-02],\n         [ 1.35740489e-02],\n         [ 4.69204932e-02],\n         [-2.71589458e-02],\n         [ 7.40651190e-02],\n         [-8.54456425e-03],\n         [-5.82772717e-02],\n         [ 1.73688829e-02],\n         [ 1.21932849e-02],\n         [-3.84873487e-02],\n         [ 7.03026503e-02],\n         [-5.56204431e-02],\n         [-5.25875799e-02],\n         [ 2.24404782e-02],\n         [ 6.17537349e-02],\n         [-6.79277629e-02],\n         [ 5.05482554e-02],\n         [ 3.84213775e-03],\n         [ 4.94484752e-02],\n         [-8.59238654e-02],\n         [-6.93360120e-02],\n         [ 7.47185200e-03],\n         [-1.63550302e-02],\n         [ 7.09845722e-02],\n         [-6.19326159e-02],\n         [-4.03806455e-02],\n         [-2.48318911e-02],\n         [-8.06715265e-02]],\n\n        [[ 5.60779423e-02],\n         [-1.97308064e-02],\n         [ 4.77646440e-02],\n         [-8.65824670e-02],\n         [ 6.51492923e-02],\n         [-7.13063776e-02],\n         [ 6.60654455e-02],\n         [ 5.68741262e-02],\n         [-7.43172839e-02],\n         [ 2.56045908e-02],\n         [-4.82629910e-02],\n         [-6.60116673e-02],\n         [ 1.42986402e-02],\n         [ 8.25365782e-02],\n         [ 1.49335414e-02],\n         [-2.98368894e-02],\n         [-4.39672098e-02],\n         [ 5.66675812e-02],\n         [ 8.67018700e-02],\n         [-1.21704489e-03],\n         [-1.93664432e-03],\n         [ 2.51788944e-02],\n         [ 6.74016178e-02],\n         [-2.88060121e-02],\n         [-2.75055021e-02],\n         [ 6.31175786e-02],\n         [ 4.65025902e-02],\n         [-3.47253680e-02],\n         [ 7.43450820e-02],\n         [-1.36887729e-02],\n         [-1.12130046e-02],\n         [-7.43731782e-02],\n         [-8.86712372e-02],\n         [-4.96190451e-02],\n         [-4.30893190e-02],\n         [ 1.96057484e-02],\n         [ 5.95064759e-02],\n         [ 6.17258400e-02],\n         [ 8.92618150e-02],\n         [-5.82217500e-02],\n         [-6.18983805e-03],\n         [-4.56119366e-02],\n         [ 5.66044450e-03],\n         [ 6.59593940e-02],\n         [ 2.04445496e-02],\n         [-3.42872590e-02],\n         [-5.89643866e-02],\n         [ 7.95955807e-02],\n         [-1.84371099e-02],\n         [ 3.64708900e-02],\n         [-6.56759515e-02],\n         [-6.65107965e-02],\n         [ 5.21381199e-02],\n         [ 2.39790455e-02],\n         [-6.42899126e-02],\n         [-2.95672528e-02],\n         [ 1.35737658e-02],\n         [ 2.03157961e-03],\n         [-3.02016325e-02],\n         [-3.15735415e-02],\n         [-6.42105788e-02],\n         [-1.44505948e-02],\n         [-7.68862963e-02],\n         [ 2.87680551e-02],\n         [ 3.69787365e-02],\n         [ 7.01536238e-02],\n         [-2.44697407e-02],\n         [ 4.07574177e-02],\n         [-5.09107560e-02],\n         [-1.91402510e-02],\n         [-4.90480214e-02],\n         [-4.05987166e-02],\n         [ 8.92209709e-02],\n         [-8.06793794e-02],\n         [ 3.07240114e-02],\n         [-7.24650845e-02],\n         [ 2.26465017e-02],\n         [-8.48072767e-03],\n         [ 6.94514960e-02],\n         [-2.21898556e-02]]],\n\n\n       [[[-5.84914535e-03],\n         [ 4.02110070e-02],\n         [ 1.63446665e-02],\n         [-5.69291115e-02],\n         [ 8.27340633e-02],\n         [-8.82607028e-02],\n         [ 1.71127170e-02],\n         [ 1.14939958e-02],\n         [ 7.85786957e-02],\n         [-6.22779131e-02],\n         [-7.60759786e-02],\n         [ 1.27326921e-02],\n         [-8.40346739e-02],\n         [-7.88068026e-02],\n         [-2.74899676e-02],\n         [-4.09957319e-02],\n         [ 6.94286376e-02],\n         [ 3.41528282e-02],\n         [ 9.96386260e-03],\n         [ 3.46415788e-02],\n         [-1.69359371e-02],\n         [-8.93547609e-02],\n         [ 2.61240527e-02],\n         [ 5.07808924e-02],\n         [ 4.04805541e-02],\n         [ 8.52264762e-02],\n         [ 7.47723132e-02],\n         [ 7.85450637e-02],\n         [-8.82485434e-02],\n         [ 5.67145646e-02],\n         [ 3.31989527e-02],\n         [ 4.20712978e-02],\n         [ 2.01429427e-03],\n         [-4.00751829e-03],\n         [ 2.11855024e-03],\n         [ 7.74366707e-02],\n         [-6.47244155e-02],\n         [ 3.29666287e-02],\n         [-7.52783418e-02],\n         [-1.64425671e-02],\n         [-1.19299442e-02],\n         [ 3.98874432e-02],\n         [ 2.90291682e-02],\n         [ 5.29039353e-02],\n         [-7.88714141e-02],\n         [ 5.08626550e-03],\n         [-2.57832706e-02],\n         [ 8.58855397e-02],\n         [-1.99269727e-02],\n         [ 2.48298794e-02],\n         [-1.91675499e-02],\n         [ 2.29682699e-02],\n         [-2.73090824e-02],\n         [-2.05718800e-02],\n         [ 2.45416388e-02],\n         [ 2.54698172e-02],\n         [-6.37732446e-04],\n         [ 7.00749308e-02],\n         [-4.74069901e-02],\n         [ 2.62927264e-03],\n         [-7.59925321e-02],\n         [-2.80511528e-02],\n         [ 8.50294530e-02],\n         [ 2.07103342e-02],\n         [ 6.65345639e-02],\n         [-1.54794157e-02],\n         [-7.36126304e-03],\n         [ 6.21038824e-02],\n         [-6.11460954e-03],\n         [ 8.59016031e-02],\n         [-4.34976816e-03],\n         [ 3.99707258e-03],\n         [-1.58403665e-02],\n         [-1.36785209e-02],\n         [ 1.79912969e-02],\n         [ 6.76628053e-02],\n         [-1.84908360e-02],\n         [ 7.83569217e-02],\n         [ 1.96401402e-02],\n         [ 6.95898235e-02]],\n\n        [[-7.32464567e-02],\n         [ 4.11924720e-02],\n         [-2.21378803e-02],\n         [-7.67942369e-02],\n         [-8.40384215e-02],\n         [-3.03809419e-02],\n         [-6.10423163e-02],\n         [-5.22996262e-02],\n         [-1.07485726e-02],\n         [-1.27563104e-02],\n         [-7.67806321e-02],\n         [-8.71716216e-02],\n         [-1.03444159e-02],\n         [-1.09770447e-02],\n         [-2.44840235e-03],\n         [-3.32902968e-02],\n         [ 1.61893442e-02],\n         [-7.84727335e-02],\n         [ 2.97270492e-02],\n         [-7.01100752e-02],\n         [-8.05274323e-02],\n         [ 3.36493552e-02],\n         [-7.69060254e-02],\n         [-6.39460236e-02],\n         [ 8.28910470e-02],\n         [-6.14771396e-02],\n         [-7.23859817e-02],\n         [ 3.08289379e-03],\n         [ 7.46534914e-02],\n         [-4.45334539e-02],\n         [-5.57460710e-02],\n         [ 2.15701386e-02],\n         [ 2.14174390e-04],\n         [-2.08491087e-02],\n         [ 2.44848803e-02],\n         [-5.14538772e-02],\n         [ 8.64233971e-02],\n         [-2.06746235e-02],\n         [-1.97097659e-02],\n         [-3.36059183e-02],\n         [ 5.72589785e-02],\n         [-5.62186800e-02],\n         [-4.16086540e-02],\n         [-6.96336403e-02],\n         [-1.97108090e-03],\n         [-4.03421894e-02],\n         [ 1.06892362e-02],\n         [-1.12686381e-02],\n         [-5.44629917e-02],\n         [-7.57636875e-03],\n         [ 3.31712067e-02],\n         [ 1.79309547e-02],\n         [ 6.37766868e-02],\n         [ 4.84747291e-02],\n         [ 6.75583333e-02],\n         [ 7.44717866e-02],\n         [ 6.87533468e-02],\n         [-3.58613208e-02],\n         [ 1.71726346e-02],\n         [-6.83299229e-02],\n         [ 2.25956962e-02],\n         [-7.86925331e-02],\n         [-6.34106994e-03],\n         [-1.25122815e-02],\n         [ 6.78445995e-02],\n         [ 9.02007669e-02],\n         [ 8.51386786e-03],\n         [ 3.54807228e-02],\n         [ 1.86202526e-02],\n         [-7.24346712e-02],\n         [-7.15015009e-02],\n         [-7.17307553e-02],\n         [ 5.47309667e-02],\n         [-5.06162643e-03],\n         [ 8.51254910e-02],\n         [-3.17127965e-02],\n         [-5.51393107e-02],\n         [-1.59985721e-02],\n         [ 4.54620421e-02],\n         [ 1.11843050e-02]],\n\n        [[-8.53091478e-05],\n         [ 6.91594929e-03],\n         [ 5.94755560e-02],\n         [-1.45619884e-02],\n         [-7.31065348e-02],\n         [ 7.19336122e-02],\n         [ 4.70753610e-02],\n         [-4.24152501e-02],\n         [-5.71407564e-02],\n         [-4.50520478e-02],\n         [ 1.72860622e-02],\n         [ 6.01129979e-03],\n         [ 2.33177170e-02],\n         [-5.82444817e-02],\n         [ 3.17270681e-02],\n         [-2.97086015e-02],\n         [-4.57729474e-02],\n         [ 8.96536857e-02],\n         [ 5.97913116e-02],\n         [-7.84944892e-02],\n         [ 7.69010186e-02],\n         [ 2.36018226e-02],\n         [-6.05088808e-02],\n         [ 7.93994218e-02],\n         [-6.73169643e-02],\n         [-4.34751324e-02],\n         [-2.55097225e-02],\n         [-1.69676691e-02],\n         [ 3.28890905e-02],\n         [ 3.55202556e-02],\n         [ 3.97144556e-02],\n         [-4.41646241e-02],\n         [-6.66345209e-02],\n         [-5.47794364e-02],\n         [-2.81448811e-02],\n         [-1.54666528e-02],\n         [ 7.88435787e-02],\n         [ 1.85766667e-02],\n         [ 8.98566544e-02],\n         [ 6.88901842e-02],\n         [ 7.38283396e-02],\n         [ 8.72630477e-02],\n         [-8.98000300e-02],\n         [ 2.05239505e-02],\n         [ 1.64571181e-02],\n         [-7.38870278e-02],\n         [-7.20257163e-02],\n         [ 6.71169013e-02],\n         [ 5.51901907e-02],\n         [ 2.06734985e-02],\n         [ 5.24660051e-02],\n         [-4.01865393e-02],\n         [-5.46478480e-03],\n         [-2.46686265e-02],\n         [-8.21819603e-02],\n         [-8.88603181e-03],\n         [ 4.98017818e-02],\n         [ 5.62631935e-02],\n         [-3.75733599e-02],\n         [ 4.18387502e-02],\n         [ 5.23654670e-02],\n         [-6.31816536e-02],\n         [ 3.09696198e-02],\n         [-3.27555090e-03],\n         [ 3.91517431e-02],\n         [-6.41032532e-02],\n         [ 1.56040192e-02],\n         [ 6.25575185e-02],\n         [-8.04004669e-02],\n         [ 9.05000120e-02],\n         [ 2.06054077e-02],\n         [ 7.87998587e-02],\n         [-6.71841726e-02],\n         [ 8.60875547e-02],\n         [-8.06511194e-03],\n         [-2.68246159e-02],\n         [ 2.42396221e-02],\n         [ 7.70409405e-03],\n         [-4.87914905e-02],\n         [-5.84577024e-03]]],\n\n\n       [[[-5.18979169e-02],\n         [-1.29781663e-02],\n         [-4.42067347e-02],\n         [ 2.07927004e-02],\n         [ 9.03669596e-02],\n         [ 7.68898875e-02],\n         [ 1.74083784e-02],\n         [-8.67637694e-02],\n         [-1.80084705e-02],\n         [ 6.28810972e-02],\n         [-6.71272650e-02],\n         [-7.43137822e-02],\n         [-6.01076260e-02],\n         [ 6.83317631e-02],\n         [ 5.94337583e-02],\n         [ 6.11006916e-02],\n         [ 4.50369120e-02],\n         [ 1.58677772e-02],\n         [-2.91393287e-02],\n         [ 8.43183547e-02],\n         [-2.33400390e-02],\n         [-6.56155199e-02],\n         [ 4.50850278e-02],\n         [-4.66600917e-02],\n         [ 3.47312242e-02],\n         [ 5.65498322e-02],\n         [ 5.23720831e-02],\n         [ 8.81164372e-02],\n         [ 3.87121290e-02],\n         [ 8.00198466e-02],\n         [ 2.30577588e-03],\n         [-8.37183446e-02],\n         [-8.58316571e-02],\n         [ 2.71602049e-02],\n         [ 1.54801682e-02],\n         [-8.77510160e-02],\n         [ 3.49156708e-02],\n         [-5.48282079e-02],\n         [-7.40876868e-02],\n         [ 1.91271678e-02],\n         [-8.34271610e-02],\n         [ 7.08111674e-02],\n         [-3.13480757e-02],\n         [-6.76752627e-03],\n         [-2.61476710e-02],\n         [-6.52745888e-02],\n         [ 9.19596106e-03],\n         [ 3.94702852e-02],\n         [-2.73025036e-02],\n         [ 1.18244588e-02],\n         [ 1.00233704e-02],\n         [ 9.75269079e-03],\n         [ 1.50873736e-02],\n         [ 1.12585127e-02],\n         [-1.16562843e-02],\n         [-6.76131994e-02],\n         [-3.73151861e-02],\n         [ 2.79009789e-02],\n         [ 5.94480485e-02],\n         [ 1.13650635e-02],\n         [-8.67695659e-02],\n         [ 6.93037361e-03],\n         [ 1.24204829e-02],\n         [ 7.09071159e-02],\n         [ 2.00572014e-02],\n         [ 3.69146466e-02],\n         [-4.51577976e-02],\n         [ 7.35674053e-03],\n         [ 7.86654800e-02],\n         [-7.00597465e-02],\n         [-3.24099883e-02],\n         [-4.23965417e-02],\n         [ 1.70223266e-02],\n         [ 5.45520782e-02],\n         [-4.19597477e-02],\n         [ 5.09645045e-03],\n         [ 8.47926736e-02],\n         [-6.14454299e-02],\n         [ 1.21515989e-03],\n         [-4.99765649e-02]],\n\n        [[ 6.57738447e-02],\n         [ 6.24109805e-02],\n         [ 8.74182433e-02],\n         [ 8.73289257e-03],\n         [ 4.61881608e-02],\n         [-3.81395966e-03],\n         [-8.02959278e-02],\n         [-6.69443011e-02],\n         [-6.45301789e-02],\n         [ 4.92454618e-02],\n         [-8.16550553e-02],\n         [-6.38800114e-02],\n         [ 1.29331574e-02],\n         [-3.11547033e-02],\n         [ 7.88394213e-02],\n         [-5.89481406e-02],\n         [ 1.72838569e-02],\n         [ 6.49392605e-02],\n         [ 8.28227997e-02],\n         [-4.48755063e-02],\n         [ 9.84593481e-03],\n         [ 8.48104656e-02],\n         [-7.23440871e-02],\n         [-4.25726920e-02],\n         [ 3.58900279e-02],\n         [-4.16989587e-02],\n         [ 2.90746316e-02],\n         [ 8.41400027e-03],\n         [-1.88604072e-02],\n         [ 2.15766951e-02],\n         [ 6.29189312e-02],\n         [-4.38243225e-02],\n         [-6.85873851e-02],\n         [-2.70587578e-02],\n         [ 8.75262469e-02],\n         [ 7.11815804e-02],\n         [-1.08493194e-02],\n         [ 6.76216781e-02],\n         [ 1.60098597e-02],\n         [-1.17600188e-02],\n         [ 8.35716277e-02],\n         [ 4.97377217e-02],\n         [-6.35839403e-02],\n         [-8.62665474e-02],\n         [-8.69972855e-02],\n         [ 7.41271228e-02],\n         [ 8.38458538e-03],\n         [-4.91441786e-03],\n         [ 3.59526873e-02],\n         [-5.11599518e-02],\n         [-1.94199681e-02],\n         [-6.80598542e-02],\n         [ 8.40997845e-02],\n         [ 3.43301892e-02],\n         [ 8.91987383e-02],\n         [-4.12658863e-02],\n         [ 3.19558457e-02],\n         [-6.04224280e-02],\n         [ 8.80318433e-02],\n         [-6.38480484e-03],\n         [-5.49390204e-02],\n         [ 5.01138717e-02],\n         [ 2.56813318e-02],\n         [-4.02124524e-02],\n         [ 3.97543162e-02],\n         [-4.54578027e-02],\n         [-5.25314957e-02],\n         [ 7.22054988e-02],\n         [-2.86726654e-02],\n         [ 2.26465687e-02],\n         [ 4.84447032e-02],\n         [ 6.62037581e-02],\n         [-2.12631524e-02],\n         [-4.19703275e-02],\n         [ 4.47040200e-02],\n         [ 9.03887749e-02],\n         [-3.35769579e-02],\n         [-3.92476581e-02],\n         [ 3.06936651e-02],\n         [-3.01413275e-02]],\n\n        [[-6.86226860e-02],\n         [ 2.56546438e-02],\n         [ 9.05700028e-04],\n         [-7.46324956e-02],\n         [ 4.18021530e-03],\n         [-4.43961695e-02],\n         [ 3.14273238e-02],\n         [ 6.53959811e-02],\n         [ 6.25206679e-02],\n         [-3.89690697e-03],\n         [-8.27523321e-02],\n         [ 6.36325181e-02],\n         [ 1.25399679e-02],\n         [-3.25430743e-02],\n         [-5.08897975e-02],\n         [-6.98667467e-02],\n         [ 5.19038886e-02],\n         [-8.96776691e-02],\n         [ 4.90792394e-02],\n         [-2.71956995e-02],\n         [ 2.63153687e-02],\n         [-7.94061273e-03],\n         [-4.44498993e-02],\n         [ 3.11568901e-02],\n         [-8.91817808e-02],\n         [ 1.04742795e-02],\n         [ 3.27769592e-02],\n         [ 2.36314163e-02],\n         [-8.32556784e-02],\n         [ 6.31143749e-02],\n         [-3.06018889e-02],\n         [-7.65512139e-03],\n         [ 7.88181424e-02],\n         [-4.68332618e-02],\n         [ 5.35438210e-03],\n         [ 4.00155634e-02],\n         [ 3.35958824e-02],\n         [-4.07227650e-02],\n         [-4.90287468e-02],\n         [ 3.24261039e-02],\n         [ 3.56603563e-02],\n         [ 4.64657247e-02],\n         [ 3.60893607e-02],\n         [-1.73000321e-02],\n         [ 2.16753706e-02],\n         [-7.57938400e-02],\n         [ 5.20444810e-02],\n         [-7.80439675e-02],\n         [-4.99321148e-02],\n         [-3.92834321e-02],\n         [ 1.15781128e-02],\n         [ 2.30405107e-02],\n         [-1.62133351e-02],\n         [-4.15987037e-02],\n         [ 1.24722868e-02],\n         [ 1.60832703e-03],\n         [ 2.77733058e-03],\n         [-5.77132553e-02],\n         [-1.00504905e-02],\n         [-2.95329243e-02],\n         [ 8.14649761e-02],\n         [-6.08291961e-02],\n         [ 4.59731072e-02],\n         [ 2.64740214e-02],\n         [-4.40926626e-02],\n         [-1.39200389e-02],\n         [-6.26430213e-02],\n         [-4.96255122e-02],\n         [ 6.73583150e-02],\n         [ 1.95362493e-02],\n         [-5.08857518e-03],\n         [ 4.05250192e-02],\n         [-2.81211957e-02],\n         [-7.79925734e-02],\n         [-7.48280957e-02],\n         [ 2.66898870e-02],\n         [-3.24114785e-02],\n         [ 5.29607385e-02],\n         [-8.56849402e-02],\n         [-9.46895033e-03]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_369/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-0.01600621],\n         [-0.0206226 ],\n         [-0.05870853],\n         [ 0.07041705],\n         [-0.08658364],\n         [-0.0837106 ],\n         [-0.09041726],\n         [-0.06074735],\n         [-0.04771982],\n         [ 0.07986329],\n         [ 0.04748525],\n         [ 0.06918384],\n         [-0.03831931],\n         [-0.04343462],\n         [ 0.05270354],\n         [ 0.08669657],\n         [-0.02835546],\n         [ 0.06845921],\n         [-0.01128858],\n         [ 0.08573388],\n         [ 0.04985376],\n         [ 0.0107471 ],\n         [-0.05223337],\n         [-0.03628594],\n         [ 0.07356998],\n         [-0.06135752],\n         [-0.03760758],\n         [-0.0186867 ],\n         [-0.04661478],\n         [-0.0695835 ],\n         [-0.08027875],\n         [ 0.08215152],\n         [-0.06020347],\n         [-0.0775924 ],\n         [-0.02817166],\n         [-0.00459857],\n         [ 0.02732104],\n         [ 0.05444027],\n         [ 0.07827002],\n         [ 0.04020494],\n         [ 0.00154802],\n         [ 0.03795271],\n         [-0.03571411],\n         [ 0.02884784],\n         [-0.05169555],\n         [-0.04088529],\n         [ 0.0391954 ],\n         [ 0.05324049],\n         [ 0.04587327],\n         [-0.08285181],\n         [-0.00216667],\n         [-0.07414357],\n         [-0.0495032 ],\n         [-0.0634231 ],\n         [-0.03617192],\n         [-0.00133503],\n         [-0.07008895],\n         [-0.05924229],\n         [-0.00211243],\n         [ 0.06468417],\n         [ 0.08749191],\n         [ 0.03379022],\n         [ 0.02569479],\n         [ 0.02337521],\n         [ 0.06108853],\n         [-0.08352179],\n         [ 0.08037116],\n         [ 0.05618405],\n         [ 0.08567195],\n         [ 0.04495244],\n         [ 0.08281152],\n         [ 0.07639305],\n         [ 0.06881417],\n         [-0.03728664],\n         [-0.080458  ],\n         [ 0.07462579],\n         [ 0.0338658 ],\n         [-0.02745286],\n         [ 0.02065434],\n         [-0.06552455]],\n\n        [[ 0.06454384],\n         [ 0.02544671],\n         [-0.08284193],\n         [-0.07031135],\n         [ 0.07840705],\n         [ 0.00757066],\n         [-0.03221459],\n         [-0.04674406],\n         [-0.06118564],\n         [ 0.03810154],\n         [-0.00148616],\n         [ 0.04116797],\n         [ 0.06399305],\n         [ 0.00229814],\n         [-0.05166531],\n         [ 0.0120061 ],\n         [ 0.00890303],\n         [ 0.02730787],\n         [ 0.0586262 ],\n         [-0.07085326],\n         [-0.02227953],\n         [-0.04130259],\n         [-0.0715718 ],\n         [ 0.02267756],\n         [ 0.02873881],\n         [ 0.07358196],\n         [ 0.06912003],\n         [ 0.00881037],\n         [ 0.07535508],\n         [-0.03026325],\n         [-0.05525306],\n         [ 0.0818425 ],\n         [ 0.04866399],\n         [-0.01226088],\n         [-0.07912634],\n         [-0.05115699],\n         [ 0.08867393],\n         [ 0.01141189],\n         [ 0.010703  ],\n         [-0.08298659],\n         [-0.03415677],\n         [-0.0479064 ],\n         [ 0.07922077],\n         [-0.019612  ],\n         [ 0.0547884 ],\n         [ 0.03872889],\n         [ 0.02949293],\n         [-0.06313352],\n         [ 0.05025709],\n         [-0.09000675],\n         [-0.04600253],\n         [-0.04075696],\n         [-0.08642825],\n         [ 0.0378263 ],\n         [ 0.02591559],\n         [ 0.07144879],\n         [ 0.03760752],\n         [ 0.06288363],\n         [-0.01431212],\n         [-0.02159153],\n         [ 0.01015607],\n         [-0.08264425],\n         [ 0.05647694],\n         [-0.03154404],\n         [ 0.00279271],\n         [-0.04473792],\n         [ 0.06829026],\n         [ 0.07636249],\n         [-0.0173232 ],\n         [ 0.02805622],\n         [ 0.08407116],\n         [-0.02082247],\n         [-0.08899893],\n         [ 0.06630994],\n         [-0.04920302],\n         [ 0.01240251],\n         [-0.07652726],\n         [ 0.05057393],\n         [ 0.01986223],\n         [-0.06521591]],\n\n        [[ 0.06106016],\n         [ 0.04444835],\n         [-0.04862328],\n         [ 0.08014607],\n         [ 0.0185731 ],\n         [ 0.00763246],\n         [ 0.01646703],\n         [-0.02231226],\n         [ 0.01734747],\n         [-0.0656421 ],\n         [-0.0362459 ],\n         [-0.05090353],\n         [-0.06204948],\n         [ 0.040162  ],\n         [-0.0291345 ],\n         [-0.05862651],\n         [ 0.08315486],\n         [ 0.0162378 ],\n         [-0.07629269],\n         [ 0.08780169],\n         [ 0.02022412],\n         [-0.08628324],\n         [-0.07226743],\n         [ 0.05807839],\n         [-0.06170176],\n         [-0.06870501],\n         [ 0.05182597],\n         [ 0.04086147],\n         [-0.00543617],\n         [-0.07205366],\n         [-0.02906797],\n         [ 0.08504102],\n         [-0.02236218],\n         [ 0.03399744],\n         [-0.07358938],\n         [-0.08874545],\n         [-0.02938199],\n         [-0.01679076],\n         [-0.05750435],\n         [ 0.08886965],\n         [ 0.04435591],\n         [-0.04876385],\n         [-0.06633183],\n         [ 0.08405508],\n         [ 0.07615724],\n         [-0.07540823],\n         [ 0.01486044],\n         [-0.05777754],\n         [-0.08844194],\n         [ 0.06136224],\n         [-0.07163232],\n         [ 0.04050763],\n         [-0.02731129],\n         [ 0.08520986],\n         [-0.02314357],\n         [ 0.08000842],\n         [ 0.04039456],\n         [ 0.07959454],\n         [ 0.01398768],\n         [ 0.05429527],\n         [-0.04258416],\n         [-0.03303466],\n         [-0.03775131],\n         [ 0.01311076],\n         [ 0.08606456],\n         [ 0.0547407 ],\n         [-0.03649241],\n         [-0.03879999],\n         [ 0.03170715],\n         [ 0.05338366],\n         [ 0.00604353],\n         [-0.08491962],\n         [-0.04821305],\n         [ 0.08843155],\n         [-0.06926277],\n         [ 0.01609599],\n         [-0.04646367],\n         [ 0.02595581],\n         [-0.00704869],\n         [ 0.07099125]]],\n\n\n       [[[-0.03439318],\n         [ 0.05464979],\n         [ 0.06814954],\n         [ 0.07287803],\n         [-0.05960675],\n         [ 0.00679958],\n         [ 0.08388372],\n         [ 0.05153243],\n         [-0.04720237],\n         [-0.04091014],\n         [ 0.02461005],\n         [-0.07180804],\n         [ 0.03277101],\n         [-0.00893807],\n         [ 0.08697055],\n         [ 0.03065449],\n         [-0.05237619],\n         [ 0.07568575],\n         [ 0.00192421],\n         [-0.01069659],\n         [-0.00659702],\n         [-0.08936873],\n         [ 0.00382103],\n         [-0.07518393],\n         [ 0.05479001],\n         [-0.0330368 ],\n         [-0.0660102 ],\n         [-0.05359979],\n         [-0.0437606 ],\n         [-0.05239904],\n         [ 0.07488513],\n         [-0.05932895],\n         [ 0.07576726],\n         [-0.08361151],\n         [ 0.00968017],\n         [-0.03202684],\n         [ 0.03183699],\n         [ 0.03335508],\n         [-0.02320001],\n         [-0.05790762],\n         [-0.00117021],\n         [ 0.02891076],\n         [ 0.0527461 ],\n         [ 0.04134075],\n         [-0.01271605],\n         [ 0.03478827],\n         [ 0.0056755 ],\n         [ 0.05732571],\n         [ 0.03975552],\n         [ 0.00780277],\n         [-0.04020789],\n         [ 0.05645049],\n         [-0.03051157],\n         [-0.07079345],\n         [ 0.04343908],\n         [-0.01440632],\n         [-0.05538935],\n         [-0.06777376],\n         [-0.07733899],\n         [-0.08893438],\n         [ 0.08936045],\n         [ 0.04630409],\n         [-0.00832902],\n         [ 0.04109794],\n         [-0.08449624],\n         [ 0.02117929],\n         [-0.07794204],\n         [-0.07332753],\n         [-0.07813239],\n         [ 0.01198562],\n         [-0.01843277],\n         [-0.00338741],\n         [-0.06394293],\n         [-0.02035232],\n         [-0.03099361],\n         [ 0.08444282],\n         [-0.01290114],\n         [ 0.03934237],\n         [-0.05370608],\n         [ 0.04444964]],\n\n        [[ 0.04795139],\n         [-0.05006955],\n         [-0.08449902],\n         [ 0.08656631],\n         [-0.07934783],\n         [-0.07238637],\n         [ 0.04571348],\n         [ 0.05784106],\n         [-0.08663724],\n         [-0.02568722],\n         [-0.06806206],\n         [-0.05583685],\n         [-0.03087903],\n         [-0.00434838],\n         [-0.07153343],\n         [-0.07858845],\n         [-0.03677648],\n         [-0.0474926 ],\n         [ 0.0672465 ],\n         [ 0.05960694],\n         [ 0.04241595],\n         [ 0.03242076],\n         [ 0.04172051],\n         [-0.05686058],\n         [-0.02280974],\n         [-0.04594781],\n         [ 0.05692723],\n         [ 0.0128015 ],\n         [ 0.03092422],\n         [-0.06508881],\n         [ 0.0083436 ],\n         [ 0.04642199],\n         [-0.09023134],\n         [ 0.05540383],\n         [ 0.08533372],\n         [-0.04996486],\n         [ 0.07013816],\n         [ 0.02422011],\n         [-0.03511105],\n         [-0.08318097],\n         [-0.02801962],\n         [ 0.062619  ],\n         [ 0.05514929],\n         [ 0.00088003],\n         [ 0.00961305],\n         [ 0.03457424],\n         [-0.00572824],\n         [ 0.00104087],\n         [ 0.06182562],\n         [-0.01831153],\n         [-0.08123594],\n         [-0.08651081],\n         [-0.02462154],\n         [ 0.08303367],\n         [-0.00522128],\n         [ 0.01555525],\n         [-0.08419406],\n         [-0.03876471],\n         [-0.01294966],\n         [-0.01523703],\n         [-0.07200619],\n         [-0.07770481],\n         [ 0.08491018],\n         [-0.02954939],\n         [ 0.01237104],\n         [ 0.02095315],\n         [-0.03640401],\n         [ 0.09063245],\n         [ 0.02780644],\n         [-0.08265509],\n         [-0.04961604],\n         [ 0.02904656],\n         [ 0.02795975],\n         [ 0.02803621],\n         [ 0.08968671],\n         [ 0.00079295],\n         [ 0.04115978],\n         [ 0.07075083],\n         [-0.01063058],\n         [-0.08415087]],\n\n        [[ 0.04289268],\n         [ 0.02253383],\n         [ 0.02521108],\n         [ 0.00552247],\n         [-0.04373315],\n         [ 0.06863317],\n         [-0.01576283],\n         [ 0.07880753],\n         [-0.0817377 ],\n         [-0.03646507],\n         [ 0.01314285],\n         [ 0.03727648],\n         [-0.07778986],\n         [ 0.0040131 ],\n         [-0.03475442],\n         [-0.02355272],\n         [ 0.05532633],\n         [ 0.05746979],\n         [ 0.00388023],\n         [-0.02011409],\n         [ 0.02624319],\n         [-0.07128261],\n         [ 0.02495412],\n         [-0.02145927],\n         [-0.04908412],\n         [ 0.05741556],\n         [ 0.01613925],\n         [-0.05212189],\n         [ 0.04068768],\n         [ 0.07601371],\n         [ 0.05732544],\n         [-0.01296292],\n         [ 0.00994273],\n         [-0.00780037],\n         [-0.01887916],\n         [ 0.06144768],\n         [ 0.02504261],\n         [-0.03740054],\n         [ 0.03239471],\n         [-0.0095595 ],\n         [ 0.05132715],\n         [-0.07979634],\n         [-0.07203699],\n         [ 0.03362973],\n         [ 0.01250707],\n         [-0.01115906],\n         [-0.06675653],\n         [-0.03852055],\n         [ 0.08017631],\n         [-0.04855302],\n         [-0.07270706],\n         [ 0.06638491],\n         [ 0.078354  ],\n         [ 0.01830097],\n         [ 0.0393759 ],\n         [-0.04577898],\n         [-0.06185605],\n         [-0.06433676],\n         [ 0.02336165],\n         [ 0.03888601],\n         [-0.00698512],\n         [-0.02915953],\n         [-0.05568836],\n         [-0.00137289],\n         [-0.0340073 ],\n         [ 0.02974269],\n         [-0.08003635],\n         [-0.08871648],\n         [-0.06783809],\n         [ 0.04988261],\n         [ 0.01790869],\n         [-0.08514535],\n         [ 0.0243558 ],\n         [ 0.07767427],\n         [-0.05715869],\n         [-0.0641366 ],\n         [ 0.05355912],\n         [-0.05489305],\n         [-0.08908144],\n         [ 0.03220511]]],\n\n\n       [[[-0.00921452],\n         [ 0.0803498 ],\n         [-0.08006564],\n         [ 0.00664341],\n         [-0.00819857],\n         [-0.0092383 ],\n         [-0.08308002],\n         [ 0.03703022],\n         [ 0.02280276],\n         [-0.07295965],\n         [-0.02472242],\n         [-0.00789887],\n         [ 0.06652224],\n         [ 0.08374992],\n         [-0.06964504],\n         [ 0.04821539],\n         [-0.04014177],\n         [-0.05125577],\n         [ 0.01146798],\n         [ 0.02154462],\n         [ 0.02256513],\n         [ 0.04684851],\n         [ 0.0073119 ],\n         [ 0.01258602],\n         [ 0.01630591],\n         [-0.08093256],\n         [-0.04007504],\n         [-0.02742815],\n         [-0.01965506],\n         [ 0.02373669],\n         [-0.0072577 ],\n         [-0.04185859],\n         [ 0.08790347],\n         [ 0.01798648],\n         [-0.0357546 ],\n         [ 0.02926634],\n         [ 0.05560397],\n         [-0.05917413],\n         [ 0.01684429],\n         [-0.07449038],\n         [-0.04452478],\n         [-0.07550339],\n         [ 0.07128809],\n         [-0.05355911],\n         [-0.07850723],\n         [ 0.00247869],\n         [ 0.06466383],\n         [ 0.02426475],\n         [-0.05038818],\n         [-0.08217754],\n         [-0.05163583],\n         [-0.07642098],\n         [-0.08651254],\n         [ 0.05633286],\n         [ 0.01005168],\n         [ 0.0829557 ],\n         [-0.04722948],\n         [ 0.02617657],\n         [-0.00626238],\n         [-0.01940751],\n         [ 0.03215223],\n         [ 0.01465224],\n         [-0.07727533],\n         [ 0.00451645],\n         [ 0.08965227],\n         [-0.05691884],\n         [-0.07671122],\n         [-0.07998491],\n         [ 0.0429627 ],\n         [-0.00506941],\n         [-0.0647569 ],\n         [-0.05407454],\n         [ 0.04066515],\n         [-0.02502465],\n         [ 0.02083133],\n         [-0.07419092],\n         [ 0.06905513],\n         [-0.04689573],\n         [-0.01026058],\n         [-0.01963817]],\n\n        [[-0.00042576],\n         [ 0.02825534],\n         [-0.07700498],\n         [-0.08751058],\n         [ 0.06672238],\n         [ 0.02742995],\n         [-0.03742941],\n         [-0.04620892],\n         [ 0.08442891],\n         [-0.0709316 ],\n         [-0.01839037],\n         [-0.0542335 ],\n         [-0.06751826],\n         [ 0.07714646],\n         [-0.0104171 ],\n         [ 0.01074695],\n         [ 0.02469435],\n         [ 0.07063743],\n         [-0.0327493 ],\n         [-0.0755353 ],\n         [ 0.00591516],\n         [ 0.04403464],\n         [-0.03788291],\n         [ 0.01440731],\n         [ 0.0596998 ],\n         [ 0.03732093],\n         [-0.02360446],\n         [ 0.09070389],\n         [-0.0526428 ],\n         [-0.08513747],\n         [ 0.05910468],\n         [ 0.08513291],\n         [-0.08437148],\n         [-0.01315188],\n         [ 0.04105917],\n         [ 0.06920059],\n         [-0.01534907],\n         [-0.0135079 ],\n         [-0.04427939],\n         [ 0.05362083],\n         [ 0.0640797 ],\n         [ 0.00205128],\n         [-0.01989764],\n         [-0.00851627],\n         [-0.07596673],\n         [ 0.02637255],\n         [ 0.04401585],\n         [ 0.04327717],\n         [ 0.04830043],\n         [-0.00292231],\n         [ 0.01323822],\n         [ 0.03646477],\n         [-0.08690289],\n         [ 0.02839699],\n         [-0.04851104],\n         [ 0.02587734],\n         [ 0.07510634],\n         [-0.0533677 ],\n         [-0.08331601],\n         [ 0.03574041],\n         [ 0.07514776],\n         [-0.05801672],\n         [-0.07079626],\n         [-0.02076923],\n         [ 0.08842552],\n         [ 0.0693385 ],\n         [ 0.07639015],\n         [ 0.07331933],\n         [-0.04775411],\n         [-0.02329315],\n         [-0.07337005],\n         [-0.00239167],\n         [-0.080801  ],\n         [-0.05133885],\n         [-0.01261067],\n         [-0.0412913 ],\n         [-0.04999951],\n         [-0.06438401],\n         [ 0.04126069],\n         [ 0.03144409]],\n\n        [[-0.03387536],\n         [ 0.03176899],\n         [-0.02875099],\n         [ 0.00553655],\n         [ 0.04028113],\n         [ 0.02161485],\n         [-0.00026284],\n         [-0.04835786],\n         [ 0.05722496],\n         [ 0.06647928],\n         [-0.03651828],\n         [ 0.07866651],\n         [-0.06662171],\n         [-0.03158788],\n         [-0.04929345],\n         [ 0.01912864],\n         [-0.00304266],\n         [-0.07884619],\n         [ 0.03785446],\n         [-0.00327944],\n         [ 0.05006424],\n         [-0.05030322],\n         [ 0.05671658],\n         [-0.07199451],\n         [ 0.05695082],\n         [-0.02219864],\n         [-0.02198619],\n         [ 0.06546898],\n         [ 0.06142278],\n         [-0.02687625],\n         [ 0.06183472],\n         [-0.03455735],\n         [ 0.04254839],\n         [ 0.05322735],\n         [ 0.01316968],\n         [ 0.07830706],\n         [ 0.02586642],\n         [-0.07009414],\n         [ 0.08445281],\n         [-0.06079325],\n         [ 0.06495531],\n         [ 0.01944076],\n         [ 0.02505359],\n         [-0.02044953],\n         [ 0.05903317],\n         [-0.04032047],\n         [ 0.06159015],\n         [ 0.03527623],\n         [ 0.04042086],\n         [ 0.06553836],\n         [ 0.02051701],\n         [ 0.07365525],\n         [ 0.08486727],\n         [ 0.01555815],\n         [ 0.02324913],\n         [ 0.0709354 ],\n         [-0.08552174],\n         [ 0.08135769],\n         [ 0.0457149 ],\n         [-0.03494783],\n         [ 0.00343809],\n         [-0.03860806],\n         [-0.04027758],\n         [-0.02931628],\n         [ 0.0539455 ],\n         [-0.08106333],\n         [ 0.05497667],\n         [-0.08832414],\n         [ 0.08937459],\n         [-0.02014273],\n         [-0.0336242 ],\n         [ 0.01431895],\n         [ 0.07311136],\n         [ 0.05644143],\n         [-0.01560835],\n         [-0.03821421],\n         [ 0.03716514],\n         [ 0.0191099 ],\n         [ 0.07970025],\n         [-0.03246188]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_858/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.0303254 , -0.0819697 ,  0.08410805, ..., -0.06141984,\n          -0.08405113,  0.02839591],\n         [-0.01751167,  0.11686455, -0.1423717 , ..., -0.00651311,\n          -0.07611485, -0.10667967],\n         [ 0.154586  ,  0.03512892, -0.02582129, ...,  0.04207398,\n           0.11323774, -0.1730972 ],\n         ...,\n         [-0.17776512,  0.18271811,  0.03414432, ..., -0.09747736,\n           0.06577013,  0.07179998],\n         [-0.10561133, -0.01691975, -0.05215042, ..., -0.11437327,\n          -0.05070565,  0.09380252],\n         [-0.13176028,  0.0462377 , -0.05236724, ...,  0.05854955,\n          -0.02808286, -0.10600992]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.1032524 , -0.0852347 , -0.17175597, ...,  0.06863623,\n          -0.16006066, -0.09043074],\n         [ 0.06144108,  0.03829359,  0.03092938, ..., -0.05503388,\n          -0.03225653, -0.02320758],\n         [ 0.03018818,  0.01783336,  0.05729922, ...,  0.07761155,\n          -0.2282479 , -0.06780922],\n         ...,\n         [ 0.17606936,  0.12889607, -0.17214462, ...,  0.05573615,\n           0.08149698,  0.22606923],\n         [ 0.08149737,  0.12252472,  0.02563435, ...,  0.05499631,\n          -0.07131711,  0.17855643],\n         [ 0.06686174,  0.00555492,  0.14189926, ...,  0.06560292,\n           0.04463634,  0.12230655]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 144, 4) dtype=float32, numpy=\narray([[[[ 0.02781812, -0.10467465,  0.00763623, -0.18184307],\n         [-0.10790048,  0.01949662,  0.00228341, -0.02564921],\n         [ 0.10475592, -0.05194062,  0.00470034, -0.0009797 ],\n         [-0.02483257,  0.01449299, -0.00221108,  0.07965975],\n         [-0.00880836, -0.08095035,  0.05068102, -0.03321116],\n         [ 0.07774796,  0.05541421, -0.01019561, -0.00738755],\n         [ 0.07167569,  0.09657817, -0.08016557,  0.00460754],\n         [ 0.10482001, -0.00587355, -0.02716144, -0.1231537 ],\n         [ 0.01614355, -0.0390297 , -0.18049675,  0.05236965],\n         [-0.0414603 , -0.11422865,  0.08183887, -0.15308303],\n         [-0.04233493, -0.00621603,  0.02066295,  0.05311586],\n         [-0.11993722, -0.05538895,  0.12665986,  0.12747706],\n         [ 0.11302688,  0.10914613,  0.05164585, -0.138162  ],\n         [ 0.00137327,  0.04312422, -0.11729242, -0.09260522],\n         [ 0.03482617, -0.02629261, -0.11653887, -0.04376264],\n         [-0.1418027 ,  0.07619706, -0.01736691, -0.02391838],\n         [-0.05393205,  0.00058426, -0.04389622,  0.06046414],\n         [-0.15328075, -0.0171194 ,  0.1412294 ,  0.08382887],\n         [-0.06514154, -0.10495731,  0.1785092 ,  0.02724832],\n         [ 0.06038187, -0.10013646,  0.08798193, -0.06743342],\n         [ 0.17818542,  0.07686073,  0.09393784,  0.00141435],\n         [ 0.01476073,  0.03074213,  0.04083981,  0.03966681],\n         [ 0.12831053,  0.00565182,  0.03811986, -0.01918929],\n         [-0.16411954, -0.00378172,  0.08017598,  0.02592126],\n         [-0.03222862,  0.17076059,  0.08582189,  0.06488298],\n         [-0.04534769, -0.07555675, -0.09187201,  0.03024918],\n         [ 0.04430831,  0.04746226, -0.08159558,  0.02088543],\n         [-0.12769966, -0.1406385 ,  0.14367042,  0.08048964],\n         [ 0.04510144,  0.06538825,  0.10111261,  0.01675177],\n         [ 0.02263882, -0.06764921,  0.06164803, -0.0747363 ],\n         [-0.07113492, -0.16860454,  0.1107435 ,  0.01606433],\n         [-0.06703167, -0.03916488,  0.06900434,  0.0857251 ],\n         [-0.11859088, -0.02712234,  0.02407813,  0.10918757],\n         [-0.01572594, -0.00342232, -0.10131246, -0.0034873 ],\n         [ 0.1601355 , -0.04543341,  0.019896  , -0.01303508],\n         [ 0.03964147, -0.115504  , -0.04012456,  0.10991706],\n         [ 0.03378871,  0.00206046, -0.06423229,  0.05971781],\n         [-0.07236121, -0.04041272, -0.0386173 , -0.15356416],\n         [-0.12539357, -0.1717742 , -0.0625822 ,  0.16011864],\n         [-0.06222475, -0.03065197, -0.0134316 , -0.03281127],\n         [-0.05859878,  0.11652099,  0.01211956, -0.16647477],\n         [-0.0118046 ,  0.03708535,  0.00945484, -0.00457471],\n         [-0.12068707, -0.02912297, -0.08979406, -0.07850562],\n         [ 0.09730059, -0.08763624,  0.05224653,  0.02733338],\n         [ 0.13149309, -0.02282393,  0.13077568,  0.12508166],\n         [ 0.06256086, -0.06049864, -0.03094569, -0.04552351],\n         [-0.03685125,  0.0229169 , -0.12412675,  0.06657435],\n         [ 0.03647917, -0.12029204, -0.17516567,  0.07715946],\n         [-0.10658403,  0.11799251, -0.08898059, -0.05066445],\n         [-0.0200756 , -0.07743263, -0.07239279,  0.02045222],\n         [-0.09816105, -0.02788364,  0.04272325, -0.06470992],\n         [ 0.14765032, -0.07892913,  0.06642003, -0.02861522],\n         [ 0.0860071 , -0.11518759,  0.02554224, -0.01693372],\n         [ 0.04510541, -0.10765831,  0.14720987,  0.01197299],\n         [-0.17210904, -0.08002077,  0.10323658,  0.04554013],\n         [-0.03632028, -0.01370316,  0.01973625,  0.15068756],\n         [ 0.01775385,  0.04000584, -0.00929072,  0.06062938],\n         [-0.03964074, -0.01880754, -0.05460619, -0.10628366],\n         [-0.18053329,  0.07793874, -0.08137066, -0.14814475],\n         [ 0.13764939, -0.02763202,  0.02531153,  0.00732083],\n         [-0.13969319,  0.03051428,  0.10970824,  0.05044277],\n         [ 0.16025524,  0.13886319,  0.00454604, -0.03589414],\n         [-0.04580107,  0.05267937, -0.10092057, -0.09903374],\n         [-0.17318746,  0.00293897,  0.00089837,  0.02475446],\n         [-0.04353496,  0.05663297, -0.00168399, -0.10670562],\n         [ 0.01641766, -0.09341971, -0.08044145, -0.07330538],\n         [ 0.00268797,  0.08154051, -0.12635797,  0.02417696],\n         [ 0.0340312 , -0.07623601,  0.12978488, -0.08772268],\n         [-0.12161236, -0.08259763, -0.10462891,  0.01370023],\n         [-0.00738282, -0.03372376, -0.1271356 , -0.01789768],\n         [-0.01221484, -0.01397653, -0.00155973,  0.13049084],\n         [-0.07796519,  0.02867266, -0.03495677, -0.07061622],\n         [ 0.09797794,  0.01851783, -0.0485487 ,  0.02205472],\n         [ 0.03562444, -0.06502075,  0.05930261, -0.03671053],\n         [-0.12492716, -0.13721663,  0.06473758,  0.00604675],\n         [ 0.070114  , -0.01902341,  0.05244958, -0.0936335 ],\n         [-0.12206123,  0.11637246,  0.02030917, -0.02577622],\n         [-0.04966445,  0.12071061, -0.1429379 , -0.06815837],\n         [-0.04834042, -0.01325547,  0.02769884, -0.0166651 ],\n         [ 0.00218471, -0.07542607, -0.12479062, -0.04049531],\n         [-0.02186379,  0.04181989,  0.01509402, -0.16750224],\n         [ 0.03025393,  0.09274626,  0.08653527,  0.18617915],\n         [-0.08553559,  0.12182727,  0.05546219, -0.06653943],\n         [-0.01760615, -0.03670194, -0.11697042,  0.02722358],\n         [-0.04513986, -0.16960108, -0.04496966,  0.00640422],\n         [ 0.04990316,  0.10711133,  0.06566343,  0.09644027],\n         [ 0.12983647,  0.00266442, -0.14251651, -0.09428623],\n         [ 0.15761271,  0.01112566, -0.0604986 ,  0.0471209 ],\n         [ 0.05440122, -0.00222425, -0.05638983, -0.0531702 ],\n         [-0.08496695, -0.04488914,  0.07705095, -0.08783916],\n         [-0.1614243 ,  0.00813478, -0.01612123, -0.06694531],\n         [ 0.07071088,  0.12121177,  0.03337152,  0.01874368],\n         [-0.09960195,  0.09487536, -0.13873644, -0.09701242],\n         [-0.12459549,  0.09799752,  0.02508489,  0.00279215],\n         [-0.04410345, -0.03381923, -0.11009634, -0.03064325],\n         [ 0.13902055,  0.08125252, -0.04899363, -0.06853049],\n         [ 0.00429458, -0.03418063,  0.13988534,  0.01229757],\n         [-0.00297144,  0.00167207, -0.09436485, -0.03940474],\n         [ 0.13002272, -0.10842835,  0.02537668, -0.08801584],\n         [ 0.05087539,  0.12321518,  0.09751833, -0.1145931 ],\n         [-0.11106663,  0.10242482, -0.06019084, -0.00707043],\n         [ 0.03710387,  0.13167235, -0.04639511, -0.03251163],\n         [ 0.04181461, -0.0442941 ,  0.04968412, -0.13256364],\n         [ 0.1288824 , -0.02596609, -0.08981573,  0.10586812],\n         [ 0.15427276,  0.02435395,  0.04180205, -0.11795913],\n         [ 0.04712658,  0.00182793,  0.08125487, -0.11472569],\n         [ 0.13352992, -0.07388116, -0.05926284,  0.07106   ],\n         [ 0.12169028,  0.04248454,  0.05388284, -0.05092555],\n         [-0.03049528,  0.00694684, -0.01086393, -0.02781583],\n         [-0.04314344,  0.1655162 , -0.01598664, -0.05014084],\n         [-0.17657654,  0.04656468, -0.1563552 , -0.06544053],\n         [ 0.09241959,  0.01808688,  0.03161157, -0.00464515],\n         [ 0.03739675, -0.12678948, -0.07785824, -0.00226444],\n         [ 0.00252193,  0.04234374,  0.02774007, -0.07421461],\n         [ 0.15311487, -0.06055634,  0.06075127, -0.10565766],\n         [-0.128886  , -0.13769747, -0.159068  , -0.05143348],\n         [ 0.0950316 , -0.00615977, -0.11900305, -0.02050137],\n         [-0.05680747, -0.09456473, -0.03905823,  0.00235562],\n         [-0.04001148, -0.0253312 , -0.09710392, -0.09817521],\n         [-0.15209791, -0.02605542, -0.00302898,  0.03755013],\n         [ 0.13905612,  0.12455417, -0.01791719, -0.03234477],\n         [ 0.16744149,  0.04360336,  0.06300595, -0.03470729],\n         [-0.05102193, -0.1452873 ,  0.13981695,  0.02392637],\n         [-0.02224801, -0.1296511 ,  0.0298916 ,  0.04581955],\n         [-0.05060181,  0.03933307, -0.03699891, -0.00718969],\n         [-0.10295284, -0.1461309 ,  0.00513936, -0.07845126],\n         [ 0.0991139 ,  0.09987702,  0.16783518, -0.06146259],\n         [-0.00878084,  0.04451089, -0.0242034 , -0.00290466],\n         [ 0.05170459,  0.0212477 , -0.04025416, -0.06230281],\n         [-0.09381144,  0.09066012, -0.01569835,  0.16495815],\n         [-0.10223784,  0.03141678, -0.04474649,  0.1285678 ],\n         [ 0.00156122, -0.10547151, -0.13626057, -0.08621756],\n         [-0.08295612, -0.01915357,  0.06684773,  0.05639355],\n         [ 0.06895996, -0.08734882, -0.14016761,  0.1212548 ],\n         [-0.0158081 , -0.03138791,  0.00259429, -0.02383161],\n         [-0.12326996, -0.12929712, -0.00574765,  0.01299437],\n         [ 0.1307537 , -0.17042147,  0.00517274, -0.08292925],\n         [-0.08437347,  0.1136998 , -0.14168651,  0.18472771],\n         [-0.1371271 , -0.05755889, -0.04240495,  0.09164174],\n         [-0.05730253,  0.04933271,  0.06620687, -0.13063405],\n         [ 0.04163403, -0.09053862,  0.00620647, -0.02328288],\n         [ 0.02546123, -0.11092508, -0.01112259, -0.02433479],\n         [-0.1380404 , -0.17200045, -0.0439747 , -0.01185329],\n         [ 0.06170368,  0.03581291,  0.06952105,  0.12660606]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/beta:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 48, 1) dtype=float32, numpy=\narray([[[[ 3.53159457e-02],\n         [ 5.03814556e-02],\n         [ 3.07737049e-02],\n         [-2.15988215e-02],\n         [ 4.19876724e-03],\n         [-5.33763021e-02],\n         [-8.51735994e-02],\n         [-2.09488291e-02],\n         [-2.15752143e-02],\n         [-2.50222702e-02],\n         [-5.24209626e-02],\n         [-2.07700301e-02],\n         [-4.41363342e-02],\n         [-2.01633628e-02],\n         [ 7.71572962e-02],\n         [ 1.03974834e-01],\n         [ 7.07042217e-02],\n         [-4.88279201e-02],\n         [ 4.27590646e-02],\n         [-4.47826013e-02],\n         [-7.53735229e-02],\n         [ 3.93768325e-02],\n         [-1.94847491e-02],\n         [ 1.05290534e-02],\n         [ 3.27172205e-02],\n         [-1.13758286e-02],\n         [ 8.64494815e-02],\n         [-3.85653600e-02],\n         [-2.71121785e-02],\n         [-2.99452133e-02],\n         [ 3.63736451e-02],\n         [-2.41101789e-05],\n         [-1.35222292e-02],\n         [ 5.39063215e-02],\n         [ 8.62861648e-02],\n         [-4.24535349e-02],\n         [ 4.51135216e-03],\n         [ 4.61910963e-02],\n         [ 1.28559060e-02],\n         [ 9.04856101e-02],\n         [ 2.29352769e-02],\n         [ 6.60367459e-02],\n         [ 4.71788235e-02],\n         [-8.91620815e-02],\n         [-5.94145581e-02],\n         [-1.83062479e-02],\n         [-2.16789171e-03],\n         [ 4.17781137e-02]],\n\n        [[-1.10544013e-02],\n         [ 2.77538374e-02],\n         [ 4.25366014e-02],\n         [-8.11855122e-02],\n         [-7.34824464e-02],\n         [ 2.91182846e-02],\n         [-3.53838801e-02],\n         [-8.43996033e-02],\n         [-4.09992747e-02],\n         [ 9.57622472e-03],\n         [ 7.88755864e-02],\n         [ 2.84397155e-02],\n         [ 7.03790486e-02],\n         [-3.75360297e-03],\n         [ 8.29164833e-02],\n         [-1.04061039e-02],\n         [-2.10589655e-02],\n         [-2.99800187e-02],\n         [ 6.16447702e-02],\n         [ 4.25974047e-03],\n         [-7.45044574e-02],\n         [ 1.42984455e-02],\n         [ 3.56371738e-02],\n         [ 3.49963121e-02],\n         [ 4.69331406e-02],\n         [-1.01489738e-01],\n         [-4.20799218e-02],\n         [ 4.64648046e-02],\n         [ 5.84333315e-02],\n         [ 1.35016004e-02],\n         [-3.72487381e-02],\n         [-1.34304436e-02],\n         [ 3.26460823e-02],\n         [-3.02999914e-02],\n         [-8.83728564e-02],\n         [ 8.60380605e-02],\n         [ 6.65825419e-03],\n         [-7.72655755e-02],\n         [-8.19081888e-02],\n         [ 5.57227544e-02],\n         [-3.38321999e-02],\n         [-4.83520105e-02],\n         [-3.83248068e-02],\n         [-2.92716399e-02],\n         [ 2.84039066e-03],\n         [-1.36643904e-03],\n         [ 1.39363986e-02],\n         [-5.42569906e-02]],\n\n        [[-1.05620874e-02],\n         [ 5.66055300e-03],\n         [-2.31237859e-02],\n         [ 3.80208939e-02],\n         [ 9.30777118e-02],\n         [-3.79978530e-02],\n         [-4.48042266e-02],\n         [ 9.41825733e-02],\n         [-2.14360226e-02],\n         [-1.00182248e-02],\n         [-2.63821706e-02],\n         [ 5.45234606e-02],\n         [-1.47585385e-02],\n         [-4.30061668e-02],\n         [ 1.80854220e-02],\n         [ 3.27795520e-02],\n         [-6.09450378e-02],\n         [-7.69356266e-02],\n         [-5.77506311e-02],\n         [ 3.63277979e-02],\n         [ 7.19530284e-02],\n         [-7.94472471e-02],\n         [-3.95163186e-02],\n         [ 4.45337966e-02],\n         [-6.61355704e-02],\n         [-2.78428365e-02],\n         [-1.01313412e-01],\n         [-2.78258715e-02],\n         [ 1.96183268e-02],\n         [ 4.92886417e-02],\n         [-3.31377573e-02],\n         [-5.91154695e-02],\n         [-8.64304006e-02],\n         [ 6.26434200e-03],\n         [-5.53163663e-02],\n         [-2.06293687e-02],\n         [ 4.71837409e-02],\n         [ 2.93763615e-02],\n         [-2.23852135e-02],\n         [-7.31137097e-02],\n         [-2.36331783e-02],\n         [-6.30450323e-02],\n         [ 6.93192612e-03],\n         [ 4.29211184e-02],\n         [-9.05910414e-03],\n         [ 3.25310193e-02],\n         [-2.02540513e-02],\n         [-1.38577148e-02]]],\n\n\n       [[[-2.79277768e-02],\n         [-5.62481582e-02],\n         [-2.28641815e-02],\n         [-4.19692397e-02],\n         [ 1.06789172e-02],\n         [-4.74768318e-02],\n         [-3.79102565e-02],\n         [-7.51478672e-02],\n         [ 4.63297628e-02],\n         [ 4.25189594e-03],\n         [ 2.61666626e-02],\n         [ 2.80124284e-02],\n         [ 8.14502388e-02],\n         [ 2.86713075e-02],\n         [-2.59397109e-03],\n         [ 4.75228950e-02],\n         [ 4.31774855e-02],\n         [-7.67606795e-02],\n         [ 6.30831867e-02],\n         [-1.00543194e-01],\n         [-3.22792754e-02],\n         [ 6.17848756e-03],\n         [ 2.03208588e-02],\n         [ 3.78086120e-02],\n         [ 3.44711021e-02],\n         [-1.16852187e-02],\n         [-3.78838852e-02],\n         [-1.54898490e-03],\n         [ 6.92383647e-02],\n         [-7.46587515e-02],\n         [ 3.50788571e-02],\n         [-3.77873145e-03],\n         [-4.66197692e-02],\n         [-5.64974546e-02],\n         [-7.91984499e-02],\n         [ 5.05828522e-02],\n         [ 2.21440066e-02],\n         [-1.09414160e-02],\n         [-5.27949482e-02],\n         [ 3.79642136e-02],\n         [ 1.94794424e-02],\n         [-2.77312868e-03],\n         [-4.97424640e-02],\n         [ 3.61784659e-02],\n         [ 3.92357782e-02],\n         [-3.78513746e-02],\n         [-1.95586891e-03],\n         [ 9.43043306e-02]],\n\n        [[ 1.39089739e-02],\n         [-2.37878021e-02],\n         [-9.25822482e-02],\n         [ 9.19769183e-02],\n         [-9.83104259e-02],\n         [-3.48892175e-02],\n         [-2.68912427e-02],\n         [-9.96044874e-02],\n         [ 4.34916355e-02],\n         [-7.23978803e-02],\n         [-2.09711213e-02],\n         [ 2.26920191e-03],\n         [ 7.14952052e-02],\n         [-1.69049613e-02],\n         [-4.46030349e-02],\n         [ 4.41316590e-02],\n         [ 5.54548623e-03],\n         [-9.16829854e-02],\n         [-4.89749052e-02],\n         [-5.27027175e-02],\n         [ 7.69813135e-02],\n         [-1.42667666e-02],\n         [ 6.14000894e-02],\n         [-3.34884450e-02],\n         [-3.31978314e-02],\n         [-4.75349836e-02],\n         [ 6.68137372e-02],\n         [-8.15757923e-03],\n         [-2.34489273e-02],\n         [ 4.26237769e-02],\n         [ 2.95912102e-02],\n         [-3.88364643e-02],\n         [ 8.46106932e-02],\n         [-5.05492911e-02],\n         [-6.93544075e-02],\n         [ 1.15405498e-02],\n         [-2.08933055e-02],\n         [-3.15332599e-02],\n         [ 8.03300587e-04],\n         [ 1.69281960e-02],\n         [-1.64860785e-02],\n         [ 2.91454475e-02],\n         [-2.07784139e-02],\n         [ 1.16712777e-02],\n         [-7.96888843e-02],\n         [ 6.38474897e-02],\n         [-2.59472001e-02],\n         [-6.30716905e-02]],\n\n        [[-4.85102460e-02],\n         [ 1.65536981e-02],\n         [-1.43328048e-02],\n         [ 4.80605252e-02],\n         [-2.67029479e-02],\n         [-3.62486318e-02],\n         [ 9.25540701e-02],\n         [ 3.19261588e-02],\n         [ 6.34673983e-02],\n         [-6.42840862e-02],\n         [-2.19921190e-02],\n         [-5.08274361e-02],\n         [ 4.64251153e-02],\n         [-1.60259083e-02],\n         [ 4.44377139e-02],\n         [-6.41317219e-02],\n         [ 1.09003473e-03],\n         [-1.31795090e-02],\n         [ 4.71654497e-02],\n         [ 7.37250149e-02],\n         [-1.44194858e-02],\n         [-1.05053023e-01],\n         [-5.32207973e-02],\n         [-3.15502882e-02],\n         [ 7.78401792e-02],\n         [-2.80140154e-02],\n         [-4.26099822e-02],\n         [-7.79997259e-02],\n         [ 9.48408172e-02],\n         [ 4.26637232e-02],\n         [ 2.82237511e-02],\n         [ 8.41055438e-02],\n         [ 3.61208469e-02],\n         [ 8.96926448e-02],\n         [ 7.77909905e-02],\n         [-2.48177424e-02],\n         [-1.00088092e-02],\n         [ 7.70199811e-04],\n         [ 7.22677074e-03],\n         [ 5.43387197e-02],\n         [ 8.37420486e-03],\n         [ 1.91782080e-02],\n         [ 9.26666483e-02],\n         [-8.43878686e-02],\n         [ 8.74332897e-03],\n         [ 3.58072594e-02],\n         [ 5.50977737e-02],\n         [-6.13569617e-02]]],\n\n\n       [[[ 3.63879949e-02],\n         [-5.04389107e-02],\n         [ 9.03431606e-03],\n         [-2.61386670e-03],\n         [-3.75118442e-02],\n         [ 3.28350961e-02],\n         [-1.09143689e-01],\n         [-6.48222566e-02],\n         [-4.68815211e-03],\n         [-7.73714110e-02],\n         [ 4.88298610e-02],\n         [ 5.26318289e-02],\n         [-6.18577898e-02],\n         [-8.75663944e-03],\n         [-1.01612182e-02],\n         [ 4.21457402e-02],\n         [ 2.91728098e-02],\n         [ 1.43084396e-02],\n         [-6.33279160e-02],\n         [-7.44637325e-02],\n         [ 7.07439110e-02],\n         [-5.98586909e-02],\n         [ 2.31313109e-02],\n         [ 5.80266528e-02],\n         [-1.37082068e-02],\n         [ 1.37210740e-02],\n         [-1.55142499e-02],\n         [-2.40824441e-03],\n         [ 1.63402166e-02],\n         [ 7.07966881e-03],\n         [ 9.01942700e-02],\n         [-2.58190017e-02],\n         [-2.78343316e-02],\n         [ 1.01193681e-01],\n         [ 1.08919226e-01],\n         [-4.77640443e-02],\n         [-3.68368700e-02],\n         [-3.92691046e-02],\n         [ 7.88680557e-03],\n         [ 6.16163947e-02],\n         [ 2.05405243e-02],\n         [-8.97570164e-04],\n         [ 1.82925388e-02],\n         [ 9.45965797e-02],\n         [-4.27553244e-02],\n         [-6.72508255e-02],\n         [-1.68191288e-02],\n         [ 1.25851613e-02]],\n\n        [[ 2.44568735e-02],\n         [ 5.06686233e-03],\n         [-1.05945505e-02],\n         [ 2.43188925e-02],\n         [-9.09846053e-02],\n         [ 1.03353029e-02],\n         [-8.29538517e-03],\n         [-7.20995069e-02],\n         [ 2.39007100e-02],\n         [ 7.88740739e-02],\n         [-8.35611895e-02],\n         [-3.59471105e-02],\n         [-2.41697431e-02],\n         [-6.53790757e-02],\n         [-4.12599146e-02],\n         [ 1.24697462e-02],\n         [ 7.42886662e-02],\n         [ 8.32449123e-02],\n         [-4.48404402e-02],\n         [-3.56145985e-02],\n         [ 4.65434529e-02],\n         [-4.89874072e-02],\n         [-5.65120280e-02],\n         [ 1.57853737e-02],\n         [-4.78245392e-02],\n         [-1.04616903e-01],\n         [-3.88760827e-02],\n         [-8.78322572e-02],\n         [ 9.70100518e-04],\n         [ 1.35737900e-02],\n         [-9.53916609e-02],\n         [ 6.40029386e-02],\n         [-1.15573443e-02],\n         [-4.10155877e-02],\n         [ 1.97382737e-02],\n         [ 2.55914535e-02],\n         [-3.34017649e-02],\n         [-1.05393343e-02],\n         [ 3.74893062e-02],\n         [ 3.69113497e-02],\n         [-3.42543498e-02],\n         [-1.31756440e-02],\n         [-5.67687228e-02],\n         [-2.57813092e-02],\n         [-1.52693605e-02],\n         [-1.98891871e-02],\n         [-3.07427328e-02],\n         [ 7.66428784e-02]],\n\n        [[-7.16740042e-02],\n         [ 5.69579229e-02],\n         [ 5.90049662e-03],\n         [-7.64006078e-02],\n         [ 2.24321913e-02],\n         [-4.77536619e-02],\n         [-5.58662862e-02],\n         [ 2.67203245e-02],\n         [-1.58236083e-02],\n         [ 6.88611418e-02],\n         [-6.67586327e-02],\n         [ 4.53167669e-02],\n         [-2.33590454e-02],\n         [ 2.05879640e-02],\n         [-6.13767244e-02],\n         [ 3.18792909e-02],\n         [ 5.73027395e-02],\n         [-2.28201542e-02],\n         [ 4.83403467e-02],\n         [ 5.57980239e-02],\n         [-4.77933474e-02],\n         [ 2.33414024e-02],\n         [ 2.32983828e-02],\n         [ 3.41300890e-02],\n         [-7.73488823e-03],\n         [-2.33861282e-02],\n         [-1.44032165e-02],\n         [ 2.48822179e-02],\n         [-1.06486976e-01],\n         [-2.03070100e-02],\n         [-7.03199059e-02],\n         [-8.40019360e-02],\n         [ 1.04896137e-02],\n         [-1.12567900e-03],\n         [ 3.64941433e-02],\n         [ 2.43053827e-02],\n         [ 5.60640544e-03],\n         [-4.31202464e-02],\n         [-5.10355877e-03],\n         [ 6.55611679e-02],\n         [ 2.94309873e-02],\n         [ 5.28715625e-02],\n         [-2.27759797e-02],\n         [ 3.00714429e-02],\n         [ 2.05432670e-03],\n         [ 1.08848670e-02],\n         [-9.61027760e-03],\n         [ 9.56708863e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[-0.01417633, -0.03319129,  0.00286524, ...,  0.04760628,\n           0.02724828,  0.02691896],\n         [ 0.03771644,  0.07957841,  0.04870487, ...,  0.00988172,\n          -0.02380049, -0.00231152],\n         [ 0.0382299 ,  0.04970492, -0.03999446, ...,  0.03511826,\n           0.08485122, -0.05274315],\n         ...,\n         [-0.01438226, -0.08192959,  0.01288222, ...,  0.00827811,\n           0.01224355, -0.03826889],\n         [-0.01319871,  0.03518998, -0.07306327, ..., -0.06097677,\n           0.03845571, -0.08157586],\n         [ 0.00127259,  0.02016406,  0.01575197, ..., -0.0404964 ,\n           0.04768638,  0.06940842]]]], dtype=float32)>, <tf.Variable 'conv2d_864/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.00893544,  0.00931665,  0.00565999, ..., -0.02806362,\n          -0.02665524,  0.12389425],\n         [-0.18776798, -0.18925822,  0.02337648, ...,  0.05347696,\n           0.06285261,  0.03375933],\n         [ 0.11734153,  0.07295968, -0.05787664, ..., -0.12069435,\n          -0.06886938,  0.12980045],\n         ...,\n         [ 0.03962326, -0.13732831,  0.17900416, ..., -0.03899585,\n          -0.06190008,  0.01398859],\n         [-0.1371161 ,  0.00211848,  0.05134314, ...,  0.12428765,\n           0.20507903,  0.15506223],\n         [ 0.01173747,  0.13485728, -0.00387883, ..., -0.06674843,\n           0.13342224,  0.0603268 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_844/kernel:0' shape=(1, 1, 24, 40) dtype=float32, numpy=\narray([[[[-0.26612765,  0.03539177, -0.03010099, -0.07685361,\n           0.20067775, -0.24287722, -0.33287975,  0.4183457 ,\n           0.25707003, -0.13190171,  0.43313092, -0.06353056,\n           0.15011865, -0.09036477,  0.05158886,  0.07530625,\n          -0.18704566, -0.24176463, -0.07085809,  0.17440704,\n          -0.11164927, -0.09579259,  0.24499743, -0.17246103,\n          -0.27655062,  0.23568289, -0.19660127,  0.42349058,\n          -0.09335127, -0.27969927, -0.36118516,  0.2766599 ,\n          -0.4124004 ,  0.2447695 , -0.2750374 ,  0.14996801,\n          -0.22801284, -0.3275562 ,  0.40218624,  0.08543184],\n         [ 0.02760542, -0.1022142 ,  0.01950224, -0.29201382,\n          -0.24712808, -0.01616955, -0.1714271 ,  0.27840713,\n          -0.15799658,  0.05762885,  0.11866532, -0.01749915,\n           0.21127133, -0.15286581,  0.15736781, -0.16343082,\n          -0.26516587, -0.31273413, -0.15783918, -0.25324246,\n          -0.03646548, -0.21888506,  0.24075603,  0.03661891,\n           0.42971668, -0.15031898,  0.03665186,  0.18387263,\n          -0.04490378, -0.11625357,  0.0596994 , -0.10842396,\n           0.16878104,  0.12240873,  0.25805238,  0.23097195,\n           0.18400913, -0.17084856,  0.1533958 , -0.093521  ],\n         [-0.17441136,  0.13797534,  0.05565358, -0.41164976,\n          -0.07375833,  0.42785686, -0.1793502 , -0.03087219,\n          -0.01667484,  0.29367438,  0.13757153,  0.36647794,\n           0.01900608,  0.34951788,  0.15879296,  0.14030989,\n           0.32498214,  0.30281392, -0.12969168,  0.03235579,\n           0.36160567,  0.368509  , -0.01446664, -0.08962359,\n          -0.1525086 , -0.07711559,  0.14647909,  0.04995252,\n          -0.12380992,  0.17655186, -0.25552142, -0.02930377,\n           0.37407365,  0.11124046, -0.04503384,  0.06300842,\n           0.08235773,  0.213994  ,  0.02669655, -0.02076308],\n         [-0.38985303, -0.39230025,  0.10929905, -0.18809451,\n           0.42426923, -0.19428578, -0.23750228, -0.01487223,\n           0.21898156, -0.05823644, -0.25372   , -0.3777752 ,\n           0.38529953, -0.26071587,  0.3375565 ,  0.02722104,\n          -0.03519839,  0.3869795 , -0.1336692 ,  0.02585745,\n           0.0338083 , -0.00156765, -0.11782176, -0.31203067,\n          -0.2270928 , -0.1984539 ,  0.2984742 , -0.08511255,\n          -0.08396938, -0.2160836 , -0.02074038,  0.04352935,\n          -0.2220997 , -0.32769802,  0.31321204,  0.01259614,\n           0.20286883, -0.14696471, -0.19427735,  0.07024283],\n         [-0.3331219 ,  0.21216762, -0.38397554,  0.37801495,\n           0.05204998, -0.00815488,  0.10213754,  0.05495131,\n          -0.05822546, -0.26441944, -0.09523135,  0.07770756,\n           0.36111182,  0.09291603,  0.01347374,  0.24783754,\n          -0.26751524, -0.01596982, -0.0693484 ,  0.05634258,\n          -0.04294525,  0.15577057, -0.0170864 ,  0.04750102,\n           0.02832501, -0.16439876,  0.01768424,  0.00054948,\n           0.02267146,  0.04675772, -0.11960793,  0.02872481,\n          -0.30074987,  0.08002444, -0.11517092,  0.18286076,\n          -0.10061716,  0.19056948, -0.31814408,  0.40550297],\n         [-0.30751976,  0.22278789,  0.06436134, -0.08272123,\n          -0.23657992,  0.30457327,  0.2408229 ,  0.17367011,\n           0.15933962, -0.03249415, -0.20639968,  0.12999274,\n           0.02718118,  0.22092266,  0.23868819,  0.36281896,\n           0.29599398,  0.4320648 ,  0.28759035, -0.18543464,\n           0.00461237, -0.17913595,  0.11695091,  0.21002087,\n          -0.05013748,  0.05743557,  0.2952539 ,  0.16416705,\n          -0.16420043, -0.12554374,  0.11104595,  0.2647914 ,\n           0.28961322,  0.4131639 , -0.01286893, -0.2654958 ,\n           0.04271907, -0.28657883,  0.13446228,  0.06460872],\n         [-0.1443402 , -0.06399219,  0.27283114,  0.38340366,\n           0.36619362,  0.2306422 ,  0.0878112 ,  0.09166153,\n          -0.01406525, -0.21166506, -0.04848509,  0.14059405,\n           0.03481422,  0.07951848, -0.1739722 , -0.400549  ,\n           0.0647438 ,  0.20734277, -0.03430211,  0.3305663 ,\n           0.24181153, -0.23509836, -0.03420889, -0.17804445,\n          -0.2796256 ,  0.17701761,  0.27608898,  0.04669648,\n           0.25997078,  0.18438675, -0.11276163,  0.08107632,\n           0.3302622 , -0.05758501, -0.0164114 , -0.07507894,\n           0.12887318,  0.18627018,  0.2555415 , -0.27708003],\n         [-0.2634517 ,  0.30746722, -0.15585753,  0.22625153,\n           0.38095275,  0.21207178, -0.06137256,  0.29889044,\n          -0.22840302,  0.37019625,  0.35120937, -0.26527044,\n          -0.3463419 , -0.20458324,  0.0068853 ,  0.29969892,\n          -0.18551363,  0.04943659,  0.0439841 ,  0.19670455,\n          -0.00133047, -0.17500031, -0.37108597, -0.0769826 ,\n           0.17162162,  0.04533614,  0.2626481 , -0.00734868,\n          -0.09853044,  0.42154455, -0.04103972, -0.17537934,\n           0.16155909, -0.17501317, -0.09401121, -0.20617306,\n          -0.42599836,  0.030265  ,  0.23222825,  0.23349908],\n         [-0.41936803,  0.37516555, -0.11884803,  0.30028796,\n           0.34312603,  0.4075996 ,  0.00375418, -0.12759939,\n          -0.13075104,  0.05297039, -0.12681012,  0.05836933,\n           0.24926496, -0.31209552, -0.00976384,  0.25806454,\n          -0.44350228,  0.2849175 , -0.19418086,  0.17200883,\n          -0.02415418, -0.05521749, -0.4215325 ,  0.12385736,\n           0.06298042,  0.04003501,  0.138103  , -0.31618324,\n          -0.06742612, -0.17845657,  0.14380437,  0.04574826,\n           0.17975941,  0.03723933,  0.19766103,  0.10188191,\n          -0.02858445, -0.17888357, -0.01486607,  0.07851655],\n         [-0.05536302,  0.26031595, -0.3516389 ,  0.18534024,\n          -0.10805655, -0.11935399,  0.08193924,  0.13583788,\n           0.15625446, -0.21298549, -0.30798465,  0.20153232,\n           0.32222646, -0.10716551,  0.17941168,  0.06163031,\n           0.10845102,  0.18192211,  0.00198092,  0.1256109 ,\n           0.28104275, -0.17905737, -0.10289639,  0.33829412,\n          -0.08557675,  0.36513355,  0.06322505,  0.01937181,\n           0.01712705, -0.18976107,  0.42853302,  0.45543876,\n          -0.4005901 ,  0.18054976,  0.13052465,  0.1596327 ,\n          -0.3378976 ,  0.03734895,  0.01261216, -0.02560599],\n         [ 0.19420688,  0.24152932, -0.2738372 ,  0.0574615 ,\n           0.04559427, -0.14552984,  0.41244003, -0.15594277,\n          -0.04256302, -0.23256166,  0.2991894 ,  0.18004656,\n           0.34139362, -0.33223185,  0.04614733,  0.30934703,\n           0.039724  ,  0.30182582,  0.16940568, -0.20466511,\n          -0.1362336 , -0.03044419, -0.32169405, -0.19622493,\n           0.06439164, -0.25640315, -0.30964527, -0.1239585 ,\n          -0.07131123, -0.11010169,  0.0191714 , -0.28776374,\n          -0.39162078, -0.15761662,  0.36517996, -0.02510663,\n          -0.08894569,  0.00769533,  0.12738949, -0.01253839],\n         [-0.4497005 ,  0.13914731, -0.19806302, -0.16818118,\n          -0.41837156, -0.12098682,  0.05196934, -0.13239385,\n           0.14837602,  0.29936   , -0.20102647, -0.07059862,\n          -0.06621028,  0.2234595 ,  0.01684102, -0.12272306,\n          -0.03963729, -0.1920501 , -0.18856807,  0.00700842,\n           0.13952023,  0.23870659,  0.22175245, -0.06058592,\n           0.13067655, -0.32535428,  0.04258349, -0.11056731,\n           0.20736244, -0.18920767,  0.01975874,  0.11414749,\n          -0.07578363,  0.39530325, -0.14123948, -0.29406244,\n          -0.18265855, -0.2892531 ,  0.364718  ,  0.38575736],\n         [ 0.27707914,  0.04710755, -0.12688656, -0.01721698,\n           0.04282366,  0.2604268 ,  0.22586921, -0.2868515 ,\n          -0.251027  , -0.11194225, -0.08980644,  0.13758025,\n           0.36530164,  0.37803793,  0.3866741 , -0.22601545,\n          -0.37253618,  0.30739567, -0.03073063,  0.12404712,\n           0.17264578, -0.32391268, -0.22178732, -0.01223296,\n           0.11609384,  0.0757632 ,  0.2964583 , -0.35540453,\n          -0.24322674,  0.37437227, -0.05056396,  0.12491502,\n          -0.02962478, -0.4013013 , -0.01696869, -0.28358784,\n          -0.11382962,  0.1088635 , -0.13343582, -0.15464821],\n         [ 0.06946544, -0.06768081, -0.1031743 , -0.23153976,\n           0.12644683,  0.16024828, -0.13626692, -0.06004736,\n          -0.2850844 , -0.03006786, -0.17581382, -0.2119357 ,\n           0.4094881 ,  0.03771643, -0.17363505,  0.14754231,\n          -0.18658045,  0.12486137, -0.01730932, -0.25173682,\n          -0.0516717 , -0.1272997 ,  0.26505265,  0.17360497,\n          -0.32806087,  0.3508029 ,  0.36579394,  0.00754141,\n          -0.29493862, -0.06661863,  0.12967014, -0.22087497,\n           0.19735593, -0.06390043, -0.08938279,  0.13409956,\n           0.06445905,  0.05386739,  0.07088631,  0.12261354],\n         [ 0.09729882, -0.15903388,  0.17876945,  0.18069077,\n           0.3798783 ,  0.02753179,  0.10748763,  0.1767273 ,\n          -0.25072965, -0.01079263,  0.29257762,  0.27935654,\n          -0.11697014, -0.04883001, -0.00641297, -0.318633  ,\n           0.3399769 , -0.19843449, -0.1301943 , -0.08776686,\n          -0.01529333, -0.08259024,  0.40131626,  0.1682398 ,\n           0.3331283 ,  0.1303495 , -0.10764422, -0.2347675 ,\n           0.11949359,  0.1555066 , -0.45952138, -0.22474845,\n           0.3082912 ,  0.29830483, -0.34177932,  0.14336285,\n          -0.08031669, -0.12034832,  0.22637908, -0.2994427 ],\n         [-0.15006673, -0.01378446,  0.13234746,  0.22631086,\n          -0.09306253,  0.09801712, -0.17393805, -0.27421582,\n          -0.03991576,  0.11299498,  0.23515877,  0.16165458,\n           0.08464465, -0.33795577,  0.26129913, -0.08001439,\n          -0.38156837, -0.28234112, -0.15267865, -0.03464477,\n           0.13398603, -0.25033855, -0.337025  ,  0.01325399,\n          -0.0447702 ,  0.12821981, -0.1429522 ,  0.06470641,\n           0.13511096,  0.12876196, -0.28609785,  0.18516445,\n          -0.0470242 , -0.13911627, -0.1260926 ,  0.17518559,\n          -0.15979275, -0.37225538, -0.22824155, -0.31986883],\n         [ 0.02420627,  0.10199033, -0.29586083,  0.16805045,\n           0.3240896 , -0.24461368, -0.04408116, -0.3894818 ,\n           0.06190571,  0.07943973,  0.31324726, -0.22212279,\n           0.33722585,  0.19169994, -0.28927568,  0.17652024,\n           0.26221076, -0.07251318,  0.23510292,  0.44161934,\n          -0.06303921, -0.12677667,  0.20609759, -0.13964136,\n          -0.30503997, -0.16382529,  0.22308536, -0.06889992,\n          -0.075771  , -0.2913703 , -0.33822072, -0.24617912,\n          -0.08902863, -0.29792723,  0.23306003, -0.13686919,\n          -0.12873462,  0.16795625,  0.05351104,  0.154744  ],\n         [ 0.08763546, -0.18022923, -0.03294386,  0.06805636,\n          -0.07171855,  0.2605746 ,  0.01097168,  0.24657239,\n           0.21632311, -0.19709869, -0.13290423, -0.09989335,\n           0.12477641,  0.14554241, -0.16026525,  0.00280446,\n           0.01563234,  0.07242709,  0.28772455, -0.2986819 ,\n          -0.05915742,  0.30262142, -0.01766063, -0.15191483,\n           0.02856509, -0.00915187, -0.02375627,  0.27065602,\n           0.1022602 ,  0.07587232, -0.3117727 ,  0.08361859,\n          -0.16309178, -0.11843568,  0.21476053,  0.00467917,\n          -0.13806637, -0.1254266 ,  0.05112955, -0.13238683],\n         [ 0.35669038,  0.05614121, -0.25424355, -0.08128577,\n           0.13306387, -0.24759427, -0.4546411 ,  0.15776418,\n           0.14185682,  0.13924907, -0.2249725 , -0.39843374,\n           0.11038958,  0.41711953, -0.3669926 ,  0.06033428,\n          -0.06482619, -0.28510076, -0.02815536,  0.04190137,\n          -0.21179637, -0.15555811,  0.07052849, -0.18483718,\n          -0.04127508, -0.13930203, -0.4455054 ,  0.17786127,\n          -0.3457968 , -0.2918939 , -0.10577527, -0.31302375,\n          -0.00723211,  0.20127435,  0.17139535, -0.31524232,\n          -0.01925805,  0.01276865, -0.05545994, -0.14071578],\n         [-0.19877805,  0.4390016 ,  0.14079106,  0.01844993,\n          -0.04676826, -0.16754402, -0.39681628,  0.16673757,\n          -0.0356009 , -0.10559606, -0.12446998,  0.17895772,\n           0.05603748,  0.16005942, -0.00516651, -0.31618026,\n           0.09006545,  0.10866824, -0.2890184 ,  0.08678721,\n           0.36295837, -0.26434368,  0.16564968, -0.3712366 ,\n           0.03313078,  0.01882163, -0.02027442, -0.26889062,\n           0.3474036 , -0.07299661, -0.3799147 ,  0.23087016,\n           0.10814088,  0.16715388,  0.0114469 ,  0.14813192,\n           0.02990018, -0.00540092,  0.06299698, -0.01916094],\n         [ 0.09225386, -0.09043281,  0.07119819, -0.01800496,\n          -0.04227459, -0.09253699, -0.14877221,  0.09818866,\n          -0.22063951,  0.04366291,  0.18619518, -0.2602888 ,\n          -0.09240307,  0.29722038,  0.16359796,  0.16288732,\n           0.01286373,  0.16240959, -0.00831234, -0.00719998,\n           0.23148592,  0.22359373,  0.02428894,  0.06910174,\n          -0.15467952,  0.36659357,  0.04818127,  0.12478944,\n           0.36288878, -0.01701926, -0.17572847, -0.19010995,\n          -0.12768528, -0.37327302,  0.15119368, -0.03899619,\n           0.00651566, -0.08161657,  0.44762132,  0.09201499],\n         [-0.00096833, -0.16610275,  0.00957482, -0.13241282,\n          -0.3787512 ,  0.1865296 , -0.23480009, -0.09229969,\n           0.11001218,  0.32114103,  0.24047793,  0.20699112,\n          -0.12491856,  0.22574641,  0.06402686,  0.44879815,\n           0.272528  ,  0.04274595, -0.23817708,  0.29930636,\n           0.31458136, -0.11090562,  0.03667688,  0.11129505,\n          -0.10801628, -0.12049586,  0.01047495, -0.28445372,\n          -0.0796704 ,  0.45121607,  0.00855509, -0.31021333,\n          -0.07645407, -0.00856624, -0.01604011, -0.19731057,\n          -0.18300876, -0.4244736 ,  0.04728486,  0.12921283],\n         [ 0.14853111,  0.09289654, -0.09426411,  0.03368388,\n           0.20055242,  0.0331548 , -0.08234011,  0.31251115,\n           0.36040065, -0.1448588 ,  0.23381497, -0.1368149 ,\n          -0.10675763, -0.15270075, -0.03700992, -0.27636224,\n           0.4277965 ,  0.1556857 ,  0.25048342, -0.21749131,\n          -0.06007688, -0.15035053,  0.36123127,  0.232577  ,\n          -0.12087265, -0.03857862, -0.07297247,  0.03051981,\n           0.12450643,  0.03933071, -0.09821913, -0.10123347,\n          -0.17982943, -0.03278572, -0.2366058 , -0.0145291 ,\n          -0.07628655, -0.16001341, -0.1115007 ,  0.01261141],\n         [ 0.1377829 , -0.00886243,  0.13906124,  0.23228301,\n          -0.43146566,  0.2505391 ,  0.2177207 ,  0.30927545,\n           0.08572311, -0.34716436, -0.13779445,  0.03378799,\n           0.04955504,  0.19748144, -0.14517608, -0.15466875,\n          -0.06533208,  0.07988477,  0.00753112,  0.07374901,\n          -0.17887443, -0.17260677, -0.15784723,  0.36253494,\n          -0.20754693, -0.34404004,  0.05335993, -0.03839185,\n           0.39778095, -0.11600128, -0.01954329,  0.29894316,\n           0.050449  , -0.16397692,  0.44146144,  0.01031566,\n           0.25981775,  0.18380827, -0.12638122,  0.22857845]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv2d_872/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[ 0.007216  , -0.2006934 ,  0.06595994, ..., -0.10638613,\n           0.03039303, -0.06347275],\n         [-0.20517051,  0.13212545, -0.02837271, ...,  0.09439936,\n           0.12070698,  0.06202617],\n         [ 0.03411064,  0.08945523, -0.05197076, ..., -0.08014309,\n           0.0764438 ,  0.00438121],\n         ...,\n         [ 0.02949173, -0.02795532, -0.06832376, ..., -0.06677493,\n           0.12151764, -0.0473615 ],\n         [ 0.0828369 ,  0.00741579,  0.12542737, ...,  0.08023496,\n           0.03417279,  0.05050914],\n         [ 0.08378289, -0.08632613, -0.11509917, ..., -0.13094294,\n           0.0048934 , -0.05380997]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 240, 1) dtype=float32, numpy=\narray([[[[ 0.00361359],\n         [ 0.04095529],\n         [ 0.00316548],\n         ...,\n         [ 0.02852679],\n         [-0.00127756],\n         [-0.00396635]],\n\n        [[-0.01464037],\n         [ 0.02170953],\n         [ 0.00711485],\n         ...,\n         [-0.01353325],\n         [-0.01001555],\n         [ 0.00088421]],\n\n        [[-0.00073993],\n         [ 0.0342293 ],\n         [ 0.00517643],\n         ...,\n         [ 0.00198585],\n         [ 0.03166028],\n         [ 0.00753639]]],\n\n\n       [[[ 0.03673049],\n         [ 0.00388108],\n         [ 0.00144381],\n         ...,\n         [ 0.00307223],\n         [-0.03761655],\n         [-0.03889809]],\n\n        [[ 0.00630493],\n         [ 0.00058662],\n         [-0.00015376],\n         ...,\n         [ 0.04104026],\n         [ 0.01272106],\n         [-0.02278687]],\n\n        [[ 0.02781311],\n         [-0.00788468],\n         [ 0.04180369],\n         ...,\n         [ 0.02702546],\n         [ 0.01159141],\n         [-0.02160001]]],\n\n\n       [[[ 0.02890312],\n         [-0.00567244],\n         [ 0.00483864],\n         ...,\n         [-0.0016178 ],\n         [ 0.01079715],\n         [ 0.00109585]],\n\n        [[ 0.00929708],\n         [ 0.00790813],\n         [ 0.01690235],\n         ...,\n         [-0.00819204],\n         [ 0.02864849],\n         [ 0.02318237]],\n\n        [[-0.03781854],\n         [-0.00231716],\n         [-0.00362662],\n         ...,\n         [ 0.03110815],\n         [-0.01950197],\n         [-0.0275612 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 2.27700863e-02],\n         [ 6.18389947e-03],\n         [-1.68393645e-02],\n         ...,\n         [ 1.29628554e-02],\n         [-1.50023848e-02],\n         [ 4.19705920e-03]],\n\n        [[-2.49519851e-02],\n         [ 1.65948514e-02],\n         [ 7.82239344e-03],\n         ...,\n         [-8.48267879e-03],\n         [ 9.95279843e-05],\n         [-2.87308656e-02]],\n\n        [[ 2.34211814e-02],\n         [-8.48619640e-03],\n         [ 9.87909269e-03],\n         ...,\n         [ 5.90163562e-03],\n         [ 6.06126431e-03],\n         [-2.36742795e-02]]],\n\n\n       [[[ 1.48242861e-02],\n         [-1.38357542e-02],\n         [ 8.01176485e-03],\n         ...,\n         [-8.31632502e-03],\n         [ 4.21907241e-03],\n         [-7.87684508e-03]],\n\n        [[-8.34575109e-03],\n         [ 1.26982881e-02],\n         [ 1.33783529e-02],\n         ...,\n         [-4.65760211e-04],\n         [ 1.28695741e-02],\n         [-2.19112262e-03]],\n\n        [[-1.35911889e-02],\n         [-1.34860747e-03],\n         [-1.09946765e-02],\n         ...,\n         [ 4.68300330e-03],\n         [ 8.82822741e-03],\n         [ 7.00743264e-03]]],\n\n\n       [[[ 6.50743459e-06],\n         [-2.54191016e-03],\n         [-1.48029365e-02],\n         ...,\n         [-1.02036651e-02],\n         [-1.60242841e-02],\n         [ 2.62133498e-02]],\n\n        [[-1.96620333e-03],\n         [ 1.13371189e-03],\n         [ 5.82671724e-03],\n         ...,\n         [-2.26821490e-02],\n         [-1.72922085e-03],\n         [-3.47829424e-03]],\n\n        [[-3.76356533e-03],\n         [ 7.86869880e-03],\n         [ 1.61905941e-02],\n         ...,\n         [-6.50087546e-04],\n         [ 2.39117630e-03],\n         [-2.53763460e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_871/kernel:0' shape=(1, 1, 80, 48) dtype=float32, numpy=\narray([[[[ 0.03833852,  0.20332606, -0.09309868, ..., -0.05508476,\n           0.06792289, -0.13238743],\n         [-0.08538309,  0.0172676 ,  0.15478314, ...,  0.0847337 ,\n           0.01861911, -0.09736871],\n         [ 0.03905815,  0.02464032,  0.0310296 , ..., -0.13386288,\n          -0.04234823, -0.03500171],\n         ...,\n         [-0.12071764,  0.18907587, -0.05510516, ..., -0.21982713,\n           0.08482188,  0.06529619],\n         [-0.00628479, -0.13129911, -0.07300559, ...,  0.09685443,\n          -0.03105544,  0.09022444],\n         [ 0.01251499, -0.07774226, -0.02430129, ...,  0.1024375 ,\n           0.10441688, -0.14937389]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_865/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[ 0.02411344, -0.13661703,  0.02722762, ...,  0.00925887,\n           0.08891682,  0.0897679 ],\n         [ 0.11008906, -0.09490944,  0.13148436, ...,  0.14169534,\n          -0.07897919,  0.01057128],\n         [ 0.12693833,  0.16536288, -0.06694122, ..., -0.04913049,\n           0.07672325,  0.16468029],\n         ...,\n         [ 0.05694449, -0.01258849,  0.14806037, ...,  0.08759274,\n           0.02142863, -0.01292466],\n         [-0.12036449, -0.14026907,  0.00601822, ..., -0.11640905,\n          -0.14340554,  0.04850876],\n         [-0.00213935,  0.05652082, -0.06207975, ...,  0.10701577,\n           0.10216901, -0.03753307]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[-0.01490578, -0.05710156, -0.04545795, ..., -0.05189452,\n           0.0215784 , -0.03356608],\n         [ 0.05173114,  0.02754072,  0.03241063, ...,  0.05668699,\n          -0.02749225, -0.06422673],\n         [ 0.06804349, -0.0539492 , -0.02078557, ...,  0.03017703,\n          -0.0204422 ,  0.06679015],\n         ...,\n         [-0.00368524,  0.0425052 ,  0.02759175, ..., -0.00398665,\n          -0.05968226, -0.02618733],\n         [-0.07207836,  0.02183909, -0.02732921, ..., -0.05292643,\n          -0.05857046, -0.00968426],\n         [ 0.0762352 ,  0.01691345,  0.01194862, ..., -0.04609174,\n          -0.01583928, -0.00638036]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.13249783,  0.02318034, -0.1469356 , ..., -0.21334508,\n           0.13531697,  0.06542119],\n         [ 0.08150274,  0.094526  ,  0.16939604, ..., -0.01665658,\n          -0.24367528,  0.07418942],\n         [ 0.09712027,  0.08825405, -0.20956749, ...,  0.01624975,\n           0.06103171, -0.06181553],\n         ...,\n         [ 0.0553126 ,  0.08008792, -0.17248517, ..., -0.13454898,\n           0.01710662, -0.08034048],\n         [-0.1250034 , -0.05013902,  0.16992112, ...,  0.10233922,\n           0.03171736,  0.10239489],\n         [ 0.01610618, -0.03048126, -0.10421265, ..., -0.04390194,\n           0.08561885,  0.17167659]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01272625],\n         [ 0.00728031],\n         [-0.01217502],\n         ...,\n         [-0.027579  ],\n         [ 0.01250099],\n         [-0.01037847]],\n\n        [[-0.0066451 ],\n         [ 0.02831286],\n         [-0.02853808],\n         ...,\n         [-0.01873752],\n         [ 0.00382689],\n         [-0.00273907]],\n\n        [[-0.01166499],\n         [-0.01857358],\n         [ 0.00578545],\n         ...,\n         [-0.01336968],\n         [-0.02097239],\n         [ 0.00595605]]],\n\n\n       [[[-0.0128473 ],\n         [ 0.02809521],\n         [-0.00572962],\n         ...,\n         [-0.02010335],\n         [-0.011215  ],\n         [-0.02284807]],\n\n        [[-0.00082153],\n         [ 0.01884537],\n         [ 0.00780495],\n         ...,\n         [-0.00696189],\n         [ 0.00565941],\n         [ 0.00305079]],\n\n        [[ 0.00650343],\n         [-0.01017918],\n         [ 0.00605743],\n         ...,\n         [ 0.01090154],\n         [ 0.01851295],\n         [ 0.00105348]]],\n\n\n       [[[ 0.00415246],\n         [ 0.01017713],\n         [-0.00482241],\n         ...,\n         [ 0.00561099],\n         [-0.00199022],\n         [-0.01361026]],\n\n        [[ 0.00386302],\n         [-0.00073984],\n         [-0.01768358],\n         ...,\n         [ 0.01622449],\n         [ 0.01467205],\n         [-0.00592439]],\n\n        [[ 0.00721675],\n         [ 0.00694128],\n         [ 0.00374853],\n         ...,\n         [-0.01006365],\n         [-0.01590519],\n         [ 0.00629308]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32, numpy=\narray([[[[ 0.00273761],\n         [ 0.01840184],\n         [ 0.00101   ],\n         ...,\n         [ 0.03413397],\n         [-0.02954865],\n         [-0.02038744]],\n\n        [[-0.03126529],\n         [-0.00116317],\n         [-0.02669207],\n         ...,\n         [-0.06302322],\n         [ 0.03095977],\n         [-0.05862692]],\n\n        [[ 0.01780701],\n         [-0.00188849],\n         [ 0.00049404],\n         ...,\n         [ 0.00953829],\n         [-0.01585733],\n         [-0.03262889]]],\n\n\n       [[[ 0.00426864],\n         [-0.03473822],\n         [ 0.01711899],\n         ...,\n         [-0.03901818],\n         [-0.0070464 ],\n         [ 0.04326975]],\n\n        [[-0.03147697],\n         [-0.03441074],\n         [-0.04883455],\n         ...,\n         [ 0.01327733],\n         [-0.00314525],\n         [-0.03477336]],\n\n        [[ 0.03656965],\n         [-0.03191112],\n         [-0.01642364],\n         ...,\n         [-0.04224136],\n         [-0.02051395],\n         [-0.01923537]]],\n\n\n       [[[ 0.01101114],\n         [ 0.0202704 ],\n         [-0.02399719],\n         ...,\n         [-0.00708194],\n         [ 0.02386889],\n         [-0.01342128]],\n\n        [[-0.00869599],\n         [ 0.01933667],\n         [ 0.05174597],\n         ...,\n         [-0.02846763],\n         [ 0.04372767],\n         [ 0.00262401]],\n\n        [[ 0.04888885],\n         [-0.03226555],\n         [ 0.02704348],\n         ...,\n         [-0.00147522],\n         [-0.04485749],\n         [-0.02772819]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_373/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.04263331],\n         [-0.06288601],\n         [ 0.00477404],\n         ...,\n         [-0.04807945],\n         [-0.03820441],\n         [ 0.07037295]],\n\n        [[-0.04663417],\n         [ 0.05784094],\n         [-0.02211667],\n         ...,\n         [ 0.03838182],\n         [-0.07275215],\n         [ 0.06997608]],\n\n        [[ 0.01055564],\n         [-0.01345254],\n         [ 0.01151282],\n         ...,\n         [ 0.05672888],\n         [-0.07261999],\n         [-0.05797169]]],\n\n\n       [[[ 0.03376754],\n         [-0.06496424],\n         [ 0.01581814],\n         ...,\n         [ 0.01900373],\n         [ 0.05719236],\n         [ 0.02423024]],\n\n        [[-0.04545081],\n         [-0.06339463],\n         [-0.00745048],\n         ...,\n         [ 0.02355675],\n         [ 0.05960526],\n         [-0.04625335]],\n\n        [[-0.04928169],\n         [-0.05738964],\n         [ 0.01630542],\n         ...,\n         [-0.0734398 ],\n         [ 0.02155813],\n         [-0.06700976]]],\n\n\n       [[[-0.04644428],\n         [-0.05793499],\n         [ 0.00464613],\n         ...,\n         [-0.00151309],\n         [-0.01399658],\n         [-0.00424643]],\n\n        [[ 0.00160737],\n         [ 0.06047013],\n         [-0.06176232],\n         ...,\n         [-0.0256828 ],\n         [ 0.01875258],\n         [ 0.06401441]],\n\n        [[ 0.04411042],\n         [ 0.03984445],\n         [ 0.02975758],\n         ...,\n         [-0.02810097],\n         [ 0.07215598],\n         [ 0.04747872]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/gamma:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_352/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[ 0.10001469],\n         [ 0.13312617],\n         [-0.10059712],\n         [-0.0840577 ],\n         [ 0.15206873],\n         [-0.02083839],\n         [-0.05155053],\n         [ 0.11020508],\n         [ 0.04702321],\n         [-0.14137912],\n         [-0.1479309 ],\n         [ 0.0529359 ],\n         [-0.15588734],\n         [-0.10804333],\n         [ 0.00547558],\n         [ 0.12429106],\n         [ 0.09541672],\n         [ 0.11415061],\n         [ 0.15873662],\n         [ 0.06989884],\n         [-0.07574955],\n         [ 0.02112775],\n         [-0.04514755],\n         [-0.096457  ]],\n\n        [[-0.11175588],\n         [-0.10096493],\n         [-0.04420754],\n         [ 0.09282717],\n         [ 0.09311378],\n         [ 0.00801577],\n         [-0.01964749],\n         [ 0.15509629],\n         [ 0.10698187],\n         [-0.09048147],\n         [ 0.1383042 ],\n         [-0.14744654],\n         [ 0.09268925],\n         [ 0.00713992],\n         [ 0.14048791],\n         [-0.14807212],\n         [ 0.09999919],\n         [ 0.14294553],\n         [ 0.05660161],\n         [-0.1587643 ],\n         [ 0.10146621],\n         [-0.08437513],\n         [-0.15285765],\n         [ 0.12299672]],\n\n        [[ 0.05398941],\n         [-0.07741972],\n         [ 0.08774626],\n         [-0.03212458],\n         [-0.08111857],\n         [ 0.11453387],\n         [-0.04332289],\n         [-0.06567338],\n         [-0.11189935],\n         [-0.13045798],\n         [ 0.05246216],\n         [ 0.07704316],\n         [ 0.00615275],\n         [ 0.15890399],\n         [ 0.06699404],\n         [-0.10015266],\n         [ 0.14846304],\n         [-0.05691737],\n         [-0.10016005],\n         [ 0.11074159],\n         [-0.0517714 ],\n         [-0.04316311],\n         [ 0.04376271],\n         [ 0.05692628]]],\n\n\n       [[[-0.12783639],\n         [-0.10170139],\n         [ 0.05655801],\n         [-0.14350346],\n         [ 0.12432042],\n         [-0.03622015],\n         [-0.15380968],\n         [ 0.04874548],\n         [-0.06748558],\n         [ 0.09952906],\n         [ 0.04137835],\n         [-0.11922128],\n         [-0.08485452],\n         [-0.11527473],\n         [ 0.15233809],\n         [-0.03582931],\n         [ 0.0767682 ],\n         [-0.02584696],\n         [-0.09713982],\n         [ 0.13235423],\n         [-0.01523331],\n         [-0.02064836],\n         [ 0.07878618],\n         [-0.11750065]],\n\n        [[ 0.15693933],\n         [-0.14667861],\n         [-0.01683559],\n         [-0.06964134],\n         [-0.04093365],\n         [-0.15532312],\n         [-0.10566639],\n         [ 0.00439276],\n         [ 0.09001011],\n         [ 0.03539565],\n         [ 0.08309819],\n         [-0.11804089],\n         [-0.03537281],\n         [ 0.15246367],\n         [ 0.07489519],\n         [ 0.00810347],\n         [ 0.04117543],\n         [-0.06719658],\n         [-0.10137074],\n         [ 0.08326864],\n         [-0.14270668],\n         [-0.15749429],\n         [ 0.02940795],\n         [-0.16020153]],\n\n        [[-0.138672  ],\n         [ 0.09224272],\n         [-0.12069394],\n         [-0.03783582],\n         [-0.03645808],\n         [ 0.09374353],\n         [ 0.08863407],\n         [-0.07007342],\n         [ 0.00406517],\n         [ 0.13580924],\n         [ 0.00430785],\n         [-0.08296581],\n         [-0.08947582],\n         [ 0.11991331],\n         [ 0.10833943],\n         [-0.04485465],\n         [ 0.09659362],\n         [ 0.13178083],\n         [-0.10084346],\n         [ 0.02697369],\n         [ 0.04423881],\n         [-0.0880885 ],\n         [-0.1458118 ],\n         [-0.1355086 ]]],\n\n\n       [[[ 0.0764813 ],\n         [ 0.00084466],\n         [ 0.1470544 ],\n         [ 0.03860888],\n         [ 0.09628525],\n         [-0.1228219 ],\n         [-0.00537167],\n         [-0.0010125 ],\n         [ 0.09705555],\n         [-0.10845147],\n         [-0.10109757],\n         [ 0.01278307],\n         [-0.08098249],\n         [ 0.09342444],\n         [-0.043586  ],\n         [-0.06804086],\n         [ 0.0301805 ],\n         [ 0.03195545],\n         [-0.04866224],\n         [-0.04038659],\n         [-0.10356363],\n         [ 0.14262527],\n         [-0.04422198],\n         [ 0.0871256 ]],\n\n        [[ 0.10301226],\n         [ 0.06864262],\n         [ 0.09682655],\n         [-0.01638652],\n         [-0.00502971],\n         [ 0.02334718],\n         [-0.05787011],\n         [-0.05860911],\n         [-0.10093546],\n         [ 0.0394312 ],\n         [-0.01531971],\n         [-0.06164613],\n         [-0.09779137],\n         [-0.00999573],\n         [ 0.12439638],\n         [-0.14875735],\n         [ 0.07475911],\n         [ 0.00815199],\n         [ 0.14240155],\n         [-0.02571942],\n         [ 0.02418785],\n         [ 0.09044281],\n         [-0.1175582 ],\n         [-0.09185926]],\n\n        [[-0.09505134],\n         [ 0.03327794],\n         [ 0.14172608],\n         [ 0.05927561],\n         [-0.15562664],\n         [ 0.06807913],\n         [ 0.02597198],\n         [-0.15241863],\n         [ 0.13160947],\n         [ 0.14953697],\n         [-0.14661382],\n         [ 0.13706541],\n         [-0.08536934],\n         [-0.04065181],\n         [-0.04539762],\n         [-0.10432474],\n         [-0.09098157],\n         [-0.03015107],\n         [ 0.08694902],\n         [-0.10212013],\n         [ 0.00323857],\n         [ 0.0143093 ],\n         [ 0.14501524],\n         [ 0.15223223]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32, numpy=\narray([[[[-1.90160889e-02],\n         [ 8.55769869e-03],\n         [ 7.40848249e-03],\n         [-2.57769898e-02],\n         [-8.13578907e-03],\n         [ 4.95368242e-02],\n         [-2.97863968e-02],\n         [-5.42707406e-02],\n         [ 5.83589189e-02],\n         [-3.51196043e-02],\n         [ 3.67196612e-02],\n         [ 2.20721811e-02],\n         [-1.73089001e-02],\n         [ 3.81607525e-02],\n         [ 2.25758459e-02],\n         [ 9.88030992e-03],\n         [-1.72919910e-02],\n         [-3.60557698e-02],\n         [ 5.29062189e-03],\n         [ 3.98513526e-02],\n         [ 5.33022843e-02],\n         [ 6.36270195e-02],\n         [ 4.85002287e-02],\n         [-7.95493601e-04],\n         [ 2.21737735e-02],\n         [-2.58481465e-02],\n         [ 5.59286075e-03],\n         [ 2.51820702e-02],\n         [ 7.62233511e-02],\n         [ 2.08746344e-02],\n         [-3.49819520e-03],\n         [-1.65728629e-02],\n         [-6.16216324e-02],\n         [-2.43379399e-02],\n         [ 4.15821970e-02],\n         [ 6.39693514e-02],\n         [ 5.13687842e-02],\n         [-1.97514184e-02],\n         [ 1.02070663e-02],\n         [-7.61961341e-02],\n         [ 1.27179129e-02],\n         [-3.63764428e-02],\n         [ 2.18997691e-02],\n         [-5.46428338e-02],\n         [ 3.82360481e-02],\n         [-6.28425507e-03],\n         [-5.72638810e-02],\n         [ 6.90188631e-02],\n         [-2.40503587e-02],\n         [ 4.62326966e-03],\n         [-3.29692513e-02],\n         [ 3.23206298e-02],\n         [ 8.83722678e-04],\n         [-8.41705222e-03],\n         [-3.99606526e-02],\n         [-6.34750957e-03],\n         [-1.58585738e-02],\n         [-5.50634563e-02],\n         [ 5.30995317e-02],\n         [-1.28836920e-02],\n         [ 9.30537470e-03],\n         [ 2.09804229e-03],\n         [-1.93841681e-02],\n         [ 1.05347782e-02],\n         [ 1.11155827e-02],\n         [ 1.08445976e-02],\n         [ 3.60366516e-02],\n         [-5.78090083e-03],\n         [-2.81825718e-02],\n         [-2.33819038e-02],\n         [-1.38428351e-02],\n         [-4.12552245e-02],\n         [-2.40287231e-03],\n         [-1.84646677e-02],\n         [ 1.22904507e-02],\n         [ 1.01066642e-02],\n         [-2.47031040e-02],\n         [ 2.50838269e-02],\n         [-6.12689331e-02],\n         [-2.15557180e-02],\n         [-7.14254230e-02],\n         [-6.04167720e-03],\n         [-2.48565488e-02],\n         [ 4.50144745e-02],\n         [-5.07047167e-04],\n         [-5.17293848e-02],\n         [ 2.43586348e-03],\n         [ 4.10685092e-02],\n         [ 2.12247614e-02],\n         [ 5.87182976e-02],\n         [ 1.75710134e-02],\n         [ 2.07354277e-02],\n         [ 3.40621993e-02],\n         [-3.07670422e-02],\n         [-3.18118371e-02],\n         [ 7.58629814e-02]],\n\n        [[ 2.86841504e-02],\n         [-2.90753748e-02],\n         [-1.42791783e-02],\n         [-1.68650951e-02],\n         [-3.34790535e-02],\n         [-7.30769560e-02],\n         [-2.68030539e-02],\n         [-2.50302125e-02],\n         [ 3.29320505e-02],\n         [-4.12235931e-02],\n         [ 6.47536665e-02],\n         [ 1.28947559e-03],\n         [ 7.37283230e-02],\n         [-3.77494097e-02],\n         [ 9.20705206e-04],\n         [-3.54500264e-02],\n         [-1.45461299e-02],\n         [-1.19312601e-02],\n         [ 1.35813914e-02],\n         [-3.44959833e-02],\n         [-4.54218015e-02],\n         [ 6.48302399e-03],\n         [-3.09914420e-03],\n         [ 4.10082899e-02],\n         [ 2.12972742e-02],\n         [-8.24617688e-03],\n         [ 1.34761585e-02],\n         [-7.67567893e-03],\n         [ 2.13364623e-02],\n         [ 1.93197583e-03],\n         [ 5.43924384e-02],\n         [ 1.37227057e-02],\n         [ 5.92507683e-02],\n         [-3.05025559e-02],\n         [ 2.62016691e-02],\n         [ 3.02824434e-02],\n         [ 1.97384413e-02],\n         [ 2.61941403e-02],\n         [ 2.94937622e-02],\n         [-2.90962961e-02],\n         [-1.31109320e-02],\n         [-7.49762058e-02],\n         [-4.10516839e-03],\n         [-4.37277332e-02],\n         [ 5.34159429e-02],\n         [-5.68089895e-02],\n         [ 1.47542451e-02],\n         [-4.15044837e-02],\n         [-7.65726268e-02],\n         [-4.73236479e-02],\n         [ 2.94470717e-03],\n         [-1.71788596e-02],\n         [ 4.39810827e-02],\n         [-4.03269082e-02],\n         [ 8.02136119e-03],\n         [ 4.82406989e-02],\n         [-1.82129294e-02],\n         [-2.97666881e-02],\n         [-4.25536893e-02],\n         [ 6.04979023e-02],\n         [ 3.35657783e-02],\n         [-1.33670690e-02],\n         [-1.22372331e-02],\n         [-2.02408787e-02],\n         [ 6.53217360e-02],\n         [-6.83558881e-02],\n         [ 4.01681960e-02],\n         [ 3.35166976e-02],\n         [ 3.00301351e-02],\n         [-1.89380590e-02],\n         [ 3.87645094e-03],\n         [-1.97119974e-02],\n         [ 1.04216486e-02],\n         [-4.26318496e-02],\n         [ 3.41201983e-02],\n         [ 7.13122264e-02],\n         [ 2.44827699e-02],\n         [ 7.34582990e-02],\n         [-6.37584424e-04],\n         [-6.93784282e-02],\n         [-6.25360943e-03],\n         [-3.82769071e-02],\n         [ 7.26265684e-02],\n         [ 2.31881142e-02],\n         [-1.45788128e-02],\n         [-3.99686843e-02],\n         [-3.75398062e-02],\n         [ 5.28801680e-02],\n         [ 2.03776583e-02],\n         [-6.08669966e-02],\n         [ 5.80535047e-02],\n         [ 9.90150124e-03],\n         [-1.22612445e-02],\n         [-2.12487788e-03],\n         [-6.13570679e-03],\n         [ 1.28253167e-02]],\n\n        [[ 1.78321991e-02],\n         [ 3.52540263e-03],\n         [ 8.69328529e-03],\n         [ 5.51350340e-02],\n         [-1.66669693e-02],\n         [-9.05857701e-03],\n         [-4.19413624e-03],\n         [ 2.45327484e-02],\n         [ 4.02850695e-02],\n         [ 3.66112334e-03],\n         [-3.10312118e-02],\n         [-1.79302786e-02],\n         [ 2.75723431e-02],\n         [-6.43176660e-02],\n         [-2.88273860e-03],\n         [-6.10434338e-02],\n         [ 3.04565940e-04],\n         [-3.06480639e-02],\n         [ 3.88599187e-02],\n         [ 5.06903790e-02],\n         [ 1.03382682e-02],\n         [ 2.36488190e-02],\n         [-6.06590556e-03],\n         [-3.16828154e-02],\n         [ 3.57676484e-02],\n         [-5.13529181e-02],\n         [-3.35097965e-03],\n         [-2.34881770e-02],\n         [ 1.06381942e-02],\n         [ 2.10531224e-02],\n         [-5.78047335e-03],\n         [ 1.32255554e-02],\n         [ 4.16406542e-02],\n         [ 2.08775289e-02],\n         [ 2.24578083e-02],\n         [-3.14511284e-02],\n         [-1.43834874e-02],\n         [-4.88085076e-02],\n         [-7.12350830e-02],\n         [-4.14953940e-02],\n         [-3.08229658e-03],\n         [ 3.93391885e-02],\n         [-6.54832721e-02],\n         [-1.33407849e-03],\n         [ 6.23984151e-02],\n         [ 2.61615124e-02],\n         [-1.31307133e-02],\n         [-1.50887929e-02],\n         [ 1.52213611e-02],\n         [-2.41810903e-02],\n         [ 2.77113784e-02],\n         [ 2.50880551e-02],\n         [-1.17928656e-02],\n         [-4.20650356e-02],\n         [-1.07062813e-02],\n         [-6.51940405e-02],\n         [ 3.41940895e-02],\n         [-1.63996238e-02],\n         [-2.32980177e-02],\n         [ 3.29232849e-02],\n         [-8.85374751e-03],\n         [ 3.85922119e-02],\n         [-3.52485701e-02],\n         [ 2.44478825e-02],\n         [-1.32598449e-02],\n         [ 1.24570075e-02],\n         [-1.68649759e-02],\n         [-2.37990972e-02],\n         [ 4.80658635e-02],\n         [-2.06871852e-02],\n         [-3.64925899e-02],\n         [-4.18528877e-02],\n         [-4.08642143e-02],\n         [-4.44239518e-03],\n         [ 2.18017735e-02],\n         [ 4.11264002e-02],\n         [ 1.07586952e-02],\n         [-6.25929087e-02],\n         [-1.52672930e-02],\n         [ 1.18325092e-02],\n         [-4.81702201e-02],\n         [-6.55871704e-02],\n         [-2.69706286e-02],\n         [-5.61708659e-02],\n         [ 1.89562719e-02],\n         [ 4.14320081e-02],\n         [-6.60058334e-02],\n         [-4.98724431e-02],\n         [-3.36601697e-02],\n         [ 1.34921949e-02],\n         [-3.34772691e-02],\n         [-1.11695761e-02],\n         [-2.40365509e-02],\n         [ 5.01842946e-02],\n         [-4.98277992e-02],\n         [ 9.67855845e-03]]],\n\n\n       [[[-4.64680139e-03],\n         [-1.91865284e-02],\n         [-3.99850458e-02],\n         [-5.87839866e-04],\n         [-3.54266502e-02],\n         [ 5.48285395e-02],\n         [ 4.90917340e-02],\n         [ 1.41928615e-02],\n         [ 3.41797806e-02],\n         [-8.72857345e-04],\n         [-6.58218041e-02],\n         [-3.75170335e-02],\n         [-2.62529701e-02],\n         [-9.77869891e-03],\n         [-5.11245504e-02],\n         [ 3.84107605e-02],\n         [-5.34661040e-02],\n         [ 3.89951952e-02],\n         [ 7.43405148e-02],\n         [-4.82621370e-03],\n         [ 4.16626520e-02],\n         [ 3.83932702e-02],\n         [ 3.54097076e-02],\n         [ 5.22870645e-02],\n         [ 4.62999418e-02],\n         [ 1.05635673e-02],\n         [-1.58611126e-02],\n         [ 4.64394353e-02],\n         [-5.10240300e-03],\n         [-1.60327461e-02],\n         [-2.50356775e-02],\n         [-1.60772111e-02],\n         [ 1.23649277e-03],\n         [ 4.06242087e-02],\n         [-6.39205948e-02],\n         [-3.28747705e-02],\n         [-1.69761237e-02],\n         [ 3.26623432e-02],\n         [ 3.53783965e-02],\n         [-4.04498465e-02],\n         [ 1.03932517e-02],\n         [-1.35556208e-02],\n         [-4.81741615e-02],\n         [ 2.86245323e-03],\n         [-2.69097299e-03],\n         [ 2.89227925e-02],\n         [-2.93226354e-02],\n         [ 2.15702970e-02],\n         [-4.49868385e-03],\n         [ 1.20356455e-02],\n         [-4.08714563e-02],\n         [ 3.31743434e-02],\n         [-5.18817315e-03],\n         [ 2.42372621e-02],\n         [ 2.65531838e-02],\n         [-9.19512566e-03],\n         [-2.84051476e-03],\n         [ 1.65928621e-02],\n         [ 1.21588707e-02],\n         [-4.61118761e-03],\n         [ 2.41015088e-02],\n         [-8.43095500e-03],\n         [ 1.47917762e-03],\n         [ 1.08291553e-02],\n         [ 5.81129678e-02],\n         [ 4.13350500e-02],\n         [-2.56471825e-03],\n         [ 7.21534118e-02],\n         [ 6.96794922e-03],\n         [ 3.47403390e-03],\n         [ 3.62009145e-02],\n         [-4.63912785e-02],\n         [-3.15381326e-02],\n         [ 1.03032095e-02],\n         [-4.83709499e-02],\n         [ 4.81650345e-02],\n         [ 3.32553163e-02],\n         [-7.05641881e-03],\n         [-2.76282672e-02],\n         [-1.90628767e-02],\n         [-3.56937572e-02],\n         [-5.38310260e-02],\n         [ 5.00832684e-02],\n         [-2.71977810e-03],\n         [-1.42642995e-02],\n         [ 2.00925227e-02],\n         [ 5.20729944e-02],\n         [-7.02719986e-02],\n         [-9.84746683e-03],\n         [-4.33089025e-02],\n         [-3.70783806e-02],\n         [-1.95435341e-03],\n         [-5.50831743e-02],\n         [ 1.93897057e-02],\n         [-2.73871876e-04],\n         [ 2.90807392e-02]],\n\n        [[-6.74395263e-02],\n         [ 4.32557203e-02],\n         [ 1.94679629e-02],\n         [ 1.38694318e-02],\n         [-3.02368961e-02],\n         [-3.89602520e-02],\n         [ 1.02418754e-02],\n         [-1.25367567e-03],\n         [ 1.96299180e-02],\n         [ 3.93325426e-02],\n         [ 1.10083465e-02],\n         [ 2.40730140e-02],\n         [ 8.18834174e-03],\n         [-2.28850432e-02],\n         [ 8.12405348e-03],\n         [ 1.79094542e-02],\n         [ 4.31548171e-02],\n         [-4.68930565e-02],\n         [ 9.19088628e-03],\n         [-5.05662896e-02],\n         [ 1.66500546e-02],\n         [-1.60634462e-02],\n         [-6.83423318e-03],\n         [-3.87573354e-02],\n         [ 2.43681762e-03],\n         [ 2.42828391e-02],\n         [ 8.33588373e-03],\n         [-1.88937166e-03],\n         [-4.78344448e-02],\n         [ 1.81965530e-02],\n         [-6.88301474e-02],\n         [-4.47501764e-02],\n         [ 2.51650028e-02],\n         [ 7.39559829e-02],\n         [-3.35531048e-02],\n         [-2.98859123e-02],\n         [ 2.12868042e-02],\n         [-2.35810112e-02],\n         [ 7.38676861e-02],\n         [ 9.60389432e-03],\n         [-8.34713131e-03],\n         [ 3.15413438e-02],\n         [-7.29163736e-02],\n         [-4.23950776e-02],\n         [-1.14294840e-02],\n         [-4.59900200e-02],\n         [-3.70372236e-02],\n         [ 1.38172572e-02],\n         [ 3.21126543e-02],\n         [-6.51196763e-03],\n         [-1.85906719e-02],\n         [ 2.43448615e-02],\n         [-8.59650597e-03],\n         [-4.25778553e-02],\n         [ 4.63605113e-02],\n         [-1.34887930e-03],\n         [-3.80540569e-03],\n         [-2.94191241e-02],\n         [-5.56971990e-02],\n         [ 3.11283059e-02],\n         [-5.89338178e-03],\n         [-1.88801754e-02],\n         [ 5.56643717e-02],\n         [-5.57514206e-02],\n         [-6.38994295e-03],\n         [ 3.25407237e-02],\n         [-5.25850430e-02],\n         [-9.33761057e-03],\n         [-2.09331177e-02],\n         [-2.79502720e-02],\n         [ 4.27337065e-02],\n         [ 7.46503007e-03],\n         [-2.12693792e-02],\n         [ 2.87652463e-02],\n         [ 4.72236723e-02],\n         [ 6.55288901e-03],\n         [-7.00667426e-02],\n         [ 4.98267300e-02],\n         [ 4.71049827e-03],\n         [-3.96759761e-03],\n         [ 2.63300957e-03],\n         [-3.52290235e-02],\n         [ 7.62251467e-02],\n         [-4.11124229e-02],\n         [ 1.02957794e-02],\n         [-1.16070807e-02],\n         [-7.51058850e-03],\n         [ 6.47347420e-02],\n         [-3.83506995e-03],\n         [ 6.78133890e-02],\n         [ 7.71264965e-03],\n         [ 4.10412773e-02],\n         [-1.00502521e-02],\n         [-3.81018594e-02],\n         [-1.73107032e-02],\n         [ 2.35231695e-04]],\n\n        [[-2.06546541e-02],\n         [-4.05387394e-02],\n         [-6.36429293e-04],\n         [-2.48058159e-02],\n         [ 3.93921211e-02],\n         [-1.64525229e-02],\n         [ 7.79196806e-03],\n         [ 2.15941612e-02],\n         [ 3.55941802e-02],\n         [ 1.44613907e-02],\n         [-1.09461127e-02],\n         [-2.54917797e-02],\n         [ 8.22267123e-03],\n         [ 1.57667901e-02],\n         [ 1.44752637e-02],\n         [ 2.23349705e-02],\n         [-1.89722665e-02],\n         [ 6.37795450e-03],\n         [-4.54066843e-02],\n         [ 2.61826552e-02],\n         [ 1.34759005e-02],\n         [-1.84010845e-02],\n         [-3.08709797e-02],\n         [-5.64446300e-02],\n         [ 3.84760350e-02],\n         [ 9.87800490e-03],\n         [ 1.29271932e-02],\n         [-1.55530013e-02],\n         [-2.79720202e-02],\n         [ 3.90259437e-02],\n         [ 3.06299850e-02],\n         [ 1.65673569e-02],\n         [ 2.13436764e-02],\n         [-1.01100300e-02],\n         [ 2.37435885e-02],\n         [ 1.41908992e-02],\n         [ 2.78286356e-02],\n         [-5.78923500e-04],\n         [ 5.55674965e-03],\n         [-6.27913186e-03],\n         [ 6.37861639e-02],\n         [-3.20162647e-03],\n         [ 3.09657641e-02],\n         [-3.52709182e-02],\n         [-4.55339737e-02],\n         [ 6.42167404e-02],\n         [ 4.14626822e-02],\n         [-6.60510287e-02],\n         [ 8.82186182e-03],\n         [ 3.83737287e-03],\n         [-5.67292683e-02],\n         [ 2.93677635e-02],\n         [ 1.40585089e-02],\n         [-4.11898345e-02],\n         [-2.76859794e-02],\n         [-1.62277948e-02],\n         [ 1.66427679e-02],\n         [-4.81642485e-02],\n         [-2.58113090e-02],\n         [ 2.12432761e-02],\n         [ 7.71180615e-02],\n         [-2.19570436e-02],\n         [-1.30429771e-02],\n         [ 3.58745903e-02],\n         [-7.77779007e-03],\n         [-2.78367326e-02],\n         [ 4.28582216e-03],\n         [ 5.82197532e-02],\n         [ 1.22893229e-02],\n         [-2.56866310e-02],\n         [-3.34948935e-02],\n         [-4.86595090e-03],\n         [-4.89291698e-02],\n         [ 2.93815206e-03],\n         [-1.32133695e-03],\n         [ 9.30861011e-03],\n         [-2.66279485e-02],\n         [ 1.78464856e-02],\n         [ 8.67902674e-03],\n         [-4.10268158e-02],\n         [ 3.09227896e-03],\n         [-2.98239440e-02],\n         [ 1.38280243e-02],\n         [ 2.18158471e-03],\n         [ 1.91902462e-03],\n         [-4.53047752e-02],\n         [ 2.33070999e-02],\n         [ 3.57807763e-02],\n         [-1.18171070e-02],\n         [-2.12659650e-02],\n         [-7.57923201e-02],\n         [ 3.11290268e-02],\n         [ 1.92667656e-02],\n         [ 6.86241686e-02],\n         [-4.68439143e-03],\n         [-6.04944527e-02]]],\n\n\n       [[[-3.41465659e-02],\n         [ 5.81638254e-02],\n         [ 1.56380925e-02],\n         [-4.25218679e-02],\n         [ 5.37979370e-03],\n         [ 1.60052981e-02],\n         [-5.82351089e-02],\n         [ 6.57215863e-02],\n         [-1.13178901e-02],\n         [-2.88999341e-02],\n         [-6.28021732e-02],\n         [ 3.29784453e-02],\n         [ 5.43721095e-02],\n         [ 2.54591610e-02],\n         [-3.21672820e-02],\n         [ 5.53741939e-02],\n         [ 9.81798396e-03],\n         [ 3.46757285e-02],\n         [ 3.66533324e-02],\n         [ 3.15880626e-02],\n         [ 7.01450557e-02],\n         [-6.43768162e-02],\n         [-2.48144064e-02],\n         [ 1.67769790e-02],\n         [ 4.55061346e-02],\n         [-5.07331314e-03],\n         [-1.75252501e-02],\n         [-1.59028824e-02],\n         [ 1.13984076e-02],\n         [ 4.06104922e-02],\n         [-6.69032708e-02],\n         [-5.58005348e-02],\n         [-2.88016107e-02],\n         [-4.96260673e-02],\n         [-3.39032039e-02],\n         [ 5.62938675e-03],\n         [ 4.66414578e-02],\n         [ 5.90855964e-02],\n         [ 5.44242226e-02],\n         [ 2.20182557e-02],\n         [-3.43444990e-03],\n         [ 2.90858727e-02],\n         [ 5.94939431e-03],\n         [-2.86477674e-02],\n         [-3.08004990e-02],\n         [-2.47117653e-02],\n         [-4.63868231e-02],\n         [ 7.17238784e-02],\n         [ 1.71008836e-02],\n         [-4.71023470e-02],\n         [-4.42099161e-02],\n         [ 1.19843511e-02],\n         [ 6.47959858e-02],\n         [-3.29784416e-02],\n         [-7.45706772e-03],\n         [-2.95829382e-02],\n         [-2.45215856e-02],\n         [ 4.37009074e-02],\n         [-3.24823521e-03],\n         [-2.67674327e-02],\n         [-1.08348038e-02],\n         [-9.31677781e-03],\n         [-2.88844872e-02],\n         [ 1.33068049e-02],\n         [-3.11212689e-02],\n         [-3.12990695e-02],\n         [-5.04442025e-04],\n         [ 2.57508047e-02],\n         [-3.94091681e-02],\n         [-6.17339015e-02],\n         [ 4.90235910e-02],\n         [-1.21262120e-02],\n         [ 4.22374792e-02],\n         [ 4.33656387e-02],\n         [-3.88936885e-02],\n         [-1.06513966e-02],\n         [-1.76367145e-02],\n         [-3.03303972e-02],\n         [ 1.84642561e-02],\n         [-6.80963099e-02],\n         [-2.75295936e-02],\n         [-3.93952755e-03],\n         [ 1.29523044e-02],\n         [ 3.19160782e-02],\n         [-4.56807017e-02],\n         [ 1.50446594e-02],\n         [ 2.22309362e-02],\n         [-4.81259525e-02],\n         [ 1.13944318e-02],\n         [-7.22853541e-02],\n         [-2.72589419e-02],\n         [ 1.10309981e-02],\n         [ 5.54347336e-02],\n         [-8.10986571e-03],\n         [ 2.04334650e-02],\n         [ 2.21726410e-02]],\n\n        [[ 1.97344963e-02],\n         [ 3.34124155e-02],\n         [-3.41649167e-02],\n         [ 7.55426884e-02],\n         [-1.34485746e-02],\n         [-1.51635744e-02],\n         [-3.00866384e-02],\n         [-6.88824654e-02],\n         [ 4.37152311e-02],\n         [-5.35400212e-02],\n         [ 1.92199938e-03],\n         [-3.85545641e-02],\n         [ 1.57548990e-02],\n         [-2.57950258e-02],\n         [-5.36139421e-02],\n         [-5.46980090e-02],\n         [ 7.39246316e-04],\n         [ 2.41459347e-03],\n         [-7.41394311e-02],\n         [ 1.49446102e-02],\n         [ 2.38039414e-03],\n         [-4.62909378e-02],\n         [-3.22352946e-02],\n         [ 4.58682664e-02],\n         [ 1.51627911e-02],\n         [-5.31959571e-02],\n         [ 4.84510027e-02],\n         [-8.54962133e-03],\n         [ 2.98969522e-02],\n         [ 1.64800901e-02],\n         [ 7.50461295e-02],\n         [ 3.26598622e-03],\n         [ 3.09518464e-02],\n         [ 2.26831678e-02],\n         [-2.00685468e-02],\n         [-3.74395847e-02],\n         [-5.02397232e-02],\n         [ 5.43880882e-03],\n         [ 3.20787504e-02],\n         [-3.10423169e-02],\n         [-5.80419712e-02],\n         [-6.11436963e-02],\n         [-5.78401759e-02],\n         [-7.58594414e-03],\n         [ 4.02283929e-02],\n         [ 2.67925840e-02],\n         [-3.57044004e-02],\n         [-1.77380107e-02],\n         [-6.91286477e-05],\n         [-1.28558958e-02],\n         [ 4.72057238e-03],\n         [ 5.82720786e-02],\n         [-2.31368910e-03],\n         [ 6.48346916e-03],\n         [-2.45214216e-02],\n         [-1.68843176e-02],\n         [-4.50990163e-02],\n         [ 1.57752354e-02],\n         [-1.87138673e-02],\n         [-1.33384662e-02],\n         [ 5.75799495e-03],\n         [-1.15012228e-02],\n         [-2.13075746e-02],\n         [-1.59209203e-02],\n         [-3.75638716e-03],\n         [-1.38817811e-02],\n         [ 3.01352013e-02],\n         [-9.30990186e-03],\n         [-5.95276069e-04],\n         [ 4.41431776e-02],\n         [ 1.77764334e-02],\n         [ 1.06397877e-02],\n         [-4.87470925e-02],\n         [ 6.56936467e-02],\n         [-1.34581001e-02],\n         [-5.13215847e-02],\n         [ 2.46132202e-02],\n         [ 1.25330370e-02],\n         [ 3.60654742e-02],\n         [ 4.65048151e-03],\n         [ 1.26185296e-02],\n         [-2.38201767e-02],\n         [ 1.16250257e-03],\n         [-1.94289126e-02],\n         [ 6.59322441e-02],\n         [-2.35691555e-02],\n         [-5.02180122e-02],\n         [-5.74936206e-03],\n         [-2.66437884e-02],\n         [-5.63602836e-04],\n         [-2.21516155e-02],\n         [-1.99179891e-02],\n         [-6.03596531e-02],\n         [ 1.84425469e-02],\n         [ 3.49337831e-02],\n         [ 3.97745073e-02]],\n\n        [[ 2.85815615e-02],\n         [ 2.44856812e-02],\n         [-1.54120205e-02],\n         [ 5.79418913e-02],\n         [ 2.56738868e-02],\n         [-1.81693025e-02],\n         [-9.73844528e-03],\n         [-1.73406042e-02],\n         [-3.53817479e-03],\n         [ 4.20774817e-02],\n         [ 2.33705249e-02],\n         [ 1.07041504e-02],\n         [-9.59975459e-03],\n         [-5.45060188e-02],\n         [ 4.00467729e-03],\n         [-4.34475020e-02],\n         [ 5.36432266e-02],\n         [ 5.89255951e-02],\n         [-1.29372543e-02],\n         [-4.00446691e-02],\n         [-4.62214870e-04],\n         [-1.11353640e-02],\n         [-1.04453731e-02],\n         [ 2.89717573e-03],\n         [-6.44698292e-02],\n         [-7.59332394e-03],\n         [-8.54592770e-03],\n         [ 1.50192585e-02],\n         [-4.32775840e-02],\n         [ 5.03191613e-02],\n         [ 1.44195631e-02],\n         [-1.84308086e-02],\n         [ 5.44398930e-03],\n         [ 5.10232635e-02],\n         [-3.08292601e-02],\n         [-2.55938247e-03],\n         [ 3.02674482e-03],\n         [-3.78650427e-02],\n         [ 3.64730433e-02],\n         [ 5.53104356e-02],\n         [ 5.60677908e-02],\n         [-3.41725908e-02],\n         [-2.39204541e-02],\n         [-5.17999679e-02],\n         [-2.22356506e-02],\n         [ 2.10858379e-02],\n         [ 2.44526491e-02],\n         [-1.97184142e-02],\n         [-7.24752396e-02],\n         [-2.36421339e-02],\n         [ 5.70698008e-02],\n         [ 8.17507133e-03],\n         [ 4.20638872e-03],\n         [-1.52752139e-02],\n         [ 4.60575037e-02],\n         [ 2.75822226e-02],\n         [-5.43203689e-02],\n         [-4.19757217e-02],\n         [ 1.30052445e-02],\n         [-3.48091982e-02],\n         [-2.14055795e-02],\n         [ 7.56405219e-02],\n         [-6.59000352e-02],\n         [ 1.51229417e-02],\n         [ 6.39136136e-02],\n         [-1.55721344e-02],\n         [ 5.41127007e-03],\n         [ 3.42050823e-03],\n         [ 2.36518234e-02],\n         [ 7.56104589e-02],\n         [-4.93267775e-02],\n         [-1.66745856e-02],\n         [ 1.90046653e-02],\n         [-2.80911904e-02],\n         [ 8.18926934e-03],\n         [ 6.37791604e-02],\n         [ 8.76459200e-03],\n         [-4.53863330e-02],\n         [ 2.36270893e-02],\n         [-4.82450984e-02],\n         [ 2.53257584e-02],\n         [-5.70374429e-02],\n         [-7.23257139e-02],\n         [ 5.51828146e-02],\n         [-3.17415893e-02],\n         [ 1.58346016e-02],\n         [ 1.78072024e-02],\n         [-5.49448505e-02],\n         [ 5.24226483e-03],\n         [-1.70902368e-02],\n         [-2.16505975e-02],\n         [ 9.50210914e-03],\n         [-1.80623569e-02],\n         [ 2.51439703e-03],\n         [ 8.21074354e-04],\n         [ 1.93892773e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.08582504, -0.03154688, -0.02472441, ...,  0.05114538,\n           0.02134192,  0.08217423],\n         [-0.02687356, -0.03523573, -0.02748936, ...,  0.00829158,\n          -0.00424485, -0.05202765],\n         [-0.02399553,  0.01546687, -0.01261965, ..., -0.02033881,\n          -0.01851904, -0.01318672],\n         ...,\n         [ 0.04365416,  0.00028961, -0.0380946 , ...,  0.03771873,\n          -0.00818539,  0.00801078],\n         [ 0.05301303,  0.00112985,  0.01298863, ..., -0.06383356,\n          -0.07071722,  0.07320289],\n         [ 0.03127687,  0.03877531,  0.07543416, ...,  0.05840112,\n          -0.05934082, -0.03483654]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_362/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 4.28269953e-02],\n         [ 8.46724361e-02],\n         [ 5.39221615e-03],\n         [-8.17120820e-03],\n         [ 2.07749680e-02],\n         [ 5.07356673e-02],\n         [ 4.58774865e-02],\n         [-8.47737864e-02],\n         [-1.13191381e-02],\n         [-4.20750156e-02],\n         [-7.80195445e-02],\n         [-1.50079727e-02],\n         [-7.85644650e-02],\n         [ 8.66185874e-02],\n         [-3.74215618e-02],\n         [-1.83688924e-02],\n         [-3.13784629e-02],\n         [-8.08448717e-02],\n         [ 2.97465846e-02],\n         [ 3.77123356e-02],\n         [ 8.81125182e-02],\n         [ 5.50087690e-02],\n         [ 3.96977365e-03],\n         [ 1.18944049e-02],\n         [-8.63856599e-02],\n         [ 2.30550691e-02],\n         [ 6.94445968e-02],\n         [-2.06224769e-02],\n         [ 6.03375882e-02],\n         [ 5.93662411e-02],\n         [ 1.40510872e-02],\n         [-5.61439060e-02],\n         [ 4.38373834e-02],\n         [-6.04808703e-02],\n         [ 4.10610735e-02],\n         [ 4.32150811e-02],\n         [-1.61305964e-02],\n         [-3.47953178e-02],\n         [-6.06836900e-02],\n         [ 1.37610584e-02],\n         [-2.92449258e-02],\n         [-4.65401150e-02],\n         [ 3.27540711e-02],\n         [ 6.15942180e-02],\n         [-6.50064051e-02],\n         [ 4.36626673e-02],\n         [-7.31704533e-02],\n         [ 6.83103055e-02],\n         [ 4.90907580e-02],\n         [ 8.22643042e-02],\n         [-9.00026560e-02],\n         [-2.92925984e-02],\n         [ 6.45719022e-02],\n         [-5.06734326e-02],\n         [ 8.25121105e-02],\n         [-6.83700070e-02],\n         [ 4.37162369e-02],\n         [-8.68562609e-02],\n         [ 7.01926649e-02],\n         [-5.28914146e-02],\n         [-5.66179864e-02],\n         [-3.80210541e-02],\n         [ 5.92679828e-02],\n         [ 8.95935446e-02],\n         [-5.53652570e-02],\n         [ 8.95287097e-02],\n         [-2.78583169e-03],\n         [ 6.20062053e-02],\n         [ 1.57074779e-02],\n         [ 7.71839023e-02],\n         [-2.28914618e-02],\n         [-8.08405653e-02],\n         [ 2.13974044e-02],\n         [-2.10771561e-02],\n         [ 1.47674233e-02],\n         [ 3.37278694e-02],\n         [-5.44464588e-03],\n         [-3.60045321e-02],\n         [-3.27149034e-02],\n         [-3.12917493e-02]],\n\n        [[ 8.08229148e-02],\n         [ 6.97452873e-02],\n         [ 1.84553042e-02],\n         [ 8.07527304e-02],\n         [ 1.02674365e-02],\n         [-5.81119992e-02],\n         [ 4.50941175e-02],\n         [-5.34976982e-02],\n         [ 4.39196080e-02],\n         [-6.65856600e-02],\n         [ 6.70263469e-02],\n         [ 8.39530677e-02],\n         [-6.19964227e-02],\n         [-3.29031795e-03],\n         [ 5.79956472e-02],\n         [ 2.65475810e-02],\n         [ 4.28702086e-02],\n         [-2.96014696e-02],\n         [-1.80319399e-02],\n         [-1.39070973e-02],\n         [ 6.30037189e-02],\n         [-7.66180903e-02],\n         [-7.40779340e-02],\n         [-3.33965011e-02],\n         [-6.76903725e-02],\n         [-9.38634574e-03],\n         [ 6.59121573e-03],\n         [-4.78502288e-02],\n         [-4.37137708e-02],\n         [-2.59595364e-02],\n         [-3.03943753e-02],\n         [-7.51628131e-02],\n         [-6.52876347e-02],\n         [-8.59321728e-02],\n         [-8.33602175e-02],\n         [-5.36965169e-02],\n         [-7.01468438e-02],\n         [-5.29133528e-03],\n         [ 7.92012662e-02],\n         [-3.98632400e-02],\n         [-6.78558424e-02],\n         [-4.95172776e-02],\n         [ 8.75190645e-02],\n         [ 8.59352797e-02],\n         [-4.44206968e-02],\n         [ 2.66710892e-02],\n         [ 3.95102054e-02],\n         [ 5.07500619e-02],\n         [ 3.21748704e-02],\n         [-4.72914651e-02],\n         [ 3.83873284e-02],\n         [ 5.09196520e-02],\n         [ 2.86727324e-02],\n         [-7.61229545e-03],\n         [ 7.09731430e-02],\n         [-5.91117926e-02],\n         [ 4.53509986e-02],\n         [ 1.59333646e-03],\n         [-5.61313406e-02],\n         [-2.27809101e-02],\n         [-8.73516053e-02],\n         [ 4.30742651e-02],\n         [ 1.10983849e-04],\n         [-5.40995039e-02],\n         [ 7.17569888e-03],\n         [ 6.26754463e-02],\n         [-3.02238874e-02],\n         [ 6.54036105e-02],\n         [-8.37131962e-02],\n         [-7.20845088e-02],\n         [ 6.73909783e-02],\n         [-6.08345792e-02],\n         [-8.37994069e-02],\n         [-4.73284088e-02],\n         [-8.65198970e-02],\n         [-2.93880068e-02],\n         [-5.48602864e-02],\n         [ 7.05562383e-02],\n         [-7.91203529e-02],\n         [ 4.69418019e-02]],\n\n        [[ 7.28705078e-02],\n         [-8.51018056e-02],\n         [-4.59615178e-02],\n         [ 7.04643875e-03],\n         [ 3.02229822e-02],\n         [ 4.77257669e-02],\n         [ 6.80828691e-02],\n         [-7.70705193e-02],\n         [ 3.41712385e-02],\n         [ 4.79703844e-02],\n         [-4.95088659e-02],\n         [-2.79208571e-02],\n         [ 8.78461897e-02],\n         [-7.13086724e-02],\n         [-7.69459754e-02],\n         [ 6.42100573e-02],\n         [-1.54028833e-02],\n         [ 1.78284049e-02],\n         [-7.36938715e-02],\n         [ 9.12173092e-03],\n         [ 6.09690994e-02],\n         [ 4.29426879e-03],\n         [-2.59544104e-02],\n         [ 4.13956046e-02],\n         [ 1.02830082e-02],\n         [ 7.62232989e-02],\n         [-3.07073146e-02],\n         [-2.06271484e-02],\n         [-8.80261064e-02],\n         [-6.04937226e-03],\n         [ 8.07984471e-02],\n         [-1.94637477e-03],\n         [-7.80182928e-02],\n         [ 7.07685053e-02],\n         [ 2.80540958e-02],\n         [ 6.70236349e-02],\n         [ 8.73848200e-02],\n         [ 5.02893478e-02],\n         [ 2.37325951e-02],\n         [ 7.00959116e-02],\n         [-6.11191206e-02],\n         [-8.48576427e-04],\n         [-4.78450805e-02],\n         [-8.12107772e-02],\n         [-1.58459917e-02],\n         [-1.73354149e-03],\n         [ 5.71528226e-02],\n         [-8.92080441e-02],\n         [ 2.62036473e-02],\n         [-4.40712906e-02],\n         [ 1.26582608e-02],\n         [ 8.75729024e-02],\n         [ 7.45024383e-02],\n         [ 4.31228280e-02],\n         [-6.07036352e-02],\n         [-4.48594354e-02],\n         [ 7.86433667e-02],\n         [ 6.26421124e-02],\n         [-4.62650694e-02],\n         [-6.89353868e-02],\n         [-5.42144664e-02],\n         [-3.14252041e-02],\n         [ 5.24268448e-02],\n         [ 3.08040231e-02],\n         [-6.66236803e-02],\n         [-8.19105208e-02],\n         [-4.98717912e-02],\n         [-2.16535032e-02],\n         [ 5.03255427e-03],\n         [-1.52296945e-02],\n         [ 4.59656417e-02],\n         [-4.83131260e-02],\n         [ 1.51817501e-03],\n         [-1.84968337e-02],\n         [ 6.24037087e-02],\n         [-1.07339695e-02],\n         [-3.93754654e-02],\n         [-8.40526968e-02],\n         [-1.11565068e-02],\n         [-7.02010095e-02]]],\n\n\n       [[[-1.88174844e-03],\n         [-3.95279340e-02],\n         [-1.16212219e-02],\n         [-5.74074313e-02],\n         [-2.06013247e-02],\n         [-8.26342776e-02],\n         [-7.36834258e-02],\n         [-1.08584240e-02],\n         [ 8.21966827e-02],\n         [ 5.38731515e-02],\n         [-6.95563853e-03],\n         [-8.21231231e-02],\n         [ 7.84364790e-02],\n         [-7.03761280e-02],\n         [-2.77230889e-03],\n         [-6.93803951e-02],\n         [ 3.57173383e-04],\n         [ 8.28897506e-02],\n         [ 7.91763961e-02],\n         [-5.46111986e-02],\n         [ 2.53843591e-02],\n         [-8.99789482e-02],\n         [-3.33938412e-02],\n         [ 6.86710328e-02],\n         [-3.76909822e-02],\n         [ 6.14869744e-02],\n         [ 7.20043927e-02],\n         [ 1.50363892e-03],\n         [ 5.52062094e-02],\n         [ 5.70312291e-02],\n         [ 1.45866647e-02],\n         [-5.88830784e-02],\n         [-3.54687832e-02],\n         [ 4.34832275e-02],\n         [-5.01024053e-02],\n         [-2.76517123e-03],\n         [-4.00847271e-02],\n         [ 6.14974946e-02],\n         [ 8.09743404e-02],\n         [-3.15937027e-02],\n         [-4.48716134e-02],\n         [ 1.10346898e-02],\n         [-8.54407847e-02],\n         [-8.79987851e-02],\n         [-2.05985084e-02],\n         [ 3.40024829e-02],\n         [ 8.72720033e-03],\n         [ 1.27187148e-02],\n         [ 8.37341547e-02],\n         [ 2.95871496e-02],\n         [-1.18961409e-02],\n         [ 8.29768181e-03],\n         [-8.82872194e-02],\n         [ 2.92985886e-03],\n         [-2.52170935e-02],\n         [ 2.35160440e-02],\n         [-4.91173007e-02],\n         [ 6.32706732e-02],\n         [ 4.74678129e-02],\n         [ 4.81871516e-02],\n         [ 4.86250669e-02],\n         [ 9.04350579e-02],\n         [-1.94194689e-02],\n         [ 8.98382664e-02],\n         [-2.97903642e-02],\n         [ 6.71013296e-02],\n         [-1.99943036e-02],\n         [-4.10344936e-02],\n         [-6.06265254e-02],\n         [ 6.49362355e-02],\n         [-8.97735730e-02],\n         [ 5.78931421e-02],\n         [ 5.61877638e-02],\n         [ 1.08370334e-02],\n         [ 7.03570098e-02],\n         [ 6.59906864e-02],\n         [-5.09135239e-02],\n         [ 4.20082659e-02],\n         [-4.42665629e-02],\n         [-2.26240531e-02]],\n\n        [[-2.61288732e-02],\n         [ 3.26860696e-03],\n         [ 1.06093809e-02],\n         [ 6.15821928e-02],\n         [ 8.47809017e-02],\n         [-8.64596963e-02],\n         [ 9.78504866e-03],\n         [ 1.17909312e-02],\n         [ 2.80781910e-02],\n         [-2.14898065e-02],\n         [-4.42550778e-02],\n         [-3.04374099e-03],\n         [-6.37948513e-02],\n         [ 5.68743646e-02],\n         [ 3.23657990e-02],\n         [-6.91337138e-03],\n         [ 2.35499963e-02],\n         [-5.26974835e-02],\n         [-3.15858945e-02],\n         [ 5.04564643e-02],\n         [-6.41708449e-02],\n         [ 6.00376129e-02],\n         [ 4.54047024e-02],\n         [-7.36108422e-03],\n         [ 2.84871683e-02],\n         [ 5.01757711e-02],\n         [-2.07389072e-02],\n         [-4.28575575e-02],\n         [-8.57160464e-02],\n         [-5.04826158e-02],\n         [ 1.11802146e-02],\n         [-1.62985548e-02],\n         [-2.57684812e-02],\n         [ 1.24095827e-02],\n         [ 6.02629036e-03],\n         [-2.32553408e-02],\n         [-8.02639574e-02],\n         [-2.17057839e-02],\n         [-5.11438400e-03],\n         [ 1.80221871e-02],\n         [ 5.17442822e-02],\n         [-5.03415614e-03],\n         [ 6.18252009e-02],\n         [ 4.17437702e-02],\n         [ 6.45234734e-02],\n         [-2.24099830e-02],\n         [-1.86283812e-02],\n         [-5.79401068e-02],\n         [ 8.93696845e-02],\n         [-8.47689658e-02],\n         [ 6.00128174e-02],\n         [ 6.93603009e-02],\n         [-2.16657445e-02],\n         [ 4.61700857e-02],\n         [-5.07384539e-02],\n         [-1.20193809e-02],\n         [ 4.92925942e-02],\n         [-1.32743642e-02],\n         [ 2.10070983e-02],\n         [-3.89861315e-02],\n         [ 4.94220853e-03],\n         [ 2.58753747e-02],\n         [-5.25311492e-02],\n         [ 5.99264801e-02],\n         [ 2.50149220e-02],\n         [-4.02270295e-02],\n         [-1.09766573e-02],\n         [ 7.99624175e-02],\n         [ 8.55708122e-03],\n         [-4.94656041e-02],\n         [-8.81139860e-02],\n         [-6.36781007e-02],\n         [-3.83532867e-02],\n         [ 6.63741231e-02],\n         [ 5.14726490e-02],\n         [ 3.54928523e-02],\n         [ 8.98922235e-03],\n         [ 3.78441513e-02],\n         [-2.97950767e-02],\n         [-6.48227856e-02]],\n\n        [[-5.54358102e-02],\n         [-7.77578503e-02],\n         [-8.96378607e-03],\n         [-5.00068031e-02],\n         [-5.41034341e-03],\n         [ 7.64813721e-02],\n         [-8.66460204e-02],\n         [-2.15928704e-02],\n         [ 8.32418650e-02],\n         [ 6.56603128e-02],\n         [-2.75039673e-03],\n         [-1.93122923e-02],\n         [-4.27472442e-02],\n         [ 1.26364827e-02],\n         [ 7.45639056e-02],\n         [ 9.40008461e-03],\n         [ 4.14515138e-02],\n         [-6.77006245e-02],\n         [ 7.45674819e-02],\n         [-2.35171467e-02],\n         [-3.67381275e-02],\n         [-7.07440823e-03],\n         [-2.57614031e-02],\n         [-4.28733043e-02],\n         [ 7.81133771e-02],\n         [ 4.25002128e-02],\n         [-9.59236920e-03],\n         [-7.71595240e-02],\n         [ 1.23315454e-02],\n         [-7.16127604e-02],\n         [ 8.64599794e-02],\n         [ 6.62310421e-03],\n         [-3.20300460e-05],\n         [ 2.25376412e-02],\n         [-5.11577241e-02],\n         [ 6.11948222e-02],\n         [-2.70512775e-02],\n         [-8.60325322e-02],\n         [-6.41967803e-02],\n         [-6.22589663e-02],\n         [-7.01373070e-02],\n         [ 2.40609348e-02],\n         [-4.69311997e-02],\n         [ 8.30149800e-02],\n         [ 6.53957427e-02],\n         [ 1.75359100e-03],\n         [ 2.38923579e-02],\n         [ 8.63955617e-02],\n         [-4.05928344e-02],\n         [ 6.23798370e-03],\n         [-5.27035184e-02],\n         [-5.64305484e-03],\n         [ 3.66475433e-02],\n         [-4.12845612e-03],\n         [-9.07036364e-02],\n         [-3.17191742e-02],\n         [ 1.72224939e-02],\n         [ 1.63192526e-02],\n         [ 5.96878082e-02],\n         [-2.58554742e-02],\n         [-5.86879142e-02],\n         [-2.48274729e-02],\n         [ 3.47564071e-02],\n         [-4.19784375e-02],\n         [ 3.45746279e-02],\n         [-2.07633749e-02],\n         [-8.04629773e-02],\n         [-7.79192671e-02],\n         [ 5.74323982e-02],\n         [ 1.07824206e-02],\n         [-7.52278566e-02],\n         [-3.81230153e-02],\n         [ 8.75751674e-02],\n         [-1.94032043e-02],\n         [ 7.98942894e-02],\n         [-6.83071688e-02],\n         [-8.01637918e-02],\n         [-5.80620356e-02],\n         [-5.56412712e-02],\n         [-8.63611698e-04]]],\n\n\n       [[[ 4.26595956e-02],\n         [ 4.18077409e-02],\n         [ 7.04083890e-02],\n         [-1.56771317e-02],\n         [-1.20178014e-02],\n         [ 4.88903224e-02],\n         [ 5.01275808e-02],\n         [-7.61444420e-02],\n         [-1.37378275e-02],\n         [ 3.17263380e-02],\n         [ 2.13926211e-02],\n         [ 8.32998753e-02],\n         [ 1.12161860e-02],\n         [ 4.41337377e-02],\n         [-6.12845048e-02],\n         [-7.62168318e-03],\n         [-7.29644895e-02],\n         [ 1.37341693e-02],\n         [ 2.08148956e-02],\n         [-7.03651458e-03],\n         [ 4.08317596e-02],\n         [ 6.63416982e-02],\n         [ 7.97964483e-02],\n         [-3.69173288e-02],\n         [-6.95387498e-02],\n         [-5.39264828e-03],\n         [-8.88661817e-02],\n         [ 4.08463329e-02],\n         [ 1.94887966e-02],\n         [ 6.13608509e-02],\n         [ 5.68960011e-02],\n         [ 8.81732553e-02],\n         [ 3.41234803e-02],\n         [-1.21322498e-02],\n         [-5.36374487e-02],\n         [-4.53162566e-02],\n         [-1.60529241e-02],\n         [-2.15667635e-02],\n         [-7.13304281e-02],\n         [-3.88340503e-02],\n         [-3.23315598e-02],\n         [-7.09931776e-02],\n         [ 2.67773345e-02],\n         [ 3.28914449e-02],\n         [-2.83065811e-02],\n         [ 6.81047887e-03],\n         [-1.06015503e-02],\n         [-4.04884703e-02],\n         [ 3.06448340e-03],\n         [ 4.79763448e-02],\n         [-1.14663318e-02],\n         [ 6.16762042e-03],\n         [ 4.10256833e-02],\n         [ 6.89630657e-02],\n         [-2.31774077e-02],\n         [-3.07180211e-02],\n         [-3.18850130e-02],\n         [ 6.82625920e-02],\n         [ 7.82368332e-02],\n         [-5.00280671e-02],\n         [-3.78705114e-02],\n         [ 8.63984674e-02],\n         [ 8.05471539e-02],\n         [-4.03002910e-02],\n         [ 3.27968821e-02],\n         [-3.79887186e-02],\n         [ 1.46899447e-02],\n         [ 3.29197794e-02],\n         [-7.59748369e-02],\n         [-5.72847016e-02],\n         [-7.73597509e-03],\n         [-5.96136227e-02],\n         [-6.97472841e-02],\n         [ 6.60738945e-02],\n         [ 8.84169936e-02],\n         [ 1.60476044e-02],\n         [ 8.65660459e-02],\n         [ 5.31691164e-02],\n         [-7.92297274e-02],\n         [ 4.45018262e-02]],\n\n        [[ 2.59382278e-02],\n         [ 2.98092663e-02],\n         [ 6.80446327e-02],\n         [-6.13748506e-02],\n         [ 4.99933958e-02],\n         [ 5.91568649e-02],\n         [-2.13061273e-02],\n         [ 5.66306412e-02],\n         [-2.65929103e-03],\n         [ 8.96140188e-02],\n         [-6.38575181e-02],\n         [ 8.34863186e-02],\n         [-4.88398559e-02],\n         [-2.86746323e-02],\n         [ 6.70631230e-03],\n         [ 7.28157461e-02],\n         [-1.15867481e-02],\n         [ 4.15063649e-02],\n         [-4.16673720e-04],\n         [ 2.04535499e-02],\n         [-5.51038608e-02],\n         [ 3.21254730e-02],\n         [ 1.17579252e-02],\n         [-8.26735571e-02],\n         [ 1.63267553e-02],\n         [-2.59094164e-02],\n         [-6.06765747e-02],\n         [-1.77703947e-02],\n         [ 1.26971304e-02],\n         [-6.21755198e-02],\n         [-4.63599376e-02],\n         [-1.24521554e-04],\n         [ 1.17802694e-02],\n         [ 6.48866147e-02],\n         [-3.23696919e-02],\n         [ 3.19117680e-02],\n         [ 5.93329072e-02],\n         [-1.61769688e-02],\n         [-1.16089582e-02],\n         [ 4.22929376e-02],\n         [ 6.75553828e-02],\n         [-7.60738179e-02],\n         [-7.70254806e-02],\n         [-6.14794940e-02],\n         [-8.88771564e-03],\n         [ 4.35371399e-02],\n         [ 4.75450605e-03],\n         [ 2.63791084e-02],\n         [ 8.35929364e-02],\n         [-1.76268592e-02],\n         [ 5.46123832e-03],\n         [ 2.01231316e-02],\n         [ 7.49666393e-02],\n         [ 4.14167047e-02],\n         [-7.37124979e-02],\n         [-2.29581669e-02],\n         [ 9.02353525e-02],\n         [-7.47415125e-02],\n         [-2.35016569e-02],\n         [-5.82432933e-02],\n         [ 8.68637264e-02],\n         [ 8.23300928e-02],\n         [-5.99479675e-03],\n         [-8.12120363e-02],\n         [ 7.72652924e-02],\n         [ 2.06527561e-02],\n         [-1.39459670e-02],\n         [-5.18173724e-03],\n         [ 6.56164438e-02],\n         [ 8.67024511e-02],\n         [-7.50793517e-03],\n         [ 1.58068463e-02],\n         [-7.06612244e-02],\n         [ 4.30848897e-02],\n         [-6.47549778e-02],\n         [-8.62887129e-02],\n         [-1.64756328e-02],\n         [-4.72717173e-02],\n         [ 1.29260197e-02],\n         [ 6.00086302e-02]],\n\n        [[-4.56284732e-03],\n         [ 3.99043858e-02],\n         [-4.14173603e-02],\n         [ 9.52903926e-03],\n         [ 1.13097578e-03],\n         [ 3.08772400e-02],\n         [-1.74266100e-02],\n         [-5.90561181e-02],\n         [ 5.74377179e-02],\n         [-7.72907585e-03],\n         [ 9.00814384e-02],\n         [ 5.23706377e-02],\n         [-6.06794730e-02],\n         [-6.11447953e-02],\n         [ 6.40147477e-02],\n         [ 5.10952324e-02],\n         [ 2.33447552e-02],\n         [ 5.07457852e-02],\n         [-3.13534588e-02],\n         [-5.77361397e-02],\n         [ 2.41619274e-02],\n         [-1.46108046e-02],\n         [-2.19585747e-03],\n         [-3.77264135e-02],\n         [-4.60195728e-02],\n         [-2.75286883e-02],\n         [ 2.17884481e-02],\n         [ 2.45093033e-02],\n         [ 2.42421925e-02],\n         [-1.13943666e-02],\n         [ 6.24240935e-02],\n         [ 5.10726869e-03],\n         [ 4.76746261e-03],\n         [ 1.76798925e-02],\n         [ 3.70710790e-02],\n         [-3.12309712e-02],\n         [-4.25287634e-02],\n         [ 8.49948227e-02],\n         [-2.24267244e-02],\n         [-3.73374224e-02],\n         [-5.64185828e-02],\n         [-5.19541092e-02],\n         [-4.30715829e-02],\n         [ 7.65275508e-02],\n         [-3.87361981e-02],\n         [-4.36279885e-02],\n         [-3.53991576e-02],\n         [-1.12169981e-03],\n         [ 8.88430178e-02],\n         [-3.18342447e-02],\n         [ 7.05901086e-02],\n         [ 4.06839103e-02],\n         [ 3.23081985e-02],\n         [ 3.46971601e-02],\n         [ 4.83417213e-02],\n         [ 5.50644547e-02],\n         [ 7.31638074e-03],\n         [-9.03065503e-02],\n         [ 4.10574377e-02],\n         [ 1.24988928e-02],\n         [-6.97014481e-02],\n         [-5.60067073e-02],\n         [-7.88989663e-02],\n         [-6.45250306e-02],\n         [-5.36771603e-02],\n         [ 5.55333495e-03],\n         [-1.38175935e-02],\n         [-2.18377411e-02],\n         [ 8.66425782e-03],\n         [-2.45454237e-02],\n         [-6.92906976e-02],\n         [-2.49377638e-02],\n         [-7.07231537e-02],\n         [-4.46874350e-02],\n         [ 7.57945925e-02],\n         [-6.01265728e-02],\n         [-7.19261989e-02],\n         [ 5.46445996e-02],\n         [-6.03293628e-03],\n         [ 7.17076659e-03]]]], dtype=float32)>, <tf.Variable 'conv2d_868/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.11377605, -0.19837369, -0.10293127, ...,  0.03562347,\n          -0.18975647, -0.02582112],\n         [ 0.10182679,  0.01593432,  0.03020365, ...,  0.009907  ,\n          -0.00535053, -0.09950298],\n         [ 0.0855576 , -0.127197  , -0.08279993, ...,  0.09936242,\n          -0.05976695,  0.05062583],\n         ...,\n         [-0.24529052, -0.02732827, -0.00027736, ...,  0.11329194,\n          -0.11313015, -0.13003397],\n         [-0.19731423, -0.03873628, -0.20429744, ...,  0.21081927,\n          -0.01312663, -0.16429222],\n         [ 0.1405715 , -0.00138492,  0.1414134 , ...,  0.01170814,\n          -0.01567286,  0.05142608]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_356/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.14340137],\n         [-0.08418159],\n         [ 0.10534087],\n         [-0.11075669],\n         [-0.03815177],\n         [ 0.06203593],\n         [ 0.02642174],\n         [ 0.04302326],\n         [ 0.10022238],\n         [ 0.05761124],\n         [ 0.05405563],\n         [ 0.13017288],\n         [-0.15817238],\n         [ 0.0664524 ],\n         [ 0.12732226],\n         [-0.08743418],\n         [-0.12439197],\n         [ 0.12777665],\n         [-0.15144914],\n         [ 0.10406849],\n         [ 0.09318924],\n         [-0.00128275],\n         [-0.09732779],\n         [ 0.10372761]],\n\n        [[ 0.10296056],\n         [-0.05869111],\n         [ 0.01091655],\n         [ 0.05750546],\n         [ 0.02351768],\n         [ 0.04889004],\n         [-0.05116598],\n         [-0.06799826],\n         [ 0.01638015],\n         [ 0.07803227],\n         [ 0.08502676],\n         [ 0.11258233],\n         [-0.15656272],\n         [-0.13711524],\n         [ 0.04636733],\n         [-0.1131624 ],\n         [ 0.00166009],\n         [ 0.11383539],\n         [-0.14547984],\n         [ 0.02747874],\n         [ 0.02423362],\n         [ 0.09881812],\n         [-0.06227331],\n         [-0.09644669]],\n\n        [[-0.10719107],\n         [-0.0035094 ],\n         [ 0.00278959],\n         [-0.1298213 ],\n         [ 0.0928914 ],\n         [ 0.15386549],\n         [ 0.08788311],\n         [-0.07467841],\n         [-0.09631143],\n         [ 0.06356439],\n         [ 0.0592282 ],\n         [-0.01641122],\n         [-0.13982958],\n         [ 0.03058729],\n         [-0.10343094],\n         [-0.02755797],\n         [-0.13711372],\n         [ 0.03288919],\n         [ 0.14578092],\n         [-0.00610331],\n         [ 0.10902637],\n         [-0.06512679],\n         [-0.08758812],\n         [ 0.03284201]]],\n\n\n       [[[ 0.14794993],\n         [-0.07280301],\n         [ 0.1460459 ],\n         [ 0.1381455 ],\n         [ 0.04432176],\n         [-0.03030466],\n         [-0.13750586],\n         [ 0.05140468],\n         [-0.04495747],\n         [ 0.06694192],\n         [ 0.09736428],\n         [ 0.00194964],\n         [ 0.072345  ],\n         [-0.1620485 ],\n         [-0.15177895],\n         [ 0.12911889],\n         [-0.13187525],\n         [ 0.13725403],\n         [-0.0977779 ],\n         [ 0.00980504],\n         [ 0.13831535],\n         [ 0.11125684],\n         [-0.01418884],\n         [-0.09442148]],\n\n        [[ 0.15736821],\n         [-0.00862259],\n         [-0.09820578],\n         [ 0.11407554],\n         [-0.15723331],\n         [-0.09020294],\n         [ 0.02782907],\n         [-0.02137613],\n         [-0.08519721],\n         [-0.01988187],\n         [-0.12133288],\n         [ 0.04116012],\n         [ 0.09762278],\n         [ 0.09618241],\n         [-0.15225911],\n         [ 0.05478311],\n         [ 0.14637521],\n         [-0.14642562],\n         [-0.02799571],\n         [ 0.00862208],\n         [-0.07752488],\n         [-0.16157728],\n         [-0.06047893],\n         [-0.13463053]],\n\n        [[ 0.09026361],\n         [ 0.06642258],\n         [ 0.14101288],\n         [-0.04409311],\n         [ 0.0086033 ],\n         [-0.06567015],\n         [-0.14833087],\n         [ 0.02079596],\n         [ 0.12021786],\n         [ 0.15288576],\n         [-0.01743361],\n         [-0.12073404],\n         [ 0.02286515],\n         [-0.12555106],\n         [ 0.07635018],\n         [-0.07986639],\n         [-0.01178087],\n         [-0.0014002 ],\n         [ 0.07575636],\n         [ 0.1027998 ],\n         [-0.16324918],\n         [ 0.13055208],\n         [ 0.00924727],\n         [-0.00898354]]],\n\n\n       [[[ 0.1501388 ],\n         [ 0.11451405],\n         [-0.07104454],\n         [ 0.05734381],\n         [-0.14877604],\n         [ 0.1525822 ],\n         [-0.14026228],\n         [ 0.04728715],\n         [-0.13821156],\n         [-0.07567448],\n         [ 0.07381606],\n         [-0.06193272],\n         [ 0.08085775],\n         [-0.04403739],\n         [ 0.0650564 ],\n         [ 0.04998952],\n         [-0.07261878],\n         [-0.10575512],\n         [-0.13955559],\n         [-0.00409834],\n         [-0.12075993],\n         [-0.05481094],\n         [ 0.05576271],\n         [ 0.00463387]],\n\n        [[-0.0325347 ],\n         [ 0.07343136],\n         [-0.14436798],\n         [ 0.14143744],\n         [-0.00939149],\n         [-0.00686255],\n         [ 0.00649199],\n         [-0.10386813],\n         [-0.14436257],\n         [ 0.02648079],\n         [-0.1363825 ],\n         [ 0.12504905],\n         [-0.15712246],\n         [-0.09095681],\n         [ 0.03356683],\n         [-0.0382178 ],\n         [-0.07120024],\n         [-0.08896598],\n         [ 0.11554801],\n         [-0.10271048],\n         [ 0.04675201],\n         [ 0.08268806],\n         [-0.10615049],\n         [-0.08132538]],\n\n        [[-0.01475766],\n         [-0.06688647],\n         [ 0.1612347 ],\n         [-0.0804479 ],\n         [ 0.00622654],\n         [ 0.07393162],\n         [ 0.101621  ],\n         [ 0.1587502 ],\n         [-0.16110246],\n         [-0.11021995],\n         [-0.09468786],\n         [-0.01166391],\n         [ 0.10361844],\n         [-0.08487037],\n         [ 0.09539708],\n         [-0.08777291],\n         [ 0.076672  ],\n         [-0.14978823],\n         [-0.1465212 ],\n         [-0.04055825],\n         [ 0.038368  ],\n         [ 0.01941599],\n         [-0.07661279],\n         [ 0.03800572]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_361/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.05862133],\n         [-0.06787249],\n         [-0.00143874],\n         [ 0.0522846 ],\n         [ 0.02843143],\n         [-0.05796753],\n         [-0.03070563],\n         [ 0.03558707],\n         [ 0.00286934],\n         [ 0.04302962],\n         [-0.0577325 ],\n         [ 0.04925835],\n         [-0.06406352],\n         [-0.01138317],\n         [ 0.00832298],\n         [-0.05808154],\n         [ 0.00169984],\n         [ 0.08342668],\n         [-0.08837145],\n         [-0.08583248],\n         [-0.0452465 ],\n         [-0.06962996],\n         [ 0.01602703],\n         [ 0.08493581],\n         [-0.03485757],\n         [ 0.06025551],\n         [-0.06781401],\n         [-0.01794404],\n         [ 0.0348888 ],\n         [-0.07669795],\n         [-0.0490337 ],\n         [ 0.07483491],\n         [ 0.06025095],\n         [-0.00535823],\n         [-0.02514351],\n         [ 0.03641158],\n         [ 0.00575929],\n         [-0.0299454 ],\n         [ 0.00780084],\n         [ 0.01027875],\n         [ 0.06777018],\n         [ 0.04706654],\n         [-0.02420408],\n         [-0.07793529],\n         [ 0.08365996],\n         [ 0.07645322],\n         [ 0.04628013],\n         [-0.02425781],\n         [ 0.07502417],\n         [ 0.06599805],\n         [ 0.03913902],\n         [ 0.01872989],\n         [-0.06520419],\n         [-0.00075293],\n         [ 0.01351236],\n         [-0.04886895],\n         [ 0.043605  ],\n         [-0.05501736],\n         [-0.07609047],\n         [-0.06157172],\n         [-0.05589629],\n         [-0.01788189],\n         [-0.04286225],\n         [ 0.02731637],\n         [-0.07283528],\n         [ 0.04904722],\n         [-0.04857277],\n         [-0.05936235],\n         [ 0.0266699 ],\n         [ 0.0253202 ],\n         [-0.07372662],\n         [ 0.0230236 ],\n         [-0.07591793],\n         [ 0.06320105],\n         [-0.06062237],\n         [-0.02340686],\n         [ 0.0557498 ],\n         [ 0.08509123],\n         [ 0.0446057 ],\n         [-0.07428408]],\n\n        [[ 0.07721901],\n         [ 0.02545991],\n         [-0.02271096],\n         [ 0.07300392],\n         [-0.08588627],\n         [-0.02822874],\n         [-0.00096042],\n         [ 0.04805009],\n         [-0.04831713],\n         [-0.02971262],\n         [ 0.0291623 ],\n         [-0.01356574],\n         [-0.02229521],\n         [-0.07300246],\n         [-0.03045924],\n         [-0.00594945],\n         [-0.02454614],\n         [-0.0476848 ],\n         [ 0.03519863],\n         [ 0.02090736],\n         [ 0.05277282],\n         [-0.046572  ],\n         [-0.05920203],\n         [ 0.03778207],\n         [ 0.05434914],\n         [-0.01817024],\n         [-0.00426063],\n         [ 0.08842298],\n         [ 0.07764566],\n         [-0.04779985],\n         [ 0.0873276 ],\n         [ 0.03511068],\n         [ 0.03061718],\n         [-0.00619334],\n         [-0.0184059 ],\n         [-0.02919291],\n         [ 0.00738354],\n         [-0.01426036],\n         [ 0.01189101],\n         [ 0.02988032],\n         [ 0.0846733 ],\n         [ 0.00946552],\n         [-0.02045307],\n         [ 0.00101848],\n         [ 0.08865036],\n         [-0.08417495],\n         [ 0.08208813],\n         [-0.0785756 ],\n         [ 0.03740524],\n         [ 0.02468041],\n         [ 0.03092171],\n         [-0.03615016],\n         [-0.0801071 ],\n         [ 0.03581479],\n         [ 0.05957553],\n         [ 0.08237936],\n         [-0.07721847],\n         [ 0.06855331],\n         [ 0.0003814 ],\n         [-0.02432015],\n         [ 0.05368485],\n         [-0.00667358],\n         [ 0.00073729],\n         [-0.02639027],\n         [-0.01773159],\n         [ 0.03252644],\n         [-0.05595233],\n         [ 0.00672303],\n         [-0.07951189],\n         [-0.03684853],\n         [-0.06077854],\n         [ 0.02722027],\n         [ 0.07564095],\n         [ 0.00493526],\n         [-0.06356188],\n         [-0.03022943],\n         [ 0.02337889],\n         [-0.02516462],\n         [ 0.08925943],\n         [ 0.0522835 ]],\n\n        [[-0.02456156],\n         [ 0.02857678],\n         [ 0.03507963],\n         [ 0.07255268],\n         [-0.01634862],\n         [-0.01399302],\n         [ 0.06031664],\n         [ 0.0779556 ],\n         [-0.06671466],\n         [-0.00915476],\n         [ 0.0672055 ],\n         [ 0.02125512],\n         [ 0.00261952],\n         [ 0.04044171],\n         [-0.07184018],\n         [-0.00181242],\n         [ 0.08271779],\n         [-0.00473344],\n         [-0.03401157],\n         [ 0.03392548],\n         [-0.05159209],\n         [-0.0717988 ],\n         [-0.02933209],\n         [-0.00342577],\n         [ 0.00734285],\n         [ 0.03482041],\n         [-0.07988546],\n         [ 0.02886037],\n         [-0.07378212],\n         [-0.05460815],\n         [-0.0393249 ],\n         [ 0.06679575],\n         [-0.00195777],\n         [ 0.04739965],\n         [-0.08581632],\n         [ 0.04518142],\n         [-0.00184961],\n         [ 0.01261881],\n         [-0.00224381],\n         [-0.01192985],\n         [-0.01102502],\n         [-0.05512393],\n         [-0.04728866],\n         [ 0.00331844],\n         [ 0.01729564],\n         [-0.0501302 ],\n         [-0.07037815],\n         [ 0.03195289],\n         [ 0.07023205],\n         [-0.01874557],\n         [-0.01445946],\n         [ 0.04807998],\n         [-0.01940126],\n         [-0.01581582],\n         [-0.01973686],\n         [ 0.03475253],\n         [ 0.08207478],\n         [-0.07116315],\n         [ 0.05247119],\n         [ 0.03359995],\n         [-0.07978815],\n         [ 0.04428263],\n         [ 0.03059847],\n         [ 0.01560552],\n         [-0.04788633],\n         [ 0.02635573],\n         [ 0.01764799],\n         [ 0.05597052],\n         [-0.07732634],\n         [ 0.01235746],\n         [-0.05946237],\n         [ 0.04475005],\n         [-0.05329708],\n         [ 0.08195986],\n         [ 0.04055862],\n         [ 0.03729253],\n         [ 0.06574923],\n         [-0.02528181],\n         [-0.05548031],\n         [ 0.03708637]]],\n\n\n       [[[ 0.04131354],\n         [-0.02366098],\n         [-0.00551046],\n         [-0.00086305],\n         [ 0.05134383],\n         [-0.03414534],\n         [ 0.00183507],\n         [-0.02873745],\n         [ 0.00403973],\n         [-0.08824188],\n         [ 0.0222329 ],\n         [ 0.08102261],\n         [ 0.07718936],\n         [-0.05539208],\n         [ 0.01658904],\n         [-0.07282518],\n         [ 0.02694903],\n         [ 0.07285637],\n         [ 0.08844501],\n         [ 0.07910861],\n         [ 0.02708575],\n         [ 0.08990203],\n         [-0.0240164 ],\n         [-0.05650413],\n         [-0.04124846],\n         [-0.07619873],\n         [ 0.08021528],\n         [-0.00269753],\n         [-0.0348221 ],\n         [ 0.03171368],\n         [-0.08979475],\n         [-0.06474152],\n         [ 0.07013246],\n         [ 0.0086266 ],\n         [-0.00619234],\n         [-0.08474578],\n         [-0.09029496],\n         [ 0.05931535],\n         [ 0.04343687],\n         [ 0.04223551],\n         [ 0.07155059],\n         [ 0.07888953],\n         [ 0.03588842],\n         [-0.07390042],\n         [-0.04451332],\n         [-0.08843549],\n         [ 0.0579996 ],\n         [ 0.02964737],\n         [ 0.00341677],\n         [-0.02227283],\n         [ 0.00178009],\n         [ 0.08750346],\n         [-0.02411523],\n         [ 0.08277509],\n         [ 0.05163233],\n         [ 0.05877222],\n         [ 0.04689845],\n         [-0.05654879],\n         [-0.05907158],\n         [-0.02672895],\n         [-0.03180189],\n         [ 0.08623222],\n         [-0.05974528],\n         [ 0.03930502],\n         [ 0.06115223],\n         [ 0.06551525],\n         [ 0.02286189],\n         [ 0.07035287],\n         [-0.08282754],\n         [-0.07002901],\n         [ 0.05888487],\n         [-0.04605331],\n         [-0.06600455],\n         [-0.08956316],\n         [-0.0674441 ],\n         [ 0.07339886],\n         [-0.04315964],\n         [ 0.03424843],\n         [ 0.03260674],\n         [ 0.07929479]],\n\n        [[ 0.08247361],\n         [-0.01025383],\n         [-0.0355892 ],\n         [-0.07657394],\n         [ 0.0091054 ],\n         [-0.01682857],\n         [-0.04353513],\n         [-0.07771338],\n         [ 0.04457857],\n         [ 0.02758469],\n         [ 0.02358595],\n         [ 0.03270664],\n         [ 0.06104478],\n         [-0.03830769],\n         [ 0.06694925],\n         [-0.01769655],\n         [-0.05800402],\n         [-0.0330021 ],\n         [ 0.07623743],\n         [-0.0177782 ],\n         [ 0.01703777],\n         [-0.0837172 ],\n         [-0.01936416],\n         [-0.03471963],\n         [ 0.01185422],\n         [-0.04075783],\n         [-0.03957249],\n         [-0.00642893],\n         [ 0.06090166],\n         [-0.06661635],\n         [-0.03783067],\n         [ 0.08443964],\n         [-0.02471675],\n         [ 0.00353675],\n         [-0.0468951 ],\n         [-0.01810096],\n         [ 0.00715558],\n         [-0.08179883],\n         [ 0.07040827],\n         [ 0.02572674],\n         [-0.06271429],\n         [-0.03628284],\n         [ 0.05091259],\n         [-0.05034399],\n         [ 0.0786377 ],\n         [ 0.0280863 ],\n         [-0.04355047],\n         [ 0.03778856],\n         [ 0.04001403],\n         [ 0.06786926],\n         [ 0.00249891],\n         [ 0.02162971],\n         [-0.06200027],\n         [-0.03715584],\n         [ 0.00671139],\n         [-0.03643687],\n         [-0.04893312],\n         [-0.07927226],\n         [-0.06967054],\n         [-0.00533827],\n         [ 0.00943832],\n         [ 0.04864115],\n         [-0.07900567],\n         [-0.00270824],\n         [-0.01999229],\n         [-0.03156742],\n         [ 0.03180978],\n         [-0.00216118],\n         [-0.05231823],\n         [ 0.02281787],\n         [ 0.07461306],\n         [ 0.02685514],\n         [-0.00315276],\n         [ 0.05754547],\n         [ 0.00546037],\n         [-0.06526371],\n         [ 0.06875122],\n         [ 0.05377905],\n         [-0.04036626],\n         [ 0.06201176]],\n\n        [[ 0.00949335],\n         [ 0.08289196],\n         [-0.04254466],\n         [-0.08694872],\n         [-0.07277346],\n         [-0.07764788],\n         [ 0.05940598],\n         [ 0.02990221],\n         [ 0.0803875 ],\n         [-0.07934746],\n         [-0.03326341],\n         [ 0.08784597],\n         [ 0.0128228 ],\n         [ 0.06761551],\n         [ 0.04819334],\n         [ 0.05613832],\n         [-0.05433987],\n         [-0.05080116],\n         [ 0.04192294],\n         [ 0.01857803],\n         [ 0.06814912],\n         [-0.01618525],\n         [-0.04278021],\n         [ 0.00103077],\n         [ 0.01503325],\n         [ 0.07725485],\n         [ 0.0611382 ],\n         [ 0.06120856],\n         [ 0.03415036],\n         [ 0.04896116],\n         [ 0.06452547],\n         [-0.08227083],\n         [ 0.0720647 ],\n         [ 0.00602363],\n         [ 0.06589034],\n         [-0.00748993],\n         [ 0.0238327 ],\n         [-0.08020195],\n         [-0.03807123],\n         [ 0.08222513],\n         [-0.05276975],\n         [-0.03908035],\n         [-0.07836901],\n         [ 0.02132025],\n         [-0.03410187],\n         [ 0.0266423 ],\n         [-0.03243826],\n         [ 0.06792916],\n         [ 0.05551526],\n         [-0.05240239],\n         [ 0.02939975],\n         [-0.04590768],\n         [ 0.06535724],\n         [-0.08101938],\n         [ 0.03674592],\n         [ 0.04880942],\n         [-0.02492849],\n         [-0.03719017],\n         [-0.02101711],\n         [ 0.07957974],\n         [ 0.07638951],\n         [-0.07266613],\n         [ 0.03130862],\n         [ 0.08442576],\n         [ 0.08298282],\n         [-0.0768824 ],\n         [-0.08268139],\n         [ 0.01941225],\n         [-0.05475246],\n         [ 0.02066569],\n         [ 0.01758488],\n         [ 0.06787933],\n         [-0.06037681],\n         [ 0.08864908],\n         [-0.0720289 ],\n         [ 0.07373147],\n         [ 0.09013467],\n         [ 0.05156834],\n         [ 0.06052239],\n         [ 0.0318631 ]]],\n\n\n       [[[-0.03392524],\n         [ 0.00912499],\n         [-0.03485991],\n         [-0.06790743],\n         [-0.07071039],\n         [-0.06318291],\n         [-0.00849964],\n         [-0.02936424],\n         [-0.02635108],\n         [ 0.03226935],\n         [ 0.03140797],\n         [ 0.00033191],\n         [-0.0304587 ],\n         [ 0.01048739],\n         [-0.04042747],\n         [-0.05333292],\n         [ 0.01903509],\n         [-0.0355407 ],\n         [ 0.02509222],\n         [-0.08152802],\n         [ 0.00059201],\n         [ 0.06729455],\n         [ 0.02589207],\n         [-0.05556232],\n         [-0.04875301],\n         [ 0.01317454],\n         [ 0.04868667],\n         [ 0.0268387 ],\n         [-0.0246893 ],\n         [-0.04488046],\n         [ 0.04566497],\n         [-0.07064676],\n         [-0.07056984],\n         [ 0.03463709],\n         [-0.02291454],\n         [-0.008719  ],\n         [-0.02562536],\n         [-0.03146546],\n         [-0.06284931],\n         [ 0.04440957],\n         [-0.07968035],\n         [ 0.05213402],\n         [-0.02299087],\n         [ 0.04789007],\n         [-0.09047034],\n         [ 0.07150608],\n         [-0.01475951],\n         [ 0.02269763],\n         [-0.07563212],\n         [-0.00975929],\n         [ 0.08480932],\n         [ 0.00114093],\n         [-0.02058414],\n         [-0.00842404],\n         [-0.00774994],\n         [ 0.03215186],\n         [ 0.06082876],\n         [-0.07206398],\n         [-0.02735444],\n         [ 0.01445282],\n         [-0.00354075],\n         [ 0.06043807],\n         [ 0.00200986],\n         [-0.01584757],\n         [ 0.04492085],\n         [ 0.04690719],\n         [-0.06885198],\n         [-0.07592513],\n         [ 0.00753573],\n         [ 0.0634876 ],\n         [-0.01528414],\n         [ 0.03892908],\n         [ 0.06138667],\n         [ 0.08318278],\n         [ 0.07324603],\n         [-0.00943415],\n         [ 0.06991668],\n         [ 0.05192149],\n         [-0.00508434],\n         [-0.0098428 ]],\n\n        [[ 0.04794404],\n         [-0.08520563],\n         [ 0.01584879],\n         [ 0.00127707],\n         [-0.01096416],\n         [ 0.06917842],\n         [-0.02692366],\n         [ 0.07861941],\n         [-0.01046617],\n         [-0.03980467],\n         [-0.05822581],\n         [ 0.05601834],\n         [ 0.03866021],\n         [ 0.07628843],\n         [-0.01748268],\n         [ 0.00183295],\n         [-0.03276833],\n         [ 0.05582231],\n         [ 0.03761731],\n         [ 0.08075538],\n         [ 0.0675859 ],\n         [ 0.06167038],\n         [ 0.04227944],\n         [-0.02539866],\n         [-0.08508437],\n         [-0.03594803],\n         [ 0.0129812 ],\n         [ 0.05990578],\n         [-0.06660353],\n         [-0.00040136],\n         [ 0.05011389],\n         [-0.08077427],\n         [-0.0151326 ],\n         [ 0.00020023],\n         [-0.06197159],\n         [ 0.01304068],\n         [ 0.06728661],\n         [ 0.0667434 ],\n         [-0.06405506],\n         [-0.00077231],\n         [ 0.03447378],\n         [ 0.02687009],\n         [-0.0570691 ],\n         [-0.02197856],\n         [-0.04235393],\n         [ 0.04266931],\n         [ 0.07164069],\n         [-0.06393702],\n         [ 0.03450568],\n         [-0.04970691],\n         [-0.02636155],\n         [ 0.06492317],\n         [ 0.06755865],\n         [-0.03215123],\n         [ 0.05774942],\n         [-0.03554027],\n         [ 0.06879117],\n         [-0.06295136],\n         [-0.0464917 ],\n         [-0.00615349],\n         [-0.0686335 ],\n         [-0.02820376],\n         [ 0.02623101],\n         [-0.05194769],\n         [-0.03156608],\n         [ 0.04817665],\n         [-0.02641541],\n         [-0.02007347],\n         [-0.0414317 ],\n         [ 0.07679266],\n         [ 0.06080408],\n         [ 0.07480045],\n         [-0.09010449],\n         [ 0.0259641 ],\n         [ 0.03417961],\n         [-0.06173239],\n         [ 0.01845957],\n         [-0.07137416],\n         [ 0.04579808],\n         [-0.00348966]],\n\n        [[ 0.00680531],\n         [ 0.0589366 ],\n         [-0.02025044],\n         [-0.03384155],\n         [-0.03997241],\n         [ 0.05575636],\n         [ 0.06276664],\n         [-0.04335844],\n         [ 0.06811893],\n         [ 0.03964104],\n         [ 0.0797206 ],\n         [ 0.02679319],\n         [ 0.0156488 ],\n         [-0.03093265],\n         [ 0.0359986 ],\n         [-0.0618838 ],\n         [ 0.08989947],\n         [-0.02006587],\n         [-0.09001925],\n         [ 0.04252441],\n         [-0.05294558],\n         [-0.02587382],\n         [ 0.07319094],\n         [ 0.09016059],\n         [ 0.07911155],\n         [-0.08186112],\n         [ 0.07288016],\n         [-0.05612703],\n         [ 0.06419812],\n         [ 0.08612832],\n         [ 0.03541279],\n         [ 0.03683811],\n         [ 0.03753251],\n         [-0.03604174],\n         [ 0.07631277],\n         [ 0.00750179],\n         [ 0.03689261],\n         [-0.08473907],\n         [ 0.06278251],\n         [ 0.07894029],\n         [ 0.08228348],\n         [-0.03164697],\n         [ 0.06372122],\n         [ 0.01757789],\n         [-0.07366971],\n         [ 0.01894738],\n         [ 0.01700513],\n         [-0.03727212],\n         [-0.02945125],\n         [ 0.09013818],\n         [ 0.03047349],\n         [ 0.04940854],\n         [ 0.02127507],\n         [ 0.08978595],\n         [-0.07326807],\n         [ 0.04303537],\n         [-0.02022564],\n         [-0.08902168],\n         [-0.02779374],\n         [-0.0635439 ],\n         [-0.02826819],\n         [ 0.07579274],\n         [-0.07877778],\n         [-0.01744852],\n         [ 0.02953462],\n         [-0.06369025],\n         [ 0.04691987],\n         [-0.07481118],\n         [-0.07864437],\n         [ 0.08330482],\n         [-0.07464539],\n         [ 0.05260731],\n         [-0.04967913],\n         [ 0.03227251],\n         [ 0.04554082],\n         [ 0.06617132],\n         [-0.03394462],\n         [-0.03974465],\n         [-0.01948126],\n         [-0.06254589]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_842/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[ 0.11949858,  0.06378268,  0.03810585, ..., -0.05398615,\n           0.21680692,  0.34825197],\n         [-0.11084814,  0.32638538,  0.07742921, ...,  0.06220793,\n          -0.2845991 , -0.07662066],\n         [ 0.34297124, -0.01897088, -0.04536596, ...,  0.08679746,\n          -0.16584131,  0.03761359],\n         ...,\n         [-0.42379293,  0.17675616, -0.03988766, ..., -0.21568966,\n           0.16601686, -0.12089289],\n         [ 0.04077285, -0.2336567 ,  0.38495407, ...,  0.34639072,\n          -0.29553336, -0.11165991],\n         [ 0.37638202, -0.04997886,  0.07167383, ...,  0.16532663,\n          -0.09114525,  0.330695  ]]]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[231], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/ckpt-277200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:871\u001b[0m, in \u001b[0;36mCheckpointLoadStatus.assert_nontrivial_match\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m unused_python_objects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    866\u001b[0m     object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m    867\u001b[0m         _objects_with_attributes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mall_python_objects)) \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m    868\u001b[0m     object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m    869\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mobject_by_proto_id\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unused_python_objects:\n\u001b[1;32m--> 871\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    872\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNothing except the root object matched a checkpointed value. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypically this means that the checkpoint does not match the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython program. The following objects have no matching \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpointed value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(unused_python_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    878\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNothing to load. No dependencies have been added to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_graph_view\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Nothing except the root object matched a checkpointed value. Typically this means that the checkpoint does not match the Python program. The following objects have no matching checkpointed value: [<tf.Variable 'sync_batch_normalization_855/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00676957, -0.09634139, -0.18770218, ...,  0.19944258,\n          -0.14135365,  0.18210804],\n         [-0.22393149,  0.19635543,  0.3284623 , ...,  0.00707996,\n           0.17528068,  0.10661352],\n         [-0.06039536,  0.03249402, -0.04811416, ..., -0.02716474,\n          -0.34512892,  0.44819278],\n         ...,\n         [ 0.1813063 , -0.062728  ,  0.04288131, ...,  0.22318785,\n           0.03546751, -0.18583813],\n         [ 0.04279966,  0.35971355,  0.3433167 , ...,  0.11765954,\n          -0.15561853, -0.4560668 ],\n         [ 0.2192535 , -0.16841394,  0.34175915, ..., -0.12580775,\n           0.20856485,  0.08633108]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_3/bias:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.0997659 , -0.00611321, -0.18242279, ...,  0.11405627,\n          -0.20777628,  0.00823767],\n         [-0.15320902, -0.11812736, -0.03383697, ..., -0.07117647,\n          -0.16950558,  0.19228572],\n         [-0.10441853,  0.04289228,  0.05561689, ...,  0.09746017,\n          -0.10889871,  0.03978932],\n         ...,\n         [-0.05037222,  0.02201761,  0.05079253, ..., -0.01017809,\n          -0.01778072,  0.11996267],\n         [-0.06045947,  0.02519628,  0.14621687, ...,  0.00115731,\n           0.04565639, -0.12305149],\n         [-0.00972935, -0.05885803,  0.06527564, ..., -0.01145692,\n          -0.08041909,  0.11880798]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 8, 240) dtype=float32, numpy=\narray([[[[ 0.27731138,  0.04643292, -0.38297847, ...,  0.4261856 ,\n          -0.4225839 , -0.32063508],\n         [ 0.24490221, -0.7143248 ,  0.47505182, ..., -0.12800658,\n          -0.3476433 , -0.35257545],\n         [ 0.39996067,  0.10616689, -0.05825517, ..., -0.11987177,\n           0.2880929 , -0.01947466],\n         ...,\n         [-0.42928702,  0.6382745 , -0.5178266 , ..., -0.5657525 ,\n          -0.13675056, -0.21231355],\n         [ 0.5169263 , -0.01521067, -0.07734648, ...,  0.35280368,\n           0.00682982,  0.14982584],\n         [-0.63911027, -0.7410649 ,  0.21043786, ...,  0.17746843,\n           0.14269972,  0.222384  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/conv2d_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32, numpy=\narray([[[[-0.09169228, -0.17684546,  0.00077084, ...,  0.08946985,\n           0.12061378, -0.03456267],\n         [ 0.08814655, -0.03033741,  0.00327894, ..., -0.05660526,\n          -0.03112386, -0.03194665],\n         [ 0.03745024, -0.11542568,  0.15877414, ...,  0.0266645 ,\n          -0.03882101,  0.02975029],\n         ...,\n         [ 0.165348  , -0.00459389, -0.05289736, ..., -0.03627867,\n           0.08504474,  0.02361331],\n         [-0.02914958,  0.04039643, -0.04958714, ...,  0.07881252,\n          -0.02740583, -0.1303127 ],\n         [ 0.05912042,  0.13693923, -0.00121247, ...,  0.03564801,\n           0.00267298,  0.11568356]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01851536],\n         [ 0.00733757],\n         [-0.02172983],\n         ...,\n         [-0.01355479],\n         [-0.01662578],\n         [-0.01723021]],\n\n        [[-0.01505743],\n         [-0.00514163],\n         [-0.00984013],\n         ...,\n         [ 0.00863782],\n         [ 0.01521116],\n         [ 0.00124205]],\n\n        [[-0.01724247],\n         [ 0.01015843],\n         [ 0.00190519],\n         ...,\n         [ 0.00429162],\n         [ 0.01235284],\n         [-0.02300341]]],\n\n\n       [[[-0.0053674 ],\n         [ 0.01600971],\n         [ 0.01254517],\n         ...,\n         [ 0.00232234],\n         [ 0.02664229],\n         [-0.00911285]],\n\n        [[-0.00159731],\n         [ 0.0068529 ],\n         [-0.00538531],\n         ...,\n         [-0.00150066],\n         [-0.00620795],\n         [-0.00976478]],\n\n        [[-0.01721664],\n         [-0.00563165],\n         [-0.00876007],\n         ...,\n         [-0.01049968],\n         [-0.00411376],\n         [ 0.01610754]]],\n\n\n       [[[ 0.00756265],\n         [ 0.01863839],\n         [-0.00499333],\n         ...,\n         [ 0.02452152],\n         [ 0.00356664],\n         [ 0.02676314]],\n\n        [[-0.02471363],\n         [-0.01248526],\n         [-0.01646867],\n         ...,\n         [ 0.02315362],\n         [-0.02153059],\n         [ 0.01352349]],\n\n        [[-0.01798632],\n         [-0.00676703],\n         [ 0.01538937],\n         ...,\n         [ 0.01650815],\n         [-0.0081065 ],\n         [-0.01477999]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[-0.02889698,  0.02226775, -0.01635587, ..., -0.0593063 ,\n           0.00962293,  0.04774904],\n         [-0.05340093, -0.00032051, -0.04290819, ..., -0.04047496,\n           0.05356967, -0.03279585],\n         [-0.0034331 ,  0.0413938 ,  0.06591232, ...,  0.06192049,\n           0.00501347,  0.00511633],\n         ...,\n         [-0.06566343,  0.05439257, -0.01089434, ...,  0.03299806,\n          -0.01511324,  0.05338838],\n         [-0.07359076,  0.10325756, -0.07991882, ..., -0.05974494,\n          -0.00324952,  0.03667715],\n         [ 0.05204966, -0.03199239,  0.00443521, ...,  0.05713964,\n          -0.00215116,  0.00376912]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 4, 144) dtype=float32, numpy=\narray([[[[-4.46340144e-01,  7.93159604e-02,  7.18156472e-02,\n          -7.01569438e-01,  7.22354710e-01, -5.13633430e-01,\n          -9.11757708e-01, -6.91454392e-03,  1.84001654e-01,\n           1.79240108e-01,  7.31972337e-01, -5.57208061e-03,\n          -5.27487576e-01,  1.97126582e-01, -3.50069672e-01,\n           1.47738814e-01,  9.46457446e-01, -2.83633918e-01,\n          -1.66928172e-01, -7.94632196e-01, -9.70720947e-02,\n          -3.29954833e-01,  2.78714225e-02, -5.83465099e-01,\n           5.06822169e-01,  4.15582180e-01,  9.81585801e-01,\n          -2.36347020e-01, -8.95969383e-03, -3.64610165e-01,\n           1.53712071e-02, -8.52691708e-04, -2.87975639e-01,\n          -9.55588758e-01,  7.16764271e-01, -1.63399026e-01,\n           1.04565933e-01, -6.00904465e-01,  7.43077517e-01,\n          -6.49221897e-01,  4.11271870e-01,  3.67594481e-01,\n           6.40672982e-01,  1.00946164e+00,  8.60740423e-01,\n           2.02992275e-01, -3.13182235e-01,  9.43895817e-01,\n          -1.91528112e-01,  5.41741431e-01, -1.30889997e-01,\n           5.65349609e-02,  9.55905497e-01, -1.12009741e-01,\n           6.85158074e-01, -4.55812737e-03,  6.70388758e-01,\n           6.32442296e-01,  2.01906741e-01,  1.63134206e-02,\n           7.01259255e-01,  3.75902832e-01, -1.70112163e-01,\n           1.45945415e-01, -1.37455270e-01, -8.20871949e-01,\n           4.51416224e-02, -3.38635981e-01, -8.08708891e-02,\n           4.60304111e-01,  7.34384358e-01, -4.16380525e-01,\n           6.80697858e-01,  2.19746679e-01, -1.59120068e-01,\n           5.40223658e-01,  2.91262895e-01,  4.63455826e-01,\n          -1.82620689e-01, -2.90297776e-01, -2.02242151e-01,\n           2.94709682e-01,  5.09671532e-02, -9.59728658e-02,\n           7.87021518e-01, -4.36704755e-01,  9.82804745e-02,\n           6.05372667e-01, -5.98747373e-01, -1.31339297e-01,\n           6.46744609e-01, -3.97263914e-01, -4.49462742e-01,\n          -1.12317979e-01, -1.87217683e-01, -5.61753154e-01,\n           2.76214778e-01,  3.13881367e-01, -2.64108018e-03,\n           4.43142891e-01,  1.42929871e-02, -1.07067004e-01,\n          -4.35749531e-01,  5.00990570e-01,  7.81666338e-02,\n          -1.86943308e-01, -8.74825940e-02, -1.95845455e-01,\n          -9.71517265e-01, -2.46700689e-01, -1.21074267e-01,\n           7.11524129e-01,  7.43147314e-01, -2.28119478e-01,\n           1.76789705e-02, -5.13711631e-01, -5.87541282e-01,\n          -1.10757565e+00, -2.46246591e-01,  8.27490464e-02,\n           3.55259217e-02, -3.69520217e-01,  3.83370727e-01,\n           1.12603873e-01, -2.94867903e-01, -2.65561044e-01,\n          -1.14038594e-01,  9.16518688e-01,  1.01806760e-01,\n          -3.32017750e-01, -3.21504623e-02, -7.78673172e-01,\n           3.97894114e-01, -4.69386011e-01, -6.51777327e-01,\n           8.36739302e-01, -1.92956522e-01,  2.48538435e-01,\n          -1.65233955e-01, -1.02110110e-01, -3.46793592e-01,\n           1.66390046e-01,  4.63413656e-01, -6.09368309e-02],\n         [ 2.76504248e-01, -2.94113219e-01,  4.90575284e-02,\n           3.86512250e-01, -3.06029528e-01,  1.85810909e-01,\n           1.77106068e-01,  9.27807391e-01, -4.23859917e-02,\n          -6.75970986e-02,  9.85717699e-02,  1.09832954e+00,\n          -8.14502221e-03, -7.64670670e-02, -1.52079388e-01,\n          -3.73686522e-01, -5.59421107e-02, -1.32697582e-01,\n           9.30295169e-01, -2.77064502e-01, -9.45520699e-01,\n           8.12557995e-01,  8.00177038e-01,  5.38711429e-01,\n          -8.94329667e-01,  6.10652447e-01,  6.77239716e-01,\n          -2.12189794e-01,  4.58199292e-01, -5.68707764e-01,\n           5.70656002e-01,  5.05347997e-02,  1.30876914e-01,\n           3.29079062e-01, -4.46394026e-01, -6.18453681e-01,\n          -8.79559875e-01,  3.98167223e-02,  3.04595739e-01,\n          -2.21079096e-01, -1.53937593e-01,  5.78534722e-01,\n           6.67724311e-01, -4.53105450e-01,  9.52875391e-02,\n           6.73621535e-01, -7.00639069e-01, -9.73989606e-01,\n          -1.49385750e-01, -4.82515961e-01,  5.46199158e-02,\n           2.99282581e-01,  4.52675112e-02,  7.50335217e-01,\n          -9.60190892e-02,  4.18219298e-01, -2.91757584e-01,\n           7.80740142e-01,  1.22061417e-01,  6.62682593e-01,\n          -8.01023766e-02,  2.94262677e-01,  4.93465364e-02,\n           1.05587947e+00, -2.51865014e-02, -4.22197692e-02,\n           5.25712907e-01, -1.80739880e-01,  5.01862466e-01,\n          -3.85191804e-03,  2.37913519e-01, -2.26544797e-01,\n          -1.43163921e-02, -1.82581231e-01, -1.31738216e-01,\n           1.59695849e-01,  2.34032586e-01,  1.82970181e-01,\n           4.83427286e-01,  3.55180949e-02, -8.24137852e-02,\n           1.85222834e-01, -7.93191865e-02,  8.83779109e-01,\n           9.55560684e-01,  2.58072317e-01,  3.00341874e-01,\n          -6.02832139e-01, -6.10780299e-01,  2.43433952e-01,\n           2.48009369e-01,  1.64592668e-01,  8.47473443e-01,\n          -8.64022553e-01, -7.44314551e-01, -3.96793604e-01,\n          -2.08855346e-01,  7.68810868e-01, -2.07488388e-01,\n          -6.36597872e-01, -4.05166149e-01, -3.89181107e-01,\n          -1.24542795e-01,  3.86424541e-01,  7.89532959e-02,\n          -6.95697144e-02,  9.79464725e-02, -4.74115819e-01,\n          -6.35868907e-01,  6.31757796e-01,  3.92273217e-01,\n          -2.37837628e-01, -5.28538287e-01, -1.99763123e-02,\n          -2.92223305e-01, -9.70181108e-01, -5.42902470e-01,\n          -2.08970517e-01,  1.92479700e-01,  7.17415363e-02,\n          -7.67787173e-02,  1.00109899e+00, -6.63973808e-01,\n          -3.65166783e-01, -3.50617528e-01, -8.60527992e-01,\n          -4.39661533e-01,  6.59075100e-03, -5.49427807e-01,\n           7.50225127e-01, -4.81145352e-01, -2.90592372e-01,\n          -2.30954289e-01,  6.48002028e-01, -7.20387816e-01,\n          -8.25280011e-01, -7.63143241e-01,  3.37564975e-01,\n          -1.28592372e-01,  4.89051163e-01, -3.48206647e-02,\n          -9.77943361e-01, -9.25292552e-01,  1.01913050e-01],\n         [ 1.10909067e-01, -2.23356664e-01,  1.10569155e+00,\n           7.47347295e-01,  1.69710085e-01, -5.11639833e-01,\n          -2.51277834e-01, -1.05084740e-01,  5.02517879e-01,\n           3.27106386e-01, -4.16090161e-01, -1.07925355e+00,\n          -1.47663996e-01, -2.50119835e-01,  2.58389741e-01,\n          -2.11905435e-01,  4.73861605e-01, -3.48890841e-01,\n           1.63393077e-02,  3.86200756e-01,  2.19942808e-01,\n           6.32769763e-01,  2.43289188e-01, -2.86607683e-01,\n           9.48658049e-01, -2.99302429e-01, -3.13399374e-01,\n           2.48380557e-01, -4.71069813e-01,  2.82425672e-01,\n          -7.29298055e-01, -1.87825933e-01,  1.24720372e-01,\n           7.79111981e-02, -5.25923789e-01, -7.58746624e-01,\n          -4.21178751e-02, -4.00482416e-01, -3.40509355e-01,\n           1.06970072e+00,  3.95473912e-02, -8.18126500e-02,\n           2.00698879e-02, -5.46225943e-02, -6.07739091e-02,\n          -6.66431308e-01, -2.33661473e-01, -3.61612320e-01,\n          -1.22290738e-01,  2.80953884e-01,  3.68051529e-01,\n          -4.07108277e-01,  4.84371871e-01,  1.46658465e-01,\n          -4.40875918e-01, -1.02284839e-02, -3.61073792e-01,\n           1.61406174e-01, -4.69722360e-01, -6.18475556e-01,\n           1.08635701e-01, -7.86353290e-01, -4.74258274e-01,\n          -4.69396174e-01, -2.74679512e-01,  9.30852443e-02,\n          -3.57051164e-01, -7.75208417e-03, -2.70747423e-01,\n          -8.40524510e-02,  1.40307471e-01,  1.02327496e-01,\n          -1.33433370e-02,  7.11541995e-02, -9.31351006e-01,\n          -4.55794722e-01, -3.94440830e-01,  3.88966531e-01,\n          -2.58769006e-01,  7.85629213e-01,  7.57014394e-01,\n           7.45148420e-01, -3.81585956e-01, -1.06873953e+00,\n           5.79514027e-01, -6.60916626e-01, -6.05771422e-01,\n           5.31518102e-01, -1.74734741e-01, -3.17256570e-01,\n          -6.16019607e-01,  7.00652242e-01,  5.14042489e-02,\n           9.31720376e-01, -1.62156180e-01, -8.97937268e-03,\n           8.61314535e-01,  3.67090523e-01,  4.20677900e-01,\n           3.40258867e-01,  7.01290369e-01,  2.06433669e-01,\n          -8.80719543e-01,  4.33599502e-01,  8.15899491e-01,\n          -2.69388348e-01, -6.08404875e-01,  8.38132501e-01,\n          -4.82518703e-01, -9.51939672e-02,  5.60109913e-01,\n           4.68016446e-01, -4.18788880e-01, -3.20009366e-02,\n          -3.68941784e-01,  5.67998588e-01, -1.49871394e-01,\n          -2.72118077e-02,  7.01223671e-01,  7.89658844e-01,\n           1.34858459e-01,  2.42518559e-01, -7.89716184e-01,\n           9.52703580e-02, -1.02502263e+00,  5.45569919e-02,\n           7.07489192e-01,  1.34081081e-01,  7.90163219e-01,\n          -7.57170379e-01, -4.23197180e-01,  6.75555766e-01,\n          -1.08942008e+00, -3.29081357e-01, -8.88271406e-02,\n          -3.92588153e-02, -5.77842295e-01, -7.46620238e-01,\n           5.12914181e-01,  7.76664972e-01, -4.65337604e-01,\n           8.07154596e-01, -5.98765910e-01, -4.93479878e-01],\n         [ 6.18531406e-01, -3.77676547e-01,  2.67430753e-01,\n          -1.75654635e-01,  3.99663538e-01, -2.46960267e-01,\n          -4.25701410e-01, -8.47621262e-01, -2.75878787e-01,\n          -2.16059238e-01,  7.27733135e-01,  8.09149146e-01,\n           5.23460627e-01,  1.89121395e-01,  2.72398710e-01,\n           2.40583286e-01, -1.21978886e-01,  2.52825290e-01,\n          -5.97628236e-01,  9.89215672e-02, -6.27292812e-01,\n           1.21734841e-02, -1.76808581e-01,  1.62136108e-01,\n           5.05934775e-01, -1.36404738e-01,  3.34036201e-01,\n          -4.85410661e-01,  2.48070583e-01,  2.82083243e-01,\n          -5.07388592e-01,  9.31717753e-02,  4.93431002e-01,\n           3.34313154e-01,  9.01049137e-01, -4.87115294e-01,\n           4.43518966e-01, -5.83407342e-01,  5.32543600e-01,\n          -5.05783930e-02, -5.59384584e-01, -8.95728767e-02,\n           1.56855389e-01, -1.67145401e-01, -1.07825927e-01,\n           1.03315282e+00,  1.26618827e-02,  2.91273147e-01,\n           2.96938159e-02, -1.41806126e-01,  1.80486709e-01,\n          -9.66712952e-01, -5.32025278e-01,  4.00541723e-01,\n           7.04733074e-01, -8.97689521e-01, -4.85900551e-01,\n          -9.44968998e-01, -1.00858247e+00,  5.43566167e-01,\n          -3.50022644e-01, -3.59959714e-02, -4.16132718e-01,\n           8.45791399e-01,  1.97148561e-01, -6.80939019e-01,\n          -7.70855248e-01,  1.51649043e-01, -7.47665465e-01,\n          -3.37648422e-01, -7.84658849e-01,  2.34365296e-02,\n          -3.64647448e-01, -1.29679143e-01,  3.48851770e-01,\n           3.19147468e-01, -3.59509200e-01, -1.08784211e+00,\n           1.16424151e-01,  7.83614159e-01,  2.37695828e-01,\n          -7.62130439e-01, -1.04980206e+00,  1.02022171e-01,\n          -1.14864133e-01,  2.93863803e-01, -1.03277087e+00,\n          -2.08005197e-02,  4.51303273e-01, -2.62943745e-01,\n          -5.94456196e-02, -7.21348226e-02, -2.28022151e-02,\n           3.91022652e-01, -8.68185282e-01,  2.02530205e-01,\n           6.35487363e-02, -8.52396429e-01,  2.23136991e-01,\n           8.82301092e-01, -2.86025405e-01, -4.99148756e-01,\n           5.88356517e-02, -3.87952387e-01,  8.32631364e-02,\n          -3.40651751e-01,  4.48175788e-01,  3.13712984e-01,\n           2.90078670e-02,  3.06020021e-01, -8.41080308e-01,\n           2.32717413e-02,  2.93076247e-01,  4.49456125e-01,\n          -6.33266211e-01,  9.77284431e-01,  6.75373733e-01,\n           7.46764779e-01,  6.19113922e-01, -3.31757188e-01,\n          -9.16023314e-01,  1.99519824e-02,  3.93653721e-01,\n           1.15947768e-01,  4.90968525e-01, -1.38241267e-02,\n          -4.91675556e-01,  8.30584943e-01,  1.73599020e-01,\n          -7.58920372e-01,  3.67022157e-01, -3.55812103e-01,\n          -4.41733152e-01, -1.54181877e-02,  6.82702601e-01,\n          -9.76422668e-01, -5.17291427e-01, -7.55771637e-01,\n          -3.00056726e-01,  6.22777104e-01,  6.67394936e-01,\n           5.46495795e-01,  3.48491430e-01, -3.67247522e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/conv2d/kernel:0' shape=(1, 1, 40, 240) dtype=float32, numpy=\narray([[[[-0.10846975, -0.04387538,  0.04996194, ..., -0.22216865,\n          -0.02056042,  0.12688816],\n         [-0.29914814, -0.16314988, -0.00831862, ..., -0.06202249,\n          -0.07067244,  0.2181089 ],\n         [ 0.07977994,  0.05879841, -0.04792768, ..., -0.31141752,\n           0.01455813,  0.25767425],\n         ...,\n         [-0.04463792,  0.01344586, -0.03338015, ...,  0.12839402,\n           0.02043189,  0.07568845],\n         [ 0.01852733,  0.03186574,  0.08006775, ..., -0.18717928,\n           0.20442119,  0.05691642],\n         [ 0.02191412, -0.03355732,  0.07488471, ..., -0.24066308,\n          -0.19299074, -0.17654353]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_866/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.2501783 ,  0.07888674,  0.0325722 , ...,  0.08762973,\n          -0.19800052, -0.01862198],\n         [ 0.00796617,  0.13541149,  0.0856686 , ..., -0.04317694,\n           0.02006071, -0.07993342],\n         [ 0.09086728, -0.05608286, -0.05533084, ..., -0.08206446,\n          -0.09444878,  0.09587992],\n         ...,\n         [-0.08529392,  0.16880657, -0.20645188, ...,  0.03909325,\n          -0.00030573,  0.18943132],\n         [-0.0479279 ,  0.18441351, -0.09271561, ...,  0.12802796,\n           0.05643995, -0.15682791],\n         [ 0.08678026,  0.04738859, -0.02438919, ...,  0.00179102,\n          -0.05145963, -0.10679142]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/moving_variance:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.03893273,  0.06076668,  0.02495129, ...,  0.01068159,\n          -0.0079745 ,  0.09844283],\n         [ 0.12363878,  0.16640107,  0.03771288, ..., -0.16220391,\n          -0.07075275, -0.02629996],\n         [-0.05427835,  0.02844169, -0.10229241, ...,  0.0790605 ,\n           0.0564952 ,  0.06399786],\n         ...,\n         [ 0.01145475,  0.0648926 , -0.1306466 , ...,  0.03741225,\n           0.02403267, -0.04959186],\n         [ 0.02992491,  0.00162175, -0.15101081, ..., -0.08398304,\n          -0.01948462, -0.20555066],\n         [-0.07307259,  0.06151012,  0.05935737, ..., -0.11286869,\n          -0.03899459,  0.05054926]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_3/bias:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_840/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[-3.98744762e-01,  3.24916959e-01, -1.56644732e-02,\n          -2.09920958e-01,  1.69025540e-01, -6.15426712e-02,\n           4.03022617e-01, -1.10374950e-01, -2.86790401e-01,\n          -1.91736761e-02, -7.49783218e-02, -1.57237574e-02,\n          -3.27626437e-01, -4.13801908e-01, -7.88480118e-02,\n           7.31269643e-02, -1.63358394e-02, -4.06948738e-02,\n           1.17733777e-01, -3.35734099e-01, -5.46164811e-02,\n          -2.22047776e-01,  9.15764943e-02,  3.62923890e-01],\n         [-2.05070563e-02,  4.03076053e-01,  1.46990508e-01,\n          -8.69363546e-02,  1.31527603e-01, -2.77412739e-02,\n           1.91128820e-01,  5.62993065e-02,  4.24983263e-01,\n           2.72930056e-01, -1.57165870e-01,  6.90236911e-02,\n           4.01723981e-01,  4.08069156e-02,  4.25368268e-03,\n          -1.02996364e-01, -1.73692092e-01,  7.09248483e-02,\n           1.10495528e-02,  4.50279027e-01,  9.94370133e-02,\n           3.64469051e-01, -1.48290396e-01,  1.27464771e-01],\n         [ 4.02755588e-02,  1.59933910e-01, -1.57675534e-01,\n          -3.17200005e-01,  2.35306904e-01, -1.11838907e-01,\n           3.23110074e-01, -2.73816377e-01, -2.59810776e-01,\n           1.08839892e-01, -1.27539545e-01, -1.33992150e-01,\n          -1.28702551e-01, -1.39400929e-01,  1.38803840e-01,\n          -1.27892852e-01,  3.24678391e-01, -7.78625533e-02,\n           1.09737344e-01,  2.20608041e-02,  1.57077298e-01,\n           1.41585454e-01, -3.30714276e-03, -1.40463755e-01],\n         [ 1.39412344e-01,  6.55381382e-02,  1.96098864e-01,\n          -7.53276348e-02,  1.78287134e-01, -2.57888436e-01,\n          -1.60236061e-01,  2.12951466e-01,  2.37015352e-01,\n          -6.44323081e-02,  1.67331584e-02,  4.13743407e-01,\n           9.24480185e-02,  2.63279706e-01,  1.40750051e-01,\n          -6.97017983e-02,  1.58374347e-02, -2.42212042e-01,\n          -2.44212709e-02,  2.84537431e-02,  1.03397556e-02,\n           1.11399263e-01,  1.14202015e-01, -2.11482793e-01],\n         [-1.51300415e-01,  2.09614500e-01, -3.51036072e-01,\n          -1.28431082e-01,  2.47942507e-01, -4.25407588e-02,\n           1.23179868e-01, -5.62894344e-02,  8.31497088e-02,\n           1.68619007e-01, -7.96044022e-02,  1.82905998e-02,\n          -4.65847738e-02, -6.94306865e-02,  9.54045728e-02,\n          -1.84405312e-01, -9.19958204e-02,  1.42244488e-01,\n          -2.49998555e-01, -5.38746938e-02,  8.80688652e-02,\n          -1.94409594e-01,  1.39907569e-01, -3.11363280e-01],\n         [ 1.09884217e-02, -1.07570486e-02, -4.30404425e-01,\n           1.46780327e-01, -1.43354133e-01, -1.63133115e-01,\n           1.54467762e-01, -1.57679155e-01, -8.23075324e-03,\n          -1.52325764e-01,  2.63443798e-01,  1.37349531e-01,\n           2.05407053e-01,  2.24886313e-02, -7.65604526e-02,\n          -2.44678661e-01,  3.22479129e-01,  3.24740589e-01,\n          -4.96664345e-02,  1.65633574e-01, -2.85297874e-02,\n          -3.07544172e-01,  2.17049867e-02,  1.63968518e-01],\n         [ 4.61600691e-01, -1.29953653e-01, -1.06489714e-02,\n           1.72597855e-01, -2.89302822e-02, -3.33692491e-01,\n           1.31310746e-01, -1.20318025e-01, -2.24358261e-01,\n          -1.49492174e-01,  3.33057523e-01,  2.25320905e-01,\n          -1.91151679e-01, -5.77321723e-02, -3.57097536e-02,\n          -9.69030783e-02, -1.92144424e-01, -1.17964879e-01,\n           6.01199530e-02, -2.27425084e-01, -1.60159260e-01,\n          -1.62799418e-01,  2.29591817e-01, -1.57995597e-01],\n         [-2.65026569e-01, -3.31593037e-01,  3.76743168e-01,\n          -1.14735991e-01,  1.68919191e-02, -4.06032115e-01,\n           1.64764434e-01, -2.25920193e-02,  1.09369040e-01,\n          -4.04786497e-01, -2.01515984e-02, -1.35330796e-01,\n          -4.60773855e-01,  4.55053039e-02,  2.03868493e-01,\n          -1.06567919e-01, -2.66350120e-01,  2.50047930e-02,\n           1.74135208e-01,  2.33586356e-01,  1.03171922e-01,\n          -1.90436572e-01, -1.31052747e-01, -3.81031454e-01],\n         [-1.19460367e-01, -2.54753321e-01, -3.32350999e-01,\n           2.55292002e-02, -1.62125126e-01, -2.54650079e-02,\n          -5.71575090e-02, -3.05143625e-01, -6.22119121e-02,\n          -3.88620734e-01,  3.82516682e-01, -2.05147177e-01,\n           1.59026250e-01, -3.26179832e-01, -5.47350235e-02,\n          -1.50111243e-01,  3.23475718e-01, -3.49901081e-03,\n          -7.45047554e-02, -3.00459743e-01,  3.52437586e-01,\n          -2.74110496e-01, -3.67665112e-01,  1.42708808e-01],\n         [-4.23080847e-02,  3.97151709e-01,  3.16315204e-01,\n          -1.78291082e-01,  2.05567658e-01,  2.22794682e-01,\n           3.96551862e-02,  3.10912073e-01,  2.46468261e-01,\n          -1.72455937e-01, -2.54351646e-01, -3.05025876e-01,\n          -1.99753076e-01, -7.87938386e-02, -4.16367739e-01,\n           4.41769250e-02,  7.48884901e-02, -8.84809345e-02,\n           4.17002112e-01,  4.63550687e-01, -1.90631539e-01,\n           2.38003150e-01,  5.50110117e-02, -3.08317572e-01],\n         [-1.51426569e-01,  5.12997173e-02, -3.14696640e-01,\n           4.21107888e-01,  1.26865610e-01, -1.26972675e-01,\n           8.99012983e-02,  3.18751007e-01,  2.52864808e-01,\n          -1.09527014e-01, -3.34995277e-02, -1.95748597e-01,\n           3.52941722e-01, -1.43602654e-01, -3.21989954e-01,\n          -2.16904938e-01, -3.52620214e-01, -1.43125907e-01,\n          -9.02584866e-02, -2.15404645e-01,  6.95308018e-03,\n          -1.19512856e-01, -1.21129759e-01, -3.55999559e-01],\n         [-1.62083600e-02, -2.06755877e-01,  3.47617894e-01,\n           7.53517300e-02,  4.21195067e-02,  4.13988918e-01,\n           1.29725367e-01, -1.33498847e-01, -2.32933134e-01,\n           3.22412193e-01, -8.78358632e-02, -5.47286570e-02,\n           6.71751238e-03,  1.73532560e-01, -2.91200966e-01,\n           1.99565738e-01, -3.37108791e-01, -4.63949591e-02,\n          -3.11299652e-01, -5.49414791e-02, -2.38083929e-01,\n           1.24285787e-01,  2.66104549e-01, -1.49634453e-02],\n         [-5.54125719e-02, -4.06134665e-01,  2.39789441e-01,\n           8.64854604e-02, -3.12907308e-01,  2.89627194e-01,\n           1.49804845e-01, -1.31035745e-01,  1.94335476e-01,\n          -1.00586958e-01, -8.08686465e-02,  2.81991363e-01,\n          -5.43198884e-02,  2.61789203e-01, -1.99542344e-01,\n          -2.29650438e-01, -2.51374573e-01,  3.85829985e-01,\n          -1.16104394e-01, -1.67164415e-01,  1.63868546e-01,\n           1.38005242e-01,  1.40464649e-01, -1.12362720e-01],\n         [ 9.39455181e-02, -1.14810310e-01,  9.80247632e-02,\n          -2.84063190e-01, -3.62394005e-01,  3.12610865e-01,\n          -3.25615406e-02,  1.38691023e-01,  2.56698225e-02,\n          -4.78386171e-02, -5.30254208e-02,  5.96855059e-02,\n           3.32654297e-01, -2.29626477e-01,  2.09042281e-01,\n          -7.00509027e-02,  2.27016106e-01,  2.34369040e-01,\n           3.46022516e-01,  9.78177488e-02,  7.70256966e-02,\n          -1.65916562e-01, -1.18930466e-01, -2.33623803e-01],\n         [ 5.68194082e-03,  5.87251969e-03,  4.39089872e-02,\n          -1.63235366e-01,  6.34942502e-02, -1.10668465e-01,\n          -1.60611600e-01, -9.51056331e-02, -9.89433601e-02,\n          -1.40878618e-01,  7.66124502e-02,  1.34672701e-01,\n          -2.15953872e-01, -1.89283550e-01,  1.90985352e-01,\n          -1.42657936e-01, -3.00903678e-01, -1.91503257e-01,\n           1.26229122e-01, -2.79375166e-01, -1.41020060e-01,\n           3.25634837e-01,  1.99098643e-02, -2.14155942e-01],\n         [-4.14262503e-01,  9.65789426e-03,  6.06729724e-02,\n          -1.07294813e-01,  2.43518203e-01,  2.91277841e-02,\n          -1.63813204e-01,  2.67330885e-01,  1.40205026e-01,\n           4.80431691e-02, -3.29997465e-02,  3.51133168e-01,\n           3.79026192e-03,  4.05593693e-01,  1.20759252e-02,\n          -7.09572285e-02, -4.00459707e-01,  3.46686272e-03,\n          -3.45991611e-01, -1.96331263e-01, -1.42853022e-01,\n           1.44334704e-01,  1.28495526e-02, -1.28752232e-01],\n         [ 1.91116348e-01,  1.51617810e-01,  2.38321975e-01,\n           2.02236965e-01,  2.59949803e-01,  6.20558299e-02,\n           5.42467274e-02, -8.37595761e-02,  7.52476528e-02,\n           2.58312404e-01, -1.42123461e-01,  1.21520972e-03,\n          -5.81599809e-02, -3.00382733e-01, -1.18727058e-01,\n           3.48826647e-01, -1.23561613e-01, -9.53824073e-02,\n           4.20462579e-01, -1.16105795e-01, -1.37909159e-01,\n           3.18094432e-01,  2.00111181e-01,  6.23314343e-02],\n         [ 1.94858655e-01,  1.29717276e-01,  4.50915881e-02,\n           1.04895294e-01,  1.66301742e-01, -1.17047653e-01,\n          -8.04652125e-02, -1.04753025e-01,  1.01913013e-01,\n           1.57645747e-01, -1.72372103e-01, -2.13018358e-01,\n           1.44036189e-01, -2.93255836e-01, -4.60918695e-01,\n           1.21040404e-01, -1.30950913e-01, -1.20325968e-01,\n          -4.02127594e-01,  1.43194184e-01,  8.73684511e-02,\n          -4.21112441e-02,  6.86736703e-02, -4.70029414e-02],\n         [ 1.23182110e-01, -4.40145433e-01, -5.24939783e-02,\n           2.58331690e-02, -2.19020009e-01, -2.37944871e-02,\n           1.39680386e-01,  2.28184342e-01, -4.95996960e-02,\n           9.30376053e-02, -7.83670098e-02, -1.72877580e-01,\n          -9.93379485e-03,  1.16599269e-01,  6.37399033e-02,\n           1.05182111e-01,  1.81904390e-01, -4.61650081e-02,\n          -4.29680087e-02, -2.19654460e-02,  1.01285279e-01,\n           8.48396719e-02, -5.89997768e-02, -2.23560050e-01],\n         [-3.71553183e-01,  7.06115738e-02,  9.01893750e-02,\n          -1.17594097e-02, -2.55040154e-02,  1.79949865e-01,\n           3.13523859e-01,  1.05610371e-01, -1.88348547e-01,\n           2.01815471e-01,  1.25793397e-01,  3.02127004e-02,\n          -8.18207636e-02,  6.55046627e-02,  4.37186770e-02,\n          -3.46403182e-01, -2.90146828e-01, -2.86445208e-02,\n          -4.23482507e-01,  1.54915720e-01, -3.69703293e-01,\n           3.50470632e-01, -2.25925469e-04, -1.01971906e-02],\n         [ 2.58627415e-01,  2.21890822e-01, -1.73520654e-01,\n           3.13217193e-01, -9.56916884e-02, -9.93056744e-02,\n          -8.41328502e-02,  3.38838369e-01, -1.75692048e-02,\n          -3.21697861e-01,  5.91104180e-02,  2.25315392e-01,\n           3.08550775e-01, -1.81837603e-01, -2.84738421e-01,\n          -4.09840196e-02,  2.66594976e-01,  7.65532926e-02,\n          -9.29761603e-02,  1.05110586e-01, -1.58268496e-01,\n           3.36448364e-02, -1.26135442e-02, -8.99771079e-02],\n         [-2.45816737e-01,  2.28358909e-01,  3.93657833e-01,\n          -1.80596903e-01, -2.82370336e-02, -2.00656891e-01,\n           3.37813497e-01,  1.42774448e-01,  2.43834838e-01,\n          -1.22346049e-02, -1.47147983e-01,  3.88199538e-01,\n          -7.80526474e-02,  2.52547324e-01,  1.74797207e-01,\n           2.79319525e-01,  2.18980670e-01, -6.12645708e-02,\n          -1.58138603e-01, -2.87641454e-02, -6.28589019e-02,\n          -1.25012070e-01,  1.71689525e-01, -2.94187307e-01],\n         [ 1.97546318e-01,  2.53386497e-01,  3.59842509e-01,\n          -1.24021269e-01, -1.22953303e-01, -3.46196204e-01,\n          -7.42975622e-02,  2.71183789e-01,  2.69713461e-01,\n           3.56877632e-02, -1.16049848e-01,  1.36917144e-01,\n           3.21504146e-01,  1.82195708e-01, -1.50063047e-02,\n           4.58752736e-02,  1.28179729e-01, -1.69096023e-01,\n          -2.73996871e-02, -3.99021924e-01,  1.87969744e-01,\n          -3.50153029e-01, -1.87828943e-01, -1.81775600e-01],\n         [ 5.18975817e-02, -3.16288918e-01,  5.82023636e-02,\n          -1.56205118e-01,  4.49688099e-02, -1.71544239e-01,\n           5.87657839e-02, -3.64348203e-01, -6.03703707e-02,\n          -1.82167247e-01, -3.34396333e-01,  8.89104456e-02,\n           9.60206985e-02, -5.33072539e-02, -2.50643104e-01,\n           6.04541674e-02, -1.52715549e-01, -4.38896865e-02,\n           3.30199510e-01,  1.02455333e-01, -1.62076354e-01,\n          -2.01144323e-01, -2.54707307e-01,  6.30588606e-02]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.08950169, -0.25865227, -0.06576162, ..., -0.38716087,\n          -0.07422686, -0.11374398],\n         [ 0.22133687, -0.28971478, -0.1050359 , ...,  0.3236601 ,\n          -0.1195141 , -0.0255743 ],\n         [-0.15862454,  0.41304547,  0.12608218, ..., -0.02676832,\n           0.15773886,  0.1698634 ],\n         ...,\n         [ 0.14942987, -0.07665537, -0.12274998, ...,  0.2091249 ,\n           0.38524148, -0.2502452 ],\n         [ 0.05583834,  0.01493152,  0.29702696, ..., -0.09265302,\n          -0.21088955, -0.19551441],\n         [ 0.01877302,  0.10190286,  0.05397153, ..., -0.1455231 ,\n          -0.24930139, -0.16344942]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_358/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.09909619],\n         [-0.02956621],\n         [ 0.0698209 ],\n         [-0.14270182],\n         [ 0.07355852],\n         [-0.01430281],\n         [-0.14692292],\n         [ 0.04224443],\n         [ 0.05718258],\n         [-0.10113262],\n         [ 0.09023923],\n         [ 0.10247001],\n         [ 0.15992272],\n         [ 0.05188684],\n         [ 0.13800377],\n         [ 0.14307356],\n         [ 0.00031848],\n         [-0.15293229],\n         [-0.00499187],\n         [-0.08258998],\n         [ 0.04502176],\n         [-0.05584588],\n         [-0.02169788],\n         [-0.08357633]],\n\n        [[ 0.16015646],\n         [ 0.11668113],\n         [ 0.15233621],\n         [ 0.11061075],\n         [-0.06030728],\n         [-0.00650655],\n         [ 0.0602138 ],\n         [-0.12718593],\n         [ 0.11524957],\n         [-0.07546226],\n         [-0.03680794],\n         [-0.03238069],\n         [-0.08612224],\n         [-0.02131626],\n         [-0.08379517],\n         [-0.02109718],\n         [-0.09916514],\n         [-0.10943486],\n         [ 0.07645503],\n         [ 0.1535987 ],\n         [ 0.04075666],\n         [ 0.1363785 ],\n         [-0.04356521],\n         [-0.04439578]],\n\n        [[-0.08615786],\n         [-0.08540169],\n         [ 0.12593207],\n         [-0.04387029],\n         [ 0.06912524],\n         [-0.03282422],\n         [-0.00832836],\n         [ 0.1493716 ],\n         [ 0.10355681],\n         [-0.15342818],\n         [-0.00367993],\n         [ 0.03987932],\n         [ 0.04110281],\n         [-0.03921442],\n         [ 0.15538517],\n         [ 0.03929731],\n         [ 0.05357227],\n         [-0.09325339],\n         [-0.0428125 ],\n         [-0.10149283],\n         [-0.12642007],\n         [ 0.05854729],\n         [-0.05914173],\n         [ 0.05474395]]],\n\n\n       [[[ 0.15013662],\n         [-0.01382847],\n         [-0.04366453],\n         [-0.05605047],\n         [-0.10222307],\n         [-0.02066007],\n         [-0.01637095],\n         [-0.15933923],\n         [-0.01362984],\n         [ 0.10024902],\n         [-0.13368884],\n         [-0.12773812],\n         [ 0.12727407],\n         [-0.11175829],\n         [ 0.05217604],\n         [ 0.08648308],\n         [-0.09171625],\n         [-0.03058755],\n         [-0.0588693 ],\n         [-0.06708916],\n         [-0.14114463],\n         [ 0.03217798],\n         [-0.07087292],\n         [ 0.0522975 ]],\n\n        [[-0.11327608],\n         [-0.08812973],\n         [-0.12393415],\n         [ 0.04434143],\n         [ 0.03394838],\n         [-0.08565713],\n         [-0.11106519],\n         [-0.13610008],\n         [-0.0353155 ],\n         [ 0.16052529],\n         [ 0.06148985],\n         [ 0.16215825],\n         [ 0.09222496],\n         [-0.03287268],\n         [ 0.02266651],\n         [-0.11426122],\n         [ 0.13656399],\n         [ 0.00689763],\n         [ 0.07830137],\n         [-0.1181777 ],\n         [ 0.0571273 ],\n         [-0.09140735],\n         [-0.15239005],\n         [-0.15231857]],\n\n        [[-0.14446247],\n         [ 0.0694325 ],\n         [-0.13059588],\n         [ 0.09653911],\n         [-0.10974457],\n         [ 0.14987305],\n         [-0.01269048],\n         [ 0.11169916],\n         [-0.0048551 ],\n         [ 0.15250611],\n         [-0.13860102],\n         [ 0.01482467],\n         [ 0.14114752],\n         [ 0.05875041],\n         [-0.08388655],\n         [ 0.12867272],\n         [ 0.13420573],\n         [ 0.12607074],\n         [-0.01583573],\n         [-0.12415342],\n         [ 0.08703214],\n         [ 0.00876562],\n         [ 0.15634888],\n         [-0.07655971]]],\n\n\n       [[[ 0.04984291],\n         [-0.12087651],\n         [ 0.02824812],\n         [ 0.07182212],\n         [ 0.16318181],\n         [ 0.04174647],\n         [-0.10650666],\n         [-0.00305332],\n         [-0.02595964],\n         [ 0.0749481 ],\n         [-0.0838104 ],\n         [-0.13124374],\n         [ 0.12892017],\n         [ 0.09525967],\n         [ 0.0594992 ],\n         [ 0.01839675],\n         [-0.05466194],\n         [-0.07664335],\n         [ 0.14835158],\n         [-0.1481158 ],\n         [-0.13520001],\n         [-0.12603863],\n         [-0.01207814],\n         [ 0.07727383]],\n\n        [[-0.08818506],\n         [ 0.10962209],\n         [-0.12476332],\n         [-0.15919876],\n         [ 0.07413194],\n         [ 0.08007558],\n         [-0.13655373],\n         [ 0.02392535],\n         [ 0.0981971 ],\n         [ 0.04804409],\n         [-0.14920314],\n         [ 0.15518731],\n         [-0.04636278],\n         [-0.0246865 ],\n         [ 0.1576007 ],\n         [ 0.08813962],\n         [-0.13416617],\n         [ 0.00997911],\n         [-0.13372767],\n         [ 0.06163052],\n         [ 0.11980361],\n         [ 0.06730548],\n         [-0.12897146],\n         [-0.07424024]],\n\n        [[ 0.13176432],\n         [-0.00475018],\n         [-0.06270719],\n         [-0.15862982],\n         [ 0.0837425 ],\n         [ 0.01337494],\n         [-0.02384974],\n         [-0.13205332],\n         [ 0.02677096],\n         [ 0.00769542],\n         [ 0.1328499 ],\n         [-0.05490007],\n         [-0.05947647],\n         [ 0.03733104],\n         [-0.05754548],\n         [-0.09941907],\n         [-0.15656252],\n         [-0.12614204],\n         [-0.15259391],\n         [ 0.135916  ],\n         [-0.09641857],\n         [ 0.09233513],\n         [-0.09538508],\n         [ 0.149683  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_857/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.0093849 , -0.07618431,  0.0412395 , ..., -0.00709378,\n           0.06516431,  0.14116032],\n         [ 0.0328113 ,  0.07770959,  0.04106437, ..., -0.1046966 ,\n          -0.12375969,  0.06138004],\n         [-0.00601875, -0.15626875,  0.11754517, ...,  0.01796212,\n           0.00588956,  0.04789983],\n         ...,\n         [ 0.07529315,  0.04426454, -0.02899083, ...,  0.03000407,\n           0.04389154,  0.04538391],\n         [ 0.10521343,  0.0657078 ,  0.1492111 , ..., -0.09759308,\n          -0.04631427, -0.15683034],\n         [-0.00703483,  0.06134846,  0.00979729, ...,  0.09885541,\n          -0.08550805,  0.0487494 ]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_357/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.1543562 ],\n         [-0.04362474],\n         [-0.10527924],\n         [-0.11073216],\n         [-0.00844142],\n         [ 0.00394292],\n         [ 0.05242486],\n         [ 0.0921374 ],\n         [ 0.0365122 ],\n         [-0.083565  ],\n         [-0.00918292],\n         [ 0.04601164],\n         [-0.09692603],\n         [-0.03396317],\n         [ 0.03052402],\n         [ 0.15421212],\n         [ 0.08781141],\n         [-0.08901333],\n         [ 0.04679628],\n         [-0.16155326],\n         [-0.08809371],\n         [ 0.0776916 ],\n         [ 0.05964163],\n         [ 0.08641852]],\n\n        [[-0.09491013],\n         [ 0.12147394],\n         [ 0.01445842],\n         [-0.10457781],\n         [ 0.14931008],\n         [-0.09531979],\n         [-0.03378026],\n         [-0.07134888],\n         [ 0.09466723],\n         [ 0.06590986],\n         [ 0.04273611],\n         [-0.02090174],\n         [ 0.08818796],\n         [ 0.15370569],\n         [ 0.10529679],\n         [-0.13825265],\n         [ 0.13934472],\n         [ 0.13935784],\n         [ 0.11456934],\n         [ 0.1285601 ],\n         [ 0.03718372],\n         [ 0.15407264],\n         [ 0.01547852],\n         [ 0.00163241]],\n\n        [[ 0.06718656],\n         [-0.16097058],\n         [ 0.09880129],\n         [ 0.13922703],\n         [-0.06356275],\n         [ 0.02876227],\n         [ 0.07081075],\n         [ 0.09418106],\n         [ 0.09011522],\n         [ 0.0220903 ],\n         [-0.1626848 ],\n         [-0.01907805],\n         [-0.02069713],\n         [ 0.05405334],\n         [-0.13838615],\n         [-0.09404799],\n         [-0.03725034],\n         [-0.13277519],\n         [-0.1632656 ],\n         [ 0.00141963],\n         [-0.05724858],\n         [-0.14265315],\n         [-0.0902316 ],\n         [ 0.10271519]]],\n\n\n       [[[ 0.15806687],\n         [ 0.08697987],\n         [ 0.13376415],\n         [ 0.06312501],\n         [-0.0792517 ],\n         [-0.00787194],\n         [ 0.06238902],\n         [ 0.09803048],\n         [-0.00146383],\n         [-0.09744529],\n         [-0.02142079],\n         [-0.02368778],\n         [ 0.12281302],\n         [-0.11794558],\n         [ 0.1358988 ],\n         [ 0.0239289 ],\n         [-0.1349137 ],\n         [-0.09999404],\n         [-0.03907274],\n         [ 0.07486373],\n         [ 0.08161961],\n         [-0.09107754],\n         [-0.0688071 ],\n         [-0.09561346]],\n\n        [[-0.0906777 ],\n         [-0.12004145],\n         [-0.12519537],\n         [-0.04437791],\n         [-0.01172151],\n         [-0.07900128],\n         [ 0.13290188],\n         [ 0.06057709],\n         [-0.01205812],\n         [-0.1340361 ],\n         [-0.14699666],\n         [-0.06868816],\n         [-0.07166008],\n         [-0.13240318],\n         [ 0.08321027],\n         [ 0.04692961],\n         [ 0.12844568],\n         [ 0.09649256],\n         [-0.08155961],\n         [ 0.10885033],\n         [ 0.11869517],\n         [-0.10353096],\n         [-0.08013324],\n         [ 0.15228513]],\n\n        [[-0.11148256],\n         [-0.09595013],\n         [-0.09668165],\n         [-0.13286163],\n         [ 0.06489603],\n         [-0.05243362],\n         [ 0.15236193],\n         [ 0.08546574],\n         [ 0.06281959],\n         [ 0.15405712],\n         [-0.13763885],\n         [-0.12025383],\n         [ 0.14673862],\n         [ 0.07903893],\n         [ 0.07684024],\n         [ 0.08145736],\n         [ 0.01015949],\n         [ 0.14129975],\n         [ 0.01512048],\n         [ 0.09721512],\n         [ 0.04439126],\n         [ 0.15398738],\n         [-0.02733403],\n         [ 0.08779907]]],\n\n\n       [[[ 0.11620066],\n         [-0.04848894],\n         [-0.03970467],\n         [-0.02734143],\n         [-0.01454303],\n         [-0.16219392],\n         [-0.11013629],\n         [-0.09952668],\n         [ 0.08644702],\n         [ 0.00041242],\n         [ 0.09040463],\n         [-0.04100852],\n         [-0.11363298],\n         [-0.11777081],\n         [-0.06029735],\n         [ 0.03269087],\n         [-0.00095099],\n         [-0.14430529],\n         [-0.01997325],\n         [-0.14634211],\n         [-0.03172581],\n         [-0.14706472],\n         [ 0.05975731],\n         [-0.12937275]],\n\n        [[-0.01046547],\n         [-0.15458684],\n         [-0.0688919 ],\n         [ 0.09468397],\n         [-0.14597122],\n         [-0.08475629],\n         [-0.013016  ],\n         [-0.06790439],\n         [-0.08426689],\n         [ 0.09009016],\n         [ 0.03769231],\n         [ 0.13048407],\n         [ 0.1603406 ],\n         [-0.09607479],\n         [ 0.0582872 ],\n         [-0.13456967],\n         [-0.13953456],\n         [-0.15219185],\n         [-0.13091385],\n         [-0.13461235],\n         [-0.0481285 ],\n         [-0.08452639],\n         [-0.13123249],\n         [-0.06883012]],\n\n        [[ 0.01952091],\n         [ 0.08030018],\n         [ 0.070032  ],\n         [-0.08933768],\n         [ 0.041169  ],\n         [ 0.10776007],\n         [ 0.01371825],\n         [ 0.02999565],\n         [ 0.07270238],\n         [-0.14533222],\n         [-0.01930654],\n         [-0.06409241],\n         [ 0.09145212],\n         [ 0.07270864],\n         [ 0.01512721],\n         [-0.03076972],\n         [-0.16121466],\n         [-0.00368296],\n         [ 0.01001096],\n         [ 0.11736131],\n         [ 0.08949232],\n         [ 0.05252285],\n         [ 0.08120197],\n         [-0.05429608]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_363/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.05298261],\n         [-0.04347412],\n         [-0.01350139],\n         [-0.07802997],\n         [-0.03586381],\n         [-0.049035  ],\n         [-0.00903175],\n         [ 0.06359079],\n         [ 0.06810628],\n         [ 0.03028417],\n         [-0.02746696],\n         [-0.03742422],\n         [ 0.08608593],\n         [-0.06236688],\n         [ 0.06328404],\n         [ 0.01399911],\n         [ 0.08174984],\n         [ 0.00155799],\n         [ 0.06581785],\n         [-0.00386532],\n         [-0.04672595],\n         [-0.01339091],\n         [ 0.00997933],\n         [-0.08026826],\n         [-0.01987337],\n         [ 0.02174885],\n         [ 0.00448915],\n         [-0.08418126],\n         [ 0.04969518],\n         [-0.08991464],\n         [-0.01489896],\n         [ 0.01607019],\n         [ 0.05493298],\n         [ 0.01094002],\n         [ 0.05647634],\n         [-0.04087238],\n         [ 0.0366326 ],\n         [-0.08721789],\n         [ 0.07907724],\n         [ 0.07253528],\n         [ 0.01775885],\n         [-0.01116306],\n         [ 0.04144582],\n         [-0.02251227],\n         [-0.08523309],\n         [-0.03461389],\n         [-0.00214615],\n         [-0.00633627],\n         [-0.02008063],\n         [-0.00991018],\n         [-0.01565913],\n         [ 0.0463427 ],\n         [ 0.0894313 ],\n         [-0.01497076],\n         [-0.05059624],\n         [-0.0795712 ],\n         [-0.06200073],\n         [-0.06233876],\n         [ 0.02639455],\n         [ 0.01312596],\n         [-0.07568688],\n         [-0.01599316],\n         [-0.05819158],\n         [ 0.08128271],\n         [ 0.05769262],\n         [ 0.01808815],\n         [ 0.03537878],\n         [-0.00030422],\n         [ 0.06659919],\n         [ 0.0604445 ],\n         [-0.01232339],\n         [ 0.08944979],\n         [-0.00807615],\n         [-0.05304118],\n         [-0.00095755],\n         [ 0.04006597],\n         [-0.03759263],\n         [-0.00827473],\n         [-0.02523082],\n         [-0.08866937]],\n\n        [[ 0.06721216],\n         [-0.033228  ],\n         [-0.02984305],\n         [-0.02302394],\n         [-0.03617355],\n         [-0.04404538],\n         [-0.07946093],\n         [ 0.00733095],\n         [-0.01416339],\n         [-0.06243047],\n         [-0.0339571 ],\n         [ 0.01188467],\n         [-0.00579628],\n         [-0.01025797],\n         [ 0.00913981],\n         [ 0.00266241],\n         [ 0.00711801],\n         [-0.01336891],\n         [-0.01964373],\n         [-0.05814767],\n         [ 0.06108975],\n         [ 0.02508366],\n         [-0.03270208],\n         [-0.06563758],\n         [ 0.0451217 ],\n         [ 0.07777625],\n         [-0.032192  ],\n         [ 0.08708495],\n         [-0.04778069],\n         [-0.02581466],\n         [ 0.0673447 ],\n         [-0.03781473],\n         [-0.04186957],\n         [ 0.05974098],\n         [-0.07189693],\n         [-0.04388811],\n         [ 0.04808757],\n         [-0.03152012],\n         [-0.02359442],\n         [-0.06109343],\n         [ 0.03437553],\n         [-0.07121469],\n         [ 0.07225282],\n         [-0.07119821],\n         [ 0.05967121],\n         [-0.08783079],\n         [ 0.07344154],\n         [ 0.06890786],\n         [-0.0204224 ],\n         [-0.064471  ],\n         [-0.01348638],\n         [ 0.02241152],\n         [-0.03053715],\n         [-0.02360081],\n         [ 0.08707763],\n         [ 0.03087157],\n         [ 0.00497337],\n         [-0.02413388],\n         [-0.03502923],\n         [ 0.03661242],\n         [-0.08585317],\n         [-0.02968189],\n         [-0.05406392],\n         [ 0.07562643],\n         [ 0.05342093],\n         [-0.018076  ],\n         [ 0.03067385],\n         [-0.09006127],\n         [ 0.08526392],\n         [ 0.05969599],\n         [-0.00272769],\n         [-0.08159765],\n         [-0.02885702],\n         [-0.04006831],\n         [-0.0331138 ],\n         [ 0.08193074],\n         [ 0.0533026 ],\n         [ 0.02221341],\n         [-0.03098813],\n         [ 0.02527017]],\n\n        [[ 0.04726015],\n         [-0.01815253],\n         [ 0.04471627],\n         [-0.04870324],\n         [ 0.03126625],\n         [-0.03874011],\n         [ 0.06912351],\n         [-0.0589094 ],\n         [ 0.00022583],\n         [-0.05100746],\n         [-0.07912616],\n         [-0.0871629 ],\n         [ 0.01365352],\n         [-0.03702554],\n         [-0.06915888],\n         [ 0.01731355],\n         [-0.02114066],\n         [ 0.06711836],\n         [ 0.06623952],\n         [-0.07287711],\n         [ 0.07039808],\n         [-0.06500651],\n         [ 0.05655946],\n         [-0.00628769],\n         [-0.04188831],\n         [ 0.0305813 ],\n         [-0.01088352],\n         [-0.00107394],\n         [ 0.02528505],\n         [-0.05269863],\n         [-0.08048852],\n         [ 0.04626392],\n         [ 0.01949695],\n         [-0.07173852],\n         [-0.03160785],\n         [-0.00349265],\n         [-0.03054293],\n         [-0.08337758],\n         [-0.00249264],\n         [-0.05081286],\n         [ 0.06019534],\n         [-0.06080283],\n         [-0.03675844],\n         [-0.05031133],\n         [-0.05524943],\n         [-0.04518622],\n         [ 0.04622447],\n         [-0.06099726],\n         [ 0.08748516],\n         [ 0.07312602],\n         [ 0.04065117],\n         [ 0.08390489],\n         [ 0.03313102],\n         [-0.02060351],\n         [ 0.05807929],\n         [-0.03745567],\n         [ 0.08511746],\n         [ 0.04580659],\n         [-0.05775608],\n         [ 0.06441122],\n         [ 0.00236078],\n         [ 0.08545871],\n         [-0.02402986],\n         [-0.0313197 ],\n         [ 0.02121241],\n         [ 0.00371366],\n         [-0.04359438],\n         [ 0.06536743],\n         [ 0.00878463],\n         [-0.00990772],\n         [-0.06612951],\n         [-0.01553001],\n         [ 0.05379207],\n         [-0.05864786],\n         [ 0.04181433],\n         [-0.04101801],\n         [-0.01809502],\n         [-0.04798959],\n         [ 0.0044298 ],\n         [ 0.07202011]]],\n\n\n       [[[ 0.01571522],\n         [-0.08249842],\n         [ 0.04081289],\n         [-0.04097222],\n         [ 0.06612709],\n         [ 0.03860056],\n         [-0.05283637],\n         [ 0.01772668],\n         [-0.07369085],\n         [ 0.05207188],\n         [ 0.06155628],\n         [-0.06448035],\n         [-0.06146879],\n         [ 0.01903883],\n         [ 0.05274113],\n         [ 0.01721144],\n         [ 0.08812451],\n         [-0.06960922],\n         [ 0.07264848],\n         [-0.06785725],\n         [ 0.04883473],\n         [ 0.03855909],\n         [ 0.06614052],\n         [ 0.01925318],\n         [ 0.02403027],\n         [-0.01164994],\n         [ 0.05619629],\n         [-0.01376058],\n         [-0.04031971],\n         [ 0.0783277 ],\n         [ 0.00162792],\n         [-0.0168032 ],\n         [-0.04760144],\n         [-0.03753326],\n         [ 0.01017631],\n         [ 0.06980033],\n         [-0.04708187],\n         [-0.03060254],\n         [-0.02584827],\n         [ 0.0454063 ],\n         [-0.00314181],\n         [-0.00030353],\n         [-0.07321988],\n         [ 0.06647891],\n         [ 0.07937758],\n         [-0.05759005],\n         [-0.01126476],\n         [-0.01097655],\n         [-0.06537954],\n         [ 0.03605646],\n         [ 0.01161013],\n         [-0.02746631],\n         [-0.07507539],\n         [-0.02132445],\n         [-0.03053897],\n         [-0.00925839],\n         [ 0.05670334],\n         [ 0.02233458],\n         [ 0.045771  ],\n         [-0.01127307],\n         [-0.07189704],\n         [ 0.04654463],\n         [-0.07568552],\n         [-0.0503938 ],\n         [-0.03569761],\n         [-0.05492818],\n         [-0.02972945],\n         [ 0.01547472],\n         [ 0.01795328],\n         [ 0.07521172],\n         [-0.00142259],\n         [-0.02028974],\n         [ 0.05948153],\n         [ 0.06484537],\n         [-0.0812482 ],\n         [ 0.06278796],\n         [ 0.06614925],\n         [-0.06125926],\n         [-0.08631949],\n         [ 0.00303072]],\n\n        [[-0.00266889],\n         [ 0.08065954],\n         [-0.04317368],\n         [ 0.0442248 ],\n         [-0.03473748],\n         [-0.01913017],\n         [ 0.06842253],\n         [-0.00265791],\n         [ 0.05259986],\n         [-0.00095547],\n         [ 0.06180498],\n         [-0.08946654],\n         [ 0.08469266],\n         [-0.0693448 ],\n         [ 0.03283013],\n         [ 0.00894292],\n         [ 0.08305295],\n         [ 0.02657752],\n         [ 0.06467365],\n         [ 0.02476718],\n         [-0.0036898 ],\n         [ 0.03831585],\n         [-0.05206412],\n         [ 0.08993454],\n         [ 0.05236973],\n         [-0.0387344 ],\n         [-0.03027005],\n         [ 0.02459002],\n         [ 0.00051364],\n         [ 0.07413289],\n         [-0.00449672],\n         [ 0.08163607],\n         [ 0.04305558],\n         [ 0.01502527],\n         [-0.06636741],\n         [ 0.01509394],\n         [ 0.05712076],\n         [-0.08372039],\n         [-0.0810435 ],\n         [ 0.07587318],\n         [-0.05791973],\n         [-0.00268707],\n         [-0.08797746],\n         [ 0.03167923],\n         [ 0.03817368],\n         [-0.0076912 ],\n         [-0.0421892 ],\n         [ 0.07932676],\n         [-0.02824998],\n         [-0.00691365],\n         [-0.03368426],\n         [-0.05339067],\n         [-0.05721544],\n         [-0.04501102],\n         [ 0.01614258],\n         [ 0.03812931],\n         [ 0.0330843 ],\n         [ 0.05067943],\n         [ 0.00049805],\n         [-0.06293675],\n         [-0.02410887],\n         [ 0.07818595],\n         [-0.08515929],\n         [-0.07787246],\n         [-0.08551484],\n         [ 0.04034814],\n         [ 0.07823198],\n         [-0.03642376],\n         [ 0.08446436],\n         [ 0.05211797],\n         [-0.02316309],\n         [-0.04471039],\n         [-0.06390339],\n         [-0.08627055],\n         [-0.06609765],\n         [ 0.06933999],\n         [-0.02983825],\n         [ 0.07841526],\n         [-0.00213304],\n         [ 0.06222995]],\n\n        [[-0.03588343],\n         [ 0.03703536],\n         [-0.00444068],\n         [ 0.03706549],\n         [ 0.00963035],\n         [-0.04150868],\n         [ 0.02572786],\n         [-0.01584096],\n         [ 0.01269603],\n         [ 0.02560978],\n         [ 0.06326759],\n         [-0.00191157],\n         [ 0.0634764 ],\n         [ 0.00415725],\n         [ 0.0539695 ],\n         [-0.02289873],\n         [ 0.08630808],\n         [ 0.06478935],\n         [ 0.060959  ],\n         [-0.06802785],\n         [-0.07226115],\n         [ 0.00746965],\n         [-0.01279968],\n         [ 0.00385953],\n         [-0.02551024],\n         [ 0.01889488],\n         [-0.02910643],\n         [-0.08493765],\n         [-0.02938167],\n         [ 0.01749137],\n         [ 0.05749936],\n         [ 0.06803107],\n         [-0.03659533],\n         [ 0.03387409],\n         [ 0.05340947],\n         [-0.03732654],\n         [ 0.04502469],\n         [-0.01601503],\n         [-0.00757568],\n         [ 0.03061714],\n         [-0.03595238],\n         [-0.06391613],\n         [ 0.01188499],\n         [-0.00677743],\n         [-0.02018975],\n         [-0.00623009],\n         [ 0.05532146],\n         [ 0.07544403],\n         [-0.05821245],\n         [ 0.05636743],\n         [-0.05188254],\n         [ 0.08644456],\n         [-0.05895536],\n         [ 0.0145921 ],\n         [-0.04498322],\n         [ 0.00558998],\n         [ 0.06568819],\n         [ 0.05248705],\n         [-0.05197334],\n         [ 0.01833608],\n         [-0.05774587],\n         [-0.03460502],\n         [ 0.04242615],\n         [ 0.08387536],\n         [-0.01924414],\n         [-0.00437728],\n         [-0.07669821],\n         [-0.05113975],\n         [-0.05438313],\n         [ 0.05110666],\n         [ 0.07018316],\n         [ 0.02231926],\n         [ 0.00381547],\n         [-0.0223685 ],\n         [ 0.03747644],\n         [ 0.03459541],\n         [-0.04563073],\n         [ 0.0736798 ],\n         [ 0.03316008],\n         [-0.01813395]]],\n\n\n       [[[-0.02423878],\n         [ 0.07797226],\n         [ 0.03807068],\n         [-0.00631899],\n         [-0.00876914],\n         [-0.04925011],\n         [ 0.00236251],\n         [-0.06933993],\n         [ 0.03974116],\n         [ 0.0631649 ],\n         [-0.03801271],\n         [ 0.08618852],\n         [ 0.07530051],\n         [-0.05619071],\n         [-0.03838229],\n         [ 0.08453862],\n         [-0.01077602],\n         [ 0.00805382],\n         [-0.00778618],\n         [-0.07304459],\n         [-0.06350236],\n         [ 0.07296205],\n         [ 0.05610761],\n         [-0.05298892],\n         [-0.01056236],\n         [ 0.05716655],\n         [-0.02405711],\n         [-0.04933511],\n         [ 0.00080677],\n         [-0.05880363],\n         [ 0.00881442],\n         [ 0.05351634],\n         [ 0.08383499],\n         [-0.0343006 ],\n         [-0.05330446],\n         [ 0.07195105],\n         [-0.0642347 ],\n         [-0.0041671 ],\n         [ 0.0244135 ],\n         [-0.08328581],\n         [ 0.06141348],\n         [-0.06520589],\n         [ 0.08840807],\n         [ 0.00100643],\n         [ 0.02748553],\n         [-0.03759426],\n         [-0.01107072],\n         [ 0.0114359 ],\n         [ 0.00114785],\n         [-0.08934857],\n         [ 0.04356533],\n         [ 0.00132091],\n         [-0.04682833],\n         [-0.033108  ],\n         [-0.03509461],\n         [-0.03491593],\n         [ 0.05675182],\n         [ 0.07475892],\n         [-0.01360677],\n         [ 0.07503277],\n         [ 0.02173384],\n         [-0.03374   ],\n         [ 0.01120178],\n         [-0.04248057],\n         [ 0.08882083],\n         [-0.01205386],\n         [ 0.00249625],\n         [-0.03216157],\n         [ 0.00605943],\n         [ 0.04429269],\n         [-0.07407198],\n         [-0.04262311],\n         [ 0.03181848],\n         [-0.00508138],\n         [ 0.06243475],\n         [-0.06759265],\n         [-0.02038645],\n         [-0.04766614],\n         [-0.05789425],\n         [ 0.03875859]],\n\n        [[-0.05498375],\n         [ 0.07196572],\n         [-0.03352485],\n         [ 0.05193637],\n         [ 0.08970053],\n         [ 0.03560111],\n         [ 0.08372411],\n         [ 0.0727316 ],\n         [ 0.05939794],\n         [-0.08119646],\n         [-0.0663714 ],\n         [ 0.08519144],\n         [-0.08296606],\n         [-0.02253439],\n         [-0.07285725],\n         [-0.02640917],\n         [ 0.08806486],\n         [-0.08965061],\n         [ 0.01921749],\n         [-0.03408625],\n         [ 0.06478612],\n         [-0.08946513],\n         [ 0.00086991],\n         [-0.01710597],\n         [ 0.04944408],\n         [-0.03569393],\n         [ 0.08852285],\n         [-0.02689541],\n         [ 0.05829068],\n         [-0.02087124],\n         [-0.079473  ],\n         [ 0.0412841 ],\n         [-0.00937908],\n         [-0.05664892],\n         [ 0.09037028],\n         [-0.00119993],\n         [ 0.03810446],\n         [ 0.06485112],\n         [ 0.02597673],\n         [-0.07480225],\n         [ 0.03263115],\n         [ 0.06719066],\n         [ 0.03863017],\n         [-0.0874357 ],\n         [ 0.06974791],\n         [ 0.04161599],\n         [ 0.05079345],\n         [-0.06709854],\n         [-0.0559641 ],\n         [ 0.00122615],\n         [-0.08903044],\n         [-0.00087019],\n         [ 0.08381924],\n         [ 0.00430283],\n         [-0.01478854],\n         [ 0.03676821],\n         [ 0.00955837],\n         [ 0.09017073],\n         [-0.04440818],\n         [-0.08323701],\n         [ 0.06960882],\n         [-0.01692379],\n         [ 0.01286794],\n         [ 0.0579643 ],\n         [-0.0024348 ],\n         [ 0.02280697],\n         [ 0.00862096],\n         [ 0.02688994],\n         [ 0.02745242],\n         [-0.00347713],\n         [-0.01137786],\n         [ 0.04120582],\n         [ 0.07254343],\n         [-0.01458654],\n         [ 0.03719547],\n         [-0.01093223],\n         [-0.07239213],\n         [ 0.0102988 ],\n         [-0.07117034],\n         [-0.07215825]],\n\n        [[ 0.06401111],\n         [ 0.03959036],\n         [ 0.05608577],\n         [ 0.04146512],\n         [ 0.03233084],\n         [ 0.0883051 ],\n         [ 0.02049804],\n         [ 0.0679214 ],\n         [-0.02757848],\n         [-0.02697765],\n         [ 0.03461236],\n         [-0.05619473],\n         [-0.04930007],\n         [ 0.00036307],\n         [ 0.03059166],\n         [-0.07037257],\n         [-0.05837158],\n         [ 0.02039538],\n         [-0.05001729],\n         [-0.01006038],\n         [ 0.01551396],\n         [-0.03320389],\n         [ 0.08062479],\n         [ 0.02198747],\n         [-0.08660924],\n         [ 0.08359334],\n         [ 0.0221254 ],\n         [ 0.0420687 ],\n         [-0.01767944],\n         [-0.04771078],\n         [-0.05976676],\n         [-0.01163623],\n         [-0.03774322],\n         [-0.07739663],\n         [ 0.05385284],\n         [-0.07637759],\n         [ 0.03350002],\n         [-0.00863411],\n         [ 0.08102506],\n         [-0.03638881],\n         [ 0.06339975],\n         [ 0.04734057],\n         [ 0.08683293],\n         [-0.00292556],\n         [ 0.05364266],\n         [-0.0047215 ],\n         [-0.01581299],\n         [-0.05688905],\n         [ 0.04153381],\n         [ 0.04032065],\n         [ 0.04003891],\n         [-0.07048607],\n         [-0.05761322],\n         [-0.08222716],\n         [-0.0249026 ],\n         [-0.08375267],\n         [-0.02189976],\n         [-0.08946429],\n         [-0.02234875],\n         [ 0.01131012],\n         [ 0.05345422],\n         [ 0.08069211],\n         [-0.08599442],\n         [-0.06281762],\n         [-0.04166894],\n         [ 0.03026291],\n         [-0.03565991],\n         [ 0.00847517],\n         [-0.05613817],\n         [-0.0522868 ],\n         [ 0.07152873],\n         [-0.06991398],\n         [ 0.02356897],\n         [-0.05245274],\n         [-0.0902288 ],\n         [-0.04701141],\n         [-0.0849292 ],\n         [-0.082191  ],\n         [ 0.05579554],\n         [ 0.03321183]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_365/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.03762719],\n         [-0.06765648],\n         [-0.02261388],\n         ...,\n         [ 0.02738792],\n         [-0.00503846],\n         [ 0.01876736]],\n\n        [[-0.05111894],\n         [-0.0380067 ],\n         [-0.03986791],\n         ...,\n         [ 0.0012834 ],\n         [-0.07362705],\n         [ 0.06896204]],\n\n        [[-0.06999747],\n         [ 0.0544914 ],\n         [-0.04789488],\n         ...,\n         [-0.00994051],\n         [-0.00434703],\n         [-0.05593389]]],\n\n\n       [[[-0.0667069 ],\n         [ 0.04695951],\n         [ 0.05050121],\n         ...,\n         [-0.0364014 ],\n         [ 0.0445068 ],\n         [ 0.01760181]],\n\n        [[-0.009887  ],\n         [ 0.04765859],\n         [-0.06164052],\n         ...,\n         [-0.00143437],\n         [-0.04872097],\n         [-0.07529665]],\n\n        [[-0.01585843],\n         [ 0.04813932],\n         [-0.02708377],\n         ...,\n         [ 0.06668133],\n         [-0.04745383],\n         [-0.00772466]]],\n\n\n       [[[-0.06773119],\n         [-0.00132074],\n         [-0.04974524],\n         ...,\n         [ 0.05137196],\n         [ 0.04442416],\n         [ 0.04990995]],\n\n        [[-0.03002636],\n         [ 0.05004986],\n         [ 0.04871169],\n         ...,\n         [ 0.0603417 ],\n         [-0.05783801],\n         [-0.06110721]],\n\n        [[ 0.0551278 ],\n         [-0.02551181],\n         [-0.05651419],\n         ...,\n         [ 0.03303595],\n         [-0.04500189],\n         [-0.0156684 ]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_3/bias:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.01658905, -0.12280189,  0.06993378, ..., -0.05392851,\n          -0.18978202,  0.10081572],\n         [-0.15168327,  0.19776334,  0.02604588, ..., -0.15478946,\n           0.18204238,  0.04901138],\n         [ 0.08388478,  0.14212546, -0.09431023, ...,  0.09118468,\n          -0.09930729, -0.15872936],\n         ...,\n         [-0.08831567,  0.16264564, -0.16311279, ..., -0.14829364,\n           0.14444685, -0.08092939],\n         [ 0.12456746, -0.14399062,  0.03143291, ..., -0.13659625,\n          -0.01475079, -0.04189293],\n         [ 0.08818238,  0.08747164, -0.20623776, ...,  0.05156706,\n          -0.04760793, -0.08368319]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00488612,  0.06367554, -0.04758362, ..., -0.06799134,\n          -0.07085303, -0.01728459],\n         [-0.04960776, -0.00126126, -0.00250457, ..., -0.03316573,\n          -0.01437286,  0.03525544],\n         [ 0.03727841,  0.00344019,  0.0149868 , ...,  0.00034829,\n          -0.03347583,  0.0214332 ],\n         ...,\n         [ 0.03459127,  0.00861935, -0.02618259, ...,  0.01970274,\n           0.04708534, -0.02193658],\n         [-0.08417591, -0.04112738,  0.02865127, ...,  0.03760048,\n          -0.01352026,  0.03545061],\n         [-0.04757636, -0.01101664,  0.07599798, ..., -0.02374493,\n           0.03344459, -0.03833356]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 1, 48) dtype=float32, numpy=\narray([[[[ 0.7404909 ,  0.56219536,  0.24308355,  1.5340345 ,\n          -0.01874331, -0.03071641,  1.1585215 , -0.38498497,\n          -1.4970548 ,  0.56059647, -0.31612855,  0.75669056,\n           1.7689947 ,  0.8327923 , -1.1946516 , -1.0904458 ,\n          -1.410809  ,  0.3714936 ,  0.22209634,  2.143168  ,\n          -0.88328695, -1.1126337 ,  0.65773   ,  0.2261296 ,\n          -0.04583891,  0.761963  ,  0.13926555, -0.21019983,\n           2.1661325 ,  1.0278002 , -0.61582106,  0.10402781,\n          -0.3814819 , -1.9717189 , -0.13954045,  1.0542117 ,\n          -1.7299129 ,  0.5243758 ,  0.24475217,  0.8119778 ,\n          -1.2099042 ,  1.2681862 , -0.5052424 , -0.05570395,\n          -0.5492941 ,  1.7826109 ,  1.6415349 ,  1.2810686 ]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.03906785, -0.02342352,  0.01477214, ..., -0.02024208,\n          -0.08442139,  0.02677416],\n         [-0.06315084,  0.02019881,  0.02644959, ...,  0.02682174,\n           0.07651258,  0.05560122],\n         [-0.04194982,  0.04132916, -0.02152626, ..., -0.00141184,\n          -0.03437819,  0.01942666],\n         ...,\n         [ 0.02105216, -0.08037941, -0.05350014, ...,  0.07565188,\n          -0.00267469,  0.00558348],\n         [-0.01411896,  0.02114264,  0.03964148, ...,  0.00572557,\n           0.04597827,  0.01819152],\n         [ 0.0159985 , -0.08654074, -0.00345057, ..., -0.02308543,\n          -0.03023461, -0.02956009]]]], dtype=float32)>, <tf.Variable 'conv2d_862/kernel:0' shape=(1, 1, 40, 40) dtype=float32, numpy=\narray([[[[-0.19510962, -0.16538887,  0.14235024, ..., -0.17945194,\n          -0.12381437, -0.1320807 ],\n         [-0.24394798,  0.09417666,  0.18778458, ...,  0.07669416,\n           0.03160644,  0.11128829],\n         [-0.09943087, -0.0457889 , -0.088308  , ...,  0.22536829,\n          -0.3144904 ,  0.280321  ],\n         ...,\n         [ 0.2967983 ,  0.0040529 ,  0.27416223, ..., -0.26558125,\n           0.06644094, -0.01057662],\n         [ 0.01293906, -0.05595003, -0.25726846, ...,  0.04517451,\n          -0.10223775,  0.07583397],\n         [-0.05328713, -0.30322883,  0.04000769, ..., -0.16328062,\n          -0.04939308,  0.14867821]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_372/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-0.02096654],\n         [-0.02547816],\n         [ 0.03509732],\n         [ 0.06326845],\n         [ 0.0393284 ],\n         [ 0.03448409],\n         [ 0.04049325],\n         [-0.07527789],\n         [ 0.07047138],\n         [-0.04551506],\n         [-0.07745431],\n         [-0.05530279],\n         [ 0.08874471],\n         [-0.08881976],\n         [ 0.05326498],\n         [-0.08357954],\n         [-0.03307954],\n         [-0.0772261 ],\n         [ 0.00345832],\n         [ 0.06620777],\n         [-0.06195031],\n         [-0.02191382],\n         [ 0.01365224],\n         [-0.04145774],\n         [ 0.02637491],\n         [-0.00359432],\n         [ 0.00557709],\n         [-0.0500715 ],\n         [-0.02922494],\n         [ 0.0898051 ],\n         [-0.00905362],\n         [-0.04852683],\n         [-0.08758183],\n         [ 0.04163501],\n         [-0.03487174],\n         [-0.00260518],\n         [-0.06572375],\n         [-0.04844665],\n         [-0.04085516],\n         [-0.04487728],\n         [ 0.06034635],\n         [ 0.07380494],\n         [ 0.0814725 ],\n         [ 0.07182264],\n         [ 0.0285807 ],\n         [ 0.05810456],\n         [ 0.06730178],\n         [-0.0727153 ],\n         [ 0.00653466],\n         [-0.01358891],\n         [ 0.04964857],\n         [-0.01387385],\n         [-0.02348863],\n         [ 0.08659266],\n         [-0.03473441],\n         [ 0.09040332],\n         [-0.08477879],\n         [ 0.0029147 ],\n         [ 0.04467465],\n         [ 0.00861053],\n         [-0.08372515],\n         [ 0.01247564],\n         [-0.05152121],\n         [-0.06418285],\n         [-0.03387835],\n         [-0.0171935 ],\n         [ 0.05519977],\n         [-0.04485174],\n         [-0.02811518],\n         [ 0.01969028],\n         [ 0.0749996 ],\n         [-0.0471326 ],\n         [-0.08250969],\n         [-0.08820126],\n         [ 0.00250097],\n         [-0.07256934],\n         [-0.02964795],\n         [ 0.00526609],\n         [-0.0187603 ],\n         [-0.07818399]],\n\n        [[ 0.06431007],\n         [ 0.07228655],\n         [ 0.02512307],\n         [-0.01005116],\n         [ 0.05289756],\n         [ 0.02921235],\n         [-0.01132569],\n         [ 0.04374647],\n         [ 0.05426705],\n         [ 0.06336267],\n         [ 0.06573857],\n         [ 0.03915541],\n         [-0.02891217],\n         [-0.02074149],\n         [ 0.03495865],\n         [-0.055798  ],\n         [-0.02522174],\n         [ 0.0885333 ],\n         [-0.00988602],\n         [-0.04804669],\n         [ 0.07968669],\n         [ 0.07780275],\n         [ 0.06833668],\n         [-0.07959592],\n         [-0.04030773],\n         [ 0.0243078 ],\n         [ 0.08121514],\n         [ 0.02996377],\n         [-0.0576778 ],\n         [ 0.02315063],\n         [ 0.04265656],\n         [ 0.03457145],\n         [-0.0740831 ],\n         [-0.01404648],\n         [ 0.07089727],\n         [-0.02502487],\n         [ 0.08088446],\n         [ 0.06121987],\n         [-0.02627725],\n         [-0.0021539 ],\n         [ 0.05019344],\n         [ 0.02420393],\n         [ 0.08350724],\n         [-0.02342896],\n         [-0.06920002],\n         [ 0.04321969],\n         [ 0.03726254],\n         [-0.04965411],\n         [-0.04356582],\n         [-0.01503351],\n         [ 0.07028621],\n         [-0.06220014],\n         [-0.03167886],\n         [ 0.0043587 ],\n         [-0.07585778],\n         [-0.07803332],\n         [ 0.00506148],\n         [-0.07069439],\n         [ 0.06257975],\n         [-0.06323914],\n         [-0.03800369],\n         [-0.04511073],\n         [-0.04219692],\n         [ 0.01318298],\n         [-0.05358534],\n         [-0.00687379],\n         [-0.04812525],\n         [-0.0050878 ],\n         [ 0.0558354 ],\n         [-0.0167324 ],\n         [-0.00727517],\n         [ 0.06534432],\n         [ 0.00827575],\n         [ 0.0012537 ],\n         [ 0.03155179],\n         [ 0.05589311],\n         [ 0.02829975],\n         [-0.00814244],\n         [-0.00882728],\n         [ 0.08118433]],\n\n        [[ 0.07054847],\n         [ 0.00830815],\n         [-0.0385762 ],\n         [-0.04134419],\n         [-0.07180704],\n         [-0.02081232],\n         [ 0.00679471],\n         [-0.08325174],\n         [ 0.07125555],\n         [-0.00252822],\n         [ 0.03736442],\n         [ 0.06800468],\n         [ 0.07556258],\n         [ 0.01287532],\n         [-0.06845068],\n         [-0.02446204],\n         [-0.02766052],\n         [-0.04308201],\n         [-0.07743364],\n         [-0.02089339],\n         [ 0.04340079],\n         [ 0.08427325],\n         [-0.01094282],\n         [-0.01732856],\n         [-0.0266362 ],\n         [ 0.02797913],\n         [ 0.02802241],\n         [-0.00537102],\n         [-0.01126546],\n         [-0.06643727],\n         [-0.07618685],\n         [-0.01291888],\n         [ 0.05291091],\n         [ 0.03193665],\n         [ 0.03889868],\n         [ 0.034234  ],\n         [-0.00200162],\n         [-0.06482662],\n         [-0.00074173],\n         [-0.01714577],\n         [ 0.04356186],\n         [ 0.01707554],\n         [ 0.06558362],\n         [ 0.00342774],\n         [ 0.05005808],\n         [ 0.00829026],\n         [ 0.0889975 ],\n         [ 0.03153249],\n         [-0.0849438 ],\n         [-0.01617397],\n         [-0.0602076 ],\n         [ 0.07014669],\n         [-0.00766092],\n         [ 0.05153817],\n         [-0.01343189],\n         [ 0.04047537],\n         [ 0.01964018],\n         [ 0.0234865 ],\n         [-0.02720028],\n         [-0.06740729],\n         [ 0.03372145],\n         [ 0.01607075],\n         [-0.08212923],\n         [-0.02866038],\n         [ 0.0323332 ],\n         [-0.03841993],\n         [ 0.06774609],\n         [ 0.00707575],\n         [-0.07641453],\n         [ 0.06000093],\n         [-0.0716135 ],\n         [-0.04864374],\n         [ 0.03839293],\n         [ 0.03807189],\n         [ 0.05814312],\n         [ 0.05412212],\n         [-0.07561401],\n         [-0.00487048],\n         [ 0.07688969],\n         [-0.05863472]]],\n\n\n       [[[ 0.04850857],\n         [ 0.02203775],\n         [ 0.04419391],\n         [-0.00668416],\n         [-0.02577306],\n         [-0.07440465],\n         [ 0.06067465],\n         [-0.03396897],\n         [-0.01490155],\n         [ 0.07188052],\n         [ 0.08106525],\n         [ 0.06434801],\n         [ 0.03524522],\n         [-0.0673974 ],\n         [-0.04316286],\n         [-0.00947765],\n         [ 0.08046174],\n         [-0.02729768],\n         [ 0.06662819],\n         [ 0.02045504],\n         [-0.00288857],\n         [ 0.00769909],\n         [-0.02376673],\n         [ 0.01445522],\n         [-0.04328479],\n         [ 0.01443664],\n         [ 0.06879218],\n         [-0.044843  ],\n         [ 0.00973234],\n         [ 0.02714926],\n         [ 0.04129244],\n         [ 0.03168998],\n         [-0.0696326 ],\n         [-0.01254229],\n         [ 0.04176594],\n         [-0.08683859],\n         [ 0.01200939],\n         [-0.01619533],\n         [-0.07919255],\n         [ 0.08684473],\n         [-0.01949383],\n         [ 0.03971623],\n         [ 0.08568107],\n         [ 0.01009412],\n         [ 0.04217716],\n         [-0.05140586],\n         [ 0.02875973],\n         [-0.02235552],\n         [ 0.05854645],\n         [ 0.06855178],\n         [-0.08368503],\n         [ 0.04721566],\n         [ 0.02016442],\n         [ 0.05235235],\n         [ 0.01004143],\n         [-0.07818023],\n         [-0.03980791],\n         [-0.0514512 ],\n         [-0.01222701],\n         [ 0.05692902],\n         [-0.07067318],\n         [-0.05907113],\n         [ 0.06455272],\n         [ 0.07511957],\n         [-0.04286997],\n         [-0.01924863],\n         [-0.07477586],\n         [-0.08313925],\n         [-0.0453638 ],\n         [-0.00010519],\n         [ 0.08581428],\n         [-0.08763608],\n         [ 0.0280812 ],\n         [-0.01684594],\n         [ 0.01621846],\n         [-0.02964123],\n         [-0.02716133],\n         [-0.05479414],\n         [-0.08460036],\n         [ 0.06485201]],\n\n        [[-0.07736278],\n         [ 0.01318901],\n         [-0.03002301],\n         [-0.0712563 ],\n         [ 0.06034116],\n         [ 0.0679622 ],\n         [-0.06382375],\n         [-0.07024846],\n         [-0.01885255],\n         [ 0.01565122],\n         [ 0.00839986],\n         [-0.05467996],\n         [ 0.06287131],\n         [-0.05307075],\n         [ 0.06207609],\n         [ 0.00709554],\n         [ 0.05369076],\n         [ 0.00696643],\n         [ 0.00054736],\n         [ 0.0574246 ],\n         [-0.04762865],\n         [ 0.02696233],\n         [-0.00376503],\n         [ 0.08204199],\n         [-0.02301029],\n         [-0.08198426],\n         [ 0.00951628],\n         [ 0.07039967],\n         [-0.05864744],\n         [ 0.06031162],\n         [-0.07862911],\n         [ 0.05857252],\n         [ 0.04723008],\n         [-0.05667591],\n         [-0.05684832],\n         [ 0.08514482],\n         [-0.04490302],\n         [ 0.07813905],\n         [ 0.04722664],\n         [-0.01053872],\n         [-0.06755197],\n         [-0.02294171],\n         [ 0.06432956],\n         [-0.0584717 ],\n         [-0.05351225],\n         [ 0.00588548],\n         [ 0.00819024],\n         [-0.07040476],\n         [ 0.07272455],\n         [ 0.0853558 ],\n         [-0.03669061],\n         [ 0.08214718],\n         [ 0.0140751 ],\n         [-0.00635327],\n         [-0.08249711],\n         [-0.04269205],\n         [ 0.03815567],\n         [ 0.08456619],\n         [ 0.01322488],\n         [ 0.02199936],\n         [ 0.01221572],\n         [-0.0168642 ],\n         [ 0.01701418],\n         [ 0.06302094],\n         [-0.08851526],\n         [-0.02659078],\n         [-0.07666338],\n         [-0.07062167],\n         [ 0.08720551],\n         [-0.03129601],\n         [-0.07411682],\n         [-0.02010792],\n         [ 0.0631167 ],\n         [ 0.01662184],\n         [-0.02372219],\n         [ 0.04048118],\n         [ 0.05279231],\n         [-0.00056205],\n         [ 0.02111957],\n         [ 0.04961306]],\n\n        [[ 0.04272774],\n         [ 0.03872673],\n         [ 0.00847818],\n         [-0.04207746],\n         [ 0.01427913],\n         [-0.06165045],\n         [ 0.02240896],\n         [-0.01163524],\n         [ 0.0190302 ],\n         [ 0.0581426 ],\n         [-0.07772157],\n         [-0.07002407],\n         [ 0.05576298],\n         [-0.01095609],\n         [ 0.02564716],\n         [-0.03008649],\n         [ 0.09048761],\n         [-0.03314419],\n         [ 0.02270406],\n         [-0.05169334],\n         [-0.04535194],\n         [-0.05564004],\n         [ 0.07324217],\n         [-0.07798974],\n         [ 0.06658395],\n         [ 0.00336756],\n         [-0.08988246],\n         [ 0.00383535],\n         [ 0.03856547],\n         [-0.05642466],\n         [ 0.07420161],\n         [-0.01294432],\n         [ 0.01173199],\n         [ 0.07420632],\n         [ 0.01575688],\n         [ 0.04694052],\n         [ 0.06166641],\n         [ 0.06386191],\n         [-0.02226904],\n         [-0.02691157],\n         [-0.0608632 ],\n         [ 0.07331561],\n         [-0.04800973],\n         [ 0.0190645 ],\n         [ 0.06243269],\n         [-0.08690052],\n         [ 0.03989702],\n         [-0.06034084],\n         [ 0.06752492],\n         [-0.04753506],\n         [-0.07199165],\n         [ 0.0054161 ],\n         [-0.05494083],\n         [-0.02310949],\n         [ 0.00720659],\n         [ 0.03394851],\n         [-0.09058121],\n         [-0.01702127],\n         [ 0.05085547],\n         [-0.02146744],\n         [ 0.03785522],\n         [-0.06916741],\n         [ 0.05299692],\n         [ 0.05752492],\n         [-0.07440484],\n         [-0.04622466],\n         [ 0.08852999],\n         [-0.04687246],\n         [ 0.07057557],\n         [ 0.00758781],\n         [-0.06313586],\n         [ 0.00298789],\n         [-0.05139844],\n         [-0.04186741],\n         [-0.09011171],\n         [ 0.08500005],\n         [-0.00422204],\n         [ 0.01964055],\n         [-0.05992739],\n         [-0.07362959]]],\n\n\n       [[[-0.0062515 ],\n         [ 0.03474286],\n         [ 0.01174743],\n         [ 0.08167882],\n         [ 0.04475044],\n         [ 0.01691204],\n         [-0.00042626],\n         [-0.08080395],\n         [-0.00449761],\n         [ 0.05042101],\n         [ 0.03930181],\n         [ 0.05393337],\n         [ 0.0236554 ],\n         [-0.0594551 ],\n         [ 0.0058189 ],\n         [ 0.03097823],\n         [ 0.0351432 ],\n         [-0.06183808],\n         [ 0.07068662],\n         [-0.05167258],\n         [ 0.02138497],\n         [-0.06261645],\n         [-0.07179768],\n         [ 0.00119046],\n         [ 0.01810386],\n         [-0.03136839],\n         [ 0.04247981],\n         [-0.00523527],\n         [-0.04733096],\n         [ 0.0492879 ],\n         [ 0.07480505],\n         [ 0.00914552],\n         [ 0.00178145],\n         [ 0.02023649],\n         [-0.03202496],\n         [-0.00268254],\n         [ 0.03125943],\n         [-0.08076902],\n         [ 0.01169275],\n         [ 0.04592285],\n         [ 0.01564611],\n         [ 0.05736056],\n         [ 0.00931108],\n         [ 0.03982349],\n         [ 0.01883637],\n         [-0.04987151],\n         [-0.07901689],\n         [ 0.04290506],\n         [ 0.02868476],\n         [ 0.04719572],\n         [-0.08935738],\n         [ 0.0182775 ],\n         [-0.04729757],\n         [-0.04928945],\n         [-0.04509963],\n         [-0.01589107],\n         [ 0.02286912],\n         [-0.03424212],\n         [-0.0886785 ],\n         [ 0.06276941],\n         [ 0.08624864],\n         [-0.03248364],\n         [ 0.04134592],\n         [ 0.03096685],\n         [-0.05233287],\n         [-0.05949111],\n         [-0.03656288],\n         [ 0.0679131 ],\n         [ 0.03301822],\n         [-0.01287999],\n         [ 0.0664288 ],\n         [-0.02835791],\n         [ 0.05166601],\n         [-0.05069312],\n         [ 0.01608434],\n         [-0.00504393],\n         [ 0.00861233],\n         [-0.0582039 ],\n         [-0.07204382],\n         [ 0.02024458]],\n\n        [[-0.03332053],\n         [-0.0498862 ],\n         [-0.01286675],\n         [ 0.0606083 ],\n         [-0.01025366],\n         [-0.02086185],\n         [-0.06344114],\n         [-0.00023273],\n         [ 0.00954063],\n         [ 0.03457113],\n         [ 0.0004515 ],\n         [-0.04351625],\n         [-0.05198389],\n         [ 0.03092482],\n         [-0.01831917],\n         [-0.08659815],\n         [-0.06976967],\n         [ 0.06121641],\n         [-0.02770391],\n         [-0.05290783],\n         [ 0.01199514],\n         [-0.07603378],\n         [ 0.06242003],\n         [ 0.06310914],\n         [-0.00913354],\n         [ 0.06520289],\n         [ 0.04426734],\n         [-0.06369752],\n         [ 0.06571062],\n         [-0.03191136],\n         [ 0.02299182],\n         [-0.06278758],\n         [ 0.0409327 ],\n         [-0.05916394],\n         [ 0.02686253],\n         [-0.07142431],\n         [ 0.05351509],\n         [ 0.06665725],\n         [-0.08794644],\n         [ 0.08660285],\n         [ 0.03098182],\n         [-0.01195344],\n         [-0.03311287],\n         [ 0.08753082],\n         [ 0.01920377],\n         [-0.04319152],\n         [ 0.08595058],\n         [-0.01667638],\n         [ 0.06866242],\n         [-0.01192815],\n         [-0.08085451],\n         [-0.08900438],\n         [-0.01570557],\n         [-0.04753069],\n         [-0.07312791],\n         [-0.02153127],\n         [ 0.07214935],\n         [-0.01009358],\n         [ 0.00813048],\n         [ 0.06353097],\n         [ 0.04110953],\n         [-0.07320973],\n         [ 0.06237932],\n         [-0.0593524 ],\n         [-0.07025456],\n         [-0.00795604],\n         [ 0.02796981],\n         [ 0.08574452],\n         [ 0.01168211],\n         [ 0.0512486 ],\n         [ 0.04082133],\n         [ 0.08767207],\n         [-0.00188918],\n         [-0.07039621],\n         [-0.03926001],\n         [ 0.02959237],\n         [ 0.06672755],\n         [ 0.02896553],\n         [-0.07579302],\n         [-0.01049784]],\n\n        [[-0.07273716],\n         [ 0.06591006],\n         [ 0.00800654],\n         [-0.05422733],\n         [-0.01153228],\n         [ 0.06819281],\n         [ 0.06602897],\n         [ 0.0622512 ],\n         [-0.08522092],\n         [ 0.01258803],\n         [ 0.0095508 ],\n         [-0.02406327],\n         [-0.04981043],\n         [-0.0350302 ],\n         [ 0.08601013],\n         [ 0.07214412],\n         [-0.00754087],\n         [-0.05119726],\n         [ 0.04609433],\n         [ 0.02311423],\n         [-0.00165007],\n         [ 0.00159662],\n         [ 0.06075557],\n         [ 0.05827439],\n         [ 0.02302987],\n         [ 0.04253817],\n         [-0.01996729],\n         [-0.06868111],\n         [ 0.00878448],\n         [-0.06505431],\n         [-0.02599338],\n         [-0.02824178],\n         [ 0.01245533],\n         [-0.07461295],\n         [ 0.06277986],\n         [ 0.01913171],\n         [-0.02882453],\n         [ 0.04946046],\n         [ 0.07505882],\n         [-0.00213103],\n         [-0.05891795],\n         [-0.02074005],\n         [-0.00479999],\n         [-0.01341091],\n         [ 0.00064433],\n         [ 0.03066996],\n         [-0.04250038],\n         [ 0.07513709],\n         [ 0.00231966],\n         [-0.00559731],\n         [ 0.05141008],\n         [ 0.06028374],\n         [ 0.00111569],\n         [-0.08384176],\n         [ 0.01780206],\n         [-0.02295153],\n         [ 0.0600017 ],\n         [ 0.02266887],\n         [ 0.08067097],\n         [ 0.04385988],\n         [-0.0791125 ],\n         [-0.02357834],\n         [ 0.02407928],\n         [ 0.02520991],\n         [-0.08086591],\n         [-0.0603639 ],\n         [-0.0001128 ],\n         [ 0.061561  ],\n         [-0.03594918],\n         [ 0.06227112],\n         [-0.073638  ],\n         [-0.06218227],\n         [-0.02507477],\n         [-0.03840838],\n         [-0.04152884],\n         [-0.0708226 ],\n         [ 0.0044569 ],\n         [ 0.00351981],\n         [ 0.01712857],\n         [ 0.00354194]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/conv2d_1/kernel:0' shape=(1, 1, 240, 40) dtype=float32, numpy=\narray([[[[ 0.01438806,  0.02846583,  0.03476854, ..., -0.05134127,\n          -0.00119067, -0.03940116],\n         [ 0.02367445, -0.00663239,  0.09057099, ..., -0.0290843 ,\n           0.04782839, -0.07087374],\n         [-0.06886516, -0.0309397 , -0.08667625, ...,  0.00630784,\n          -0.04906496, -0.05037435],\n         ...,\n         [ 0.00997867, -0.02894117,  0.03224835, ...,  0.09210732,\n           0.02721596,  0.03571135],\n         [-0.01300522,  0.03496785, -0.01647761, ...,  0.08279741,\n           0.05215232,  0.04317404],\n         [-0.04642149, -0.0134203 ,  0.00789236, ..., -0.01071561,\n          -0.12139538, -0.03617502]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 96, 3) dtype=float32, numpy=\narray([[[[ 0.11529394, -0.19005272, -0.0508256 ],\n         [ 0.03163886,  0.13168557, -0.00281219],\n         [-0.06332602,  0.00349325, -0.09027126],\n         [-0.11583229,  0.03068131, -0.09671286],\n         [ 0.01713523, -0.10236929,  0.00656186],\n         [ 0.03792822, -0.21867377, -0.03729205],\n         [-0.09240668,  0.16166528, -0.00741112],\n         [ 0.19743049, -0.07242645, -0.207678  ],\n         [ 0.08487293, -0.02394649, -0.13200416],\n         [-0.00217033,  0.11171449, -0.134627  ],\n         [-0.09199473, -0.01641611, -0.05235366],\n         [ 0.01612227,  0.14549679, -0.0782339 ],\n         [-0.01841922,  0.20265526,  0.08458619],\n         [ 0.00484755, -0.15645751,  0.10473868],\n         [ 0.2044313 , -0.05438804,  0.08869832],\n         [-0.05763805,  0.06748469,  0.11423801],\n         [-0.06871525, -0.07132325, -0.13318641],\n         [ 0.21165773, -0.13578555,  0.00436173],\n         [ 0.03225271,  0.02998055, -0.11970099],\n         [-0.01457217, -0.12858051,  0.15676174],\n         [-0.06801501, -0.05626246,  0.1064138 ],\n         [-0.02120746,  0.06891645, -0.13885655],\n         [ 0.03473346, -0.18376318,  0.17463565],\n         [-0.06669161, -0.02821924,  0.07074515],\n         [-0.01802624, -0.11316969,  0.04556481],\n         [ 0.08352954,  0.03605136,  0.06170407],\n         [ 0.22505811,  0.06777298,  0.02074965],\n         [ 0.13030323, -0.18489185, -0.1459201 ],\n         [ 0.07177866, -0.04642604, -0.08602448],\n         [ 0.15876503, -0.00288589, -0.12091316],\n         [-0.09716125,  0.02570831, -0.05773596],\n         [ 0.13099746,  0.0174762 ,  0.02090186],\n         [ 0.02569453,  0.10116073,  0.12606859],\n         [ 0.14799334, -0.04428425, -0.0299858 ],\n         [-0.00562453,  0.11004401,  0.04876237],\n         [-0.12355031, -0.04137211,  0.00679932],\n         [-0.04719581,  0.04032993,  0.09906475],\n         [-0.09093335, -0.06382361,  0.04801764],\n         [ 0.16567501,  0.15825084, -0.05367768],\n         [-0.06483374, -0.05370474,  0.16459854],\n         [-0.04581144, -0.12550072,  0.10000475],\n         [-0.22424969,  0.19402969, -0.14073494],\n         [-0.04884648, -0.02020836,  0.1690562 ],\n         [ 0.06800474, -0.02447421, -0.02108008],\n         [-0.15282641, -0.00806909, -0.16254027],\n         [ 0.13054381, -0.05311068,  0.06653474],\n         [ 0.09858686,  0.20441228,  0.09989334],\n         [-0.04832056, -0.0324885 , -0.07499489],\n         [ 0.07873917, -0.12648521,  0.18005635],\n         [-0.04743432, -0.12588121, -0.09545369],\n         [ 0.0620551 ,  0.16714595,  0.03524103],\n         [-0.21761918, -0.03781874,  0.09311558],\n         [-0.07509334,  0.10337938,  0.05343618],\n         [ 0.020741  , -0.19643253, -0.07543913],\n         [ 0.1292863 , -0.13318788, -0.18732238],\n         [-0.03109914, -0.13218158,  0.13313574],\n         [ 0.06065136, -0.02901631, -0.03300465],\n         [ 0.04551817, -0.14049213, -0.11217486],\n         [-0.03985168, -0.01866202, -0.09609877],\n         [-0.10795367, -0.00183532, -0.07843835],\n         [ 0.10915347, -0.22238018, -0.16731355],\n         [ 0.16228463, -0.03201063, -0.01124189],\n         [-0.22773112, -0.16727057, -0.01567834],\n         [ 0.09202851, -0.03911347,  0.1026272 ],\n         [ 0.04114765,  0.02586829, -0.1376714 ],\n         [ 0.01535225,  0.18614464,  0.12493788],\n         [ 0.16191313, -0.07244462, -0.06197708],\n         [ 0.10320779,  0.07394453, -0.00789879],\n         [-0.01669077, -0.03155337,  0.09156477],\n         [ 0.04016112,  0.12372853,  0.1186845 ],\n         [-0.09438157, -0.09895606,  0.15515584],\n         [ 0.0640391 ,  0.06324702, -0.02418188],\n         [ 0.07815089,  0.03623538, -0.03010223],\n         [ 0.12125967,  0.15153205, -0.11653645],\n         [-0.07477223, -0.09147738,  0.03494742],\n         [ 0.01182703,  0.04470154, -0.033239  ],\n         [-0.18172596,  0.05104116, -0.2216115 ],\n         [ 0.15422064,  0.00991805, -0.1068592 ],\n         [ 0.07886811, -0.05802445,  0.03625564],\n         [-0.00432214, -0.06377818,  0.05842673],\n         [ 0.03245283,  0.02960906, -0.057034  ],\n         [-0.03831642, -0.09886496,  0.03403155],\n         [ 0.0159633 , -0.1884281 , -0.00798337],\n         [-0.03626551,  0.19623046,  0.19226617],\n         [-0.03239216, -0.05791129,  0.11596882],\n         [ 0.1773036 ,  0.03097832, -0.10258909],\n         [ 0.09844261,  0.03721843, -0.00831135],\n         [-0.02457668, -0.01762347, -0.0895867 ],\n         [ 0.09396394, -0.0804811 , -0.0402191 ],\n         [ 0.02126515,  0.09419583, -0.0180923 ],\n         [-0.06845336, -0.14839421, -0.08184258],\n         [ 0.00049325,  0.00986448,  0.01962392],\n         [ 0.05054731, -0.03780394, -0.04168702],\n         [ 0.16093132,  0.05427512,  0.09034681],\n         [ 0.0429286 , -0.0364722 ,  0.07176609],\n         [ 0.06201656,  0.04505612, -0.08795362]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/gamma:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.33241183, -0.2937546 ,  0.12355585, ...,  0.14157043,\n           0.06237433,  0.06119965],\n         [ 0.034905  ,  0.24702272, -0.08934848, ..., -0.22721149,\n          -0.10181592,  0.1973533 ],\n         [ 0.3685421 ,  0.24084756, -0.08125844, ..., -0.01475347,\n          -0.10632188, -0.36566815],\n         ...,\n         [ 0.10422534, -0.05458917, -0.1429891 , ...,  0.16294065,\n           0.0011848 ,  0.30756503],\n         [ 0.2384754 ,  0.00590983,  0.1123225 , ..., -0.23149118,\n          -0.17707796, -0.2737518 ],\n         [ 0.09303021, -0.18381922,  0.15918882, ..., -0.15142928,\n          -0.2874099 ,  0.05408263]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/conv2d/kernel:0' shape=(1, 1, 24, 144) dtype=float32, numpy=\narray([[[[ 0.35420915,  0.33008838,  0.3452662 , ...,  0.09189732,\n           0.32536566, -0.38743702],\n         [-0.18711002,  0.02016944,  0.27389786, ...,  0.00159151,\n          -0.00897067,  0.11584048],\n         [-0.22335051, -0.02474017,  0.41295424, ..., -0.39313602,\n          -0.21290521, -0.01398367],\n         ...,\n         [ 0.19920877,  0.23788583, -0.03997458, ..., -0.29603207,\n          -0.39062157,  0.2418448 ],\n         [-0.21102329, -0.01531912,  0.22907123, ...,  0.4117674 ,\n           0.3190978 , -0.36316037],\n         [-0.1908387 , -0.03800815, -0.32998562, ...,  0.2722815 ,\n          -0.30189952,  0.08635671]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 0.06331954,  0.00464255,  0.03007113, ..., -0.03970123,\n          -0.02585186, -0.01899425],\n         [ 0.00808769, -0.0795731 , -0.00629658, ..., -0.01046361,\n           0.04152304, -0.01951132],\n         [ 0.01454671,  0.09601972, -0.05801756, ..., -0.02340194,\n          -0.03115106,  0.04263923],\n         ...,\n         [ 0.00617959, -0.01886612, -0.04562569, ...,  0.07635859,\n           0.03176695,  0.07576016],\n         [ 0.01468667,  0.06306709, -0.05764097, ..., -0.00786962,\n          -0.05968153,  0.02547954],\n         [ 0.06376211,  0.02800516, -0.06171629, ...,  0.04484987,\n           0.00100972, -0.09002233]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[-0.01325253, -0.04283201, -0.06701066, ...,  0.00467389,\n          -0.02764933, -0.01285624],\n         [ 0.03627107,  0.00053309, -0.04123317, ..., -0.08735143,\n           0.01636383,  0.05468501],\n         [ 0.05870382, -0.00233371, -0.00456893, ...,  0.05729785,\n          -0.01479678, -0.01113155],\n         ...,\n         [ 0.00172727, -0.03193495, -0.00605418, ..., -0.09622826,\n           0.00746031,  0.03231936],\n         [-0.00981625, -0.00311895, -0.08254976, ..., -0.01715622,\n          -0.01422589,  0.03671503],\n         [-0.01628164, -0.04157427, -0.01526071, ...,  0.01514443,\n           0.00383763, -0.03793835]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_364/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.04704373],\n         [ 0.06056309],\n         [ 0.0721183 ],\n         [ 0.07146786],\n         [-0.01066765],\n         [-0.05717065],\n         [-0.03548224],\n         [-0.01117734],\n         [ 0.00929771],\n         [ 0.05523381],\n         [ 0.05893397],\n         [ 0.06006593],\n         [-0.06935412],\n         [ 0.01807272],\n         [-0.04997905],\n         [-0.04595849],\n         [ 0.06593297],\n         [-0.01143034],\n         [ 0.00960699],\n         [-0.08872131],\n         [-0.07694896],\n         [-0.06761415],\n         [-0.05451826],\n         [-0.07269202],\n         [ 0.00442442],\n         [-0.00617701],\n         [-0.03519188],\n         [ 0.00674667],\n         [-0.02921127],\n         [-0.08567056],\n         [ 0.03856634],\n         [-0.01889458],\n         [ 0.0877116 ],\n         [-0.03431522],\n         [ 0.028903  ],\n         [ 0.01695264],\n         [-0.03465905],\n         [ 0.04877891],\n         [-0.07270178],\n         [ 0.02438835],\n         [-0.03839629],\n         [ 0.04967199],\n         [-0.02782054],\n         [ 0.07858919],\n         [ 0.02876765],\n         [-0.07893944],\n         [-0.08342307],\n         [ 0.05609974],\n         [-0.00348295],\n         [ 0.08561575],\n         [ 0.03603517],\n         [ 0.06384791],\n         [-0.09011113],\n         [-0.0869869 ],\n         [-0.06709722],\n         [ 0.02688683],\n         [ 0.00942452],\n         [ 0.08843242],\n         [-0.04515393],\n         [ 0.02329276],\n         [ 0.02487417],\n         [-0.05082238],\n         [ 0.02253887],\n         [ 0.04069966],\n         [ 0.02299331],\n         [ 0.02073387],\n         [ 0.02928872],\n         [-0.06194438],\n         [-0.02693171],\n         [ 0.05400972],\n         [ 0.00060933],\n         [-0.08929549],\n         [ 0.04714367],\n         [-0.03779688],\n         [ 0.00171898],\n         [ 0.0137905 ],\n         [ 0.05600916],\n         [ 0.05895206],\n         [ 0.02303309],\n         [ 0.0176959 ]],\n\n        [[ 0.0682705 ],\n         [-0.00150044],\n         [-0.03549493],\n         [-0.02570357],\n         [ 0.08493383],\n         [ 0.07543114],\n         [-0.01688013],\n         [ 0.03158963],\n         [ 0.08540107],\n         [-0.0404366 ],\n         [-0.04759567],\n         [ 0.04839514],\n         [-0.05346947],\n         [ 0.0433002 ],\n         [-0.02963716],\n         [ 0.00265802],\n         [ 0.02902811],\n         [-0.06198916],\n         [ 0.00034896],\n         [ 0.01594919],\n         [ 0.0362505 ],\n         [ 0.02899686],\n         [-0.02219407],\n         [-0.00951072],\n         [ 0.04514982],\n         [ 0.04951847],\n         [ 0.05662534],\n         [ 0.04164819],\n         [ 0.02749577],\n         [-0.05532193],\n         [-0.08609536],\n         [ 0.00078609],\n         [ 0.03850368],\n         [-0.01517564],\n         [ 0.07998393],\n         [ 0.01605327],\n         [-0.04524564],\n         [-0.04076847],\n         [-0.08834471],\n         [-0.00992285],\n         [ 0.0449373 ],\n         [ 0.06563301],\n         [ 0.01593654],\n         [ 0.0635106 ],\n         [-0.06022611],\n         [-0.00345239],\n         [-0.09034579],\n         [-0.07672048],\n         [-0.0238369 ],\n         [-0.05053338],\n         [ 0.04809389],\n         [ 0.08047256],\n         [ 0.05765498],\n         [ 0.07663722],\n         [ 0.04339464],\n         [ 0.00822868],\n         [ 0.0897519 ],\n         [-0.05692565],\n         [-0.0783579 ],\n         [-0.0097421 ],\n         [-0.06331109],\n         [-0.0276299 ],\n         [-0.07694747],\n         [ 0.00263987],\n         [ 0.06772767],\n         [ 0.02883749],\n         [-0.04284036],\n         [-0.0112284 ],\n         [-0.07528489],\n         [ 0.07307184],\n         [ 0.07088429],\n         [-0.00740915],\n         [-0.02062996],\n         [ 0.05577351],\n         [ 0.08864111],\n         [ 0.01543272],\n         [-0.0059818 ],\n         [ 0.0032592 ],\n         [ 0.03385726],\n         [ 0.08182573]],\n\n        [[-0.05786382],\n         [ 0.05124418],\n         [ 0.00796309],\n         [ 0.04104775],\n         [ 0.00814205],\n         [ 0.00984384],\n         [-0.07605258],\n         [ 0.04822332],\n         [-0.04771995],\n         [ 0.05968463],\n         [-0.0464    ],\n         [-0.02959226],\n         [-0.06653413],\n         [ 0.01143865],\n         [-0.02303614],\n         [-0.02621459],\n         [-0.00504218],\n         [-0.06145014],\n         [-0.0034817 ],\n         [-0.0150359 ],\n         [-0.09018236],\n         [-0.05863693],\n         [ 0.00645811],\n         [-0.04828103],\n         [ 0.08005309],\n         [-0.02524236],\n         [-0.03899967],\n         [ 0.01572896],\n         [-0.04688781],\n         [-0.05755363],\n         [ 0.03826521],\n         [-0.06012757],\n         [-0.00892957],\n         [ 0.03580593],\n         [ 0.04931924],\n         [ 0.02014275],\n         [-0.07311182],\n         [-0.06382143],\n         [-0.00428311],\n         [ 0.02264027],\n         [-0.01483738],\n         [ 0.06842832],\n         [ 0.00974335],\n         [ 0.07694037],\n         [ 0.08917496],\n         [-0.0174689 ],\n         [-0.06696491],\n         [ 0.08753799],\n         [-0.01624309],\n         [ 0.02230313],\n         [ 0.01175712],\n         [ 0.02997867],\n         [-0.06108657],\n         [-0.03932665],\n         [-0.05693884],\n         [-0.06278455],\n         [-0.0527258 ],\n         [-0.0802287 ],\n         [ 0.01776469],\n         [-0.00145677],\n         [-0.01928206],\n         [ 0.03591265],\n         [-0.04345971],\n         [-0.03102019],\n         [ 0.01046301],\n         [ 0.08114894],\n         [ 0.07808657],\n         [ 0.0343423 ],\n         [ 0.06993158],\n         [ 0.01408548],\n         [-0.06093172],\n         [ 0.07527113],\n         [ 0.02670425],\n         [ 0.04057077],\n         [ 0.00105387],\n         [-0.00233775],\n         [-0.0497344 ],\n         [ 0.01712418],\n         [-0.02900213],\n         [-0.039171  ]]],\n\n\n       [[[ 0.07171911],\n         [ 0.01992186],\n         [-0.00048675],\n         [-0.01047093],\n         [-0.04854922],\n         [-0.0869187 ],\n         [-0.08694133],\n         [ 0.03855282],\n         [ 0.03418114],\n         [ 0.0482872 ],\n         [ 0.02242008],\n         [-0.05403198],\n         [-0.03989646],\n         [ 0.00917178],\n         [-0.0233963 ],\n         [ 0.05945697],\n         [-0.03179966],\n         [-0.06871909],\n         [ 0.02402551],\n         [-0.07965973],\n         [-0.03269425],\n         [ 0.04068154],\n         [ 0.04370865],\n         [ 0.09024924],\n         [-0.07195674],\n         [ 0.00187813],\n         [-0.06639826],\n         [-0.04101812],\n         [-0.02680764],\n         [-0.07542536],\n         [-0.02575634],\n         [ 0.07085477],\n         [-0.08113823],\n         [-0.01885943],\n         [-0.05286459],\n         [-0.05928723],\n         [-0.07757103],\n         [-0.07816301],\n         [ 0.08603606],\n         [-0.02677132],\n         [ 0.04176065],\n         [-0.00623716],\n         [-0.01952989],\n         [-0.02471942],\n         [-0.00798147],\n         [-0.07412536],\n         [ 0.00982811],\n         [-0.02755248],\n         [-0.00572737],\n         [-0.08674919],\n         [-0.08371507],\n         [ 0.03365567],\n         [ 0.00358481],\n         [ 0.0862357 ],\n         [-0.04430701],\n         [-0.0487982 ],\n         [-0.01928364],\n         [-0.00506844],\n         [ 0.08807836],\n         [ 0.06924039],\n         [ 0.03669664],\n         [ 0.09061152],\n         [-0.08352878],\n         [-0.0899474 ],\n         [-0.00489838],\n         [ 0.03565852],\n         [-0.05972123],\n         [ 0.05011   ],\n         [ 0.01330084],\n         [-0.02696517],\n         [-0.00146702],\n         [ 0.05984209],\n         [-0.07764994],\n         [-0.01269703],\n         [-0.03961065],\n         [ 0.09051578],\n         [ 0.0622189 ],\n         [-0.04662469],\n         [ 0.01956664],\n         [-0.01184741]],\n\n        [[ 0.04349332],\n         [ 0.05064964],\n         [-0.09030458],\n         [ 0.03592026],\n         [-0.04918632],\n         [ 0.06756341],\n         [ 0.08421725],\n         [ 0.08609986],\n         [-0.03561604],\n         [ 0.03402943],\n         [ 0.08212055],\n         [-0.02423926],\n         [ 0.02402285],\n         [-0.07478475],\n         [ 0.05734667],\n         [ 0.05313645],\n         [ 0.02255929],\n         [-0.01252009],\n         [ 0.04377624],\n         [-0.00457018],\n         [-0.05663389],\n         [-0.0846564 ],\n         [-0.06832376],\n         [-0.04526112],\n         [ 0.00745957],\n         [ 0.01864772],\n         [-0.01856163],\n         [ 0.01058857],\n         [ 0.02573517],\n         [ 0.01911134],\n         [-0.06963755],\n         [-0.04347388],\n         [-0.04250266],\n         [-0.0397717 ],\n         [-0.07477236],\n         [-0.08106872],\n         [ 0.07613871],\n         [-0.05800528],\n         [-0.07058594],\n         [ 0.06900765],\n         [-0.00303721],\n         [-0.07197463],\n         [-0.07419216],\n         [ 0.0455084 ],\n         [-0.00388698],\n         [-0.0844207 ],\n         [-0.03015474],\n         [-0.08194131],\n         [ 0.00217673],\n         [ 0.01919688],\n         [-0.06933632],\n         [-0.02486119],\n         [ 0.05563731],\n         [-0.0250513 ],\n         [ 0.0164082 ],\n         [ 0.02217101],\n         [-0.04376547],\n         [-0.0112013 ],\n         [ 0.04263836],\n         [ 0.01845405],\n         [ 0.08947431],\n         [ 0.01247478],\n         [ 0.05786878],\n         [-0.07704858],\n         [-0.05611079],\n         [ 0.03176845],\n         [-0.0801339 ],\n         [ 0.07353528],\n         [-0.07836683],\n         [ 0.06467517],\n         [ 0.00434677],\n         [-0.07659534],\n         [-0.07338809],\n         [-0.00650786],\n         [ 0.02014197],\n         [ 0.04430179],\n         [ 0.00023256],\n         [-0.06573993],\n         [ 0.02831978],\n         [ 0.07283796]],\n\n        [[-0.0492625 ],\n         [ 0.08175841],\n         [-0.01467117],\n         [ 0.08140634],\n         [-0.02893542],\n         [-0.06952119],\n         [-0.00148071],\n         [ 0.01189283],\n         [ 0.08024627],\n         [ 0.06177506],\n         [-0.0828893 ],\n         [ 0.05096097],\n         [ 0.02192521],\n         [-0.05902066],\n         [-0.07481404],\n         [ 0.00808121],\n         [ 0.00383414],\n         [ 0.02105907],\n         [-0.03091602],\n         [ 0.06825405],\n         [-0.08449872],\n         [-0.09019069],\n         [-0.02370349],\n         [ 0.02014589],\n         [-0.05123652],\n         [-0.01183402],\n         [ 0.06280151],\n         [ 0.01075977],\n         [ 0.03756769],\n         [ 0.00598954],\n         [-0.05516683],\n         [ 0.07520011],\n         [ 0.03805037],\n         [ 0.0346745 ],\n         [ 0.02562486],\n         [ 0.0610421 ],\n         [-0.02265531],\n         [-0.06252722],\n         [-0.04732986],\n         [-0.00676415],\n         [ 0.01371423],\n         [ 0.05977747],\n         [-0.00283324],\n         [-0.05467057],\n         [-0.05722648],\n         [-0.02976395],\n         [-0.01199289],\n         [ 0.05897997],\n         [-0.0575    ],\n         [ 0.00391434],\n         [-0.03992525],\n         [ 0.07603116],\n         [ 0.01011032],\n         [-0.08731288],\n         [-0.06506991],\n         [-0.03852098],\n         [-0.00558478],\n         [-0.05074189],\n         [ 0.03197169],\n         [ 0.07084781],\n         [-0.02094552],\n         [-0.02604324],\n         [-0.09017005],\n         [-0.01307102],\n         [ 0.013785  ],\n         [-0.07050404],\n         [ 0.02062881],\n         [ 0.02823933],\n         [ 0.07621004],\n         [-0.07351783],\n         [ 0.02738342],\n         [ 0.0488292 ],\n         [-0.01945934],\n         [-0.05523234],\n         [ 0.02338751],\n         [ 0.02282194],\n         [ 0.02510735],\n         [ 0.00595392],\n         [-0.0247431 ],\n         [-0.07609938]]],\n\n\n       [[[ 0.05805835],\n         [-0.07733858],\n         [ 0.08293097],\n         [-0.01705019],\n         [ 0.00707767],\n         [ 0.04854189],\n         [ 0.08099033],\n         [ 0.06596185],\n         [ 0.06638467],\n         [-0.06523574],\n         [-0.05881564],\n         [-0.01693588],\n         [-0.07783039],\n         [ 0.07417254],\n         [ 0.0094611 ],\n         [ 0.0600834 ],\n         [-0.00826167],\n         [-0.04777078],\n         [-0.08290255],\n         [ 0.07314818],\n         [ 0.04263854],\n         [-0.02226182],\n         [ 0.00776308],\n         [-0.01051994],\n         [ 0.01010859],\n         [-0.0899748 ],\n         [-0.08219299],\n         [-0.02132332],\n         [-0.08308948],\n         [ 0.00140572],\n         [-0.07739341],\n         [ 0.09015763],\n         [-0.03408002],\n         [ 0.00684948],\n         [-0.03658808],\n         [-0.0031486 ],\n         [ 0.05801111],\n         [ 0.08017521],\n         [ 0.02519094],\n         [ 0.06077428],\n         [-0.04758833],\n         [ 0.04164752],\n         [-0.01551157],\n         [ 0.06210651],\n         [ 0.06496996],\n         [ 0.09033184],\n         [ 0.03659013],\n         [ 0.06152858],\n         [ 0.05315022],\n         [ 0.02018246],\n         [ 0.00908425],\n         [-0.085867  ],\n         [-0.00273442],\n         [-0.06519023],\n         [ 0.07480469],\n         [-0.00352594],\n         [-0.03134401],\n         [ 0.07701938],\n         [ 0.00322416],\n         [ 0.07593456],\n         [-0.07133744],\n         [-0.01306628],\n         [-0.06195418],\n         [-0.04605682],\n         [ 0.03989945],\n         [ 0.0872815 ],\n         [ 0.04746671],\n         [-0.07595263],\n         [ 0.06160074],\n         [-0.07978672],\n         [ 0.08518207],\n         [-0.07278373],\n         [-0.06104528],\n         [-0.067196  ],\n         [-0.01702023],\n         [ 0.05185279],\n         [-0.07997362],\n         [-0.08609275],\n         [-0.03401243],\n         [-0.03260266]],\n\n        [[-0.01962487],\n         [ 0.02234563],\n         [-0.02558486],\n         [-0.04656925],\n         [ 0.035795  ],\n         [ 0.034128  ],\n         [ 0.05595036],\n         [ 0.04335429],\n         [-0.02954203],\n         [ 0.03235081],\n         [ 0.01931924],\n         [-0.04426202],\n         [ 0.06391293],\n         [-0.03830884],\n         [ 0.08866799],\n         [ 0.05905207],\n         [ 0.05443403],\n         [-0.07586487],\n         [-0.0280106 ],\n         [-0.04152397],\n         [-0.05066214],\n         [ 0.00329529],\n         [ 0.00794144],\n         [ 0.058981  ],\n         [ 0.0815784 ],\n         [ 0.00954169],\n         [-0.07233641],\n         [ 0.06311767],\n         [ 0.03498547],\n         [-0.07904547],\n         [-0.03057044],\n         [-0.01521564],\n         [-0.0886955 ],\n         [-0.05344085],\n         [ 0.04329479],\n         [ 0.06085089],\n         [ 0.0775903 ],\n         [ 0.00039548],\n         [-0.02303266],\n         [ 0.03587447],\n         [ 0.00279856],\n         [-0.08086321],\n         [-0.04059656],\n         [-0.03699915],\n         [ 0.0161699 ],\n         [-0.00425708],\n         [-0.05189599],\n         [-0.0820002 ],\n         [ 0.0594317 ],\n         [ 0.01968707],\n         [-0.02304412],\n         [ 0.06859192],\n         [ 0.00324343],\n         [ 0.01166714],\n         [-0.06123722],\n         [ 0.00963801],\n         [-0.03623621],\n         [ 0.05556217],\n         [ 0.0197241 ],\n         [ 0.00622027],\n         [ 0.02136517],\n         [-0.06995655],\n         [-0.00571647],\n         [-0.05176837],\n         [ 0.02858619],\n         [ 0.08529539],\n         [-0.01685704],\n         [ 0.08095355],\n         [-0.04637294],\n         [-0.03460714],\n         [ 0.07622904],\n         [-0.05750208],\n         [ 0.08455302],\n         [-0.03253871],\n         [-0.02496509],\n         [ 0.05329086],\n         [-0.08314498],\n         [ 0.03071259],\n         [-0.03210964],\n         [ 0.06944153]],\n\n        [[ 0.01360323],\n         [-0.07811504],\n         [-0.01610473],\n         [-0.0367619 ],\n         [-0.01997644],\n         [ 0.02199002],\n         [-0.01527436],\n         [-0.03885769],\n         [ 0.05444835],\n         [-0.00828706],\n         [-0.04818514],\n         [-0.03052794],\n         [-0.07078129],\n         [ 0.07921286],\n         [-0.0770357 ],\n         [ 0.02768118],\n         [-0.08084442],\n         [ 0.08914565],\n         [-0.05622789],\n         [-0.04072698],\n         [ 0.02550086],\n         [-0.0258685 ],\n         [ 0.05112925],\n         [-0.08128218],\n         [-0.03900871],\n         [ 0.03260256],\n         [ 0.05361149],\n         [-0.06995216],\n         [-0.07315704],\n         [-0.05321822],\n         [-0.03491809],\n         [-0.0132563 ],\n         [-0.0149237 ],\n         [ 0.08420019],\n         [ 0.08090866],\n         [-0.07596362],\n         [ 0.05581081],\n         [-0.04941811],\n         [ 0.07601336],\n         [ 0.03279651],\n         [-0.055463  ],\n         [-0.02301525],\n         [-0.04591828],\n         [ 0.02297549],\n         [ 0.07285769],\n         [-0.01587545],\n         [-0.07279814],\n         [ 0.03596611],\n         [ 0.08488677],\n         [-0.08835713],\n         [ 0.08163559],\n         [ 0.02366219],\n         [ 0.04443592],\n         [-0.08373445],\n         [ 0.04926142],\n         [ 0.03823374],\n         [ 0.0664776 ],\n         [ 0.04859602],\n         [-0.03474044],\n         [ 0.02676133],\n         [ 0.08789088],\n         [ 0.02141088],\n         [ 0.081526  ],\n         [ 0.06190355],\n         [ 0.09061584],\n         [-0.04921249],\n         [-0.00166885],\n         [-0.02764235],\n         [-0.06155602],\n         [ 0.083459  ],\n         [-0.06625795],\n         [-0.05969647],\n         [ 0.04613832],\n         [-0.03669249],\n         [ 0.03136527],\n         [-0.01489816],\n         [-0.0211824 ],\n         [ 0.02098166],\n         [ 0.0698358 ],\n         [ 0.06118974]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/beta:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_841/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[ 6.84014559e-02, -3.92495468e-02,  2.98464864e-01,\n           1.91253796e-01,  4.47430074e-01, -1.50372639e-01,\n          -8.67424086e-02,  9.80304182e-02,  2.42829069e-01,\n          -1.27617270e-01,  3.22487988e-02, -2.36566514e-01,\n          -1.18546292e-01,  3.08662951e-01, -5.08268140e-02,\n          -2.78982788e-01,  1.28611520e-01, -2.15595096e-01,\n           4.19246256e-01, -4.31423448e-02, -9.88996848e-02,\n           5.83896302e-02, -4.81182151e-02, -2.50762850e-01],\n         [-2.54657294e-04, -2.84498036e-01,  1.11294597e-01,\n           1.58172607e-01,  3.34406197e-02,  9.45988446e-02,\n          -1.13590725e-01, -1.88803896e-01,  2.60639876e-01,\n           3.80886883e-01,  4.98085320e-02, -1.67907774e-01,\n           4.33379769e-01, -4.32502702e-02, -2.12843508e-01,\n          -5.12624085e-02, -2.58914828e-01,  3.82817179e-01,\n          -1.58264160e-01, -2.52384320e-02, -1.20440200e-01,\n          -2.33588099e-01,  1.69621706e-01,  3.29376042e-01],\n         [-1.48603857e-01, -4.94975690e-03, -1.25284821e-01,\n          -3.14235777e-01, -3.06155179e-02, -1.61228910e-01,\n           3.28943431e-01, -2.41157398e-01, -1.72342017e-01,\n          -2.87996471e-01, -2.19827697e-01, -2.90676504e-01,\n          -1.40673921e-01,  2.52290457e-01, -2.30565965e-01,\n           4.12237078e-01, -4.02885258e-01, -3.19941223e-01,\n          -1.91585958e-01,  2.39304081e-01, -2.19422430e-01,\n           3.10061295e-02,  1.30316213e-01,  4.17715222e-01],\n         [-2.83654839e-01,  7.88801908e-02,  3.90030742e-01,\n          -2.80239731e-01, -2.60022700e-01,  5.91021441e-02,\n          -1.63197026e-01, -1.05511598e-01,  3.29035103e-01,\n          -3.08528990e-01, -2.85283744e-01, -8.81652012e-02,\n           7.35683367e-02,  3.97935122e-01, -1.48133829e-01,\n           4.57362354e-01, -2.01754242e-01,  1.40073270e-01,\n           1.45332798e-01, -2.13589311e-01,  2.30834037e-01,\n           2.66146421e-01, -1.22570517e-02, -2.81186908e-01],\n         [ 9.27113742e-02,  2.94797719e-01,  9.52996835e-02,\n          -1.14168040e-01, -2.64537960e-01,  1.61465615e-01,\n           8.48899707e-02,  2.10411370e-01,  3.34415287e-01,\n           1.12497360e-01,  1.54759303e-01,  1.03909755e-03,\n           2.04654440e-01, -1.59201503e-01,  2.31470883e-01,\n           2.08816707e-01, -2.31085315e-01,  2.41122872e-01,\n           3.60894710e-01,  7.51060098e-02, -2.24958569e-01,\n          -2.12644920e-01, -5.56731597e-02,  3.37553889e-01],\n         [-2.08547354e-01,  1.43108457e-01,  3.12944800e-01,\n          -1.38469055e-01, -2.83353180e-01, -4.07728165e-01,\n           1.80686608e-01,  3.35733108e-02, -3.44503552e-01,\n          -1.36209607e-01, -2.27211371e-01,  4.35201190e-02,\n           3.06223273e-01,  3.38013858e-01,  2.14590997e-01,\n           1.02576301e-01,  1.80911765e-01,  2.79255420e-01,\n           1.32999048e-01, -2.50599742e-01, -5.59633598e-02,\n           3.86381984e-01, -2.63577491e-01,  1.09275952e-01],\n         [-2.02991322e-01,  3.20254534e-01, -1.28931120e-01,\n          -2.22821176e-01, -4.50530529e-01, -1.56983003e-01,\n           3.09274308e-02, -2.49952246e-02,  4.32442039e-01,\n           1.62882715e-01,  5.95040247e-02, -1.03708759e-01,\n           5.70462756e-02,  1.81214690e-01,  1.77452281e-01,\n           1.82624996e-01,  2.51515925e-01,  4.01086330e-01,\n          -6.64763749e-02, -7.29998276e-02,  9.23321545e-02,\n          -1.07277729e-01,  1.39081590e-02,  3.53070088e-02],\n         [-2.45736111e-02,  2.32930586e-01,  2.46791229e-01,\n          -4.05412287e-01,  1.77785724e-01, -2.61412829e-01,\n           2.73910607e-03,  2.68365946e-02, -7.55482167e-02,\n           1.20985836e-01,  1.02372609e-01,  2.59972125e-01,\n          -1.53685585e-01,  1.38477132e-01,  1.89108759e-01,\n           3.82816106e-01,  2.86719594e-02,  1.36417747e-01,\n          -1.50075108e-01, -4.15790558e-01, -3.26630086e-01,\n           4.03426319e-01, -3.92406583e-02, -1.68544501e-01],\n         [-1.48958698e-01, -1.12082232e-02, -1.90384895e-01,\n           3.65707502e-02, -2.98519582e-01, -1.38363034e-01,\n           1.43423170e-01, -1.22984327e-01,  2.27974087e-01,\n          -1.44776367e-02, -2.28391871e-01, -1.60584435e-01,\n           1.44059226e-01,  3.87848526e-01,  4.55982924e-01,\n          -1.79180931e-02, -2.30021179e-01, -3.66843604e-02,\n          -1.18387006e-01, -2.21808821e-01,  1.48436546e-01,\n          -1.89776435e-01, -1.68751553e-01,  2.17583150e-01],\n         [-7.92236552e-02,  5.62611893e-02,  1.25069022e-01,\n           1.86897337e-01, -1.08875103e-01, -1.11209430e-01,\n           9.32304114e-02,  2.16538116e-01,  1.99880257e-01,\n          -4.03164364e-02, -7.67890087e-05, -3.16267669e-01,\n          -1.64254472e-01, -1.24856368e-01,  5.18351607e-02,\n          -2.93755352e-01,  1.59803137e-01, -1.59994736e-01,\n          -1.26577973e-01,  2.60245025e-01,  1.66056588e-01,\n          -1.65770039e-01, -1.23697177e-01, -3.05500418e-01],\n         [-5.68155013e-02,  1.60579100e-01, -6.24169186e-02,\n          -2.29602993e-01, -6.72605447e-03, -1.30686015e-02,\n           3.10763627e-01,  1.11883096e-02, -1.43394426e-01,\n           3.96723934e-02, -1.51594937e-01,  4.48242463e-02,\n          -2.00824216e-01, -6.95776343e-02, -8.52244496e-02,\n           3.37708741e-01,  5.81229255e-02,  9.78265405e-02,\n          -2.41187781e-01, -2.33654544e-01,  5.42929620e-02,\n          -1.50632605e-01, -1.39585912e-01, -8.66520852e-02],\n         [ 2.15589121e-01,  3.01770270e-01,  1.81317881e-01,\n          -2.17640847e-01, -1.94202453e-01, -5.57794385e-02,\n          -3.01259816e-01,  1.66748464e-01, -1.52296290e-01,\n          -1.12140011e-02, -4.08235997e-01,  3.36906277e-02,\n           1.24987811e-01,  1.09357908e-01,  1.22211007e-02,\n           2.06163645e-01,  4.32774693e-01,  1.11354612e-01,\n           1.57117352e-01, -8.76159742e-02, -3.88727576e-01,\n           8.88131186e-02, -4.56161648e-02, -1.03748202e-01],\n         [ 2.17320055e-01, -3.06096524e-02, -3.07308167e-01,\n          -1.84150375e-02,  4.32917736e-02,  3.64172727e-01,\n           1.35282487e-01, -3.02516341e-01, -3.60549808e-01,\n          -3.10943313e-02, -7.68045112e-02, -1.74460858e-01,\n           4.30398881e-01,  4.22906131e-01, -2.84746110e-01,\n          -6.90286160e-02, -2.45366335e-01,  5.88738658e-02,\n          -1.36877701e-01,  3.98888767e-01, -3.86585325e-01,\n          -2.37295911e-01, -2.57462233e-01, -1.06367320e-02],\n         [ 1.68956548e-01,  1.31968744e-02,  4.83044051e-02,\n          -1.40180741e-03,  1.56752951e-02,  1.62519328e-02,\n          -3.24289948e-02, -1.64080739e-01,  9.25464206e-04,\n           1.66249156e-01,  1.06085353e-02,  7.51359165e-02,\n          -1.50318056e-01,  1.73974067e-01, -1.30232424e-01,\n          -2.69660264e-01, -1.79689646e-01, -1.04240142e-01,\n           2.90815276e-03,  2.06049412e-01,  1.44253522e-01,\n          -2.34661661e-02,  2.13963658e-01,  9.76187363e-02],\n         [-2.05742612e-01,  3.90633076e-01, -1.25517040e-01,\n           1.06393941e-01, -8.10937732e-02,  1.32084474e-01,\n          -5.05283289e-02,  1.83930472e-01,  1.51309192e-01,\n           1.18198507e-01, -1.69627875e-01, -1.82145491e-01,\n          -3.80770087e-01, -1.77845597e-01, -6.37246221e-02,\n          -6.15027994e-02,  2.90250201e-02,  1.73633680e-01,\n          -2.52395906e-02,  4.51313525e-01,  9.36437696e-02,\n           2.13392470e-02, -5.18125184e-02,  4.51065898e-02],\n         [ 7.21428404e-03, -7.01751485e-02,  6.20292500e-02,\n          -1.78167790e-01, -1.79197952e-01,  1.67951733e-01,\n          -1.47651453e-02,  9.60243866e-02, -3.14050466e-02,\n          -1.73015058e-01,  2.89703339e-01, -3.65354046e-02,\n          -2.73190737e-01, -1.31683704e-02, -5.78405857e-02,\n           1.05742626e-01, -1.31691650e-01, -6.98650405e-02,\n          -2.43575409e-01, -1.10293716e-01, -1.88645765e-01,\n           4.52486724e-02, -1.01314589e-01,  3.55772853e-01],\n         [-8.10470060e-02, -1.17308587e-01, -2.77636021e-01,\n           2.12412551e-02,  2.73361616e-02, -5.80642596e-02,\n          -6.75727800e-02, -3.06788355e-01, -1.47276625e-01,\n           1.06635630e-01,  1.39611363e-01,  1.31797612e-01,\n          -2.58707870e-02, -3.33346933e-01,  2.01822981e-01,\n           1.56069934e-01,  2.27926463e-01,  3.58766988e-02,\n          -4.49413121e-01,  3.55598688e-01,  5.56149445e-02,\n           1.67433154e-02,  2.30916828e-01, -2.30243608e-01],\n         [ 7.94287398e-02,  8.46988857e-02,  1.93133757e-01,\n          -1.63043112e-01,  1.21878631e-01,  4.36030060e-01,\n          -2.90257372e-02,  2.60948658e-01,  3.29847842e-01,\n           1.47622302e-01,  3.63536060e-01,  9.75141749e-02,\n           7.86910206e-02, -8.77018645e-02,  2.08300769e-01,\n           3.69048834e-01,  2.47864962e-01,  2.11841717e-01,\n          -3.38594876e-02,  1.08390287e-01,  1.84072763e-01,\n          -4.53510553e-01, -1.61994800e-01,  1.11818321e-01],\n         [ 4.16301876e-01, -1.04084343e-01,  6.26413748e-02,\n          -1.06780179e-01,  2.17227101e-01,  1.80184394e-01,\n          -1.51087284e-01,  1.70429230e-01, -5.41463606e-02,\n           1.51863573e-02,  2.89891630e-01, -5.25343306e-02,\n           1.15656361e-01,  2.79144675e-01, -4.39649969e-01,\n           1.78336367e-01, -9.21451226e-02, -4.48728278e-02,\n           2.38898680e-01,  4.27428372e-02,  3.10139835e-01,\n          -9.08699110e-02, -1.05184801e-01,  4.37893942e-02],\n         [ 3.25950325e-01,  1.67655542e-01,  1.57173738e-01,\n           2.78030932e-01, -2.86546171e-01,  2.43394569e-01,\n           9.61122215e-02, -2.18070537e-01, -4.29121941e-01,\n          -1.23530671e-01,  7.75913000e-02,  9.19010490e-02,\n           3.39515865e-01,  9.32124481e-02, -1.59385085e-01,\n           2.00431451e-01,  3.26066852e-01,  1.05054518e-02,\n           4.32761848e-01, -7.89537653e-02, -8.59342590e-02,\n          -1.30976126e-01,  2.27657467e-01,  1.91409245e-01],\n         [-3.75073612e-01,  4.23639417e-01,  1.63915738e-01,\n          -1.95530683e-01,  7.29036108e-02, -1.22334443e-01,\n          -3.53962034e-01,  2.20930368e-01, -2.40285084e-01,\n          -2.11275905e-01,  1.98102027e-01,  2.79787555e-02,\n           3.83080766e-02, -4.61515822e-02, -1.04890592e-01,\n           3.96909148e-01,  1.64523184e-01,  2.27796227e-01,\n           3.13703954e-01, -2.78377265e-01,  3.52707654e-02,\n           1.95282340e-01, -3.65794450e-01,  9.66960192e-02],\n         [ 2.22572863e-01,  8.05358812e-02, -5.87769412e-02,\n          -1.57205448e-01,  1.03675090e-01,  3.75404745e-01,\n          -2.65001357e-01,  8.45250934e-02,  2.24628940e-01,\n          -1.57339483e-01, -5.23993634e-02, -9.57649648e-02,\n           2.71222353e-01, -5.40702902e-02,  3.09756845e-01,\n          -2.68340886e-01, -2.59965003e-01, -1.92582071e-01,\n           1.37734994e-01, -3.59820545e-01, -2.65150487e-01,\n           3.58236171e-02, -5.53906597e-02,  8.18005428e-02],\n         [ 2.65695006e-02,  2.01549023e-01, -2.54747361e-01,\n          -1.75153971e-01, -1.96663573e-01,  2.78709143e-01,\n          -3.61500412e-01, -1.69985607e-01,  4.00638580e-01,\n           1.64688677e-02, -1.62304863e-01,  3.04507405e-01,\n           1.61152065e-01, -1.36359632e-01,  2.80574888e-01,\n          -1.25894099e-01, -2.54770458e-01, -1.51105434e-01,\n           1.25800297e-01,  1.28735691e-01,  2.86624402e-01,\n          -4.36355591e-01,  1.06700897e-01,  2.17151165e-01],\n         [ 2.28441834e-01,  6.12825667e-03,  1.10644631e-01,\n           1.20842747e-01, -1.40010253e-01,  1.57839194e-01,\n          -1.51948586e-01,  3.42689008e-02, -4.17883366e-01,\n          -2.57781565e-01, -1.21073298e-01, -1.52606785e-01,\n          -6.51301146e-02,  6.13741390e-02,  1.58175871e-01,\n           3.55882376e-01,  1.06211878e-01, -1.56426564e-01,\n          -1.99634656e-01,  4.23387997e-02, -2.70452397e-03,\n           1.64158419e-01, -5.32924458e-02,  3.25408652e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_3/bias:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 3.2322290e-03, -6.8038426e-02,  3.6254149e-02, ...,\n           3.6164497e-03,  6.0175294e-03, -2.2373835e-02],\n         [ 4.4004988e-02, -6.4516165e-03,  2.9711971e-02, ...,\n          -4.6262234e-02, -2.3361182e-02,  4.8121519e-02],\n         [-2.1454789e-02, -2.3279462e-02, -5.4114871e-02, ...,\n           2.1021353e-02, -6.8069631e-03,  2.6950121e-03],\n         ...,\n         [-2.7204905e-02, -2.7014401e-02,  8.6074593e-05, ...,\n           2.2668173e-03,  2.4217796e-02, -9.2214420e-03],\n         [-6.0749897e-03, -1.7563224e-02, -2.7269751e-02, ...,\n           3.7701081e-02, -4.3942329e-02, -4.1374866e-02],\n         [ 1.6359350e-02,  6.1703615e-02,  1.3785601e-02, ...,\n           8.6689457e-02,  3.8917080e-02, -1.9491883e-03]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 0.09025844, -0.05533385, -0.03332517, ...,  0.0039877 ,\n           0.00332859, -0.01816172],\n         [-0.01412649, -0.07343955, -0.00698643, ...,  0.01780744,\n          -0.09184445, -0.00045122],\n         [ 0.01487028,  0.00755074,  0.00876115, ...,  0.00710829,\n          -0.0276674 , -0.01662439],\n         ...,\n         [ 0.0250209 , -0.01512609, -0.06588375, ..., -0.01853615,\n          -0.07150245,  0.01451693],\n         [-0.00655317, -0.05630272, -0.04374221, ...,  0.04496026,\n           0.02064656,  0.01468199],\n         [ 0.05690276,  0.08352149, -0.0858833 , ...,  0.01890404,\n          -0.08227941,  0.03291428]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_360/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 4.29344326e-02],\n         [-6.74265623e-02],\n         [-5.66367172e-02],\n         [-5.70493937e-02],\n         [-2.74301022e-02],\n         [ 4.10541743e-02],\n         [ 8.79422724e-02],\n         [ 8.19318146e-02],\n         [ 7.59763569e-02],\n         [-2.12059617e-02],\n         [-6.59518391e-02],\n         [-7.30900094e-02],\n         [-4.78762388e-03],\n         [-7.29462355e-02],\n         [-5.85789196e-02],\n         [ 3.28171924e-02],\n         [-7.79883564e-02],\n         [-7.98300877e-02],\n         [-8.37408155e-02],\n         [ 3.93167883e-02],\n         [-5.77830113e-02],\n         [-8.55350941e-02],\n         [-7.77602941e-02],\n         [ 6.17374480e-02],\n         [-4.83440608e-03],\n         [-4.40224931e-02],\n         [ 5.82516640e-02],\n         [-5.34067675e-02],\n         [ 3.82195711e-02],\n         [ 6.16061687e-03],\n         [-8.21940675e-02],\n         [-6.56566992e-02],\n         [ 1.08331218e-02],\n         [ 3.21651623e-02],\n         [ 8.35449845e-02],\n         [-7.32030049e-02],\n         [ 2.01678351e-02],\n         [-4.70406264e-02],\n         [-7.96911567e-02],\n         [ 1.14996210e-02],\n         [-6.58048838e-02],\n         [ 2.80717686e-02],\n         [ 1.50719509e-02],\n         [-2.34491155e-02],\n         [ 6.38113767e-02],\n         [-2.88781933e-02],\n         [ 8.92594457e-04],\n         [ 7.49938190e-02],\n         [ 7.98702538e-02],\n         [-2.71864608e-02],\n         [ 2.11583078e-02],\n         [-3.61310877e-02],\n         [-6.28392547e-02],\n         [ 7.85087198e-02],\n         [ 5.41489273e-02],\n         [-3.24733183e-02],\n         [ 1.07384250e-02],\n         [ 6.80008531e-02],\n         [ 2.99676433e-02],\n         [-1.47967786e-02],\n         [-6.32688850e-02],\n         [ 2.31021121e-02],\n         [-6.99172691e-02],\n         [ 3.02099586e-02],\n         [ 6.50635958e-02],\n         [-7.10258186e-02],\n         [-4.70710173e-02],\n         [ 3.78542691e-02],\n         [ 7.97744691e-02],\n         [ 6.09150082e-02],\n         [-2.20722780e-02],\n         [ 2.05085948e-02],\n         [ 8.80660713e-02],\n         [-7.80842155e-02],\n         [-5.04853837e-02],\n         [ 6.58236146e-02],\n         [-5.87391332e-02],\n         [-5.35612665e-02],\n         [ 6.61478043e-02],\n         [ 8.37584585e-03]],\n\n        [[-5.57722412e-02],\n         [ 3.61501426e-02],\n         [-5.34268171e-02],\n         [-4.32572775e-02],\n         [-4.77816388e-02],\n         [-3.05392519e-02],\n         [-1.21347606e-03],\n         [ 2.16806680e-02],\n         [ 7.74590373e-02],\n         [ 8.20591599e-02],\n         [-3.09635401e-02],\n         [ 8.38502645e-02],\n         [-2.05117092e-02],\n         [-3.74035239e-02],\n         [-7.56601244e-02],\n         [ 3.34321856e-02],\n         [ 4.02154177e-02],\n         [ 3.88269573e-02],\n         [-5.90643361e-02],\n         [ 3.03727388e-03],\n         [-2.26897225e-02],\n         [ 3.79813462e-02],\n         [-8.62237215e-02],\n         [-2.67534330e-02],\n         [-6.60271943e-02],\n         [-8.36863741e-02],\n         [ 6.10805750e-02],\n         [-6.16832450e-02],\n         [ 6.37112260e-02],\n         [-7.60613605e-02],\n         [-7.49831796e-02],\n         [-3.32641043e-02],\n         [ 7.50435293e-02],\n         [ 2.96038687e-02],\n         [-1.81979090e-02],\n         [-6.30560070e-02],\n         [ 1.04436129e-02],\n         [ 4.17065322e-02],\n         [-5.34891337e-03],\n         [-8.31440240e-02],\n         [ 6.70157373e-03],\n         [ 5.84474951e-02],\n         [-1.60550699e-02],\n         [ 7.20931590e-02],\n         [-4.69341427e-02],\n         [-8.97372589e-02],\n         [-9.27480310e-03],\n         [-6.99691400e-02],\n         [ 7.18539208e-03],\n         [ 8.22928995e-02],\n         [ 6.23858869e-02],\n         [-5.61044961e-02],\n         [ 2.46745944e-02],\n         [ 4.56547439e-02],\n         [-7.36372471e-02],\n         [-3.56410444e-02],\n         [-4.07867655e-02],\n         [-4.02390361e-02],\n         [ 5.60247898e-02],\n         [ 5.61400950e-02],\n         [-7.23836496e-02],\n         [-2.01498866e-02],\n         [-4.49745059e-02],\n         [ 5.82775027e-02],\n         [ 3.88439298e-02],\n         [-1.22525766e-02],\n         [-7.82406256e-02],\n         [-6.87655061e-02],\n         [-6.25681430e-02],\n         [-3.91839780e-02],\n         [ 3.23916972e-03],\n         [ 1.80687979e-02],\n         [-5.90614155e-02],\n         [-4.21840288e-02],\n         [ 6.05086237e-03],\n         [-3.73501629e-02],\n         [-5.48547730e-02],\n         [ 5.52416891e-02],\n         [-6.48690313e-02],\n         [ 2.32455358e-02]],\n\n        [[ 3.18724439e-02],\n         [-5.48525415e-02],\n         [-3.72464694e-02],\n         [ 6.36755824e-02],\n         [ 1.23876929e-02],\n         [ 1.00802556e-02],\n         [-6.08836599e-02],\n         [-8.51497799e-02],\n         [-5.28993085e-02],\n         [ 2.09134370e-02],\n         [ 1.96753517e-02],\n         [-2.67902017e-02],\n         [-5.95249236e-03],\n         [ 6.06220514e-02],\n         [ 8.15683901e-02],\n         [ 7.52286613e-02],\n         [ 5.28526753e-02],\n         [-5.78274168e-02],\n         [-6.89721331e-02],\n         [-4.97158170e-02],\n         [ 7.85014778e-02],\n         [ 4.77721691e-02],\n         [ 2.17933133e-02],\n         [-5.05322330e-02],\n         [ 6.45604879e-02],\n         [ 5.96921146e-02],\n         [ 4.62065786e-02],\n         [ 7.20409453e-02],\n         [-4.14944477e-02],\n         [-3.72504517e-02],\n         [-4.75932024e-02],\n         [ 4.66099083e-02],\n         [ 5.08522093e-02],\n         [ 8.87904316e-02],\n         [ 1.52190104e-02],\n         [ 1.36862621e-02],\n         [-5.48737608e-02],\n         [ 4.52680588e-02],\n         [-4.83558476e-02],\n         [ 8.55519474e-02],\n         [-5.60320914e-04],\n         [ 6.84139132e-03],\n         [-3.08615789e-02],\n         [ 6.29861802e-02],\n         [-4.23893593e-02],\n         [-7.56455958e-03],\n         [-3.36619392e-02],\n         [ 7.76530951e-02],\n         [ 7.17651695e-02],\n         [-5.12889288e-02],\n         [-5.41700423e-03],\n         [-1.50008500e-02],\n         [-8.40260237e-02],\n         [ 4.71491069e-02],\n         [ 1.98584646e-02],\n         [-2.80153826e-02],\n         [ 8.66070688e-02],\n         [ 3.64376903e-02],\n         [ 3.87914777e-02],\n         [ 6.96620345e-02],\n         [-5.99293113e-02],\n         [-2.75859013e-02],\n         [ 2.28927583e-02],\n         [ 3.63303423e-02],\n         [-2.93758065e-02],\n         [-3.14049385e-02],\n         [ 8.18703324e-02],\n         [ 6.29567802e-02],\n         [ 5.32104969e-02],\n         [-6.08915761e-02],\n         [ 1.05404109e-03],\n         [-5.11008166e-02],\n         [-3.99032533e-02],\n         [-7.78315589e-02],\n         [-5.50624803e-02],\n         [ 8.02858323e-02],\n         [-6.06996566e-02],\n         [-6.55881166e-02],\n         [-4.85333167e-02],\n         [-2.73325518e-02]]],\n\n\n       [[[ 6.66722208e-02],\n         [ 5.61857224e-02],\n         [-5.38792238e-02],\n         [-7.57335126e-02],\n         [ 6.10074401e-02],\n         [ 2.34873146e-02],\n         [ 6.53727949e-02],\n         [ 6.66008145e-02],\n         [ 3.52994949e-02],\n         [-6.09371737e-02],\n         [ 5.79679459e-02],\n         [ 5.89951575e-02],\n         [-1.51913241e-02],\n         [-4.34279442e-04],\n         [ 1.82931423e-02],\n         [-3.92464437e-02],\n         [ 6.24682158e-02],\n         [-3.11049335e-02],\n         [-5.52010424e-02],\n         [ 7.37842023e-02],\n         [-8.62824395e-02],\n         [-5.48819602e-02],\n         [ 5.34279048e-02],\n         [-1.01780593e-02],\n         [ 3.53550613e-02],\n         [ 1.91469789e-02],\n         [ 7.52201974e-02],\n         [-3.04744393e-03],\n         [-7.33405277e-02],\n         [-7.20890090e-02],\n         [ 6.93914890e-02],\n         [-1.07991621e-02],\n         [-7.93734938e-03],\n         [ 3.57979089e-02],\n         [ 1.31724924e-02],\n         [ 5.95712364e-02],\n         [ 5.93758672e-02],\n         [-7.16141686e-02],\n         [-2.65225768e-02],\n         [-7.75118098e-02],\n         [ 4.08145636e-02],\n         [ 4.88748401e-03],\n         [ 3.49420309e-02],\n         [-4.10383642e-02],\n         [ 8.71990025e-02],\n         [ 6.86141253e-02],\n         [-4.84764315e-02],\n         [ 1.51829794e-02],\n         [ 8.19181651e-02],\n         [ 3.21080387e-02],\n         [-3.92259397e-02],\n         [-9.29236412e-04],\n         [ 1.40778050e-02],\n         [ 4.29151207e-02],\n         [-5.53097539e-02],\n         [-5.04596010e-02],\n         [-1.51994377e-02],\n         [-1.31007433e-02],\n         [-7.63770193e-02],\n         [ 7.10065812e-02],\n         [-6.33141994e-02],\n         [ 3.84250730e-02],\n         [ 5.67469597e-02],\n         [-4.30296436e-02],\n         [-2.41254419e-02],\n         [-7.27467015e-02],\n         [ 7.26108998e-03],\n         [ 8.57848972e-02],\n         [-3.52650322e-02],\n         [-1.23599693e-02],\n         [ 8.85512978e-02],\n         [-5.72096556e-03],\n         [-7.89690018e-03],\n         [-7.84918070e-02],\n         [-6.06409945e-02],\n         [ 4.84788567e-02],\n         [ 6.49842918e-02],\n         [ 4.87396717e-02],\n         [ 1.04672983e-02],\n         [ 8.42150897e-02]],\n\n        [[-7.14472681e-03],\n         [ 1.50961727e-02],\n         [ 2.02860683e-02],\n         [-5.95817715e-03],\n         [ 7.13317692e-02],\n         [-6.41822070e-03],\n         [-5.88177145e-02],\n         [ 3.61466557e-02],\n         [-9.79344547e-03],\n         [-3.84752341e-02],\n         [-4.06880043e-02],\n         [ 4.66035306e-03],\n         [-3.15532312e-02],\n         [ 4.77885008e-02],\n         [-4.86982465e-02],\n         [-3.94218192e-02],\n         [ 3.43336463e-02],\n         [-3.49474847e-02],\n         [-5.24816401e-02],\n         [-7.31157959e-02],\n         [ 3.75106931e-02],\n         [ 2.28761435e-02],\n         [ 5.93446940e-02],\n         [-5.97939640e-03],\n         [-8.61727595e-02],\n         [ 8.15087259e-02],\n         [ 6.96686953e-02],\n         [ 1.81223303e-02],\n         [ 6.59119040e-02],\n         [-7.28418306e-02],\n         [ 7.49230534e-02],\n         [-2.42553055e-02],\n         [ 6.42922670e-02],\n         [-4.68006209e-02],\n         [ 3.40412408e-02],\n         [-1.75423920e-03],\n         [ 3.29241902e-02],\n         [-8.57786238e-02],\n         [-8.45115483e-02],\n         [-6.22605011e-02],\n         [ 2.30288729e-02],\n         [ 5.29200286e-02],\n         [ 2.67355442e-02],\n         [ 6.09720349e-02],\n         [ 2.25575417e-02],\n         [ 6.24920279e-02],\n         [ 3.13568562e-02],\n         [ 6.58864528e-03],\n         [ 6.92223907e-02],\n         [ 1.97137669e-02],\n         [ 3.58247608e-02],\n         [-5.32170497e-02],\n         [-3.64480279e-02],\n         [ 4.19937074e-02],\n         [-8.66998509e-02],\n         [ 8.06423873e-02],\n         [ 6.51427954e-02],\n         [ 7.01786876e-02],\n         [-4.56057489e-03],\n         [ 2.36397833e-02],\n         [-6.85281381e-02],\n         [-4.81368862e-02],\n         [ 8.83001089e-02],\n         [-5.48150167e-02],\n         [ 5.31197190e-02],\n         [ 3.06962356e-02],\n         [ 9.05111283e-02],\n         [-5.87601215e-03],\n         [-6.88491687e-02],\n         [ 8.91793817e-02],\n         [-1.51929706e-02],\n         [-7.95701593e-02],\n         [ 9.93226469e-03],\n         [ 7.71139711e-02],\n         [-9.88832861e-03],\n         [-2.94139236e-03],\n         [ 1.60878152e-03],\n         [ 4.08340991e-02],\n         [ 5.70092499e-02],\n         [ 2.74901018e-02]],\n\n        [[-3.75576131e-02],\n         [ 8.49442184e-03],\n         [ 7.32576698e-02],\n         [ 4.27309424e-03],\n         [ 8.13311338e-02],\n         [-7.17696846e-02],\n         [ 6.19389713e-02],\n         [-7.22269192e-02],\n         [ 4.85557318e-02],\n         [-4.18692939e-02],\n         [-2.59034261e-02],\n         [-6.18938357e-03],\n         [-4.65638936e-03],\n         [-4.84742485e-02],\n         [ 2.76988521e-02],\n         [ 6.96270168e-02],\n         [ 1.38992816e-03],\n         [-3.53288390e-02],\n         [ 3.99927646e-02],\n         [ 4.86508310e-02],\n         [ 8.62990767e-02],\n         [ 2.53553912e-02],\n         [-7.78173059e-02],\n         [ 8.17364752e-02],\n         [-2.70016789e-02],\n         [ 8.92897099e-02],\n         [ 8.04240257e-02],\n         [-3.27163525e-02],\n         [ 4.04493362e-02],\n         [-2.76805758e-02],\n         [ 2.92934477e-04],\n         [-4.88815345e-02],\n         [-5.65674827e-02],\n         [ 4.75613028e-02],\n         [ 7.72858411e-02],\n         [ 4.25950438e-02],\n         [-7.83738419e-02],\n         [ 6.77165240e-02],\n         [-5.72148822e-02],\n         [-2.71096528e-02],\n         [ 5.22156358e-02],\n         [ 1.41286999e-02],\n         [ 3.09604704e-02],\n         [-8.34431201e-02],\n         [-4.56343889e-02],\n         [ 1.58860311e-02],\n         [ 6.50797635e-02],\n         [-9.04949084e-02],\n         [-4.34874594e-02],\n         [ 6.50497228e-02],\n         [ 2.08747014e-02],\n         [-6.09154105e-02],\n         [-7.96606839e-02],\n         [ 2.02128962e-02],\n         [-8.00829381e-03],\n         [ 2.81296521e-02],\n         [-6.88297898e-02],\n         [ 7.20317960e-02],\n         [ 8.42758119e-02],\n         [ 7.56782144e-02],\n         [-5.37575781e-02],\n         [-6.62750527e-02],\n         [ 7.02255517e-02],\n         [-3.22245136e-02],\n         [ 7.34664351e-02],\n         [-8.87734815e-02],\n         [-3.42169814e-02],\n         [-3.47060747e-02],\n         [-5.57857603e-02],\n         [-2.54703313e-03],\n         [-4.43995669e-02],\n         [ 5.99421561e-02],\n         [-2.71768123e-02],\n         [-8.75104219e-03],\n         [ 4.55227345e-02],\n         [-2.82311812e-02],\n         [ 5.33798635e-02],\n         [-7.13920072e-02],\n         [ 6.15008175e-02],\n         [-5.95461167e-02]]],\n\n\n       [[[ 4.09314632e-02],\n         [-3.00359055e-02],\n         [-6.01564422e-02],\n         [-2.70767584e-02],\n         [ 8.66950154e-02],\n         [ 6.30721599e-02],\n         [-4.98142093e-03],\n         [-4.04364951e-02],\n         [-3.98162380e-02],\n         [ 6.16934597e-02],\n         [-7.80112296e-03],\n         [ 4.26832885e-02],\n         [ 8.87503177e-02],\n         [-2.02749744e-02],\n         [ 6.52079284e-03],\n         [-4.29207385e-02],\n         [ 1.52972490e-02],\n         [-3.30999792e-02],\n         [-9.96746123e-04],\n         [ 8.71432871e-02],\n         [-7.61571750e-02],\n         [-8.81171897e-02],\n         [ 7.50855356e-02],\n         [ 3.50174159e-02],\n         [ 4.51110750e-02],\n         [ 3.29613686e-05],\n         [-6.83810562e-02],\n         [-2.18199193e-03],\n         [ 1.70991346e-02],\n         [ 5.43313026e-02],\n         [-3.32697704e-02],\n         [ 1.79088488e-02],\n         [-5.78931496e-02],\n         [ 5.72486520e-02],\n         [-4.73573059e-02],\n         [-8.77198949e-02],\n         [ 2.94127315e-02],\n         [ 4.39245552e-02],\n         [ 5.49036562e-02],\n         [ 4.17197049e-02],\n         [ 4.78607863e-02],\n         [ 9.17787850e-03],\n         [ 5.16690314e-02],\n         [ 5.37209362e-02],\n         [-6.45646378e-02],\n         [-1.89504698e-02],\n         [-2.80972496e-02],\n         [-6.07702956e-02],\n         [-9.09752399e-03],\n         [ 2.38926709e-03],\n         [-2.17687637e-02],\n         [ 1.69982538e-02],\n         [ 1.60267949e-03],\n         [-5.50193079e-02],\n         [-5.46893887e-02],\n         [ 7.89996088e-02],\n         [-4.23323214e-02],\n         [-1.69365481e-02],\n         [-8.10032636e-02],\n         [ 8.76100063e-02],\n         [ 1.64192468e-02],\n         [ 8.16189796e-02],\n         [-3.27221490e-02],\n         [ 7.75498599e-02],\n         [-7.72237033e-03],\n         [-8.04200396e-02],\n         [-3.72867659e-02],\n         [-5.05641103e-04],\n         [-6.10338375e-02],\n         [ 2.92712897e-02],\n         [-3.03162895e-02],\n         [ 6.96438253e-02],\n         [ 3.63813937e-02],\n         [-6.37975782e-02],\n         [-7.93851838e-02],\n         [-9.67326760e-03],\n         [-3.51598896e-02],\n         [ 3.95245105e-03],\n         [-8.70468393e-02],\n         [-8.91821310e-02]],\n\n        [[ 4.83420044e-02],\n         [-8.86211395e-02],\n         [-6.35828376e-02],\n         [-5.52183464e-02],\n         [-4.12087850e-02],\n         [ 3.78708988e-02],\n         [-2.50799134e-02],\n         [ 8.52277875e-03],\n         [-1.03367418e-02],\n         [-6.30564243e-03],\n         [ 1.52819082e-02],\n         [ 4.30926234e-02],\n         [ 4.79936600e-02],\n         [ 4.81131375e-02],\n         [ 5.79863340e-02],\n         [-8.76488388e-02],\n         [-7.12413192e-02],\n         [ 8.82289559e-03],\n         [-7.03447163e-02],\n         [ 2.51292437e-03],\n         [-7.81320632e-02],\n         [-5.88131510e-02],\n         [-5.13185859e-02],\n         [-5.27008995e-02],\n         [ 8.14575255e-02],\n         [ 6.05476648e-02],\n         [ 3.33046839e-02],\n         [ 5.47196865e-02],\n         [-6.85833171e-02],\n         [ 1.86048076e-02],\n         [ 4.11576927e-02],\n         [-6.30540401e-03],\n         [ 6.32075369e-02],\n         [ 7.04057515e-03],\n         [ 2.12824419e-02],\n         [ 3.87721956e-02],\n         [ 8.93926024e-02],\n         [-3.34209427e-02],\n         [-9.00338441e-02],\n         [-2.40196288e-03],\n         [-4.19618487e-02],\n         [-2.56606117e-02],\n         [ 3.69644165e-02],\n         [-7.60750026e-02],\n         [ 6.73455149e-02],\n         [-4.73840199e-02],\n         [ 8.67134631e-02],\n         [ 1.77134573e-03],\n         [-4.07580845e-02],\n         [-8.09224322e-02],\n         [ 8.34113657e-02],\n         [ 5.04807085e-02],\n         [-5.78449778e-02],\n         [-3.32065485e-02],\n         [ 6.15741909e-02],\n         [ 7.22104162e-02],\n         [ 2.03073025e-03],\n         [ 2.50014886e-02],\n         [-5.99884242e-02],\n         [ 7.95099437e-02],\n         [-6.20882437e-02],\n         [ 2.50574872e-02],\n         [ 8.75380933e-02],\n         [ 3.81988734e-02],\n         [-3.58784087e-02],\n         [-7.64407888e-02],\n         [-4.72974367e-02],\n         [-1.57031938e-02],\n         [ 8.40732455e-02],\n         [ 5.64611703e-02],\n         [-6.86501116e-02],\n         [-3.16671990e-02],\n         [-1.21141225e-02],\n         [-6.57598525e-02],\n         [-3.35286595e-02],\n         [ 1.83440745e-04],\n         [ 4.85271513e-02],\n         [-7.28404224e-02],\n         [-2.41426304e-02],\n         [ 8.48646909e-02]],\n\n        [[ 5.40086180e-02],\n         [-5.91942444e-02],\n         [ 3.54364663e-02],\n         [-7.58298561e-02],\n         [-1.15645751e-02],\n         [-4.35891412e-02],\n         [ 5.68303466e-02],\n         [-2.48070806e-02],\n         [-8.09598938e-02],\n         [-8.60085860e-02],\n         [-4.65695523e-02],\n         [ 3.29060033e-02],\n         [ 7.32946247e-02],\n         [-4.12415974e-02],\n         [ 5.93081862e-03],\n         [ 4.22392488e-02],\n         [ 5.22114635e-02],\n         [ 7.57785738e-02],\n         [-4.79519367e-03],\n         [ 2.88132802e-02],\n         [-3.64575014e-02],\n         [ 6.78091496e-02],\n         [ 1.73615739e-02],\n         [-2.07582042e-02],\n         [ 1.40257403e-02],\n         [ 7.80557543e-02],\n         [ 3.89100760e-02],\n         [-8.55767503e-02],\n         [-7.40173906e-02],\n         [ 6.91024363e-02],\n         [ 3.22169065e-03],\n         [ 2.44976431e-02],\n         [ 2.41312534e-02],\n         [-3.76776159e-02],\n         [-4.43982035e-02],\n         [-4.58104126e-02],\n         [ 6.43711537e-02],\n         [-2.89346687e-02],\n         [-3.20175365e-02],\n         [ 6.96352869e-02],\n         [-7.26035386e-02],\n         [-6.58051670e-02],\n         [ 2.13648528e-02],\n         [-3.66676599e-03],\n         [-6.90964609e-02],\n         [ 3.52957845e-02],\n         [-4.54297476e-02],\n         [ 6.65307343e-02],\n         [-6.01144806e-02],\n         [-8.29677209e-02],\n         [-1.71187297e-02],\n         [-6.60229474e-03],\n         [ 2.42938921e-02],\n         [-5.23609668e-02],\n         [-1.13906488e-02],\n         [-3.52183320e-02],\n         [-4.05982211e-02],\n         [ 8.82812887e-02],\n         [-4.34604883e-02],\n         [-9.96544212e-03],\n         [-3.18277366e-02],\n         [ 1.58480033e-02],\n         [-8.30033496e-02],\n         [-6.49069473e-02],\n         [ 2.37236843e-02],\n         [-4.91286144e-02],\n         [ 7.93610215e-02],\n         [-3.11572552e-02],\n         [-3.33710760e-03],\n         [ 1.97163373e-02],\n         [ 8.80932510e-02],\n         [ 8.09532553e-02],\n         [-5.89937158e-02],\n         [ 4.39011753e-02],\n         [-8.83614346e-02],\n         [ 5.19813150e-02],\n         [ 4.68200892e-02],\n         [ 7.40507990e-02],\n         [-4.29757014e-02],\n         [-2.55189762e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/conv2d_1/kernel:0' shape=(1, 1, 144, 24) dtype=float32, numpy=\narray([[[[-0.03761738, -0.09302708, -0.00455803, ...,  0.09968492,\n          -0.08292634, -0.18004176],\n         [ 0.07397097, -0.05770568, -0.09359133, ...,  0.08636907,\n           0.08207563, -0.01524796],\n         [ 0.04500809, -0.07698917,  0.10304452, ..., -0.09371828,\n           0.03791093, -0.16250953],\n         ...,\n         [-0.03889801, -0.07503764,  0.13850221, ..., -0.10007132,\n           0.03929763,  0.07740211],\n         [-0.0008181 ,  0.01029518, -0.14436023, ...,  0.05831387,\n           0.16731787,  0.00278407],\n         [-0.05432349, -0.07435665,  0.11512357, ..., -0.02874178,\n          -0.09887365,  0.02115468]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[-0.10261881,  0.00186404, -0.09650893, ...,  0.09534681,\n           0.27680048,  0.04962253],\n         [-0.01291905, -0.17009313,  0.00516777, ...,  0.117024  ,\n          -0.5519193 , -0.23466766],\n         [ 0.00624772,  0.04299811, -0.11230905, ...,  0.19537391,\n           0.4081307 , -0.02647973],\n         ...,\n         [-0.314635  ,  0.24648157,  0.06411466, ..., -0.35967508,\n           0.39496776, -0.24095005],\n         [-0.09851054,  0.00824645, -0.1350275 , ..., -0.09467279,\n          -0.28634635,  0.20118222],\n         [-0.20103385,  0.07082074,  0.02687496, ..., -0.06844787,\n          -0.02555758,  0.10214295]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/conv2d/kernel:0' shape=(1, 1, 8, 48) dtype=float32, numpy=\narray([[[[-1.30371615e-01,  4.34781075e-01, -2.63606608e-01,\n           2.13728622e-01,  5.38397849e-01, -7.30965734e-01,\n           2.05442011e-02,  2.72836268e-01, -9.61526632e-02,\n          -1.97676629e-01,  6.31961599e-02, -4.35298562e-01,\n           4.06659275e-01,  4.00983930e-01,  1.39350697e-01,\n          -1.07082136e-01, -2.19532400e-01,  3.03581178e-01,\n           9.75310504e-02, -3.49944770e-01, -3.38868380e-01,\n          -7.24230051e-01, -5.44353247e-01,  1.07674621e-01,\n          -2.02909380e-01,  1.24039195e-01, -4.22120541e-01,\n          -6.65409684e-01, -2.15340227e-01, -1.83440134e-01,\n          -5.46591043e-01,  4.54149432e-02, -3.21072280e-01,\n          -6.03864789e-01, -3.95706415e-01,  8.55012536e-02,\n           2.07790121e-01, -8.28182884e-03, -2.48749986e-01,\n           2.77768523e-01, -4.56252933e-01,  1.63866892e-01,\n          -3.35387558e-01, -8.96736607e-02, -1.07812911e-01,\n           6.43281519e-01,  2.23204613e-01,  4.48113441e-01],\n         [ 6.55185759e-01, -5.55557847e-01,  5.82950450e-02,\n          -3.41936380e-01,  1.98506698e-01,  7.40282461e-02,\n          -3.59548390e-01,  6.16541386e-01,  5.34201801e-01,\n           5.03188372e-02, -2.84878444e-03, -3.60877275e-01,\n           3.01806301e-01,  7.78239429e-01,  9.23201814e-02,\n          -3.02196920e-01, -3.74142557e-01,  3.54473665e-02,\n          -4.49993797e-02,  3.29407096e-01, -1.81246951e-01,\n          -2.43523270e-01,  1.64735034e-01, -5.40523976e-02,\n           3.59328836e-01, -1.30323812e-01,  7.11880922e-01,\n           7.40212083e-01, -1.33881375e-01,  6.16194308e-02,\n          -5.38441874e-02,  5.09708188e-03,  4.73726869e-01,\n           6.14206260e-03,  4.43156749e-01, -4.73694354e-02,\n          -3.77877712e-01, -8.59411061e-02,  2.98231304e-01,\n          -3.29143643e-01,  4.27836061e-01, -2.55399108e-01,\n           7.50275552e-01,  2.95219272e-01, -2.79617161e-01,\n           2.34823883e-01, -2.28316277e-01,  1.28759257e-02],\n         [-2.43909493e-01, -1.40647709e-01,  3.53044569e-01,\n           5.43607771e-01,  3.08533698e-01,  3.30507606e-01,\n          -6.00601792e-01,  2.57177532e-01,  6.10143065e-01,\n          -2.53842264e-01, -5.57946801e-01, -6.10121965e-01,\n          -4.22241509e-01, -1.45779595e-01,  2.68900663e-01,\n           4.87116009e-01, -9.39648822e-02, -1.74923763e-01,\n          -9.96524617e-02, -4.79310036e-01,  5.62422812e-01,\n           2.58003682e-01, -3.32977295e-01,  5.05581856e-01,\n          -9.87463370e-02,  1.22005843e-01,  6.50222957e-01,\n          -4.62296247e-01,  2.59927571e-01, -4.55453664e-01,\n           1.39524132e-01,  2.57667005e-01, -1.19908892e-01,\n          -4.53735322e-01, -8.13555941e-02, -1.38005301e-01,\n          -3.10963802e-02, -6.16609395e-01,  2.10809872e-01,\n           4.41926569e-01, -9.22828987e-02,  2.21917108e-02,\n           8.73245224e-02, -1.77177057e-01, -9.73250158e-03,\n           3.23870897e-01, -1.81244999e-01,  5.11008680e-01],\n         [-3.36082697e-01,  3.09857905e-01, -2.78780997e-01,\n          -2.58673787e-01,  1.29167467e-01, -1.06577627e-01,\n          -1.59110114e-01, -1.25208750e-01,  2.89198965e-01,\n          -4.26452249e-01,  2.09363610e-01, -3.92122000e-01,\n          -2.75109380e-01, -1.75988600e-01,  4.58909512e-01,\n          -2.00244665e-01, -2.28982463e-01,  5.42957604e-01,\n           2.70010352e-01, -4.81479466e-02,  3.87907885e-02,\n           2.43521228e-01, -3.51289175e-02, -2.63527334e-01,\n           2.07889736e-01,  9.07293409e-02, -2.51384258e-01,\n          -2.28101879e-01,  1.37124151e-01, -2.41583541e-01,\n          -2.64126539e-01, -4.93406057e-01,  3.44644666e-01,\n           2.08194837e-01,  3.41462553e-01,  1.70319602e-01,\n          -7.22235084e-01,  3.42536092e-01, -3.33575785e-01,\n           4.00603004e-02,  2.95797382e-02, -5.48321724e-01,\n          -4.49197263e-01,  1.99535057e-01, -4.33827579e-01,\n           8.46194923e-02,  4.90510434e-01,  1.03158750e-01],\n         [-6.23774529e-02, -2.06018105e-01,  6.02864549e-02,\n           1.31121233e-01,  3.94064933e-01, -7.98920542e-02,\n          -5.19936025e-01, -1.77942216e-01,  1.14023462e-01,\n          -7.81024933e-01, -2.44508103e-01,  3.14915121e-01,\n           4.98266399e-01,  2.67971531e-02,  7.16745807e-03,\n           6.58785254e-02, -3.74848068e-01, -4.78841402e-02,\n          -1.23381227e-01, -6.53597936e-02,  6.88478425e-02,\n          -4.72472578e-01, -1.91605240e-01, -2.38990456e-01,\n           6.39327645e-01,  9.42275301e-02,  3.27535778e-01,\n           7.85042405e-01,  7.11090624e-01,  2.77356207e-01,\n          -1.42618284e-01,  3.49968761e-01, -3.37542631e-02,\n          -2.46769622e-01,  2.25240812e-02, -5.00006378e-01,\n          -1.73980407e-02, -5.90163767e-01, -3.40581760e-02,\n          -5.86339355e-01,  7.42378116e-01, -3.70029956e-01,\n          -7.99194872e-02, -4.52617258e-01, -2.38281161e-01,\n           4.40894783e-01, -2.81468600e-01, -1.48478588e-02],\n         [ 5.76866679e-02,  5.99527918e-02, -1.59849018e-01,\n          -2.06151139e-02, -3.50611389e-01, -6.26340330e-01,\n           4.06005502e-01,  1.31476391e-02, -2.92590827e-01,\n           6.30301774e-01,  5.17037392e-01, -1.95676252e-01,\n          -3.19275707e-01,  2.68268764e-01,  2.64434814e-01,\n          -5.09364963e-01, -3.89514238e-01,  3.95226270e-01,\n           7.86681920e-02, -2.44901851e-02,  2.62613092e-02,\n           3.33747417e-01, -6.18713677e-01,  2.07166061e-01,\n          -4.67924088e-01, -2.47854307e-01, -4.76317555e-01,\n          -2.15480641e-01,  3.88756633e-01,  5.68588786e-02,\n           1.42194331e-02,  4.45337072e-02,  7.45695651e-01,\n           1.29509017e-01,  3.05707246e-01,  2.91808378e-02,\n          -4.95722800e-01, -4.63369280e-01,  3.27441692e-01,\n           3.29889417e-01,  7.25581348e-01, -2.89845586e-01,\n           1.10017936e-04,  2.22809985e-01,  6.37530625e-01,\n          -5.65512627e-02, -1.40223756e-01, -2.05610245e-01],\n         [-9.20050740e-02, -9.19002518e-02, -3.05859387e-01,\n           3.72999012e-01, -3.64848942e-01,  3.36481541e-01,\n           1.64955139e-01, -7.46131092e-02,  5.16608775e-01,\n          -3.01174045e-01,  2.47647077e-01,  2.49442443e-01,\n          -1.73923865e-01,  3.79293203e-01, -1.96317688e-01,\n           2.70434141e-01, -1.64020136e-01, -6.64107263e-01,\n          -1.65289655e-01,  2.02671945e-01,  5.46404183e-01,\n          -2.92355418e-01,  5.40146604e-02,  2.45934520e-02,\n          -2.24546283e-01,  1.88598827e-01, -3.55933875e-01,\n           1.63007855e-01, -5.02138972e-01,  7.40029573e-01,\n           2.40355730e-01, -2.63393283e-01, -5.39008677e-01,\n           1.75718471e-01, -4.51826096e-01, -5.86757421e-01,\n          -8.68319646e-02,  2.26631295e-02,  1.54240832e-01,\n          -2.30893880e-01,  3.81271064e-01,  1.22051677e-02,\n           3.01055372e-01, -2.26523221e-01,  4.32685018e-01,\n          -2.89458334e-01,  7.70876467e-01,  2.87112683e-01],\n         [-6.86946362e-02, -3.29582065e-01,  2.87968051e-02,\n           4.51442271e-01,  1.85779352e-02, -4.44306672e-01,\n           6.43697858e-01, -5.20319641e-02, -6.39317930e-02,\n          -3.59965384e-01, -5.89129329e-01, -1.40602276e-01,\n          -2.78903514e-01,  3.38965088e-01,  2.29843929e-01,\n          -6.25931680e-01, -5.91522753e-01, -2.07590297e-01,\n           4.98617858e-01, -5.58595136e-02,  3.97536695e-01,\n          -2.38490596e-01, -4.86220509e-01,  4.12451416e-01,\n           2.79874563e-01,  2.80852705e-01,  4.05861996e-02,\n          -5.01023889e-01, -2.62293398e-01, -1.23689428e-01,\n          -4.16729569e-01,  5.37230149e-02, -4.00173604e-01,\n          -1.57297458e-02,  9.78673995e-02, -1.17588557e-01,\n           7.56999910e-01, -4.74577516e-01,  5.85263908e-01,\n          -2.15049103e-01,  9.55235884e-02, -4.91804928e-01,\n           2.19715878e-01,  4.59195942e-01,  1.16604082e-01,\n          -3.55528951e-01,  3.43461663e-01, -2.04408150e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_848/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.00915375,  0.07922173,  0.05572374, ..., -0.09017897,\n           0.07759812,  0.06905492],\n         [-0.11903498, -0.12649974, -0.08317759, ...,  0.20791508,\n           0.22465754,  0.00788698],\n         [ 0.01935739, -0.0347603 , -0.09054393, ..., -0.02241375,\n          -0.04938751, -0.04115076],\n         ...,\n         [ 0.18315037,  0.0811845 , -0.08148584, ...,  0.08541793,\n          -0.16864452,  0.03808182],\n         [-0.12373868, -0.00337576, -0.19018029, ..., -0.11701128,\n           0.15065709, -0.04049372],\n         [ 0.04576219,  0.1178515 , -0.1654289 , ...,  0.03718358,\n          -0.17015322, -0.06578033]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_852/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.00232683, -0.2034802 , -0.03521582, ..., -0.01951274,\n           0.05507628,  0.02393006],\n         [ 0.01362714,  0.16329645,  0.04095648, ..., -0.07993557,\n          -0.0466916 ,  0.04021601],\n         [ 0.01127994,  0.00726154, -0.1984283 , ...,  0.13353664,\n          -0.03450608, -0.02595006],\n         ...,\n         [ 0.00480156,  0.01318917, -0.19670637, ..., -0.06950975,\n           0.07719523, -0.10309383],\n         [ 0.02022886, -0.06834392, -0.02623226, ..., -0.15295224,\n          -0.00376821,  0.04391297],\n         [ 0.08444051,  0.01439427,  0.05817515, ...,  0.04911501,\n           0.01977255, -0.16177143]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_354/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[ 6.52240068e-02],\n         [ 9.90059376e-02],\n         [ 1.28916204e-01],\n         [ 1.22541875e-01],\n         [ 1.33134007e-01],\n         [-1.24415010e-02],\n         [ 6.83899373e-02],\n         [-4.80134934e-02],\n         [ 1.47212148e-01],\n         [ 8.86776447e-02],\n         [ 6.81191534e-02],\n         [-1.36933461e-01],\n         [ 1.59948170e-02],\n         [ 1.99729204e-03],\n         [ 1.61624879e-01],\n         [ 1.08130276e-02],\n         [-8.03222209e-02],\n         [-6.24288097e-02],\n         [-1.17029086e-01],\n         [ 1.24260604e-01],\n         [-3.61075252e-02],\n         [ 8.71927142e-02],\n         [-9.55274999e-02],\n         [ 1.02227002e-01]],\n\n        [[-1.29302114e-01],\n         [-5.29677868e-02],\n         [-7.54742846e-02],\n         [ 7.39828199e-02],\n         [ 1.17655903e-01],\n         [ 1.45157307e-01],\n         [ 1.39297396e-02],\n         [ 1.27525389e-01],\n         [ 1.31117404e-01],\n         [ 4.87599224e-02],\n         [-1.57603621e-03],\n         [-4.18982282e-02],\n         [-1.43140838e-01],\n         [ 9.10517275e-02],\n         [ 1.05135858e-01],\n         [ 8.72172415e-02],\n         [-3.78234833e-02],\n         [-1.09854832e-01],\n         [-1.48266554e-05],\n         [-1.33825690e-02],\n         [ 1.77233070e-02],\n         [-8.80322754e-02],\n         [ 9.68915522e-02],\n         [-1.20830677e-01]],\n\n        [[-1.52912661e-01],\n         [ 1.04539841e-02],\n         [-1.27866790e-01],\n         [-6.87116757e-02],\n         [ 1.53212667e-01],\n         [ 5.72305471e-02],\n         [-1.81117505e-02],\n         [-1.58471018e-02],\n         [ 9.51848924e-03],\n         [-1.07475713e-01],\n         [ 2.71092653e-02],\n         [ 6.52351826e-02],\n         [-1.28496274e-01],\n         [ 1.07269645e-01],\n         [ 4.18805182e-02],\n         [-8.56636465e-03],\n         [ 1.38491154e-01],\n         [-1.12870201e-01],\n         [ 2.52067298e-02],\n         [-9.23469737e-02],\n         [-7.69528300e-02],\n         [ 1.56718522e-01],\n         [ 1.41847253e-01],\n         [ 1.50981247e-01]]],\n\n\n       [[[ 1.15612715e-01],\n         [ 7.52513111e-02],\n         [ 3.03568393e-02],\n         [-3.43554318e-02],\n         [-1.04326651e-01],\n         [-6.60492480e-03],\n         [-1.20138943e-01],\n         [-2.83211917e-02],\n         [ 8.91003013e-02],\n         [-1.53891921e-01],\n         [-6.91871345e-02],\n         [ 6.65346235e-02],\n         [-5.36658317e-02],\n         [ 3.09724510e-02],\n         [-7.31342584e-02],\n         [ 1.38907433e-01],\n         [-1.00144014e-01],\n         [-4.06922400e-03],\n         [-7.73752183e-02],\n         [-6.93918467e-02],\n         [ 9.45885479e-02],\n         [ 1.50894374e-01],\n         [ 8.82004201e-02],\n         [ 1.06200606e-01]],\n\n        [[ 5.25698811e-02],\n         [ 1.38315141e-01],\n         [ 9.27966833e-03],\n         [ 4.35792655e-02],\n         [ 1.59385949e-02],\n         [ 6.64047897e-02],\n         [ 6.64679706e-02],\n         [-1.17619202e-01],\n         [-1.29423678e-01],\n         [ 1.06093585e-01],\n         [-1.09990589e-01],\n         [ 4.63925302e-03],\n         [-8.79362226e-03],\n         [ 5.67833185e-02],\n         [ 1.48648351e-01],\n         [ 4.16786820e-02],\n         [-5.02228960e-02],\n         [-1.27146527e-01],\n         [ 4.83026505e-02],\n         [ 2.97219455e-02],\n         [ 7.98200965e-02],\n         [ 1.41054004e-01],\n         [ 9.28908885e-02],\n         [-5.57319969e-02]],\n\n        [[ 1.75315589e-02],\n         [-1.00096762e-02],\n         [-4.23526764e-03],\n         [ 1.26854628e-02],\n         [-2.89727747e-03],\n         [-1.16087392e-01],\n         [ 7.06425905e-02],\n         [ 1.47367150e-01],\n         [-2.51947492e-02],\n         [-1.20390765e-01],\n         [ 7.00471401e-02],\n         [-7.95526803e-03],\n         [ 1.20374560e-01],\n         [-8.36162344e-02],\n         [ 5.36774099e-03],\n         [-1.18841678e-01],\n         [-1.26130357e-01],\n         [-3.97652537e-02],\n         [ 1.20895803e-01],\n         [ 2.25521624e-02],\n         [-5.53127229e-02],\n         [-3.25261354e-02],\n         [ 1.21469200e-01],\n         [ 1.38733953e-01]]],\n\n\n       [[[ 3.97834331e-02],\n         [ 1.49163812e-01],\n         [-2.21478790e-02],\n         [-8.70692208e-02],\n         [ 1.46821499e-01],\n         [ 2.72739232e-02],\n         [-9.20304060e-02],\n         [-1.40770599e-01],\n         [ 1.44219965e-01],\n         [-1.55585676e-01],\n         [-1.31509155e-02],\n         [ 6.13624156e-02],\n         [ 1.22314483e-01],\n         [ 2.82419622e-02],\n         [ 8.13578218e-02],\n         [ 5.53288460e-02],\n         [ 9.78636444e-02],\n         [ 4.74153459e-03],\n         [-1.57667845e-02],\n         [ 9.97774601e-02],\n         [-9.17739123e-02],\n         [ 8.96225274e-02],\n         [ 2.95868069e-02],\n         [ 8.07301253e-02]],\n\n        [[ 6.49972111e-02],\n         [-3.17596048e-02],\n         [ 3.32279205e-02],\n         [ 2.13889033e-02],\n         [ 3.77313942e-02],\n         [ 1.55904442e-01],\n         [-1.39071181e-01],\n         [ 9.78016257e-02],\n         [-1.48126334e-02],\n         [-5.12042567e-02],\n         [ 1.54785484e-01],\n         [-3.75085026e-02],\n         [ 4.81696129e-02],\n         [ 3.11692208e-02],\n         [ 1.33572131e-01],\n         [ 1.28133476e-01],\n         [-1.27389818e-01],\n         [-1.04279369e-02],\n         [-1.53769046e-01],\n         [ 1.29491448e-01],\n         [ 1.38839006e-01],\n         [-3.78639698e-02],\n         [ 1.10908955e-01],\n         [-1.61532402e-01]],\n\n        [[-4.39729244e-02],\n         [-1.38315827e-01],\n         [-1.17537558e-01],\n         [-1.45617247e-01],\n         [ 1.16562426e-01],\n         [ 1.49718374e-02],\n         [ 2.84336656e-02],\n         [-1.10765018e-01],\n         [ 1.14202261e-01],\n         [ 5.88011742e-02],\n         [ 9.68724489e-02],\n         [-1.25912175e-01],\n         [ 1.50351912e-01],\n         [ 1.09511077e-01],\n         [-1.44106895e-02],\n         [-2.62100548e-02],\n         [ 6.42930269e-02],\n         [-1.18620142e-01],\n         [-1.34632990e-01],\n         [ 1.32978886e-01],\n         [-3.14037949e-02],\n         [-1.18922621e-01],\n         [-1.25461131e-01],\n         [-1.32299349e-01]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_863/kernel:0' shape=(1, 1, 112, 40) dtype=float32, numpy=\narray([[[[-4.11141571e-03,  5.14028668e-02,  1.88590258e-01, ...,\n           1.09885976e-01,  5.87395020e-02,  9.84337851e-02],\n         [-1.25391915e-01, -3.63258226e-03,  1.17762573e-01, ...,\n           1.79382116e-01,  3.93138640e-02, -1.51167496e-03],\n         [-7.33519485e-03, -8.63204449e-02,  6.09833933e-02, ...,\n          -3.09295040e-02,  7.96577930e-02,  9.76926908e-02],\n         ...,\n         [ 1.97812542e-01, -1.43324854e-02, -4.86361720e-02, ...,\n          -2.61177234e-02, -1.29033878e-01, -8.43222216e-02],\n         [-1.17514849e-01,  7.62676671e-02,  5.56366779e-02, ...,\n           3.90190706e-02, -2.36992296e-02, -2.03992680e-01],\n         [-1.29779428e-01, -5.51367957e-05,  6.11162521e-02, ...,\n          -4.13446128e-02, -1.00910733e-03, -4.29802835e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/moving_mean:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_860/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[-0.14280918,  0.08944207, -0.00536764, ...,  0.04808926,\n          -0.22874428, -0.05288725],\n         [-0.040046  ,  0.04191365, -0.0528014 , ...,  0.02481813,\n          -0.02251204,  0.10579248],\n         [ 0.18502708, -0.04964897,  0.23035191, ..., -0.08768127,\n          -0.22695337, -0.01612777],\n         ...,\n         [-0.03270319, -0.02857555,  0.02711721, ..., -0.15849586,\n           0.02381836, -0.14350596],\n         [ 0.16251637, -0.06975949,  0.09996747, ...,  0.02222161,\n           0.12037649,  0.08093608],\n         [-0.09563532,  0.13964333,  0.17470478, ..., -0.0367801 ,\n           0.099773  , -0.23024009]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 3.32582789e-03],\n         [-1.17130531e-02],\n         [ 1.48885278e-02],\n         ...,\n         [ 1.13264993e-02],\n         [-2.33943644e-03],\n         [ 7.31479740e-05]],\n\n        [[-2.20304877e-02],\n         [-7.40307430e-03],\n         [ 1.06865363e-02],\n         ...,\n         [ 1.97748281e-03],\n         [ 5.23314951e-03],\n         [-1.37852854e-03]],\n\n        [[ 5.93560282e-04],\n         [ 1.95680521e-02],\n         [-1.00968806e-02],\n         ...,\n         [ 2.70695658e-03],\n         [ 1.38354534e-02],\n         [-3.93670890e-03]]],\n\n\n       [[[ 1.91939028e-03],\n         [-1.61342565e-02],\n         [ 2.13775318e-02],\n         ...,\n         [-2.70680021e-02],\n         [ 1.06727714e-02],\n         [ 2.34286692e-02]],\n\n        [[-3.78927100e-03],\n         [ 8.22613202e-03],\n         [ 5.86182578e-03],\n         ...,\n         [ 6.76022936e-03],\n         [-1.61515810e-02],\n         [ 1.26128728e-02]],\n\n        [[ 1.53807094e-02],\n         [ 1.70745049e-03],\n         [ 1.95278786e-02],\n         ...,\n         [ 7.11710542e-04],\n         [ 7.52041989e-04],\n         [ 1.68538503e-02]]],\n\n\n       [[[-2.10806518e-03],\n         [ 1.43382081e-03],\n         [ 4.59211646e-03],\n         ...,\n         [-8.86675529e-03],\n         [-1.06040807e-03],\n         [-1.02666160e-02]],\n\n        [[-2.00253967e-02],\n         [ 1.96505580e-02],\n         [ 6.65109092e-03],\n         ...,\n         [-6.07305858e-03],\n         [-7.79461174e-04],\n         [ 1.41850505e-02]],\n\n        [[-2.78654620e-02],\n         [ 1.29442792e-02],\n         [-3.16242711e-03],\n         ...,\n         [ 2.91363578e-02],\n         [-1.58665460e-02],\n         [ 1.40627408e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_843/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[-2.9278424e-01,  4.4285294e-01, -3.4178549e-01, ...,\n          -2.6762027e-01, -3.4465492e-01,  1.6365843e-01],\n         [ 1.7879924e-01,  1.8183777e-01,  3.7378509e-02, ...,\n           1.8761919e-01,  2.4028233e-01,  3.8474981e-02],\n         [-6.6355564e-02, -1.0362403e-01, -2.1356900e-01, ...,\n          -1.8357792e-01, -1.2078777e-01, -3.8993585e-01],\n         ...,\n         [ 2.7171931e-01,  4.4364431e-05, -3.4704161e-01, ...,\n          -6.9470517e-02,  2.4025753e-01, -1.7532812e-01],\n         [ 3.2199988e-01, -7.7251062e-02, -3.2872680e-01, ...,\n          -1.3861954e-01,  1.9196975e-01,  7.4934863e-02],\n         [ 2.7711937e-01,  1.5735106e-01,  1.4614473e-01, ...,\n          -8.7134212e-02, -3.5154852e-03, -1.5122482e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/conv2d/kernel:0' shape=(1, 1, 24, 144) dtype=float32, numpy=\narray([[[[-0.09745612, -0.334278  , -0.06333195, ..., -0.17459834,\n           0.22801118, -0.02319025],\n         [ 0.07986948, -0.03720871, -0.18865833, ...,  0.34430104,\n           0.00423673,  0.26967728],\n         [-0.04505704,  0.19242707, -0.14736629, ..., -0.18781132,\n           0.17052384,  0.10207271],\n         ...,\n         [ 0.18935722, -0.14822224,  0.04780588, ..., -0.29284322,\n           0.2693695 , -0.36066863],\n         [ 0.18947114,  0.09511434, -0.15232453, ...,  0.00888589,\n          -0.25829357, -0.07197316],\n         [ 0.17060845,  0.05940907,  0.2274006 , ..., -0.01121959,\n          -0.2323091 , -0.32475132]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-0.08956286, -0.13818696,  0.00412288, ..., -0.0019808 ,\n           0.16719177,  0.01161483],\n         [-0.01176096, -0.20416044,  0.09813652, ..., -0.19268797,\n           0.08704478,  0.09809109],\n         [-0.13807404, -0.10888782, -0.02586967, ..., -0.03034157,\n          -0.0376758 , -0.03446921],\n         ...,\n         [-0.10040066,  0.06523328,  0.10319647, ...,  0.10061502,\n           0.01301018, -0.08359861],\n         [-0.03302679, -0.07848048,  0.00971641, ...,  0.0357466 ,\n           0.03501476,  0.10530565],\n         [ 0.06057967,  0.02290075, -0.14311811, ...,  0.01129883,\n          -0.12733826, -0.13624685]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/moving_mean:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_375/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 7.28526711e-02],\n         [ 3.91445011e-02],\n         [-6.39508516e-02],\n         [-6.31077215e-02],\n         [ 3.67473811e-02],\n         [-7.31304809e-02],\n         [ 4.47591394e-02],\n         [-5.83743677e-02],\n         [-1.28615424e-02],\n         [-4.29154187e-02],\n         [ 3.80232185e-02],\n         [-2.10484117e-02],\n         [-5.78490011e-02],\n         [-4.20733914e-02],\n         [ 4.71396744e-02],\n         [-8.78891870e-02],\n         [-1.12204030e-02],\n         [-3.06511186e-02],\n         [ 2.61844173e-02],\n         [-3.27773690e-02],\n         [ 3.83582860e-02],\n         [-8.37524980e-02],\n         [-4.99225780e-02],\n         [-9.04571638e-02],\n         [-7.90802240e-02],\n         [ 5.13298959e-02],\n         [ 4.24787402e-02],\n         [-8.31413642e-02],\n         [ 2.94446722e-02],\n         [-3.57979238e-02],\n         [ 5.77078015e-02],\n         [-5.39896451e-02],\n         [-7.61882588e-02],\n         [-5.06312549e-02],\n         [ 3.29263508e-03],\n         [ 8.68127793e-02],\n         [-6.72610700e-02],\n         [ 2.01254040e-02],\n         [ 6.29937500e-02],\n         [-1.49826184e-02],\n         [-4.08788435e-02],\n         [ 1.57074556e-02],\n         [-1.89496055e-02],\n         [-7.11138099e-02],\n         [ 1.96378231e-02],\n         [-3.23298499e-02],\n         [-2.83720978e-02],\n         [ 4.06721532e-02],\n         [ 1.99259967e-02],\n         [ 9.23228264e-03],\n         [ 8.45717192e-02],\n         [-6.02978617e-02],\n         [-4.15782630e-02],\n         [ 1.69800222e-03],\n         [ 3.31348479e-02],\n         [-2.01477036e-02],\n         [ 1.32120699e-02],\n         [ 9.02311504e-02],\n         [ 6.19045198e-02],\n         [ 1.05432197e-02],\n         [-4.43278626e-02],\n         [-4.06676941e-02],\n         [ 7.36607611e-02],\n         [-7.12154210e-02],\n         [-6.12200648e-02],\n         [ 1.09027028e-02],\n         [ 5.28709590e-02],\n         [-1.15410239e-03],\n         [ 1.31675825e-02],\n         [ 7.34428167e-02],\n         [-4.25008833e-02],\n         [ 6.53146654e-02],\n         [ 1.09130889e-03],\n         [ 6.44366294e-02],\n         [ 7.04599023e-02],\n         [-3.00244167e-02],\n         [ 3.55179906e-02],\n         [-4.90318649e-02],\n         [-1.36217177e-02],\n         [-4.81713675e-02]],\n\n        [[ 4.62757051e-02],\n         [-2.58250833e-02],\n         [-7.21080154e-02],\n         [ 9.05430466e-02],\n         [-2.11749226e-03],\n         [-7.01871440e-02],\n         [-4.72018123e-03],\n         [-4.03886475e-02],\n         [-5.85400946e-02],\n         [-5.54201081e-02],\n         [ 4.69406992e-02],\n         [-3.64886485e-02],\n         [-4.16579694e-02],\n         [ 2.83201188e-02],\n         [ 7.65908808e-02],\n         [-7.60929808e-02],\n         [-5.05150110e-03],\n         [ 6.86824918e-02],\n         [-6.81118369e-02],\n         [ 8.75195861e-02],\n         [-2.30789185e-04],\n         [-1.31695047e-02],\n         [ 8.87021422e-02],\n         [-2.26044357e-02],\n         [-3.54580544e-02],\n         [-5.81807829e-02],\n         [ 3.62536311e-03],\n         [ 6.06642962e-02],\n         [ 6.81681186e-02],\n         [ 8.49124789e-02],\n         [-4.76897359e-02],\n         [ 8.26724321e-02],\n         [ 2.88121551e-02],\n         [ 6.77885115e-02],\n         [-5.72916679e-02],\n         [-4.97065187e-02],\n         [-4.61204946e-02],\n         [ 6.69550449e-02],\n         [ 5.75452596e-02],\n         [ 1.87550262e-02],\n         [ 3.09696421e-02],\n         [ 2.84730420e-02],\n         [ 6.92687482e-02],\n         [-7.22421706e-03],\n         [-4.83463518e-02],\n         [ 5.53288311e-02],\n         [-2.53829509e-02],\n         [-3.32420208e-02],\n         [-7.15535432e-02],\n         [ 5.72077185e-02],\n         [ 8.14914703e-02],\n         [-7.57064149e-02],\n         [ 1.10599548e-02],\n         [ 3.30481529e-02],\n         [ 4.26735133e-02],\n         [-1.02517530e-02],\n         [-1.97751969e-02],\n         [ 5.86749762e-02],\n         [-5.81355765e-02],\n         [-1.45111308e-02],\n         [-2.73989290e-02],\n         [-5.73280044e-02],\n         [-5.38819283e-02],\n         [ 7.53278434e-02],\n         [ 4.84479219e-02],\n         [-2.25935727e-02],\n         [-1.58716887e-02],\n         [-6.39434084e-02],\n         [-4.47247177e-03],\n         [ 7.38793910e-02],\n         [-2.59153023e-02],\n         [ 5.63204437e-02],\n         [-7.31931180e-02],\n         [ 8.39896202e-02],\n         [ 8.25551152e-02],\n         [ 6.70854151e-02],\n         [-3.38122882e-02],\n         [ 2.52601504e-03],\n         [-3.29485685e-02],\n         [ 1.38396397e-02]],\n\n        [[ 2.39235908e-02],\n         [-7.78282285e-02],\n         [-4.27635126e-02],\n         [ 7.72383809e-03],\n         [-1.91079825e-02],\n         [ 8.21057707e-02],\n         [-5.23586534e-02],\n         [ 5.67113012e-02],\n         [-6.30102158e-02],\n         [-8.59436765e-02],\n         [ 8.95319730e-02],\n         [-5.68731539e-02],\n         [-7.90156573e-02],\n         [ 6.28039241e-02],\n         [-5.33127859e-02],\n         [-8.18330273e-02],\n         [-4.84556705e-03],\n         [ 8.82065594e-02],\n         [ 6.33682907e-02],\n         [ 4.38508838e-02],\n         [-4.27640304e-02],\n         [ 1.56025738e-02],\n         [-1.27395913e-02],\n         [-7.49242827e-02],\n         [ 2.25714669e-02],\n         [-4.97327335e-02],\n         [ 3.98306698e-02],\n         [ 7.50660598e-02],\n         [-4.83244173e-02],\n         [-6.62696436e-02],\n         [-6.51264936e-02],\n         [ 3.22473124e-02],\n         [ 1.40005872e-02],\n         [ 3.74150723e-02],\n         [-8.12330619e-02],\n         [ 4.01631296e-02],\n         [ 4.35336679e-02],\n         [ 5.01673669e-02],\n         [ 6.66476488e-02],\n         [-8.52683932e-02],\n         [ 8.89491588e-02],\n         [-5.32492585e-02],\n         [ 5.59690297e-02],\n         [ 8.48520249e-02],\n         [ 6.21380806e-02],\n         [ 1.77809969e-02],\n         [-4.85179834e-02],\n         [-2.54385844e-02],\n         [ 3.14597040e-02],\n         [-6.35620952e-03],\n         [-7.25790262e-02],\n         [ 1.23655051e-03],\n         [ 3.53514403e-02],\n         [-6.95085302e-02],\n         [ 2.95031443e-02],\n         [ 6.24273717e-02],\n         [-8.72204155e-02],\n         [-4.34413441e-02],\n         [-2.56279483e-02],\n         [ 7.19954818e-02],\n         [-8.49455744e-02],\n         [-6.08063564e-02],\n         [-2.84376815e-02],\n         [ 7.50489384e-02],\n         [ 9.05153304e-02],\n         [ 8.43357593e-02],\n         [-7.76858181e-02],\n         [-1.72115490e-02],\n         [ 5.31002134e-03],\n         [ 7.01328814e-02],\n         [ 1.23187900e-03],\n         [-5.38202636e-02],\n         [ 6.26412928e-02],\n         [-3.02521586e-02],\n         [-1.57721713e-02],\n         [ 3.11933756e-02],\n         [ 8.04249495e-02],\n         [ 2.51883715e-02],\n         [ 8.37349296e-02],\n         [-6.06787801e-02]]],\n\n\n       [[[-6.45292476e-02],\n         [ 5.92107028e-02],\n         [ 7.81022161e-02],\n         [-6.03320785e-02],\n         [-1.24569088e-02],\n         [-5.86593188e-02],\n         [ 2.42691040e-02],\n         [ 1.03452802e-02],\n         [-7.08597898e-02],\n         [ 3.28399912e-02],\n         [ 6.88751638e-02],\n         [-8.69218409e-02],\n         [-1.65227875e-02],\n         [-1.00378394e-02],\n         [ 8.04901123e-02],\n         [ 2.57906318e-02],\n         [ 5.30617088e-02],\n         [ 7.15420097e-02],\n         [-1.75978318e-02],\n         [-1.33280903e-02],\n         [-6.22303784e-03],\n         [-8.48682895e-02],\n         [-6.67356700e-03],\n         [-8.15484449e-02],\n         [-3.58800516e-02],\n         [ 6.72456920e-02],\n         [-7.22610950e-02],\n         [ 5.54762781e-02],\n         [-4.18212526e-02],\n         [ 7.74023682e-03],\n         [ 5.67029417e-02],\n         [-4.40338701e-02],\n         [-6.00254536e-02],\n         [-2.29021460e-02],\n         [-4.20210473e-02],\n         [ 2.32432261e-02],\n         [-2.49869302e-02],\n         [ 3.10644507e-04],\n         [ 5.61808497e-02],\n         [-8.32912847e-02],\n         [-7.22687691e-03],\n         [ 7.24358559e-02],\n         [ 4.31810915e-02],\n         [-8.19243267e-02],\n         [-3.16147059e-02],\n         [-6.11914508e-02],\n         [ 4.95075285e-02],\n         [-3.65194678e-03],\n         [-3.83653566e-02],\n         [-4.84741814e-02],\n         [ 1.26120597e-02],\n         [-4.98397350e-02],\n         [-1.47620812e-02],\n         [-2.79058442e-02],\n         [-1.61395967e-02],\n         [-2.40207091e-02],\n         [-3.43447290e-02],\n         [ 6.28131628e-02],\n         [ 8.38486105e-02],\n         [ 2.44739130e-02],\n         [ 6.85842484e-02],\n         [ 1.79838613e-02],\n         [ 3.87794524e-02],\n         [-5.91459014e-02],\n         [-8.94113630e-02],\n         [ 3.66023183e-02],\n         [ 4.77886200e-03],\n         [-6.11699745e-02],\n         [-6.75247759e-02],\n         [ 7.96788037e-02],\n         [ 2.46819481e-02],\n         [ 4.85255569e-02],\n         [ 5.26346713e-02],\n         [ 3.84855568e-02],\n         [ 5.35493493e-02],\n         [ 1.12749338e-02],\n         [ 7.00348467e-02],\n         [ 3.29278931e-02],\n         [ 5.33177555e-02],\n         [ 2.10506544e-02]],\n\n        [[-1.21623576e-02],\n         [ 5.29654920e-02],\n         [ 1.51195154e-02],\n         [ 8.24648291e-02],\n         [-1.44273043e-04],\n         [ 3.69461030e-02],\n         [ 7.65410364e-02],\n         [ 4.07844335e-02],\n         [ 4.88101840e-02],\n         [-1.52005628e-02],\n         [-6.16517551e-02],\n         [ 4.75083441e-02],\n         [-4.54016067e-02],\n         [ 2.66244113e-02],\n         [ 1.92684531e-02],\n         [-8.48959088e-02],\n         [ 3.86045873e-02],\n         [ 5.45019954e-02],\n         [ 2.64833868e-02],\n         [-3.06036435e-02],\n         [-3.23637649e-02],\n         [ 7.90831894e-02],\n         [-6.42551333e-02],\n         [ 8.07065070e-02],\n         [-6.37669489e-02],\n         [-7.24608451e-02],\n         [-6.64085895e-03],\n         [ 1.83803141e-02],\n         [-6.06310889e-02],\n         [ 1.77292079e-02],\n         [ 1.35261565e-03],\n         [ 8.48597884e-02],\n         [-1.24683753e-02],\n         [-2.40745023e-02],\n         [ 8.92076492e-02],\n         [-1.39553323e-02],\n         [-7.14166239e-02],\n         [-4.36916240e-02],\n         [ 7.47563839e-02],\n         [-3.12002748e-03],\n         [ 2.85837874e-02],\n         [-6.52426854e-02],\n         [ 6.30641282e-02],\n         [-2.29202062e-02],\n         [ 5.83567172e-02],\n         [-7.60480538e-02],\n         [-1.40582472e-02],\n         [ 1.08334869e-02],\n         [-1.87237263e-02],\n         [-4.03244048e-03],\n         [-3.70869488e-02],\n         [-7.45608807e-02],\n         [-6.19382188e-02],\n         [-2.57476717e-02],\n         [ 3.40063944e-02],\n         [-7.05833733e-03],\n         [-8.88556913e-02],\n         [-3.27655822e-02],\n         [ 5.68879545e-02],\n         [ 7.18395263e-02],\n         [-8.37288797e-04],\n         [ 3.64573747e-02],\n         [-6.44081011e-02],\n         [ 3.59052569e-02],\n         [ 2.05766410e-03],\n         [ 7.05627650e-02],\n         [-1.75697580e-02],\n         [ 8.53126645e-02],\n         [-7.65192807e-02],\n         [-3.68560962e-02],\n         [ 1.94528475e-02],\n         [ 2.19369158e-02],\n         [-2.82381251e-02],\n         [ 7.23967105e-02],\n         [-3.26840580e-02],\n         [-6.19024001e-02],\n         [ 4.26062346e-02],\n         [ 8.90039653e-02],\n         [ 6.94471747e-02],\n         [ 2.65241787e-02]],\n\n        [[ 3.58991772e-02],\n         [-2.19213888e-02],\n         [ 7.89450556e-02],\n         [ 7.21188635e-03],\n         [-3.38188633e-02],\n         [-6.61256313e-02],\n         [ 5.96107244e-02],\n         [-7.21037388e-03],\n         [-6.26206174e-02],\n         [-1.53709427e-02],\n         [ 2.22101808e-05],\n         [-2.25255713e-02],\n         [-5.94106279e-02],\n         [ 7.82922357e-02],\n         [ 5.65600991e-02],\n         [-9.05037969e-02],\n         [-7.91293457e-02],\n         [ 8.48160535e-02],\n         [ 3.97062153e-02],\n         [ 1.05723962e-02],\n         [ 8.48913491e-02],\n         [ 4.36604917e-02],\n         [ 5.44806570e-02],\n         [ 7.81931281e-02],\n         [-3.88777219e-02],\n         [ 4.86341417e-02],\n         [ 6.42189085e-02],\n         [-4.16465290e-02],\n         [-4.36720476e-02],\n         [ 6.86544776e-02],\n         [ 3.56316417e-02],\n         [-7.78677687e-02],\n         [-8.03625062e-02],\n         [-1.17933303e-02],\n         [ 4.02844101e-02],\n         [ 7.01662302e-02],\n         [-4.15936857e-02],\n         [-6.22089952e-03],\n         [ 2.39614174e-02],\n         [ 7.53175318e-02],\n         [ 8.15684348e-03],\n         [ 2.72658244e-02],\n         [ 2.41537318e-02],\n         [-7.66857639e-02],\n         [ 7.07298964e-02],\n         [ 2.22469121e-02],\n         [ 4.10579145e-04],\n         [-7.72103295e-02],\n         [-3.41709554e-02],\n         [ 2.04440951e-02],\n         [ 8.94210488e-02],\n         [-3.79000790e-02],\n         [-4.78236005e-02],\n         [-6.66265637e-02],\n         [ 1.22942999e-02],\n         [-3.02282572e-02],\n         [ 2.87827626e-02],\n         [ 5.47830015e-02],\n         [-8.94605666e-02],\n         [ 1.39472485e-02],\n         [-6.56372160e-02],\n         [-2.02482939e-03],\n         [-4.17416766e-02],\n         [ 3.36340144e-02],\n         [-5.62084466e-03],\n         [-2.39717811e-02],\n         [ 3.61047238e-02],\n         [-1.90365985e-02],\n         [ 2.50247419e-02],\n         [-9.73640382e-03],\n         [-4.57206033e-02],\n         [ 1.54397637e-03],\n         [-6.20981306e-02],\n         [ 6.28499985e-02],\n         [ 8.22631270e-02],\n         [-7.43961260e-02],\n         [ 4.32961881e-02],\n         [ 7.43341744e-02],\n         [-6.02664761e-02],\n         [ 3.11856121e-02]]],\n\n\n       [[[-5.20213693e-03],\n         [-2.19637826e-02],\n         [-3.77196223e-02],\n         [ 4.07761186e-02],\n         [-7.14565814e-03],\n         [ 3.54129076e-03],\n         [-4.71006706e-02],\n         [ 7.57009536e-03],\n         [-2.32786313e-02],\n         [-5.37906066e-02],\n         [ 4.62897122e-04],\n         [-8.32235366e-02],\n         [ 1.74269751e-02],\n         [ 6.59563839e-02],\n         [ 7.09928721e-02],\n         [-5.89797869e-02],\n         [ 5.53059280e-02],\n         [ 1.83107704e-02],\n         [-8.65707695e-02],\n         [ 1.46503001e-02],\n         [-3.41665745e-03],\n         [-2.09388509e-02],\n         [ 3.61965895e-02],\n         [-2.57043019e-02],\n         [-4.13442738e-02],\n         [ 3.66648883e-02],\n         [ 7.06093758e-02],\n         [-1.04917139e-02],\n         [-9.60182399e-03],\n         [ 7.88238943e-02],\n         [ 6.63465858e-02],\n         [-1.99260190e-02],\n         [ 8.30671191e-02],\n         [-3.56917232e-02],\n         [ 6.04331791e-02],\n         [ 4.92124557e-02],\n         [-2.97531597e-02],\n         [ 8.06064457e-02],\n         [ 2.04716325e-02],\n         [ 8.36217701e-02],\n         [ 8.10841769e-02],\n         [-6.70549572e-02],\n         [ 6.92291558e-02],\n         [ 4.54470813e-02],\n         [ 6.27386719e-02],\n         [ 5.56920022e-02],\n         [ 4.55170423e-02],\n         [-2.96245515e-03],\n         [ 5.07221669e-02],\n         [ 2.14390829e-02],\n         [ 6.56091422e-02],\n         [ 5.14369905e-02],\n         [ 5.46939522e-02],\n         [-3.30587067e-02],\n         [ 4.83030230e-02],\n         [-1.78910047e-02],\n         [ 7.58766681e-02],\n         [-5.74244745e-02],\n         [ 2.39480734e-02],\n         [-4.82290238e-03],\n         [-4.95301932e-02],\n         [ 5.38721234e-02],\n         [ 5.00237197e-02],\n         [-4.83359247e-02],\n         [-5.05763143e-02],\n         [-6.23033494e-02],\n         [-4.20674235e-02],\n         [-9.05465111e-02],\n         [-3.99482027e-02],\n         [ 3.90249193e-02],\n         [-1.12568289e-02],\n         [ 5.15080988e-02],\n         [ 6.01397753e-02],\n         [ 2.47998312e-02],\n         [-9.68587399e-03],\n         [ 7.49327540e-02],\n         [-7.03932345e-03],\n         [ 7.57514536e-02],\n         [ 2.76690423e-02],\n         [ 8.85081440e-02]],\n\n        [[-2.69516259e-02],\n         [-4.10125814e-02],\n         [ 7.35234916e-02],\n         [ 8.16970617e-02],\n         [ 1.52361393e-02],\n         [ 2.40282789e-02],\n         [-1.18974149e-02],\n         [-1.83764622e-02],\n         [-8.21487308e-02],\n         [ 6.77241683e-02],\n         [ 1.93463862e-02],\n         [ 5.81960082e-02],\n         [-3.33017409e-02],\n         [ 7.94080496e-02],\n         [ 6.07161373e-02],\n         [-1.90438479e-02],\n         [-8.36869329e-02],\n         [ 2.54070014e-02],\n         [ 6.19752258e-02],\n         [ 1.21858492e-02],\n         [-1.63578391e-02],\n         [-2.49555707e-02],\n         [ 2.37797722e-02],\n         [-2.58512795e-03],\n         [-1.89727694e-02],\n         [ 8.93401355e-02],\n         [ 2.34006494e-02],\n         [ 3.11205909e-02],\n         [-6.33499473e-02],\n         [-3.11338529e-02],\n         [-3.71104851e-02],\n         [ 6.31003231e-02],\n         [-5.30763045e-02],\n         [-5.65596297e-02],\n         [ 2.24169865e-02],\n         [ 3.96944880e-02],\n         [-2.81705335e-02],\n         [-4.76664603e-02],\n         [ 3.15203741e-02],\n         [ 9.03030336e-02],\n         [ 3.90864909e-02],\n         [ 6.73514605e-03],\n         [ 2.74865776e-02],\n         [ 5.98396510e-02],\n         [-5.45834042e-02],\n         [ 1.20051503e-02],\n         [-1.88664868e-02],\n         [-7.79642165e-02],\n         [-3.52930203e-02],\n         [-8.58702213e-02],\n         [-8.66241083e-02],\n         [ 8.11291337e-02],\n         [ 3.21400911e-02],\n         [-8.24979469e-02],\n         [-3.66144255e-02],\n         [ 8.18242878e-02],\n         [-1.73285604e-02],\n         [-4.01591584e-02],\n         [-8.57183337e-03],\n         [-1.86419636e-02],\n         [ 3.52422744e-02],\n         [ 3.31092775e-02],\n         [ 7.63025582e-02],\n         [ 2.61156186e-02],\n         [ 3.21216434e-02],\n         [ 7.59961456e-02],\n         [ 6.88882321e-02],\n         [-7.30101988e-02],\n         [ 8.02195519e-02],\n         [ 1.46322399e-02],\n         [ 5.47381938e-02],\n         [-6.55098334e-02],\n         [ 8.36387873e-02],\n         [ 3.78289670e-02],\n         [-4.01978977e-02],\n         [ 6.92487955e-02],\n         [-1.41672865e-02],\n         [ 3.78771871e-03],\n         [ 7.58820474e-02],\n         [ 2.45139301e-02]],\n\n        [[-8.75632465e-02],\n         [ 3.81730050e-02],\n         [-7.02923983e-02],\n         [ 4.54707444e-03],\n         [-1.28340498e-02],\n         [-5.77332415e-02],\n         [-2.59560123e-02],\n         [-7.11853057e-03],\n         [-6.90874457e-02],\n         [-6.97539672e-02],\n         [-4.17058356e-02],\n         [-2.74846479e-02],\n         [-2.27770358e-02],\n         [ 3.00727189e-02],\n         [-6.93260431e-02],\n         [-5.61822206e-03],\n         [-1.46241933e-02],\n         [ 6.04444295e-02],\n         [-9.06875804e-02],\n         [ 1.17953420e-02],\n         [ 3.78113985e-02],\n         [-8.73811468e-02],\n         [ 5.08337766e-02],\n         [ 8.52825493e-03],\n         [-8.03018957e-02],\n         [ 6.82555139e-02],\n         [ 2.15331092e-02],\n         [ 1.08911321e-02],\n         [ 3.16039473e-03],\n         [ 5.94700277e-02],\n         [-1.25440583e-02],\n         [ 3.51771563e-02],\n         [-6.95152134e-02],\n         [ 1.12152100e-02],\n         [ 3.27402949e-02],\n         [ 1.67923421e-02],\n         [-9.31046903e-03],\n         [ 7.73964822e-02],\n         [-5.00286072e-02],\n         [-9.07859951e-03],\n         [-5.86229600e-02],\n         [ 9.00965035e-02],\n         [ 1.16679445e-02],\n         [-6.64077699e-02],\n         [ 5.69244176e-02],\n         [-1.73060223e-02],\n         [ 7.85260648e-03],\n         [ 3.87496948e-02],\n         [-7.69980997e-02],\n         [ 5.48219681e-03],\n         [ 2.23567039e-02],\n         [-1.48245245e-02],\n         [ 5.86138368e-02],\n         [ 5.43331355e-03],\n         [-1.51099265e-03],\n         [ 8.90380740e-02],\n         [-5.33448830e-02],\n         [ 1.90043300e-02],\n         [-6.67307079e-02],\n         [ 5.07788807e-02],\n         [-1.80894956e-02],\n         [ 6.81499839e-02],\n         [-2.52219588e-02],\n         [ 5.51844239e-02],\n         [-7.91102275e-02],\n         [ 2.81816050e-02],\n         [-3.06402892e-03],\n         [ 5.25378436e-03],\n         [ 1.63437352e-02],\n         [ 8.58665705e-02],\n         [-7.46324733e-02],\n         [ 1.30385160e-04],\n         [-6.13871813e-02],\n         [ 7.35837370e-02],\n         [ 2.48128101e-02],\n         [ 5.68893999e-02],\n         [-1.42303333e-02],\n         [ 2.09796876e-02],\n         [-2.04328895e-02],\n         [ 8.32817405e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.05046272,  0.06007591, -0.02920844, ...,  0.02695721,\n          -0.01326844, -0.03726521],\n         [ 0.05706462,  0.02744764,  0.037237  , ...,  0.07600765,\n          -0.00168458,  0.04729273],\n         [-0.0384852 ,  0.00893573,  0.03269324, ..., -0.03219349,\n           0.01390442,  0.04274791],\n         ...,\n         [-0.02346644, -0.03999086, -0.01793195, ...,  0.08061599,\n          -0.03513735, -0.06844829],\n         [-0.05227693, -0.00788052,  0.01526452, ..., -0.04924746,\n           0.02425674, -0.01305424],\n         [-0.04080801,  0.06984993,  0.00050349, ...,  0.03508027,\n           0.00279753, -0.00581829]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/beta:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/gamma:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01144962],\n         [ 0.02522507],\n         [-0.01131751],\n         ...,\n         [ 0.01826764],\n         [ 0.00782056],\n         [-0.01422861]],\n\n        [[ 0.02786309],\n         [-0.01285985],\n         [ 0.00374615],\n         ...,\n         [ 0.00175806],\n         [-0.00141138],\n         [-0.00010296]],\n\n        [[-0.01370689],\n         [ 0.00137622],\n         [-0.02509689],\n         ...,\n         [ 0.01128416],\n         [ 0.01138466],\n         [ 0.01225852]]],\n\n\n       [[[ 0.00208863],\n         [-0.01050105],\n         [-0.0024422 ],\n         ...,\n         [ 0.00156199],\n         [-0.00830486],\n         [-0.00059284]],\n\n        [[-0.00083528],\n         [ 0.02613376],\n         [ 0.00016552],\n         ...,\n         [ 0.0114587 ],\n         [ 0.01363227],\n         [ 0.01592212]],\n\n        [[-0.01017836],\n         [ 0.00562024],\n         [-0.01465356],\n         ...,\n         [-0.009613  ],\n         [-0.00612751],\n         [ 0.01239023]]],\n\n\n       [[[ 0.01934545],\n         [ 0.02392575],\n         [-0.00412514],\n         ...,\n         [ 0.02466849],\n         [ 0.00622535],\n         [-0.01682848]],\n\n        [[-0.00793513],\n         [ 0.00026329],\n         [ 0.00282742],\n         ...,\n         [ 0.01251697],\n         [ 0.00365846],\n         [-0.01177709]],\n\n        [[-0.00191799],\n         [ 0.01195622],\n         [-0.02108802],\n         ...,\n         [-0.00195901],\n         [-0.00041844],\n         [-0.00324453]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_861/kernel:0' shape=(1, 1, 112, 80) dtype=float32, numpy=\narray([[[[-0.1266359 ,  0.11045039, -0.03257483, ...,  0.07228381,\n           0.06834248, -0.07762287],\n         [-0.16911368, -0.01613282,  0.07163119, ..., -0.12762032,\n          -0.05904778, -0.11796178],\n         [ 0.03248651,  0.01917007, -0.12805067, ...,  0.04459731,\n           0.10522509, -0.10257526],\n         ...,\n         [-0.08092996,  0.04544629, -0.00177636, ..., -0.11388078,\n          -0.05956727,  0.04600402],\n         [ 0.02566099, -0.04777094, -0.13341656, ..., -0.12184227,\n          -0.04191307,  0.07000085],\n         [ 0.03580611, -0.02664511,  0.04335059, ..., -0.02161285,\n          -0.08119968,  0.07324789]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.00416902, -0.01898808,  0.02853693, ...,  0.06837913,\n           0.02416613, -0.06433212],\n         [-0.02656428,  0.02689713, -0.03186426, ...,  0.05149912,\n          -0.04246094, -0.03491492],\n         [-0.07809218, -0.04906044,  0.00901009, ...,  0.00561639,\n          -0.06340251, -0.04208315],\n         ...,\n         [ 0.01357094,  0.04832734,  0.01906479, ...,  0.00054336,\n           0.06311432,  0.03820171],\n         [ 0.02446797,  0.07116729, -0.03334276, ...,  0.01078002,\n           0.03525599, -0.02559269],\n         [ 0.00216287, -0.00390734, -0.02744069, ..., -0.02525058,\n          -0.00974055,  0.05592157]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00596912,  0.0758737 , -0.08659466, ..., -0.15314297,\n           0.02904191,  0.13496634],\n         [ 0.09821804, -0.12494116, -0.44603696, ...,  0.3416884 ,\n           0.13141416, -0.10054888],\n         [ 0.23386914,  0.17276263,  0.387499  , ...,  0.4686871 ,\n          -0.05558596,  0.13330305],\n         ...,\n         [-0.203752  ,  0.27078813,  0.08690373, ..., -0.06087269,\n           0.0969606 , -0.06011502],\n         [ 0.17658928,  0.06154617,  0.34182596, ...,  0.12908584,\n           0.15245552,  0.1921593 ],\n         [ 0.3073045 ,  0.28113583, -0.12928748, ..., -0.10187806,\n          -0.13608174, -0.10338311]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/beta:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_853/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.1405574 , -0.15207475, -0.19598041, ..., -0.24251375,\n          -0.02895492,  0.14112568],\n         [ 0.1620136 , -0.01453277,  0.00345453, ...,  0.05906699,\n          -0.03833256,  0.05401867],\n         [ 0.00525054, -0.06357087,  0.01641294, ...,  0.01251843,\n           0.1384145 ,  0.0905272 ],\n         ...,\n         [ 0.07684722, -0.13383977, -0.03951751, ..., -0.05140214,\n          -0.01182997, -0.08430993],\n         [-0.1596365 ,  0.03952034, -0.19004981, ..., -0.2123555 ,\n           0.12149116, -0.12049357],\n         [ 0.03327164,  0.04261284, -0.2406582 , ...,  0.0953455 ,\n           0.07206927, -0.00386533]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.05811423,  0.1362503 , -0.12640454, ...,  0.0612675 ,\n           0.05936417,  0.06814434],\n         [ 0.24953778,  0.06517745,  0.13785414, ..., -0.19750279,\n           0.24649715,  0.03465299],\n         [-0.0102851 ,  0.12188665,  0.23886727, ...,  0.23105785,\n           0.10654452, -0.00086309],\n         ...,\n         [ 0.14659844, -0.08938524,  0.09506432, ...,  0.12803504,\n           0.01484074, -0.17030828],\n         [-0.06372221,  0.11837038, -0.01875271, ..., -0.07410306,\n           0.09678932, -0.21423241],\n         [ 0.15846486,  0.07074511, -0.07767498, ..., -0.08270313,\n          -0.11419809, -0.04867493]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32, numpy=\narray([[[[ 0.00956689],\n         [ 0.0356406 ],\n         [ 0.01431889],\n         ...,\n         [ 0.05390378],\n         [ 0.01126917],\n         [-0.01312892]],\n\n        [[-0.02744819],\n         [-0.00426563],\n         [ 0.02238767],\n         ...,\n         [-0.00807348],\n         [ 0.00312854],\n         [-0.00839325]],\n\n        [[ 0.00305651],\n         [ 0.00924495],\n         [-0.05652652],\n         ...,\n         [-0.01232098],\n         [-0.03633439],\n         [ 0.00542196]]],\n\n\n       [[[-0.01142122],\n         [ 0.00742836],\n         [ 0.02056395],\n         ...,\n         [ 0.01201878],\n         [-0.03293453],\n         [ 0.04826012]],\n\n        [[-0.04431771],\n         [ 0.02888767],\n         [-0.00551713],\n         ...,\n         [-0.01253872],\n         [-0.04157709],\n         [-0.01408566]],\n\n        [[-0.03090854],\n         [-0.01968157],\n         [-0.03782297],\n         ...,\n         [ 0.05346918],\n         [ 0.02460855],\n         [ 0.00706554]]],\n\n\n       [[[ 0.02456337],\n         [-0.0138875 ],\n         [-0.02880254],\n         ...,\n         [ 0.04107539],\n         [-0.03396839],\n         [ 0.01588154]],\n\n        [[-0.0202811 ],\n         [ 0.01597953],\n         [-0.0113443 ],\n         ...,\n         [-0.03704854],\n         [-0.02136291],\n         [-0.05121685]],\n\n        [[ 0.02490765],\n         [-0.01883382],\n         [-0.04230718],\n         ...,\n         [-0.01012593],\n         [ 0.0168143 ],\n         [ 0.04470888]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_865/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/moving_mean:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_366/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.05777818],\n         [-0.07062713],\n         [-0.04863792],\n         ...,\n         [-0.02925017],\n         [ 0.0709572 ],\n         [ 0.01591302]],\n\n        [[ 0.06905168],\n         [ 0.00888311],\n         [-0.04712436],\n         ...,\n         [-0.03324165],\n         [-0.04370267],\n         [-0.06064375]],\n\n        [[-0.02441993],\n         [-0.00430445],\n         [-0.03260644],\n         ...,\n         [ 0.03926274],\n         [-0.00930229],\n         [ 0.01656462]]],\n\n\n       [[[ 0.07216664],\n         [ 0.01522211],\n         [ 0.05796278],\n         ...,\n         [-0.05099004],\n         [ 0.00157475],\n         [-0.06897628]],\n\n        [[-0.02899819],\n         [ 0.03885144],\n         [-0.02479792],\n         ...,\n         [ 0.04638881],\n         [-0.00721783],\n         [-0.07116449]],\n\n        [[ 0.04840562],\n         [-0.04435076],\n         [-0.05791862],\n         ...,\n         [ 0.02790711],\n         [-0.03284815],\n         [ 0.07212695]]],\n\n\n       [[[ 0.00313966],\n         [-0.07125422],\n         [ 0.06274168],\n         ...,\n         [-0.00969908],\n         [-0.07146905],\n         [ 0.04169833]],\n\n        [[ 0.06394929],\n         [-0.04918831],\n         [-0.02809804],\n         ...,\n         [-0.0700573 ],\n         [-0.06635001],\n         [ 0.00519253]],\n\n        [[-0.00866704],\n         [ 0.04104125],\n         [ 0.0300544 ],\n         ...,\n         [-0.03125319],\n         [ 0.00083605],\n         [-0.07406119]]]], dtype=float32)>, <tf.Variable 'conv2d_839/kernel:0' shape=(1, 1, 24, 24) dtype=float32, numpy=\narray([[[[ 0.03062384,  0.05975721, -0.03346661, -0.33880126,\n          -0.23606431,  0.29597786,  0.15808465, -0.18296699,\n          -0.06879429, -0.33556494,  0.24613525,  0.2809689 ,\n           0.31182453,  0.22688372, -0.13906536,  0.07097469,\n          -0.35635218,  0.03152678, -0.19036905,  0.24615799,\n           0.10249153,  0.19188194,  0.1624396 ,  0.02292239],\n         [ 0.14986424,  0.02821611, -0.26775223, -0.15380436,\n           0.02218385, -0.1316079 ,  0.19371812,  0.3493268 ,\n           0.04507992, -0.21514918,  0.10306091,  0.2060223 ,\n           0.07253455, -0.3264913 ,  0.40296698,  0.22712876,\n           0.39030924,  0.18067755, -0.00258197,  0.00647514,\n           0.12706292,  0.30718383,  0.01694357,  0.14938325],\n         [ 0.16731925,  0.33325297, -0.16143805, -0.12234508,\n           0.36641726,  0.14282916,  0.010698  , -0.18735264,\n           0.2590174 , -0.15867296, -0.10194314, -0.25818986,\n          -0.03503438,  0.00928926,  0.4198281 ,  0.34820598,\n          -0.3424998 , -0.40838495,  0.02942531, -0.3300267 ,\n           0.10154498, -0.41303292, -0.31633624, -0.20879796],\n         [-0.2610408 ,  0.05947717, -0.24533962,  0.19511949,\n          -0.13345174,  0.15967664,  0.22913492,  0.30631018,\n          -0.06068328,  0.02884603, -0.00747847, -0.33075136,\n           0.30835852,  0.0040927 , -0.23449352, -0.15101436,\n          -0.02796182,  0.40440384, -0.3934244 ,  0.04750809,\n           0.01081783, -0.03955649,  0.0570581 , -0.29170084],\n         [ 0.19786401,  0.19868289, -0.19706674,  0.23130663,\n          -0.06471808,  0.11834471,  0.21902914, -0.05880892,\n           0.29722884, -0.34770668,  0.07137018,  0.21155256,\n           0.07821784,  0.17075491,  0.36964014, -0.29860467,\n          -0.34952423, -0.3313592 , -0.1477382 , -0.2984979 ,\n           0.0898985 ,  0.08883379, -0.12428681, -0.29710624],\n         [ 0.00871686, -0.3177807 ,  0.14808397,  0.12337586,\n           0.37275037, -0.07269479,  0.23158231,  0.24588609,\n          -0.38877326, -0.18786578, -0.08267021, -0.03253573,\n          -0.17677768,  0.12795322, -0.41553026,  0.20002545,\n          -0.33620337, -0.1811248 ,  0.1503296 , -0.00269175,\n           0.09756897, -0.1727594 , -0.16738582,  0.1658994 ],\n         [-0.2930601 , -0.06619976, -0.16801223,  0.05647111,\n           0.10939216,  0.11112682,  0.25311172, -0.2813624 ,\n          -0.0155524 , -0.08257523, -0.12003534, -0.07909941,\n           0.0522099 , -0.15316652, -0.01161376,  0.00607055,\n          -0.05688274,  0.03261381, -0.30617902,  0.06390715,\n           0.40037552, -0.08047796,  0.29172945,  0.04309621],\n         [ 0.02464938, -0.25315508, -0.15134117, -0.23585457,\n           0.40225163, -0.14073578, -0.3427851 , -0.08951468,\n          -0.27138686, -0.01378556, -0.26382264, -0.04168974,\n           0.22221409,  0.41841316, -0.40811083,  0.15458937,\n           0.11441573, -0.18662015,  0.21932888, -0.35188037,\n           0.12569113, -0.08755241, -0.06036614, -0.03679732],\n         [-0.11013141,  0.17197676,  0.3541443 ,  0.3513652 ,\n           0.09818143,  0.28762323, -0.03448963, -0.26398298,\n          -0.00319474,  0.22177248, -0.40595487, -0.3044085 ,\n           0.16590184, -0.20552427, -0.27665448, -0.08743719,\n          -0.16769592,  0.05248893, -0.23126014,  0.00926075,\n          -0.1463171 ,  0.30725044, -0.3297196 ,  0.21425904],\n         [-0.07561939, -0.00888482, -0.24991493,  0.18235037,\n           0.09686627,  0.21171066,  0.06929341, -0.29479074,\n           0.01219886, -0.24436158, -0.13154571,  0.03806016,\n          -0.20113187, -0.12866595, -0.10043385,  0.1816125 ,\n          -0.00747695, -0.05718577, -0.31712353,  0.21404618,\n           0.0211068 , -0.19345911,  0.20698118,  0.360039  ],\n         [-0.06167805,  0.02609295, -0.00578767,  0.10609084,\n          -0.23869629, -0.44562635, -0.00382046, -0.42003703,\n           0.16176254, -0.15444446,  0.16199411, -0.16909546,\n          -0.16811593, -0.4162363 , -0.15344496, -0.22493717,\n          -0.32977328,  0.07641749, -0.1423356 ,  0.02339028,\n           0.01226292, -0.22951697,  0.00740699, -0.24002378],\n         [ 0.04044901, -0.36992973, -0.36132413, -0.24512404,\n          -0.43056428,  0.00805652,  0.18561654,  0.17108992,\n          -0.24210158,  0.3415372 , -0.24824871, -0.12206827,\n           0.27597117, -0.33747265,  0.31758174,  0.15134208,\n           0.20065941,  0.30379948,  0.44644666,  0.07389404,\n           0.45044208,  0.03209042, -0.07436906,  0.16061601],\n         [-0.0141491 , -0.20541215,  0.1048103 , -0.04766109,\n          -0.07661922, -0.07068059,  0.01396365, -0.04305394,\n           0.05832002,  0.03372009,  0.42156285,  0.3791529 ,\n           0.31633922, -0.1312994 ,  0.13000363, -0.06698339,\n          -0.3705059 ,  0.14412989, -0.07094464, -0.03259292,\n           0.03049771,  0.03817679, -0.31046775,  0.23206815],\n         [-0.19272232,  0.21480466,  0.21656677, -0.15195301,\n          -0.20480554,  0.4145326 ,  0.23338853,  0.01607073,\n           0.10373566, -0.09180898, -0.26660922,  0.20348437,\n           0.04967656, -0.2505372 , -0.13266155, -0.33720797,\n          -0.02482914,  0.43264255,  0.10365995, -0.13533884,\n          -0.19486524,  0.28157946,  0.09396666,  0.06574298],\n         [-0.22566436, -0.21851535, -0.03780637, -0.19109756,\n          -0.25911537, -0.11516505, -0.2506295 , -0.21663786,\n           0.13686253,  0.21471712, -0.23774998,  0.08448474,\n           0.17156693, -0.00667707, -0.01389841, -0.09369221,\n          -0.25584176, -0.32140395,  0.31716028,  0.11338343,\n           0.29163525, -0.2288073 , -0.09103471,  0.11345904],\n         [-0.06248783, -0.37414935, -0.15546699, -0.12268338,\n          -0.3737889 ,  0.05615642,  0.25393626, -0.38467628,\n           0.21629135,  0.31002408,  0.12528914,  0.20632207,\n          -0.12755255,  0.15369684,  0.05207777,  0.21633607,\n           0.09421716,  0.03524834,  0.45035768,  0.21995534,\n           0.01986365, -0.37133947, -0.05804251, -0.0461649 ],\n         [ 0.16278242,  0.18871406,  0.06990009,  0.14754505,\n          -0.28556508,  0.1414188 ,  0.14136213,  0.27052695,\n          -0.21504745, -0.11579344, -0.02280856, -0.00077459,\n          -0.05663946, -0.1813245 ,  0.4530155 ,  0.38428876,\n           0.17199585, -0.28138945, -0.04958959, -0.09962163,\n          -0.11489036,  0.04478546, -0.30513045,  0.05609461],\n         [ 0.23867261, -0.16115703,  0.36101183,  0.22391926,\n           0.04992346, -0.24192864, -0.13908869, -0.11337838,\n          -0.00324607,  0.01472588, -0.08148538, -0.11955827,\n           0.13516286, -0.27527627,  0.09133917,  0.4631258 ,\n           0.01564591, -0.2031011 ,  0.05332069,  0.08242253,\n           0.30734298, -0.42329094, -0.2918506 , -0.06243388],\n         [-0.12841386,  0.01828032, -0.16718334,  0.17730135,\n           0.13650404,  0.23634061,  0.38420165, -0.22820169,\n           0.1579961 , -0.08466489,  0.24776654,  0.07704747,\n          -0.00329316,  0.13251354, -0.14410871, -0.13284004,\n          -0.14355345, -0.19992374, -0.38058588,  0.01443547,\n          -0.42245463, -0.01773489, -0.35288754, -0.1662134 ],\n         [-0.33470702,  0.15700033,  0.09859345,  0.14431491,\n           0.23564643, -0.2425683 , -0.03697338, -0.20575385,\n          -0.14673854, -0.01472429,  0.1612948 , -0.14106649,\n           0.14757444,  0.22936721, -0.3111225 , -0.2635263 ,\n          -0.07195621,  0.34035832,  0.26897293, -0.02045827,\n           0.05458123, -0.03609987, -0.08548713,  0.16135593],\n         [-0.3062816 ,  0.06850225,  0.17287725,  0.2699886 ,\n           0.28188658,  0.06280138, -0.17741145,  0.1332082 ,\n          -0.02848407, -0.18534917, -0.07542988, -0.062567  ,\n          -0.18157949, -0.14015698,  0.03512174, -0.14426498,\n           0.46195164, -0.21866518, -0.07559689,  0.06073087,\n           0.32994124,  0.09589127,  0.31124058, -0.2716374 ],\n         [-0.27318773, -0.03515729, -0.24954435,  0.2580292 ,\n          -0.4141425 , -0.00817489, -0.30040064,  0.1833177 ,\n          -0.26066595,  0.373142  , -0.12220559,  0.06843333,\n          -0.29299372, -0.23750876,  0.33233926,  0.2588878 ,\n          -0.02341007, -0.01068597,  0.4277101 , -0.10878647,\n          -0.27571967, -0.3156744 ,  0.20871648,  0.30008525],\n         [-0.07741109,  0.08117925, -0.1264433 ,  0.1824279 ,\n          -0.13145943,  0.00227213,  0.01869367,  0.1355617 ,\n          -0.28441185,  0.12468906, -0.37095386, -0.2530106 ,\n           0.13156973, -0.311147  ,  0.40203658,  0.43354946,\n          -0.2974091 , -0.2693129 ,  0.21931358, -0.08465521,\n           0.12334061,  0.3069476 , -0.02620836,  0.02971777],\n         [ 0.15118662, -0.41484675, -0.13121326,  0.08708294,\n          -0.03937778,  0.17534551,  0.10814606, -0.01833585,\n          -0.30633873, -0.40307263, -0.04718204, -0.18892853,\n          -0.13139589, -0.2003905 , -0.06723245, -0.27075645,\n          -0.01098196, -0.12408727, -0.05549768, -0.03080422,\n          -0.08906356, -0.07159022, -0.1983563 , -0.11888842]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[ 1.90676264e-02, -1.97774060e-02, -4.78887483e-02, ...,\n          -3.27033773e-02, -2.32446212e-02, -2.29693633e-02],\n         [-4.53805663e-02,  3.85349169e-02, -6.62047043e-02, ...,\n          -5.71883135e-02, -5.16317323e-06,  7.92483017e-02],\n         [ 9.67299417e-02, -4.65690903e-02,  3.33701670e-02, ...,\n           2.87869442e-02,  6.03199191e-02, -2.46488675e-02],\n         ...,\n         [-3.50121520e-02, -8.59735813e-03,  1.15065835e-02, ...,\n          -1.26401912e-02,  2.34459955e-02, -5.42363934e-02],\n         [-5.46535589e-02,  1.42816622e-02, -6.21919520e-02, ...,\n          -3.39748152e-02,  8.25458579e-03, -1.40277175e-02],\n         [ 2.09191460e-02,  4.49677333e-02,  1.06156699e-03, ...,\n          -3.97581756e-02,  4.15015183e-02,  6.51729703e-02]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_862/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_885/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 0.01836401],\n         [ 0.00305542],\n         [-0.00671789],\n         ...,\n         [ 0.00582301],\n         [-0.00762974],\n         [ 0.00800924]],\n\n        [[ 0.01934782],\n         [ 0.00200556],\n         [-0.01744415],\n         ...,\n         [-0.02045186],\n         [-0.00486344],\n         [-0.01852966]],\n\n        [[-0.005448  ],\n         [-0.0284319 ],\n         [ 0.02860772],\n         ...,\n         [ 0.00821805],\n         [ 0.00846048],\n         [ 0.0014784 ]]],\n\n\n       [[[ 0.01531391],\n         [-0.00666285],\n         [-0.00462299],\n         ...,\n         [-0.01995928],\n         [ 0.0055928 ],\n         [ 0.00948393]],\n\n        [[-0.00203383],\n         [ 0.01371246],\n         [-0.01033247],\n         ...,\n         [ 0.00548469],\n         [ 0.0002679 ],\n         [ 0.01887108]],\n\n        [[ 0.00942703],\n         [-0.00409796],\n         [ 0.00100016],\n         ...,\n         [ 0.02226859],\n         [ 0.01233917],\n         [ 0.01580453]]],\n\n\n       [[[ 0.00052949],\n         [-0.01446479],\n         [ 0.00918633],\n         ...,\n         [ 0.00358088],\n         [-0.0256935 ],\n         [ 0.01774043]],\n\n        [[-0.00664139],\n         [-0.00969928],\n         [-0.01671724],\n         ...,\n         [-0.01090497],\n         [ 0.0048924 ],\n         [ 0.01408415]],\n\n        [[ 0.02435453],\n         [-0.01103743],\n         [ 0.00427603],\n         ...,\n         [ 0.00780486],\n         [ 0.00722642],\n         [ 0.02190817]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_849/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/conv2d_1/kernel:0' shape=(1, 1, 96, 24) dtype=float32, numpy=\narray([[[[-0.02960172, -0.21402088,  0.08909935, ..., -0.09983931,\n           0.01469804, -0.05941022],\n         [-0.03898183, -0.09291705,  0.03680477, ...,  0.11497281,\n           0.10587574, -0.01784064],\n         [ 0.07008724, -0.03179467,  0.11987862, ...,  0.14260657,\n          -0.04565348,  0.12003692],\n         ...,\n         [-0.0753134 ,  0.06171771,  0.03842597, ..., -0.17637046,\n           0.02448523, -0.03621456],\n         [-0.06465167,  0.17042369, -0.21982998, ...,  0.08420349,\n          -0.17042854, -0.15364723],\n         [ 0.05972956, -0.04064714, -0.14537154, ...,  0.1468447 ,\n           0.05027313, -0.15302312]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_846/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[ 0.05987923, -0.09694598, -0.17655471, ...,  0.09792732,\n          -0.11073738,  0.2826267 ],\n         [ 0.2159577 , -0.2891148 ,  0.29688302, ...,  0.16061127,\n           0.17047794, -0.3602198 ],\n         [-0.17439356, -0.34931198, -0.1628836 , ...,  0.02387322,\n          -0.18901879, -0.38223517],\n         ...,\n         [ 0.17219117, -0.4223906 , -0.19110267, ...,  0.09961442,\n           0.1690301 , -0.10864128],\n         [-0.43203303, -0.34095082,  0.28186017, ...,  0.07875165,\n           0.07673132,  0.13284554],\n         [ 0.15227865, -0.2508964 ,  0.0431558 , ...,  0.1380628 ,\n           0.14246956,  0.42815664]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.00961908,  0.06080306,  0.15744434, ..., -0.09736945,\n           0.13440733,  0.08415141],\n         [ 0.00098017, -0.14078653, -0.31074366, ...,  0.3062803 ,\n           0.12811404, -0.32735097],\n         [-0.20890622,  0.07389676,  0.13169768, ...,  0.00800692,\n          -0.39744198, -0.00296691],\n         ...,\n         [-0.06626923,  0.14961419, -0.23377885, ...,  0.22999792,\n          -0.20611005, -0.07051556],\n         [ 0.05424161,  0.1374875 , -0.27732953, ...,  0.17512889,\n          -0.01502043, -0.13449192],\n         [-0.45841926,  0.08037534, -0.00368637, ...,  0.0792795 ,\n           0.01591906,  0.05878564]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_371/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-5.88018149e-02],\n         [-4.65798266e-02],\n         [ 7.94907957e-02],\n         [-2.78239101e-02],\n         [-1.82861164e-02],\n         [ 5.25646508e-02],\n         [-1.33464113e-02],\n         [ 3.95973027e-02],\n         [ 4.69783694e-02],\n         [-1.65359154e-02],\n         [ 2.74144188e-02],\n         [-4.06037122e-02],\n         [-8.52383673e-04],\n         [ 6.95890188e-02],\n         [-4.90803123e-02],\n         [-6.01350963e-02],\n         [-7.97799677e-02],\n         [-8.33069682e-02],\n         [-2.78024971e-02],\n         [ 2.42125615e-02],\n         [-6.09733164e-02],\n         [ 7.54667968e-02],\n         [-8.93830955e-02],\n         [ 2.35835910e-02],\n         [ 6.04362637e-02],\n         [-8.46440345e-03],\n         [-3.54009867e-03],\n         [ 2.09683999e-02],\n         [ 7.38366991e-02],\n         [-8.69697928e-02],\n         [ 3.68010551e-02],\n         [ 6.76703006e-02],\n         [ 8.12256783e-02],\n         [-1.25159845e-02],\n         [-4.06650789e-02],\n         [-1.93166882e-02],\n         [-7.24017546e-02],\n         [ 1.32287294e-02],\n         [ 2.51613110e-02],\n         [-7.36855865e-02],\n         [-7.62073398e-02],\n         [-8.71939436e-02],\n         [ 3.51508409e-02],\n         [ 7.55916834e-02],\n         [ 6.59539104e-02],\n         [ 4.52609360e-03],\n         [-3.51435356e-02],\n         [ 5.69196343e-02],\n         [-8.07921141e-02],\n         [-6.32754564e-02],\n         [ 8.87970924e-02],\n         [ 1.94320083e-03],\n         [ 5.00329286e-02],\n         [-8.39677528e-02],\n         [-2.65094936e-02],\n         [ 5.72784990e-02],\n         [-2.51693577e-02],\n         [ 5.62932342e-03],\n         [-7.45939463e-03],\n         [ 5.48878163e-02],\n         [-9.28423554e-03],\n         [-5.88592850e-02],\n         [-3.85301113e-02],\n         [ 8.99260789e-02],\n         [ 6.65609539e-02],\n         [-2.85437964e-02],\n         [ 3.38473171e-03],\n         [-4.75387797e-02],\n         [ 9.05925483e-02],\n         [-6.15754873e-02],\n         [ 2.10766122e-02],\n         [ 2.19065025e-02],\n         [-5.02840094e-02],\n         [-3.89715508e-02],\n         [-7.49464110e-02],\n         [-8.60774368e-02],\n         [ 8.46531242e-03],\n         [-6.48821145e-02],\n         [ 2.71326452e-02],\n         [ 1.93779394e-02]],\n\n        [[ 3.14907655e-02],\n         [ 9.01153088e-02],\n         [ 2.48504058e-02],\n         [ 1.42137930e-02],\n         [-4.49635088e-03],\n         [ 1.56478584e-03],\n         [-2.81397924e-02],\n         [ 6.15805984e-02],\n         [ 8.95677060e-02],\n         [-2.59169936e-03],\n         [-1.66902915e-02],\n         [ 4.78016734e-02],\n         [-1.20486245e-02],\n         [ 6.82011843e-02],\n         [ 7.54691511e-02],\n         [ 6.50317073e-02],\n         [-7.30016530e-02],\n         [-5.59671894e-02],\n         [ 2.93096602e-02],\n         [ 3.31909060e-02],\n         [ 4.64432687e-03],\n         [ 4.21711206e-02],\n         [-8.41373950e-02],\n         [ 1.15782022e-03],\n         [ 3.22033837e-02],\n         [ 6.71485066e-02],\n         [ 8.31657201e-02],\n         [ 5.67877740e-02],\n         [-8.68596584e-02],\n         [-4.16687205e-02],\n         [-5.33404052e-02],\n         [ 4.92836386e-02],\n         [ 2.86651999e-02],\n         [ 4.40077484e-02],\n         [-8.30438808e-02],\n         [ 3.51902544e-02],\n         [ 1.41116753e-02],\n         [-2.22934037e-03],\n         [ 7.79208988e-02],\n         [ 7.05175847e-02],\n         [ 3.30800787e-02],\n         [ 2.62730569e-03],\n         [ 7.32305646e-02],\n         [-1.58156231e-02],\n         [-4.09118719e-02],\n         [-1.65699199e-02],\n         [-8.05589035e-02],\n         [-5.51819205e-02],\n         [-1.06657296e-02],\n         [-8.41586813e-02],\n         [-8.69862959e-02],\n         [ 8.47201645e-02],\n         [-6.91655502e-02],\n         [ 4.24424410e-02],\n         [ 8.51653367e-02],\n         [-2.91624069e-02],\n         [-7.95209110e-02],\n         [-6.43131882e-02],\n         [ 4.80777323e-02],\n         [-7.98359513e-03],\n         [-7.83308819e-02],\n         [ 6.10658228e-02],\n         [-1.70655251e-02],\n         [ 5.47883511e-02],\n         [-5.08620441e-02],\n         [ 8.43349844e-02],\n         [ 6.33711368e-03],\n         [ 4.21185791e-03],\n         [ 5.87044209e-02],\n         [ 4.49031591e-04],\n         [ 4.08013165e-02],\n         [-7.28978738e-02],\n         [-5.17366678e-02],\n         [ 8.17689747e-02],\n         [-1.33605599e-02],\n         [ 7.83394426e-02],\n         [-7.96886906e-02],\n         [-1.76154822e-03],\n         [ 7.03240782e-02],\n         [ 6.80241883e-02]],\n\n        [[ 5.10010868e-02],\n         [ 1.09636560e-02],\n         [-5.35184629e-02],\n         [ 8.81243050e-02],\n         [-3.80314812e-02],\n         [-7.64153749e-02],\n         [-8.48962963e-02],\n         [-1.39839500e-02],\n         [-8.23974758e-02],\n         [ 2.22831443e-02],\n         [ 3.04850042e-02],\n         [-7.80157745e-03],\n         [ 5.77930510e-02],\n         [ 3.06717530e-02],\n         [ 5.94808161e-02],\n         [-1.31761208e-02],\n         [-6.61691725e-02],\n         [ 7.74216354e-02],\n         [ 2.05044225e-02],\n         [ 5.96930534e-02],\n         [-5.06356359e-04],\n         [-8.84881839e-02],\n         [-5.59980124e-02],\n         [ 5.59908599e-02],\n         [-1.65462345e-02],\n         [ 7.20052719e-02],\n         [ 6.27413094e-02],\n         [-2.94196941e-02],\n         [ 8.60643983e-02],\n         [ 4.75592017e-02],\n         [ 7.57134706e-02],\n         [ 8.65180492e-02],\n         [ 6.79465532e-02],\n         [ 1.43042654e-02],\n         [-3.58423740e-02],\n         [-6.31604493e-02],\n         [ 6.70182258e-02],\n         [-5.62702008e-02],\n         [ 4.78579253e-02],\n         [ 2.71758437e-02],\n         [ 4.99012917e-02],\n         [ 4.63224947e-04],\n         [ 8.45820457e-02],\n         [-6.73233643e-02],\n         [ 5.44849187e-02],\n         [ 5.80747575e-02],\n         [ 3.83271277e-03],\n         [ 2.28725374e-02],\n         [ 2.69350186e-02],\n         [ 2.12122947e-02],\n         [-4.37125564e-05],\n         [-4.77564186e-02],\n         [ 1.70018524e-03],\n         [ 5.67411929e-02],\n         [-5.80439083e-02],\n         [ 6.37245923e-03],\n         [-5.31626306e-02],\n         [-4.24646102e-02],\n         [ 3.21025178e-02],\n         [-1.88745484e-02],\n         [-3.23973112e-02],\n         [-3.58184092e-02],\n         [ 5.23055494e-02],\n         [-8.79088715e-02],\n         [ 3.50897759e-03],\n         [ 4.52711433e-03],\n         [ 7.87090659e-02],\n         [-4.34339494e-02],\n         [-1.58749148e-02],\n         [-2.63066739e-02],\n         [-1.42330602e-02],\n         [-4.45355289e-02],\n         [-9.21272486e-03],\n         [ 3.54353637e-02],\n         [-3.45090292e-02],\n         [ 1.99693888e-02],\n         [-3.19713131e-02],\n         [ 4.61476892e-02],\n         [ 2.91141495e-02],\n         [ 1.81583688e-02]]],\n\n\n       [[[-2.74761915e-02],\n         [ 1.82947442e-02],\n         [-9.07122344e-03],\n         [-3.62894386e-02],\n         [-2.13717297e-02],\n         [ 4.82404083e-02],\n         [ 2.68925577e-02],\n         [-2.93952972e-03],\n         [ 8.33456814e-02],\n         [ 3.37923914e-02],\n         [ 1.16290152e-03],\n         [ 6.28584325e-02],\n         [-1.44057348e-02],\n         [-6.56031445e-02],\n         [-7.48293251e-02],\n         [ 5.90977967e-02],\n         [ 8.04813653e-02],\n         [ 1.96666345e-02],\n         [-7.13724568e-02],\n         [-3.45377736e-02],\n         [-6.23990409e-02],\n         [ 4.54864353e-02],\n         [-4.28588986e-02],\n         [ 7.47649372e-02],\n         [ 4.37712818e-02],\n         [ 4.36615348e-02],\n         [ 8.86613876e-02],\n         [ 5.19126207e-02],\n         [-1.24963671e-02],\n         [-3.03473510e-02],\n         [ 6.35340214e-02],\n         [ 2.35470384e-03],\n         [ 3.47787142e-03],\n         [ 3.11021432e-02],\n         [-8.37772191e-02],\n         [-4.96580899e-02],\n         [ 3.31444293e-02],\n         [ 6.45455122e-02],\n         [ 5.39162308e-02],\n         [ 6.22976571e-03],\n         [ 3.45977545e-02],\n         [ 1.29459798e-02],\n         [-2.20212266e-02],\n         [ 6.82945848e-02],\n         [-8.41173530e-03],\n         [ 7.39825666e-02],\n         [ 7.45048076e-02],\n         [-2.51943618e-03],\n         [-1.02279633e-02],\n         [ 4.61763144e-03],\n         [-2.38726065e-02],\n         [ 4.60766256e-02],\n         [-4.63176295e-02],\n         [ 2.13407129e-02],\n         [-6.13405667e-02],\n         [ 6.35558516e-02],\n         [-3.35059687e-02],\n         [-3.49435210e-03],\n         [ 3.14350277e-02],\n         [ 4.90086973e-02],\n         [ 5.06621003e-02],\n         [-6.86807409e-02],\n         [-2.23655552e-02],\n         [ 4.87334430e-02],\n         [-2.74931937e-02],\n         [ 1.68691650e-02],\n         [ 5.75257391e-02],\n         [ 1.54491067e-02],\n         [-8.62209275e-02],\n         [ 8.75294656e-02],\n         [ 2.94844061e-02],\n         [-5.12281507e-02],\n         [ 7.84778297e-02],\n         [-8.47446322e-02],\n         [ 6.36524409e-02],\n         [-3.26943547e-02],\n         [-5.72600439e-02],\n         [-3.16165388e-04],\n         [-4.20735776e-03],\n         [ 1.85069069e-02]],\n\n        [[ 3.18000466e-02],\n         [-6.81969896e-02],\n         [ 5.05842268e-03],\n         [ 3.17237377e-02],\n         [ 5.32957166e-02],\n         [ 7.30726868e-02],\n         [-3.40822078e-02],\n         [ 7.41805881e-03],\n         [ 1.10020265e-02],\n         [ 8.02206844e-02],\n         [ 2.72393897e-02],\n         [-1.97856128e-03],\n         [-5.57192490e-02],\n         [ 7.42921978e-03],\n         [ 6.18016273e-02],\n         [ 6.79056942e-02],\n         [-6.64412528e-02],\n         [ 6.29316717e-02],\n         [-1.32156163e-02],\n         [ 2.17762068e-02],\n         [ 4.22955006e-02],\n         [-8.83882120e-02],\n         [-8.71733949e-02],\n         [-5.19097261e-02],\n         [-8.19846243e-02],\n         [-7.76862055e-02],\n         [ 1.04196668e-02],\n         [ 5.25583178e-02],\n         [ 8.29672515e-02],\n         [ 8.08352828e-02],\n         [-5.44524156e-02],\n         [-4.35519591e-02],\n         [-5.65075874e-03],\n         [ 2.42175609e-02],\n         [ 3.56302708e-02],\n         [-1.45904496e-02],\n         [ 6.13344908e-02],\n         [-6.81619272e-02],\n         [-7.34260529e-02],\n         [ 3.62001657e-02],\n         [ 3.71783972e-06],\n         [-8.39623436e-02],\n         [-2.52361894e-02],\n         [ 1.25428438e-02],\n         [-8.67305920e-02],\n         [-5.74411303e-02],\n         [ 3.04310769e-02],\n         [ 1.73716098e-02],\n         [-2.14731768e-02],\n         [ 6.05130792e-02],\n         [-9.44293290e-03],\n         [ 5.33591211e-03],\n         [-3.30530852e-03],\n         [ 1.39308050e-02],\n         [-6.96139336e-02],\n         [ 7.68029690e-03],\n         [ 1.80095583e-02],\n         [ 3.64293009e-02],\n         [-2.81212330e-02],\n         [-6.57564402e-03],\n         [ 1.91225559e-02],\n         [ 6.99809939e-02],\n         [ 7.57178068e-02],\n         [ 1.69752836e-02],\n         [-6.03358224e-02],\n         [ 4.58044559e-02],\n         [-6.38880581e-02],\n         [-6.58209622e-02],\n         [-5.48430905e-02],\n         [ 3.19904387e-02],\n         [ 9.02647525e-03],\n         [ 4.01169509e-02],\n         [-1.15756914e-02],\n         [ 3.62778008e-02],\n         [-1.24780238e-02],\n         [-5.88287450e-02],\n         [-5.99050000e-02],\n         [-1.79856122e-02],\n         [ 4.27878201e-02],\n         [-6.20581135e-02]],\n\n        [[-1.21168792e-04],\n         [-4.16063406e-02],\n         [-7.02550858e-02],\n         [ 1.11555159e-02],\n         [-8.30592811e-02],\n         [ 6.35237992e-03],\n         [ 2.20604464e-02],\n         [ 1.77426189e-02],\n         [ 8.17596912e-03],\n         [-5.24880402e-02],\n         [ 1.57025680e-02],\n         [-2.70517766e-02],\n         [ 8.11271518e-02],\n         [ 2.32214257e-02],\n         [ 8.46177340e-02],\n         [ 4.12861109e-02],\n         [-1.33790821e-03],\n         [ 3.32927853e-02],\n         [-8.02079365e-02],\n         [ 5.91319054e-02],\n         [-7.94613361e-03],\n         [ 1.14203244e-02],\n         [-7.79857337e-02],\n         [ 6.85901940e-02],\n         [ 2.90777683e-02],\n         [-3.66676785e-02],\n         [-3.06459703e-02],\n         [ 8.04688036e-03],\n         [ 7.55083710e-02],\n         [-3.15738879e-02],\n         [ 2.37178281e-02],\n         [-6.79171383e-02],\n         [-3.30292694e-02],\n         [-1.94787607e-02],\n         [-5.35087734e-02],\n         [-5.55969551e-02],\n         [ 5.39450496e-02],\n         [ 4.48664427e-02],\n         [-2.84547471e-02],\n         [ 8.16355497e-02],\n         [-6.36542141e-02],\n         [-4.75564748e-02],\n         [-7.52359033e-02],\n         [-3.27689983e-02],\n         [ 8.92854184e-02],\n         [-6.63449615e-02],\n         [-2.22065747e-02],\n         [-8.20852295e-02],\n         [-8.07011798e-02],\n         [-2.52250060e-02],\n         [-8.74431431e-03],\n         [-7.26398304e-02],\n         [ 1.94612369e-02],\n         [-8.01498592e-02],\n         [-1.25075877e-02],\n         [ 3.87320966e-02],\n         [ 1.47733092e-02],\n         [ 2.77080461e-02],\n         [-2.17408016e-02],\n         [-4.88125533e-03],\n         [ 4.79518026e-02],\n         [-2.41644681e-04],\n         [ 6.98694438e-02],\n         [-7.91759789e-03],\n         [-1.10395327e-02],\n         [-4.77359369e-02],\n         [-1.87589377e-02],\n         [-2.54278556e-02],\n         [ 8.32504630e-02],\n         [ 2.48763412e-02],\n         [ 4.51364517e-02],\n         [-7.72685409e-02],\n         [ 3.02845165e-02],\n         [ 2.99702585e-02],\n         [ 3.41760144e-02],\n         [ 3.60536128e-02],\n         [-3.25632133e-02],\n         [ 4.53856289e-02],\n         [ 2.05331296e-03],\n         [-2.11457610e-02]]],\n\n\n       [[[ 2.98502743e-02],\n         [-6.36289343e-02],\n         [ 5.02189249e-03],\n         [-2.26008445e-02],\n         [ 7.19131529e-03],\n         [ 1.25197694e-02],\n         [-4.30957228e-02],\n         [ 2.70145237e-02],\n         [-2.49959305e-02],\n         [ 6.47737682e-02],\n         [-7.54746944e-02],\n         [ 8.10226202e-02],\n         [ 6.46200031e-03],\n         [-4.93434817e-02],\n         [ 1.72294751e-02],\n         [ 1.97882354e-02],\n         [-2.07978711e-02],\n         [-1.44977048e-02],\n         [ 6.35927171e-02],\n         [-4.69534136e-02],\n         [ 6.57587498e-02],\n         [ 2.08891258e-02],\n         [-7.51602203e-02],\n         [ 7.22827464e-02],\n         [-4.80535924e-02],\n         [-7.78346509e-02],\n         [ 4.23701704e-02],\n         [-6.31513447e-03],\n         [-5.38225546e-02],\n         [-5.59786744e-02],\n         [-1.63849890e-02],\n         [-5.27388602e-02],\n         [-8.40497538e-02],\n         [-3.40625644e-03],\n         [ 5.65606654e-02],\n         [ 8.81641954e-02],\n         [-7.80683756e-03],\n         [ 8.74838680e-02],\n         [-5.61197661e-02],\n         [ 4.33781147e-02],\n         [ 3.57892215e-02],\n         [-7.89739788e-02],\n         [ 5.73219955e-02],\n         [ 1.01788864e-02],\n         [ 2.32862458e-02],\n         [-5.12599908e-02],\n         [ 7.20066428e-02],\n         [ 1.35173351e-02],\n         [-3.42971869e-02],\n         [ 3.93975675e-02],\n         [-7.14652464e-02],\n         [ 5.93002141e-03],\n         [-4.78388742e-02],\n         [ 2.87072733e-02],\n         [ 3.62174958e-02],\n         [ 3.57056260e-02],\n         [ 8.59930217e-02],\n         [ 1.70100033e-02],\n         [ 2.89164558e-02],\n         [-3.55652086e-02],\n         [ 4.61629778e-02],\n         [-6.46324009e-02],\n         [ 3.93226445e-02],\n         [ 6.33807331e-02],\n         [-3.66589390e-02],\n         [-3.97481695e-02],\n         [ 4.50608730e-02],\n         [ 1.53198242e-02],\n         [ 3.72625440e-02],\n         [-8.71082023e-02],\n         [ 8.33051056e-02],\n         [ 4.47713435e-02],\n         [-5.75640090e-02],\n         [ 4.20961082e-02],\n         [-5.70861623e-02],\n         [ 7.56520182e-02],\n         [ 1.46467760e-02],\n         [ 1.23398975e-02],\n         [-4.10020910e-02],\n         [ 2.66488120e-02]],\n\n        [[-1.94339007e-02],\n         [-5.32929935e-02],\n         [ 3.56634706e-02],\n         [ 5.58752567e-02],\n         [ 4.90761548e-02],\n         [ 2.27513611e-02],\n         [ 4.80142087e-02],\n         [-6.05893210e-02],\n         [ 8.76296759e-02],\n         [-6.67539611e-02],\n         [-3.49137411e-02],\n         [-7.99823627e-02],\n         [-5.20458855e-02],\n         [-8.54301900e-02],\n         [-9.27980244e-03],\n         [ 1.54380798e-02],\n         [ 5.93365431e-02],\n         [ 6.65570050e-02],\n         [ 1.38361305e-02],\n         [-6.63234144e-02],\n         [ 3.64624411e-02],\n         [ 6.82400912e-02],\n         [-6.26146644e-02],\n         [-6.17798269e-02],\n         [ 8.92982185e-02],\n         [-1.84660330e-02],\n         [-2.14315131e-02],\n         [-4.86147329e-02],\n         [-4.94152084e-02],\n         [ 6.78405762e-02],\n         [-4.60152030e-02],\n         [ 3.28237191e-02],\n         [-6.72991574e-02],\n         [-2.38789469e-02],\n         [-5.33166565e-02],\n         [-3.60438116e-02],\n         [-7.24330246e-02],\n         [ 7.79664367e-02],\n         [ 2.31977999e-02],\n         [ 8.49186480e-02],\n         [ 8.09496045e-02],\n         [-5.04219867e-02],\n         [-1.40614808e-03],\n         [-8.14942420e-02],\n         [ 3.95540595e-02],\n         [-5.18862344e-02],\n         [-2.67770514e-02],\n         [ 1.52870342e-02],\n         [ 4.96704429e-02],\n         [-2.55383626e-02],\n         [-5.74119724e-02],\n         [-2.34784931e-03],\n         [ 4.65544909e-02],\n         [-6.37246892e-02],\n         [-6.54730201e-02],\n         [ 9.02112126e-02],\n         [-1.83752254e-02],\n         [-5.49509376e-02],\n         [-1.17177963e-02],\n         [ 4.57173437e-02],\n         [-8.96015093e-02],\n         [ 6.96691573e-02],\n         [-7.17541575e-02],\n         [ 2.77614668e-02],\n         [-5.14259338e-02],\n         [ 1.67303234e-02],\n         [-7.90323168e-02],\n         [-5.18907793e-02],\n         [-5.23210168e-02],\n         [ 8.22981149e-02],\n         [ 1.80394724e-02],\n         [ 6.48482144e-03],\n         [-4.53045331e-02],\n         [-3.80680971e-02],\n         [ 1.34538263e-02],\n         [ 3.17321122e-02],\n         [-8.17431360e-02],\n         [-1.54386833e-02],\n         [ 2.35653147e-02],\n         [-3.47129330e-02]],\n\n        [[ 1.49880052e-02],\n         [ 7.97562599e-02],\n         [-3.04464996e-03],\n         [ 8.05029422e-02],\n         [ 2.60416865e-02],\n         [ 2.85558254e-02],\n         [ 1.92568824e-02],\n         [-5.03327660e-02],\n         [ 8.33154917e-02],\n         [-4.47868705e-02],\n         [-8.74434635e-02],\n         [-4.79212180e-02],\n         [-8.50960612e-03],\n         [ 3.15978080e-02],\n         [-5.00576757e-02],\n         [-3.19065973e-02],\n         [ 9.35173780e-03],\n         [-8.36795345e-02],\n         [-7.80179203e-02],\n         [-4.78347428e-02],\n         [ 3.79682332e-03],\n         [-3.57308984e-03],\n         [-5.43522686e-02],\n         [ 6.03474379e-02],\n         [-7.80702233e-02],\n         [-7.70357251e-03],\n         [-7.66986161e-02],\n         [ 8.47189128e-02],\n         [-4.61614393e-02],\n         [-1.92526430e-02],\n         [-4.99674790e-02],\n         [-8.35281610e-03],\n         [ 6.05230927e-02],\n         [-7.74278194e-02],\n         [ 1.09563470e-02],\n         [-1.88838542e-02],\n         [-4.70326655e-02],\n         [-7.36595839e-02],\n         [ 7.03992248e-02],\n         [-2.52420083e-02],\n         [ 1.22846514e-02],\n         [ 9.28302109e-03],\n         [-2.35136151e-02],\n         [-2.12027803e-02],\n         [ 4.91269529e-02],\n         [-4.93613072e-02],\n         [ 8.70334506e-02],\n         [ 5.38759977e-02],\n         [ 1.61503255e-03],\n         [ 7.19045848e-02],\n         [ 5.93692064e-04],\n         [-3.81325334e-02],\n         [-7.59326816e-02],\n         [ 6.08555824e-02],\n         [-4.83956896e-02],\n         [ 1.84372216e-02],\n         [-5.03374152e-02],\n         [ 1.54759288e-02],\n         [-6.91940114e-02],\n         [ 2.47452185e-02],\n         [ 9.21648741e-03],\n         [-5.11176214e-02],\n         [-7.45331496e-02],\n         [ 8.26091617e-02],\n         [ 8.18341970e-02],\n         [-9.69479233e-03],\n         [ 4.89368290e-02],\n         [-4.26991396e-02],\n         [-8.83801877e-02],\n         [-7.21906647e-02],\n         [-3.15944143e-02],\n         [ 3.29303369e-02],\n         [-4.94467467e-03],\n         [-5.60007803e-02],\n         [-6.22394793e-02],\n         [-2.54822969e-02],\n         [ 6.30139560e-02],\n         [-4.89213765e-02],\n         [-6.31441623e-02],\n         [-6.62634373e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.09371144,  0.01702544, -0.16216326, ...,  0.01751067,\n           0.089059  ,  0.12657186],\n         [ 0.06208219, -0.13116959,  0.08507419, ..., -0.03308654,\n           0.02695207, -0.07929277],\n         [ 0.08479275, -0.02944072, -0.07979303, ..., -0.08352866,\n           0.06724301, -0.00620721],\n         ...,\n         [-0.07248236,  0.04174983,  0.13346577, ...,  0.10324635,\n          -0.13842711,  0.08201385],\n         [-0.17224312, -0.02182788, -0.06647483, ..., -0.11327539,\n           0.00880406, -0.15378556],\n         [-0.113997  , -0.08554917, -0.03147063, ...,  0.12497499,\n          -0.03437201,  0.04979843]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/moving_variance:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_886/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_838/kernel:0' shape=(1, 1, 16, 24) dtype=float32, numpy=\narray([[[[ 3.20742652e-02,  1.40116811e-01, -1.04097873e-01,\n          -2.95556009e-01,  9.91084203e-02, -1.62456483e-01,\n           4.35056418e-01,  1.10671699e-01, -3.83112803e-02,\n           1.98375210e-01,  6.06018156e-02, -4.29946244e-01,\n          -2.96375841e-01,  5.33206649e-02,  1.35120735e-01,\n           3.47470790e-01, -5.57247996e-01, -3.27257335e-01,\n          -4.40364450e-01,  2.72034109e-01,  3.04733664e-01,\n          -1.52809694e-01,  2.05128863e-01,  3.23439986e-01],\n         [-5.38545430e-01, -4.37696278e-01, -3.19173262e-02,\n           1.94255129e-01,  2.59733528e-01, -5.90851791e-02,\n          -1.07112803e-01, -2.98183173e-01,  1.92420051e-01,\n           1.76415220e-01, -3.37192774e-01, -3.64960432e-02,\n          -1.30132169e-01,  2.80971467e-01, -1.53224379e-01,\n           5.82320802e-02,  9.96667519e-02,  1.89746633e-01,\n           1.88022316e-01,  2.22979352e-01, -2.35726535e-02,\n           3.79733741e-01, -6.80858791e-02,  7.81807452e-02],\n         [ 2.68220454e-01, -4.98809844e-01, -1.01698689e-01,\n          -1.67037293e-01,  2.66369492e-01,  3.44779909e-01,\n           4.64066952e-01, -1.70290440e-01, -3.68132889e-01,\n          -3.48931104e-01, -3.66430104e-01, -3.23819280e-01,\n           6.43159673e-02, -4.15949151e-02, -1.40014365e-01,\n           2.14494944e-01, -1.64120018e-01,  4.26626891e-01,\n           1.02399357e-01,  1.06369622e-01,  1.82073504e-01,\n           3.91915530e-01,  3.86553444e-02, -3.67349565e-01],\n         [-3.25381666e-01,  3.26236635e-01,  4.42693502e-01,\n          -1.03761390e-01,  6.57147095e-02, -1.55175582e-01,\n           2.18856022e-01, -1.22157231e-01,  2.48216074e-02,\n          -3.47695619e-01,  7.24261850e-02,  1.10647187e-01,\n           3.30723792e-01,  2.40607962e-01, -1.93591043e-02,\n          -4.32085752e-01, -5.17130971e-01,  2.19161764e-01,\n           1.92945868e-01,  3.06347728e-01, -1.41972378e-01,\n           4.49643314e-01,  3.82418990e-01, -5.63059568e-01],\n         [-8.26441422e-02, -1.83466882e-01,  2.94966102e-02,\n           7.63941333e-02,  3.96017218e-03, -1.41985938e-01,\n          -9.87754110e-03,  2.14219347e-01,  4.78315959e-03,\n           2.53038794e-01,  2.27178987e-02, -1.68142766e-01,\n          -4.12206143e-01, -1.12982191e-01,  6.28182814e-02,\n          -2.44454637e-01,  4.66257900e-01,  1.67200640e-02,\n          -7.78398812e-02,  2.68713236e-01,  1.41591832e-01,\n           3.02275836e-01, -3.01685780e-01, -5.34852110e-02],\n         [ 2.51802862e-01, -4.33654375e-02,  6.14571981e-02,\n           3.10976744e-01, -1.51461855e-01, -2.46825889e-02,\n          -3.87763470e-01,  6.89698160e-02, -3.94356251e-01,\n          -4.16167617e-01,  2.72537619e-01,  1.44084524e-02,\n          -5.58034033e-02,  9.04297084e-02, -2.22693896e-03,\n           9.62451994e-02,  1.96298242e-01, -1.62574902e-01,\n          -5.62921584e-01, -5.12550294e-01,  2.30988517e-01,\n           3.35316658e-02,  1.30041584e-01,  2.35608205e-01],\n         [-1.18184194e-01,  2.50726432e-01,  2.24569365e-01,\n           1.87968045e-01, -1.09798796e-02, -2.02431411e-01,\n          -3.77828211e-01,  1.90364942e-02,  3.30349118e-01,\n          -2.14976951e-01, -1.78841352e-02, -1.81239784e-01,\n          -3.75614673e-01,  3.11361551e-01, -1.78824797e-01,\n           9.84678864e-02,  2.89674729e-01, -1.72588199e-01,\n           1.82460710e-01,  5.00624955e-01, -2.01215863e-01,\n           3.94987971e-01,  4.07913029e-01,  4.65680420e-01],\n         [-4.14654650e-02, -2.50445575e-01,  4.54121262e-01,\n           2.17892621e-02,  3.51245433e-01,  2.15857252e-01,\n          -2.91124191e-02,  2.21475437e-02, -2.03680947e-01,\n           7.61622265e-02, -2.67596185e-01,  2.27779374e-01,\n           1.64280578e-01, -5.93019649e-03, -1.61498412e-01,\n           5.15044928e-01,  1.78730458e-01, -1.85980320e-01,\n          -4.27465856e-01, -1.37090653e-01, -1.70269802e-01,\n          -8.65736529e-02, -2.13030223e-02,  9.62876901e-02],\n         [-9.82363001e-02, -1.20442085e-01, -1.52226850e-01,\n           6.22111298e-02, -3.73685509e-01,  3.95911038e-01,\n           1.47304684e-01,  3.12923133e-01, -4.06624913e-01,\n          -2.33076721e-01, -2.58342316e-03, -3.56965870e-01,\n          -5.54875314e-01,  3.24062377e-01,  9.72081199e-02,\n          -9.02160332e-02,  2.26063371e-01, -2.10597783e-01,\n           6.66906461e-02, -5.75837903e-02, -4.52767387e-02,\n           2.25239024e-01, -5.58979154e-01, -3.26332152e-02],\n         [ 1.96830109e-01,  2.90286958e-01,  1.32023796e-01,\n           3.81115437e-01, -2.89077288e-03,  2.27576885e-02,\n          -2.42102578e-01,  3.04634213e-01, -8.80599767e-02,\n          -1.74007475e-01, -2.06517920e-01,  2.59989858e-01,\n          -2.77630687e-01,  2.65008472e-02,  5.27820475e-02,\n           3.82901788e-01, -2.76493102e-01, -2.22222004e-02,\n           1.48414478e-01, -7.38792866e-02,  3.80482450e-02,\n           3.74507725e-01,  1.51741728e-01,  1.46540269e-01],\n         [-4.81638387e-02,  3.78227904e-02, -4.36700940e-01,\n          -2.39944831e-03,  2.68115569e-02,  1.84498549e-01,\n           1.94241583e-01, -1.94284648e-01,  9.61938277e-02,\n           1.55264378e-01, -3.41927171e-01, -1.75364986e-02,\n           3.42636406e-02, -3.21676493e-01, -3.06289090e-04,\n           2.07028776e-01,  7.09906146e-02, -2.58599788e-01,\n           4.13185060e-01,  3.40851068e-01, -1.06735915e-01,\n           2.78774172e-01, -9.09300223e-02, -1.59190923e-01],\n         [-4.90447193e-01,  4.53697354e-01,  2.84442514e-01,\n           2.10976079e-01,  2.21557230e-01, -5.74082807e-02,\n           5.23616552e-01, -3.19564134e-01, -2.68714447e-02,\n          -2.20213369e-01,  5.41305803e-02, -2.76280105e-01,\n          -1.03800166e-02, -4.48626757e-01, -2.76016265e-01,\n           3.14076170e-02, -2.94259131e-01, -5.46005547e-01,\n           1.50340006e-01, -2.46592402e-01, -2.27015167e-01,\n           2.25038007e-01, -2.80583054e-01, -3.34886611e-01],\n         [-1.41355202e-01,  6.33203834e-02, -1.19014382e-01,\n           2.58501209e-02,  1.13422863e-01, -3.64410937e-01,\n          -1.94707721e-01, -2.06906181e-02,  2.13210229e-02,\n          -2.21917316e-01,  1.54166501e-02, -2.46296570e-01,\n           6.57783300e-02, -1.86941326e-01,  1.10764362e-01,\n           3.00527066e-01, -1.47603005e-01, -4.41266567e-01,\n           1.40170261e-01,  5.53006828e-01, -2.15006769e-01,\n          -2.63788968e-01,  4.08848464e-01, -9.88116637e-02],\n         [ 7.12451637e-02, -2.13422447e-01, -1.48364037e-01,\n          -1.37245610e-01,  4.14041132e-02,  1.97828978e-01,\n          -2.29966789e-01,  6.58925176e-02, -1.94535851e-01,\n           3.94769728e-01, -4.53712285e-01,  8.66682306e-02,\n          -5.12570262e-01, -1.43356353e-01,  1.80321813e-01,\n          -3.20620537e-01,  1.87957868e-01, -1.05334789e-01,\n          -2.89559886e-02, -4.52301055e-01, -4.07211930e-01,\n          -1.91833898e-01, -3.13330293e-01, -9.47975963e-02],\n         [-2.14121178e-01, -6.47390112e-02, -4.65805203e-01,\n          -1.38596177e-01,  4.84214067e-01, -1.97526991e-01,\n          -1.77601129e-01,  4.71508503e-01, -5.37741959e-01,\n          -2.74014682e-01,  1.15513496e-01,  1.68194145e-01,\n          -8.44270438e-02, -4.71970320e-01,  4.78395313e-01,\n           9.47609618e-02,  2.18519762e-01,  3.35975587e-01,\n          -2.35171258e-01,  2.71729916e-01,  4.46444303e-01,\n           4.61972266e-01, -1.02468900e-01, -2.61221021e-01],\n         [ 2.81047791e-01, -3.66608173e-01, -5.53363264e-01,\n           1.16853835e-02,  1.09675176e-01, -3.49280149e-01,\n           1.29160464e-01, -7.58240074e-02, -2.64845073e-01,\n          -2.07234487e-01, -1.80736005e-01,  4.21559691e-01,\n           2.93599337e-01,  4.39292267e-02,  4.54771221e-02,\n          -1.17883950e-01, -9.37320851e-03,  4.14337702e-02,\n           2.53982216e-01,  9.96601488e-03, -5.62995791e-01,\n           2.10219756e-01, -8.62147212e-02,  4.33874190e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/gamma:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_869/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_876/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 240, 8) dtype=float32, numpy=\narray([[[[ 0.06104271, -0.01311505, -0.00995837, ..., -0.03434118,\n           0.07205841,  0.02138954],\n         [-0.12089845,  0.03850525,  0.12168755, ...,  0.05748101,\n          -0.05227271, -0.04151264],\n         [-0.04091245,  0.04412255, -0.10748985, ..., -0.00757462,\n           0.08675947,  0.01536237],\n         ...,\n         [ 0.09855369, -0.0741913 ,  0.02785364, ...,  0.08212776,\n           0.09798527,  0.06455448],\n         [-0.07895781, -0.06015471, -0.01694091, ...,  0.00490924,\n          -0.07673223,  0.02925727],\n         [ 0.01904452,  0.05023354, -0.03918747, ..., -0.0490978 ,\n          -0.0472915 ,  0.05387364]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[-1.5563510e-01,  1.1396616e-01,  1.3776618e-01, ...,\n           3.0482208e-02,  7.9718783e-02,  4.0278852e-02],\n         [-7.4498756e-03, -1.4900202e-01,  1.6188942e-02, ...,\n           3.8401913e-02,  8.9911497e-05, -8.9520246e-02],\n         [-4.3397471e-02, -5.7577904e-02,  1.1934477e-01, ...,\n           4.6057168e-02, -1.8963411e-03,  8.7268934e-02],\n         ...,\n         [ 1.5685430e-02,  3.0594312e-03,  3.7001889e-02, ...,\n          -7.0716918e-02,  6.4648420e-02, -1.9758138e-01],\n         [-9.1882087e-02, -5.2700132e-02, -1.3114776e-01, ...,\n           1.1755834e-01,  6.1785430e-02,  4.4620920e-02],\n         [-8.8291682e-02,  1.3106145e-01, -1.6148455e-01, ...,\n          -5.2039161e-02,  1.5217073e-01,  1.9178411e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/moving_mean:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/gamma:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_905/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_880/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00270695],\n         [-0.02168023],\n         [ 0.01089906],\n         ...,\n         [-0.01085168],\n         [ 0.00518069],\n         [ 0.00527035]],\n\n        [[-0.01328571],\n         [-0.03063876],\n         [ 0.00170411],\n         ...,\n         [ 0.01075541],\n         [ 0.0198218 ],\n         [ 0.01510967]],\n\n        [[-0.00497825],\n         [ 0.0122616 ],\n         [-0.00617395],\n         ...,\n         [ 0.00267287],\n         [ 0.00816623],\n         [-0.00939731]]],\n\n\n       [[[ 0.0294318 ],\n         [-0.0031346 ],\n         [-0.00030231],\n         ...,\n         [ 0.00255183],\n         [ 0.00244552],\n         [ 0.0065986 ]],\n\n        [[ 0.00502799],\n         [-0.00120259],\n         [ 0.02143406],\n         ...,\n         [-0.00200683],\n         [ 0.03377771],\n         [ 0.00450534]],\n\n        [[-0.02103021],\n         [-0.00144803],\n         [-0.00247725],\n         ...,\n         [-0.01430289],\n         [ 0.00970856],\n         [-0.01870752]]],\n\n\n       [[[-0.00901844],\n         [ 0.01069937],\n         [-0.02238306],\n         ...,\n         [ 0.02736621],\n         [ 0.0028149 ],\n         [-0.00029787]],\n\n        [[-0.00956764],\n         [ 0.00499731],\n         [ 0.00251494],\n         ...,\n         [ 0.00238398],\n         [-0.01011284],\n         [ 0.0165183 ]],\n\n        [[ 0.03358697],\n         [ 0.01815953],\n         [ 0.02630089],\n         ...,\n         [ 0.00729081],\n         [-0.00407788],\n         [-0.00640129]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 0.00157504,  0.03570614,  0.01792276, ...,  0.02347786,\n          -0.04321081, -0.00786104],\n         [-0.00133759, -0.00482325,  0.01555731, ..., -0.08232547,\n           0.00277166,  0.01027902],\n         [ 0.0435539 ,  0.0627959 ,  0.0203787 , ...,  0.07726475,\n           0.02704196,  0.021789  ],\n         ...,\n         [-0.01287492,  0.01203676, -0.03161851, ..., -0.01444559,\n          -0.00817202, -0.03424544],\n         [-0.01920425,  0.01116539,  0.00395886, ...,  0.04744068,\n           0.01164416, -0.04198665],\n         [ 0.03488158, -0.06175166,  0.03859141, ...,  0.02949378,\n          -0.05102222, -0.05743229]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_359/depthwise_kernel:0' shape=(3, 3, 40, 1) dtype=float32, numpy=\narray([[[[ 5.84420264e-02],\n         [-3.05774137e-02],\n         [-3.87217551e-02],\n         [ 8.08576345e-02],\n         [-1.25366464e-01],\n         [ 4.04377431e-02],\n         [-2.83118859e-02],\n         [ 6.23314828e-02],\n         [-1.27106309e-02],\n         [-4.89171371e-02],\n         [ 3.05507183e-02],\n         [ 5.35914451e-02],\n         [ 1.18267134e-01],\n         [-8.57217088e-02],\n         [-5.29292896e-02],\n         [-8.17694813e-02],\n         [-5.38919121e-02],\n         [ 4.19949293e-02],\n         [ 8.37137401e-02],\n         [-6.59022927e-02],\n         [-2.83039212e-02],\n         [-4.44772243e-02],\n         [-9.22586322e-02],\n         [ 5.11890203e-02],\n         [-4.58919853e-02],\n         [ 7.59616494e-03],\n         [-8.03175643e-02],\n         [ 3.37432325e-03],\n         [-7.79841542e-02],\n         [ 1.01828098e-01],\n         [-9.03366506e-02],\n         [-7.91627765e-02],\n         [ 1.05145872e-01],\n         [-1.12409614e-01],\n         [-7.73725808e-02],\n         [ 2.12183297e-02],\n         [ 1.19361490e-01],\n         [-6.59781471e-02],\n         [ 9.45381522e-02],\n         [ 9.87377316e-02]],\n\n        [[-4.43492606e-02],\n         [ 2.88999081e-03],\n         [-6.26203045e-02],\n         [-4.79881093e-02],\n         [-3.97244766e-02],\n         [-1.49902329e-02],\n         [-2.77420953e-02],\n         [-7.61671439e-02],\n         [-8.83090496e-03],\n         [-2.87193358e-02],\n         [ 1.08461082e-01],\n         [-1.94247067e-02],\n         [-1.73662156e-02],\n         [-5.10453433e-03],\n         [-5.11097908e-02],\n         [ 4.25506830e-02],\n         [ 2.13284492e-02],\n         [ 1.08171746e-01],\n         [-9.65194404e-02],\n         [-7.84823745e-02],\n         [-6.46590441e-03],\n         [-4.62004095e-02],\n         [ 3.87676656e-02],\n         [-2.35643387e-02],\n         [ 4.02125865e-02],\n         [-1.19840324e-01],\n         [-2.25571766e-02],\n         [ 9.30687785e-03],\n         [ 1.02365166e-02],\n         [-2.07179487e-02],\n         [-5.23784682e-02],\n         [-5.33969030e-02],\n         [ 8.69223773e-02],\n         [-6.12758324e-02],\n         [-6.11115992e-02],\n         [ 1.52042657e-02],\n         [ 4.68569994e-02],\n         [ 4.96439338e-02],\n         [ 1.09003276e-01],\n         [-1.23886526e-01]],\n\n        [[ 1.16525501e-01],\n         [ 1.02913320e-01],\n         [-1.01660915e-01],\n         [ 9.10464078e-02],\n         [ 6.37339056e-02],\n         [ 5.00026643e-02],\n         [-1.08185679e-01],\n         [-9.35241729e-02],\n         [-3.98608893e-02],\n         [ 6.16493523e-02],\n         [ 5.37328422e-03],\n         [ 6.76348507e-02],\n         [ 1.17907211e-01],\n         [ 3.55395079e-02],\n         [ 5.88136017e-02],\n         [ 5.89650124e-02],\n         [-5.14104962e-02],\n         [-8.01192224e-02],\n         [ 8.49080831e-02],\n         [-7.78726041e-02],\n         [-2.54542828e-02],\n         [ 4.16927338e-02],\n         [ 6.04283810e-02],\n         [ 1.16343051e-01],\n         [ 5.12993485e-02],\n         [ 3.13028693e-03],\n         [-9.82185230e-02],\n         [-6.05791435e-02],\n         [ 9.44961905e-02],\n         [-3.57084274e-02],\n         [-6.45935461e-02],\n         [-9.19126272e-02],\n         [-8.95265192e-02],\n         [-1.20102786e-01],\n         [ 1.12838298e-02],\n         [ 1.10697731e-01],\n         [ 1.21677116e-01],\n         [-4.00049612e-02],\n         [-3.08984593e-02],\n         [ 7.05422461e-02]]],\n\n\n       [[[ 9.46465284e-02],\n         [-8.84237811e-02],\n         [ 4.83985692e-02],\n         [ 9.87773389e-02],\n         [-6.42681867e-02],\n         [-1.19731426e-02],\n         [ 1.04284763e-01],\n         [-7.69521222e-02],\n         [ 5.23781925e-02],\n         [-1.63612142e-02],\n         [-9.05799568e-02],\n         [ 5.17198443e-02],\n         [-9.93361920e-02],\n         [ 9.19825137e-02],\n         [-1.15511015e-01],\n         [ 7.82924294e-02],\n         [ 3.66812944e-03],\n         [-6.40455186e-02],\n         [ 1.05936781e-01],\n         [ 8.73716921e-02],\n         [ 3.79988849e-02],\n         [ 1.24873579e-01],\n         [ 6.21967018e-03],\n         [ 8.72010142e-02],\n         [ 7.14607537e-02],\n         [-9.29251909e-02],\n         [ 2.81104147e-02],\n         [-4.08482552e-02],\n         [-1.06461093e-01],\n         [-6.79676235e-02],\n         [ 1.14579126e-01],\n         [-3.44698131e-03],\n         [-6.94258884e-02],\n         [ 2.45999247e-02],\n         [ 1.42939687e-02],\n         [-1.25985578e-01],\n         [-6.03745356e-02],\n         [-3.65603194e-02],\n         [ 8.82102698e-02],\n         [ 1.15857452e-01]],\n\n        [[-5.50933108e-02],\n         [ 8.38647783e-02],\n         [ 9.61752683e-02],\n         [ 2.06865668e-02],\n         [ 1.02063373e-01],\n         [ 1.21637717e-01],\n         [ 8.84062946e-02],\n         [ 4.58164960e-02],\n         [ 8.72072726e-02],\n         [ 1.56838298e-02],\n         [ 1.87835544e-02],\n         [ 1.17395967e-02],\n         [ 1.50529593e-02],\n         [ 1.15535125e-01],\n         [ 8.27411264e-02],\n         [ 3.90405804e-02],\n         [-3.63685787e-02],\n         [-2.61436775e-02],\n         [-4.78384122e-02],\n         [ 1.02655247e-01],\n         [-1.22609675e-01],\n         [ 1.22391418e-01],\n         [ 1.12662897e-01],\n         [-3.13517600e-02],\n         [ 2.06011683e-02],\n         [-7.35425204e-03],\n         [ 3.41457874e-02],\n         [-9.53677893e-02],\n         [ 6.29100353e-02],\n         [-8.63025710e-02],\n         [-1.01253375e-01],\n         [ 5.43985367e-02],\n         [-6.70780316e-02],\n         [ 4.45505530e-02],\n         [-3.00904363e-03],\n         [-3.53460088e-02],\n         [ 7.59314597e-02],\n         [-4.60441783e-02],\n         [ 8.54007900e-03],\n         [ 1.02719337e-01]],\n\n        [[ 3.86208743e-02],\n         [ 5.63320369e-02],\n         [-3.98957282e-02],\n         [-8.40318128e-02],\n         [ 1.23606473e-01],\n         [-3.42995971e-02],\n         [ 8.30029100e-02],\n         [-5.05628437e-03],\n         [ 1.18925497e-01],\n         [ 5.41552156e-02],\n         [-6.10693097e-02],\n         [-2.76740268e-02],\n         [-7.88388401e-02],\n         [-5.03802672e-02],\n         [ 1.17912009e-01],\n         [ 1.95864141e-02],\n         [-2.37672403e-02],\n         [ 6.82919174e-02],\n         [-6.46000206e-02],\n         [-8.31057653e-02],\n         [-4.76290360e-02],\n         [ 6.83069229e-05],\n         [-9.22608227e-02],\n         [-1.04643993e-01],\n         [ 3.97684723e-02],\n         [ 1.24173522e-01],\n         [-1.06648795e-01],\n         [ 2.82082409e-02],\n         [ 1.26065910e-01],\n         [ 1.06089666e-01],\n         [-2.89665014e-02],\n         [ 5.50031960e-02],\n         [-4.25761566e-02],\n         [-3.97935808e-02],\n         [ 3.77426893e-02],\n         [ 1.12010926e-01],\n         [ 6.63828850e-02],\n         [ 1.12367228e-01],\n         [-9.78244543e-02],\n         [-5.36593050e-02]]],\n\n\n       [[[-2.23992094e-02],\n         [-6.35318458e-02],\n         [-3.11326236e-03],\n         [ 1.08099997e-01],\n         [-4.42322418e-02],\n         [-3.49096134e-02],\n         [-1.18542828e-01],\n         [ 6.92158937e-02],\n         [-1.08973011e-02],\n         [-5.58410436e-02],\n         [-1.09360076e-01],\n         [-1.27183229e-01],\n         [ 7.26999789e-02],\n         [ 2.35420763e-02],\n         [-1.06749207e-01],\n         [ 7.03605115e-02],\n         [-1.29048675e-02],\n         [ 1.14574969e-01],\n         [-6.57476038e-02],\n         [ 1.11071438e-01],\n         [ 4.41964865e-02],\n         [ 1.10713542e-02],\n         [ 1.16372734e-01],\n         [ 9.34214145e-02],\n         [-2.73460150e-02],\n         [ 8.43599737e-02],\n         [ 4.60337400e-02],\n         [ 1.11784428e-01],\n         [-4.86762002e-02],\n         [ 3.77844572e-02],\n         [-1.18259057e-01],\n         [ 9.81796682e-02],\n         [ 1.25283897e-01],\n         [-1.21603489e-01],\n         [ 6.10135198e-02],\n         [ 3.80173326e-04],\n         [ 9.82794166e-03],\n         [-7.00090602e-02],\n         [-6.84467256e-02],\n         [-5.06701469e-02]],\n\n        [[-5.58854342e-02],\n         [-1.22981675e-01],\n         [-1.08027399e-01],\n         [-2.36797109e-02],\n         [ 5.47795892e-02],\n         [-1.92969292e-02],\n         [-6.12039343e-02],\n         [ 1.24440759e-01],\n         [-4.10689414e-02],\n         [-5.70808724e-02],\n         [-1.05055876e-01],\n         [-1.67580545e-02],\n         [ 1.03043482e-01],\n         [-1.20457850e-01],\n         [-1.10972084e-01],\n         [-2.95386985e-02],\n         [ 2.89097428e-02],\n         [ 7.19778985e-02],\n         [-9.30856913e-02],\n         [ 3.55580598e-02],\n         [-2.98610851e-02],\n         [-6.80394024e-02],\n         [ 1.45328045e-02],\n         [-7.02136606e-02],\n         [-1.17908180e-01],\n         [ 6.05001003e-02],\n         [-1.05876945e-01],\n         [-1.10496745e-01],\n         [ 7.02235699e-02],\n         [ 5.05477786e-02],\n         [ 3.09474766e-02],\n         [-6.72595054e-02],\n         [ 1.13452196e-01],\n         [ 1.23863101e-01],\n         [ 9.15643424e-02],\n         [-3.96163315e-02],\n         [-1.16513066e-01],\n         [ 3.25706601e-03],\n         [ 1.93021894e-02],\n         [ 1.24712199e-01]],\n\n        [[-2.39874125e-02],\n         [-5.30241430e-03],\n         [-4.16943729e-02],\n         [-8.12925249e-02],\n         [-3.11907455e-02],\n         [-3.67601588e-02],\n         [ 8.11376572e-02],\n         [-4.47151810e-02],\n         [ 2.22942680e-02],\n         [-1.16318099e-01],\n         [ 3.90666723e-02],\n         [-2.90037766e-02],\n         [-7.94845223e-02],\n         [ 7.06908256e-02],\n         [-4.99447584e-02],\n         [-6.33961931e-02],\n         [ 1.20726362e-01],\n         [ 9.50827003e-02],\n         [-1.03158943e-01],\n         [ 1.05735064e-01],\n         [-8.05437863e-02],\n         [ 3.16193551e-02],\n         [ 6.95690215e-02],\n         [-6.58819824e-02],\n         [-8.31112713e-02],\n         [ 5.24496734e-02],\n         [ 1.27278566e-01],\n         [-1.27289027e-01],\n         [-3.90216708e-04],\n         [-8.31420049e-02],\n         [-1.15026832e-01],\n         [-3.51146609e-03],\n         [-5.39738461e-02],\n         [ 1.02403700e-01],\n         [ 2.85909474e-02],\n         [ 6.03629798e-02],\n         [-7.31144696e-02],\n         [ 9.14853811e-02],\n         [ 7.08744824e-02],\n         [-1.88782588e-02]]]], dtype=float32)>, <tf.Variable 'conv2d_854/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.08927765,  0.02310633, -0.15007019, ..., -0.07187398,\n          -0.1575451 , -0.06102789],\n         [-0.01447855,  0.01099591, -0.02975849, ..., -0.038068  ,\n           0.04645854,  0.12191444],\n         [ 0.06299087,  0.02644032,  0.15216291, ..., -0.01469995,\n          -0.02496267,  0.1261727 ],\n         ...,\n         [-0.02617172,  0.05381781,  0.03638356, ...,  0.04493128,\n           0.0426027 , -0.05502084],\n         [ 0.16851349,  0.04509362, -0.01229738, ..., -0.04244415,\n          -0.00393791, -0.02106936],\n         [-0.07568511, -0.01093991,  0.01620227, ...,  0.03543338,\n           0.0591414 , -0.11505126]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[-0.1604081 ,  0.09265926, -0.02806205, ..., -0.19241086,\n           0.16014767,  0.08268873],\n         [ 0.12953569,  0.1602902 ,  0.00827568, ...,  0.05967159,\n           0.03470638, -0.18503106],\n         [-0.11435635,  0.05174587,  0.09613944, ...,  0.17460869,\n           0.10492414,  0.06297076],\n         ...,\n         [ 0.07338991,  0.12658954,  0.11675625, ...,  0.06729905,\n          -0.00999317, -0.0936647 ],\n         [-0.11777614,  0.00880963, -0.09618402, ..., -0.04232139,\n          -0.1817877 , -0.19564846],\n         [ 0.02152024, -0.05189605,  0.02172527, ...,  0.23859856,\n          -0.02769696, -0.11629164]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 144, 4) dtype=float32, numpy=\narray([[[[ 2.32039690e-02, -1.67950206e-02,  8.60020742e-02,\n          -1.09806634e-01],\n         [ 8.54323898e-03,  6.89792484e-02,  1.61746398e-01,\n          -1.12355640e-02],\n         [-6.00562021e-02,  1.61218300e-01,  4.45421711e-02,\n           3.31441276e-02],\n         [-1.10927159e-02, -8.58479589e-02, -8.30828398e-02,\n          -9.03857127e-02],\n         [ 5.03813429e-03,  6.31147102e-02,  7.37641826e-02,\n           2.98156999e-02],\n         [-3.04640774e-02,  2.30375901e-02,  3.17528062e-02,\n           7.14620501e-02],\n         [ 1.22008296e-02, -1.74540114e-02,  6.44322038e-02,\n           1.09247388e-02],\n         [ 9.27562192e-02,  5.83481453e-02, -2.53892280e-02,\n          -9.88096148e-02],\n         [-3.66993584e-02, -3.21856625e-02,  4.18056808e-02,\n           5.85153652e-03],\n         [-1.66954268e-02,  4.83328551e-02,  8.34413990e-02,\n          -1.26409590e-01],\n         [-6.98710885e-03, -1.32808149e-01, -9.67329293e-02,\n           1.56298101e-01],\n         [-3.74568701e-02, -2.29882468e-02,  3.50534543e-02,\n          -1.12085687e-02],\n         [ 3.42793353e-02, -4.68112491e-02,  6.23147599e-02,\n          -2.71762554e-02],\n         [-5.66131100e-02, -3.37956622e-02,  4.66329195e-02,\n          -1.25237539e-01],\n         [ 1.33029558e-02,  7.89156854e-02,  7.45847300e-02,\n           2.86705215e-02],\n         [ 1.87151637e-02, -7.52698211e-03, -1.70538917e-01,\n           4.67548072e-02],\n         [ 9.20384228e-02,  1.51797086e-01, -3.82008888e-02,\n           9.13437922e-03],\n         [-5.58878891e-02, -3.60749289e-02,  1.42546117e-01,\n          -1.10958822e-01],\n         [-8.01577345e-02,  3.59659665e-03,  7.23180175e-03,\n           7.21419826e-02],\n         [-8.49249139e-02,  6.21397272e-02,  1.07876889e-01,\n           1.35272881e-02],\n         [ 3.25091332e-02, -4.39030789e-02,  8.50055143e-02,\n           1.12538032e-01],\n         [-5.49431182e-02, -3.83335240e-02, -1.37099311e-01,\n           2.41757873e-02],\n         [-1.22387987e-02, -1.07813291e-01, -1.01220518e-01,\n           1.56699911e-01],\n         [-1.13809854e-02, -1.02525458e-01, -3.28203589e-02,\n           5.24778804e-03],\n         [ 2.94138882e-02,  6.01680167e-02, -1.00700408e-01,\n          -1.81398720e-01],\n         [ 2.66503040e-02, -7.06382170e-02,  1.69448033e-02,\n          -5.05105369e-02],\n         [-8.37951750e-02, -9.88824815e-02, -7.57500678e-02,\n          -9.08203721e-02],\n         [ 3.55050415e-02,  3.95638309e-02,  8.87266621e-02,\n          -2.37995237e-02],\n         [ 1.31084204e-01,  1.04590923e-01,  1.53266579e-01,\n           1.22553684e-01],\n         [ 2.47423481e-02,  9.93949026e-02,  7.40014613e-02,\n           7.61438757e-02],\n         [-1.27699435e-01,  1.14765309e-01,  2.02232730e-02,\n          -6.47297055e-02],\n         [ 1.23162106e-01,  2.32398063e-02,  7.31307790e-02,\n          -5.44489780e-03],\n         [-3.73315439e-02, -5.12728579e-02,  1.05492003e-01,\n           1.28327245e-02],\n         [ 1.27245123e-02, -7.62887858e-03, -4.48068306e-02,\n          -3.93181965e-02],\n         [-7.07176998e-02,  5.29265543e-03, -1.03549622e-01,\n           1.26691446e-01],\n         [ 3.03000100e-02,  1.66884810e-02,  5.94952554e-02,\n          -1.02508906e-02],\n         [-1.82266980e-01, -8.81214812e-02, -5.68300188e-02,\n           1.79676369e-01],\n         [-1.08829893e-01,  5.60723851e-03, -1.55494109e-01,\n          -1.01597495e-01],\n         [-8.03215504e-02, -9.57228709e-03,  3.55300866e-02,\n          -6.25646561e-02],\n         [ 9.56917554e-02,  1.44034162e-01,  3.19728069e-02,\n          -1.47246057e-02],\n         [ 1.12042025e-01,  8.63221511e-02, -1.22239351e-01,\n           9.98041034e-02],\n         [ 3.46085639e-03,  9.97041538e-02, -2.30768900e-02,\n          -1.98863167e-02],\n         [-4.02678512e-02, -8.07441622e-02,  6.74324036e-02,\n           3.26033123e-02],\n         [ 1.08782575e-01, -6.87756985e-02, -1.61177907e-02,\n           4.09306623e-02],\n         [-9.53942612e-02,  5.30852675e-02,  1.43177167e-01,\n           4.33065705e-02],\n         [ 1.20934486e-01,  9.57549512e-02, -1.02742285e-01,\n          -6.48610219e-02],\n         [-1.01046299e-03, -1.58001468e-01,  8.10680687e-02,\n          -1.04719639e-01],\n         [ 7.31753111e-02, -1.63125806e-02,  3.57170403e-02,\n          -4.53114286e-02],\n         [-3.04795783e-02,  5.61316311e-02, -1.50168940e-01,\n          -2.91790906e-02],\n         [ 6.66745380e-02,  7.66498595e-02,  3.25827375e-02,\n          -6.28206283e-02],\n         [-4.56469283e-02, -1.34376824e-01,  3.11785955e-02,\n          -8.58782977e-02],\n         [ 7.93023966e-03,  9.59705263e-02, -7.20677003e-02,\n          -6.70344802e-03],\n         [ 2.83532143e-02, -2.01694705e-02, -1.05426557e-01,\n           4.18904051e-02],\n         [ 2.59215776e-02, -9.32423994e-02, -4.82248329e-02,\n          -1.02348952e-02],\n         [-1.87132247e-02, -7.20064864e-02,  1.06809288e-01,\n          -3.38555984e-02],\n         [ 1.43188117e-02, -5.82191907e-02,  4.22617942e-02,\n           1.45122081e-01],\n         [-1.81124941e-01, -8.24285764e-03, -9.22991037e-02,\n           7.81742334e-02],\n         [ 1.07095003e-01, -1.48167275e-02,  1.05703309e-01,\n           4.12180126e-02],\n         [ 1.43192173e-03,  3.21526751e-02, -4.44653854e-02,\n           1.15426421e-01],\n         [-7.85329714e-02,  1.79682806e-01, -1.09941401e-01,\n           6.58254027e-02],\n         [-1.63890079e-01,  1.52665108e-01, -3.92826200e-02,\n          -3.03785279e-02],\n         [ 3.90254743e-02,  3.12023293e-02, -3.43946032e-02,\n          -1.25867397e-01],\n         [ 5.73839173e-02,  1.04488015e-01, -4.53505293e-02,\n          -9.76873189e-02],\n         [ 3.71899968e-03, -8.35440028e-03, -1.11207217e-01,\n           1.36384126e-02],\n         [ 7.89987445e-02, -4.29482460e-02, -1.92072000e-02,\n          -1.54440254e-01],\n         [-3.91403474e-02,  1.14596821e-01, -4.53481935e-02,\n          -4.63046394e-02],\n         [-8.94388929e-02, -9.24426541e-02,  3.32194269e-02,\n           1.22363502e-02],\n         [-2.89974790e-02,  3.60664017e-02, -6.97032660e-02,\n           1.04637556e-02],\n         [ 4.08747531e-02, -1.35821581e-01,  1.00770801e-01,\n           5.38505018e-02],\n         [ 1.56850412e-01,  5.28691411e-02,  3.05276681e-02,\n           5.70571609e-03],\n         [ 5.38112130e-03, -1.50750251e-02, -1.57747209e-01,\n          -8.17289203e-02],\n         [-3.58038209e-02, -7.44801238e-02,  9.42011103e-02,\n          -1.05326466e-01],\n         [-4.91310470e-02, -1.24013750e-02,  1.10529035e-01,\n          -3.05791311e-02],\n         [ 1.65678531e-01, -9.47073624e-02, -1.43054361e-02,\n          -3.64813060e-02],\n         [ 5.70595870e-03,  1.39429927e-01,  1.22806855e-01,\n           1.16044305e-01],\n         [-1.61446468e-03, -1.10205591e-01, -1.43830493e-01,\n           2.13228675e-04],\n         [ 4.32302586e-05,  3.82226445e-02,  5.03091849e-02,\n          -5.76266050e-02],\n         [ 4.07750234e-02, -1.23380311e-01,  4.66464534e-02,\n           1.92814097e-02],\n         [-1.18788004e-01,  1.64318904e-01, -7.32733607e-02,\n           2.20727492e-02],\n         [ 3.41420807e-02, -1.04408458e-01, -6.46848306e-02,\n           1.40925199e-02],\n         [-4.53168526e-02,  3.47976834e-02, -9.73215550e-02,\n           1.50235698e-01],\n         [-3.75344865e-02, -7.96238706e-02,  1.85299113e-01,\n           4.40764949e-02],\n         [ 1.24215938e-01,  8.74436572e-02,  2.86027230e-03,\n           5.15091643e-02],\n         [ 1.57914355e-01,  6.73373090e-03,  6.23514019e-02,\n           2.15380732e-02],\n         [-4.92914543e-02,  1.51277077e-03,  8.58472195e-03,\n           6.22164942e-02],\n         [ 8.55982900e-02, -1.19201407e-01, -7.85484463e-02,\n          -6.75909743e-02],\n         [ 9.08132046e-02,  1.05007831e-03, -2.52275635e-02,\n           2.00525504e-02],\n         [-7.26351440e-02,  5.57457656e-02, -6.94813614e-04,\n           1.46966502e-01],\n         [-7.29022399e-02, -7.50631914e-02,  6.19325489e-02,\n          -1.23839729e-01],\n         [-9.42839310e-02,  1.05201676e-02,  4.09759358e-02,\n          -8.51704255e-02],\n         [-1.44583866e-01,  6.36543557e-02, -1.29617199e-01,\n          -9.37773846e-03],\n         [ 1.77494865e-02, -2.13235710e-02, -1.37329519e-01,\n          -4.68456233e-03],\n         [-2.89609861e-02,  2.18387917e-02,  7.88196176e-02,\n           6.47911504e-02],\n         [-1.21250294e-01, -8.60397145e-02, -1.04069591e-01,\n           9.24099162e-02],\n         [-1.36837572e-01,  2.33730860e-03, -2.41260137e-02,\n          -1.03005007e-01],\n         [ 9.53079462e-02, -4.56560776e-02,  3.94328982e-02,\n           8.15901905e-03],\n         [ 8.68844762e-02,  2.41976753e-02,  1.23425666e-02,\n          -9.09224153e-03],\n         [-4.52853888e-02,  6.64553791e-02, -1.60396025e-01,\n          -5.03647476e-02],\n         [ 1.43663093e-01, -1.64743468e-01, -5.02842218e-02,\n          -1.45463809e-01],\n         [ 6.43484518e-02, -1.69897527e-01,  6.32543042e-02,\n          -7.22356588e-02],\n         [ 8.24022666e-03,  7.09612817e-02, -1.99656766e-02,\n          -1.27321571e-01],\n         [-1.47551253e-01, -8.91607106e-02, -4.83417436e-02,\n           1.40199130e-02],\n         [ 3.53745520e-02, -9.28043127e-02,  1.33486195e-02,\n           1.58304781e-01],\n         [ 1.87206984e-01, -4.88259606e-02, -3.57408673e-02,\n          -1.97686423e-02],\n         [ 4.31926884e-02, -2.48868000e-02, -1.95279196e-02,\n           3.52209271e-03],\n         [ 5.03951982e-02,  4.75277845e-03, -1.06131934e-01,\n          -2.09131669e-02],\n         [ 7.44444057e-02,  8.60180259e-02, -1.83157906e-01,\n           4.58924994e-02],\n         [-1.87769681e-01, -3.57087441e-02,  2.13760231e-02,\n           7.96313733e-02],\n         [ 1.49912313e-01,  5.28050996e-02, -1.52681256e-02,\n           6.09828755e-02],\n         [-6.29480705e-02, -3.80108804e-02, -5.32987155e-02,\n           1.44382596e-01],\n         [-8.49804357e-02, -1.33491993e-01,  1.39583051e-01,\n          -8.19478035e-02],\n         [-9.90629494e-02, -7.96142370e-02,  1.07570253e-01,\n          -9.62870643e-02],\n         [-9.13374999e-04,  5.27729804e-04, -4.00676057e-02,\n           1.19616978e-01],\n         [ 1.75227020e-02, -1.13389730e-01,  1.72196329e-01,\n           4.23182808e-02],\n         [ 7.77740777e-02,  3.93962339e-02, -2.77597345e-02,\n          -7.80640468e-02],\n         [ 6.30129054e-02, -5.66142388e-02, -1.09555200e-01,\n           2.72745695e-02],\n         [ 6.28336966e-02, -4.67941957e-03,  4.50431332e-02,\n          -3.94124053e-02],\n         [ 6.12173751e-02, -2.34600473e-02, -1.07446369e-02,\n           4.87900637e-02],\n         [ 1.00663140e-01,  5.10732681e-02, -9.26399380e-02,\n           7.73343444e-02],\n         [ 1.37057543e-01, -7.68993199e-02,  4.85730432e-02,\n           5.95064685e-02],\n         [ 5.85447326e-02,  5.04013076e-02, -1.50410458e-02,\n          -5.78494221e-02],\n         [-7.96432700e-03,  1.04273997e-01,  2.17811819e-02,\n           9.25356597e-02],\n         [ 2.44578011e-02, -6.02282174e-02,  1.77015476e-02,\n           1.18747018e-01],\n         [-1.37136888e-03,  1.68678939e-01,  4.89798263e-02,\n          -2.34737787e-02],\n         [ 1.76901394e-03,  5.47274342e-03,  1.57165229e-01,\n           1.09086476e-01],\n         [ 1.09915130e-01, -2.34477874e-02,  1.53540047e-02,\n          -7.65306875e-02],\n         [-1.97864398e-02,  1.69357419e-01, -1.63470313e-01,\n          -4.54807561e-03],\n         [-5.91897294e-02, -2.96171810e-02, -5.97766787e-02,\n           4.74084169e-02],\n         [ 1.57482158e-02, -2.70292372e-03,  1.43421218e-01,\n           1.19408602e-02],\n         [-3.84460315e-02, -2.81387772e-02, -1.59336045e-01,\n           6.04261346e-02],\n         [ 2.20307615e-03,  1.40398130e-01,  1.28400465e-02,\n           1.52370274e-01],\n         [-3.78771797e-02, -6.95474297e-02, -8.61535072e-02,\n           1.17960833e-01],\n         [ 1.44006699e-01, -1.82743184e-02,  3.14269885e-02,\n          -1.11197367e-01],\n         [-6.68191314e-02,  3.52549255e-02,  2.53247842e-02,\n           8.78826482e-04],\n         [ 2.90407408e-02,  4.71099913e-02, -5.33276871e-02,\n          -9.19872746e-02],\n         [-2.83581968e-02, -8.08664784e-02, -9.62390974e-02,\n          -1.21426634e-01],\n         [-1.02921706e-02, -1.22379558e-02,  3.70367896e-03,\n          -5.58219664e-02],\n         [-5.62939001e-03,  4.00546379e-02,  1.42955333e-01,\n           6.59830719e-02],\n         [-6.25251792e-04,  3.50408033e-02, -1.29423201e-01,\n          -5.64990677e-02],\n         [ 7.95700848e-02, -8.86222869e-02,  2.49033608e-02,\n           5.44947479e-03],\n         [-4.47278433e-02,  6.24642372e-02,  4.46977280e-02,\n          -8.24861676e-02],\n         [ 9.24923196e-02,  1.27423495e-01,  6.44644797e-02,\n           8.14308971e-02],\n         [-1.32837713e-01,  8.53462983e-03, -3.71800773e-02,\n           8.65096003e-02],\n         [-9.31186080e-02,  5.85664622e-02, -1.59089488e-03,\n          -4.31360826e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00594558, -0.00396335, -0.02186738, ...,  0.02754293,\n          -0.02509721, -0.00084529],\n         [ 0.00569535, -0.01393074,  0.07114539, ...,  0.01338242,\n          -0.04704309, -0.00306149],\n         [-0.02383177,  0.01171319, -0.04965599, ...,  0.06913605,\n           0.02784472, -0.00517856],\n         ...,\n         [-0.08232499, -0.03535913, -0.05210387, ...,  0.01173353,\n          -0.0219713 , -0.00989982],\n         [ 0.04245688, -0.0598773 , -0.02837039, ...,  0.04096496,\n           0.05643328, -0.01824093],\n         [ 0.00912231,  0.03616695, -0.01578228, ...,  0.05656989,\n          -0.06415716,  0.00909172]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[ 0.00647688, -0.0087103 , -0.03474365, ...,  0.01756965,\n          -0.06735557, -0.03243956],\n         [ 0.03777772, -0.02773981, -0.05797124, ..., -0.03325171,\n          -0.05105164,  0.01640751],\n         [ 0.03888813,  0.01243715, -0.06748699, ...,  0.00287368,\n          -0.03928642, -0.01381011],\n         ...,\n         [-0.0352194 ,  0.00258397, -0.04388691, ...,  0.07749242,\n          -0.0416784 , -0.01804771],\n         [-0.04595544,  0.01328602,  0.03966352, ...,  0.01637703,\n          -0.06882746,  0.01448714],\n         [ 0.03018468,  0.07776093,  0.06670325, ..., -0.00090415,\n          -0.00205473,  0.02096124]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00278403],\n         [ 0.00714479],\n         [-0.00851856],\n         ...,\n         [-0.0124376 ],\n         [-0.00349421],\n         [ 0.00535573]],\n\n        [[-0.01108478],\n         [ 0.00969908],\n         [ 0.0099229 ],\n         ...,\n         [ 0.01376243],\n         [ 0.00868853],\n         [-0.01018537]],\n\n        [[-0.006583  ],\n         [ 0.02807542],\n         [-0.00792098],\n         ...,\n         [-0.00828437],\n         [ 0.02432678],\n         [ 0.01999041]]],\n\n\n       [[[-0.00978566],\n         [-0.00123338],\n         [ 0.03423669],\n         ...,\n         [-0.00853852],\n         [-0.02109533],\n         [ 0.00824265]],\n\n        [[-0.01714325],\n         [-0.00771266],\n         [ 0.00853083],\n         ...,\n         [-0.03115862],\n         [-0.00929501],\n         [-0.00450352]],\n\n        [[ 0.00039372],\n         [ 0.02820576],\n         [ 0.00307397],\n         ...,\n         [ 0.01740071],\n         [ 0.00466509],\n         [-0.02758245]]],\n\n\n       [[[-0.01349994],\n         [ 0.00273102],\n         [-0.02854341],\n         ...,\n         [-0.01187812],\n         [-0.01038369],\n         [-0.01251253]],\n\n        [[-0.02923885],\n         [-0.00933978],\n         [ 0.0296658 ],\n         ...,\n         [-0.03068468],\n         [-0.0075779 ],\n         [-0.01229561]],\n\n        [[ 0.0133796 ],\n         [-0.00949907],\n         [-0.01257044],\n         ...,\n         [ 0.00901757],\n         [-0.01188081],\n         [ 0.01936061]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_877/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 48, 1) dtype=float32, numpy=\narray([[[[-0.20452431],\n         [-0.24764627],\n         [-0.02291003],\n         [ 0.26807985],\n         [-0.1896921 ],\n         [ 0.08782116],\n         [ 0.17390439],\n         [ 0.03156349],\n         [ 0.20679231],\n         [-0.31079   ],\n         [ 0.01119312],\n         [ 0.06432789],\n         [-0.09114914],\n         [ 0.08604938],\n         [ 0.16241938],\n         [ 0.10320818],\n         [ 0.05796328],\n         [ 0.01005852],\n         [-0.05520332],\n         [-0.16050872],\n         [ 0.25218022],\n         [-0.00867049],\n         [ 0.1160943 ],\n         [ 0.05627656],\n         [ 0.14947554],\n         [-0.30336204],\n         [ 0.08272176],\n         [-0.03906566],\n         [-0.00807666],\n         [ 0.13487007],\n         [ 0.00533551],\n         [ 0.14318928],\n         [ 0.01428361],\n         [ 0.00601714],\n         [ 0.13084696],\n         [-0.14707583],\n         [-0.00483005],\n         [-0.16639385],\n         [-0.23647362],\n         [ 0.09266609],\n         [-0.06807948],\n         [ 0.13821703],\n         [ 0.02837384],\n         [-0.13147762],\n         [ 0.16046478],\n         [-0.29497913],\n         [-0.16454412],\n         [ 0.10789236]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-2.6183311e-02],\n         [-1.2160144e-02],\n         [-6.3104420e-03],\n         ...,\n         [-3.7077093e-04],\n         [ 4.7504938e-05],\n         [-1.7295025e-02]],\n\n        [[-1.4817242e-02],\n         [ 1.0956171e-03],\n         [-5.6892657e-03],\n         ...,\n         [-1.8619318e-02],\n         [-3.1895090e-02],\n         [-2.3701290e-02]],\n\n        [[-8.3203958e-03],\n         [ 1.6419090e-02],\n         [-5.8985618e-03],\n         ...,\n         [-3.8686779e-03],\n         [ 2.8884599e-02],\n         [ 9.8475171e-03]]],\n\n\n       [[[ 1.1574111e-02],\n         [-3.1547617e-02],\n         [-3.6060603e-03],\n         ...,\n         [-2.4135863e-02],\n         [ 1.7948838e-02],\n         [ 4.2826994e-03]],\n\n        [[-3.6202606e-03],\n         [ 2.4351936e-03],\n         [ 1.4609898e-02],\n         ...,\n         [ 2.0362806e-02],\n         [ 1.0807214e-02],\n         [-4.2689233e-03]],\n\n        [[ 2.1754781e-02],\n         [-9.8444223e-03],\n         [-1.1385389e-03],\n         ...,\n         [ 1.0217044e-02],\n         [ 7.1875281e-03],\n         [ 1.0845623e-02]]],\n\n\n       [[[-3.7411619e-03],\n         [-3.9085140e-03],\n         [-1.3038086e-03],\n         ...,\n         [-2.4963936e-03],\n         [-7.9678698e-03],\n         [ 1.1221718e-02]],\n\n        [[-5.8524334e-03],\n         [-1.5788522e-03],\n         [-1.5313556e-02],\n         ...,\n         [ 2.4537707e-02],\n         [-1.2834115e-02],\n         [ 7.0881755e-03]],\n\n        [[-2.3915144e-02],\n         [-1.4745352e-02],\n         [-1.4594946e-03],\n         ...,\n         [-1.7016517e-02],\n         [ 2.4027515e-02],\n         [-1.0733176e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_847/kernel:0' shape=(1, 1, 40, 80) dtype=float32, numpy=\narray([[[[ 0.229332  ,  0.04093602,  0.17267238, ..., -0.11219734,\n          -0.31629854, -0.3311011 ],\n         [ 0.05939723, -0.16683371, -0.01456103, ..., -0.113846  ,\n          -0.09399445, -0.0029161 ],\n         [-0.20164867, -0.0434567 ,  0.30733716, ...,  0.23951754,\n          -0.08874512, -0.24613258],\n         ...,\n         [ 0.04953276,  0.08305011,  0.31508628, ...,  0.03028731,\n           0.3592492 ,  0.16859336],\n         [ 0.19208433, -0.04702635, -0.01239415, ...,  0.1157487 ,\n           0.10809616, -0.33572364],\n         [-0.2044123 , -0.28736696,  0.03287664, ...,  0.10693512,\n           0.00311556, -0.10930848]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_870/kernel:0' shape=(1, 1, 40, 48) dtype=float32, numpy=\narray([[[[ 0.01786763, -0.06756767, -0.06571115, ..., -0.00730964,\n           0.03190067,  0.04929996],\n         [ 0.15582205,  0.04126063, -0.11644242, ...,  0.1778791 ,\n          -0.13108164,  0.10819105],\n         [-0.23720893,  0.27776513,  0.084771  , ..., -0.04624766,\n           0.21206132,  0.07303346],\n         ...,\n         [-0.13782533,  0.13409404,  0.14941959, ..., -0.00400917,\n           0.13004081, -0.09474001],\n         [ 0.05775578, -0.1817601 , -0.10625485, ..., -0.02392761,\n          -0.18189439,  0.11780782],\n         [ 0.0129387 , -0.00960935,  0.01789157, ..., -0.10858694,\n          -0.09426206, -0.05776041]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[ 9.04455483e-02, -2.07184792e-01, -9.92554501e-02, ...,\n           1.14745311e-01,  1.09404944e-01, -7.08919689e-02],\n         [ 4.27216664e-02, -3.43268782e-01,  1.29004762e-01, ...,\n          -4.02653702e-02, -1.55820921e-01,  2.10245699e-01],\n         [ 6.75961301e-02,  1.45427153e-01,  4.89846796e-01, ...,\n           3.67045432e-01, -3.00594211e-01, -1.52926058e-01],\n         ...,\n         [ 2.75346041e-01, -3.11970025e-01, -4.46407646e-02, ...,\n           4.62386698e-01, -1.54344216e-01, -1.98008284e-01],\n         [-4.69537109e-01, -1.80055812e-01, -2.10313588e-01, ...,\n          -3.78822953e-01, -2.55688250e-01, -1.42059296e-01],\n         [-1.88061409e-02,  3.61227285e-04,  4.33175772e-01, ...,\n          -2.52818614e-01, -2.48124629e-01,  7.25146569e-03]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_904/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_861/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.06218434, -0.02912119,  0.02528213, ..., -0.06105898,\n           0.00827789,  0.01344541],\n         [-0.04778626,  0.07393913,  0.00090825, ...,  0.02585004,\n           0.06451119,  0.0195078 ],\n         [ 0.07892776,  0.05214995, -0.02863943, ..., -0.05960136,\n          -0.04461313, -0.01483198],\n         ...,\n         [-0.00203958,  0.02563635,  0.0337376 , ...,  0.03392703,\n          -0.02019267,  0.00203115],\n         [-0.02177941,  0.02133331,  0.00691758, ...,  0.00056913,\n           0.01574793, -0.06987429],\n         [ 0.02815631, -0.07254051, -0.05622057, ...,  0.05674487,\n          -0.02285005,  0.06077871]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.09860171, -0.11219367,  0.0709422 , ...,  0.08694396,\n           0.18968357,  0.10887267],\n         [-0.01329385,  0.12000927, -0.11050098, ...,  0.11348261,\n          -0.05166499, -0.01582274],\n         [ 0.09126663,  0.20365034,  0.03514957, ..., -0.03547748,\n          -0.00111086, -0.07441013],\n         ...,\n         [ 0.03441123, -0.1054856 , -0.05878557, ..., -0.04722461,\n          -0.04590106, -0.1330409 ],\n         [-0.07849413, -0.15322424, -0.13777962, ...,  0.10463468,\n           0.09271255,  0.14085548],\n         [-0.10808384, -0.16496061,  0.08698642, ...,  0.01723261,\n           0.07496623,  0.09839762]]]], dtype=float32)>, <tf.Variable 'conv2d_845/kernel:0' shape=(1, 1, 80, 40) dtype=float32, numpy=\narray([[[[-0.19312444,  0.0357251 ,  0.01952331, ..., -0.01949608,\n          -0.12020243,  0.0675675 ],\n         [-0.09228604, -0.12264537,  0.15288417, ..., -0.10980439,\n          -0.00611857,  0.02119552],\n         [-0.11897351, -0.06030397,  0.17962353, ..., -0.00189233,\n           0.22617678,  0.11639097],\n         ...,\n         [-0.06119209,  0.13107713, -0.00023754, ..., -0.11844175,\n          -0.0159166 , -0.0230818 ],\n         [ 0.11544303, -0.0404611 ,  0.10752261, ...,  0.04909577,\n          -0.08193842, -0.19968154],\n         [ 0.03710693,  0.13424017, -0.03987942, ...,  0.04734444,\n          -0.05461815, -0.14645886]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_892/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_908/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_871/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_848/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_884/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 3, 96) dtype=float32, numpy=\narray([[[[-0.8593429 , -0.6109924 ,  0.36287078,  0.45430574,\n           0.14662363, -0.46694908,  0.44328102,  0.40329054,\n           0.36155355,  0.18604578, -0.94025755,  0.95838004,\n          -0.76577735,  1.213723  , -0.68889666, -0.16700104,\n          -0.74892443, -1.1795899 , -0.8641835 , -0.30184627,\n           0.63804334, -0.32673252, -0.3049658 , -0.22566764,\n           0.91246814,  0.50334316, -0.5088513 , -0.437984  ,\n          -0.65780735,  0.0071061 ,  0.50954175, -0.26528206,\n           0.7372988 , -0.75061214,  0.3759602 ,  0.2658918 ,\n          -0.06775504, -0.7239791 , -0.5217252 ,  0.47276732,\n          -0.5091465 ,  0.21450779,  0.34305522, -0.6261916 ,\n           0.29846773,  0.7305226 ,  1.1869324 , -0.75986063,\n           0.7797713 ,  0.13992728, -0.07813749,  0.10864262,\n           0.7253289 , -0.36918446, -1.2462404 ,  0.29151687,\n           0.95042956, -0.43650752, -0.60653543,  0.04379154,\n           0.12984595,  0.71820587,  0.69131374,  0.12424265,\n          -0.30545488, -0.4368651 , -0.7535283 ,  0.48615748,\n           0.72840834,  1.0319091 ,  0.859103  ,  0.64009833,\n           0.49592033, -0.04839873, -0.21526663, -0.18156706,\n          -0.23926209, -0.78757334,  0.4112407 ,  0.6257132 ,\n           0.8758807 ,  0.67707735, -0.03155694, -0.36504424,\n          -0.4371244 ,  0.67949617,  0.66544366, -0.11875213,\n           0.75677997,  0.824948  ,  0.05948771, -0.51029384,\n          -0.32522076,  0.16038771,  0.9327282 ,  0.30767703],\n         [-0.5149336 , -0.16470696,  0.31653985, -0.16991876,\n          -0.0901171 ,  0.842091  , -0.9595922 ,  0.4612894 ,\n           1.0868502 ,  0.9509355 , -0.04431336, -0.2887685 ,\n          -0.14857617, -0.27049974,  0.3779367 ,  0.5350244 ,\n           0.21228361,  0.5017787 , -0.03958563,  0.5398204 ,\n           0.7143424 ,  0.46369573, -0.57510746,  0.6716289 ,\n          -0.85309744,  0.18525329, -0.20368175,  0.09259929,\n           0.27726224, -0.66497225,  0.38098735,  0.22189927,\n          -0.42487353, -0.25962558,  0.4879799 ,  0.06922325,\n          -0.2949499 ,  0.38467517,  0.4912171 , -0.3304667 ,\n          -0.08945231, -1.3060173 , -0.4923653 ,  0.01481713,\n           0.6855385 , -0.131608  ,  0.29371914,  0.617395  ,\n           0.4626659 , -0.05616185,  0.15508533, -0.3404533 ,\n           0.152904  , -0.22411352,  0.36773992,  0.19951057,\n           0.4924971 , -0.11172747,  0.09707072, -0.19990876,\n          -0.12556368,  1.1386222 , -0.34875035,  0.03312385,\n          -0.20032091, -0.11300383,  0.84240663,  0.1291132 ,\n          -0.7391954 , -1.1676342 ,  0.33909613, -0.40474394,\n          -0.22760735,  0.27282873, -0.38112888, -0.37546006,\n           0.7538182 ,  0.5045261 ,  1.1025451 , -0.30221808,\n          -0.80742127, -0.2066607 , -0.24623291,  0.1884451 ,\n           0.044443  ,  0.66836005,  0.9218799 ,  0.34738305,\n          -0.7384581 ,  0.8018028 ,  0.26269802, -0.50505793,\n          -0.5469436 , -0.41108543,  1.0984261 ,  0.3808754 ],\n         [-0.3181677 ,  0.3926193 , -0.24732952,  0.7514955 ,\n          -0.37740493,  0.60732955,  0.22855878, -0.36008295,\n          -0.94813   ,  0.16374506, -0.80468255,  0.11867169,\n          -0.22354127, -0.1988464 , -0.17168859, -0.1275264 ,\n          -0.17421068,  0.5361863 , -0.39278293,  0.21524292,\n          -0.8568358 , -0.36071274, -0.22772855, -0.25146058,\n          -0.21862538,  0.4152325 , -0.5275163 ,  0.5676322 ,\n          -0.8980084 , -0.3808319 ,  0.01031865,  1.1934484 ,\n           0.13256325,  0.94505733, -0.47729507, -0.8778686 ,\n          -0.79745376,  1.2455444 , -0.12721737,  0.38777995,\n          -0.12185254, -0.54620564,  0.4413523 , -0.00657901,\n          -0.18665062,  0.05991966, -0.03109413, -0.8999574 ,\n          -0.42473194,  0.6517911 ,  1.0288966 ,  0.24611346,\n           0.8151978 ,  0.18124261, -0.3569229 , -0.22670203,\n          -0.264546  ,  0.33624667, -0.9034328 , -0.5437337 ,\n          -1.2012364 , -0.0924942 , -0.40718198,  0.41623724,\n          -0.79206127, -0.6891899 ,  0.19105347,  1.2648487 ,\n          -0.331584  ,  1.1567346 ,  0.47548437,  0.3004957 ,\n          -0.6069525 , -0.82851535, -0.1622208 ,  0.2856439 ,\n          -0.06693541, -0.8659546 , -0.3870505 ,  0.45674446,\n           0.21934836, -0.0392806 ,  0.41481543, -0.5834661 ,\n          -1.159805  ,  0.3857798 ,  1.0796093 , -1.0500197 ,\n          -0.5846484 ,  0.6644391 ,  0.19117105,  0.6010996 ,\n          -0.2686303 ,  0.5102761 ,  0.02802917,  0.14588255]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/conv2d/kernel:0' shape=(1, 1, 40, 240) dtype=float32, numpy=\narray([[[[-0.03580589, -0.03718453,  0.09063021, ...,  0.2840908 ,\n           0.0600919 ,  0.12841374],\n         [ 0.12966247, -0.04607128, -0.05790869, ..., -0.31139356,\n          -0.13142434,  0.14053947],\n         [-0.12613043, -0.11303505,  0.13390559, ..., -0.01209663,\n           0.15497226,  0.22257319],\n         ...,\n         [ 0.1730419 ,  0.12086028, -0.04780838, ...,  0.04298738,\n           0.16725871, -0.32186684],\n         [ 0.1727904 ,  0.1389913 , -0.14906678, ...,  0.08908752,\n          -0.13282941,  0.04531224],\n         [ 0.3381272 , -0.05858222,  0.05869281, ...,  0.21563582,\n          -0.00696808, -0.10495767]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.04094838, -0.01697714, -0.02476349, ..., -0.01517121,\n          -0.05534598, -0.0133063 ],\n         [-0.01546451,  0.08713336,  0.03070217, ...,  0.03287918,\n           0.0441424 ,  0.0240233 ],\n         [-0.06429084,  0.0282733 ,  0.07640268, ...,  0.0755832 ,\n          -0.06094262, -0.03022468],\n         ...,\n         [-0.05749188,  0.00406919, -0.04209737, ...,  0.01730248,\n           0.0636812 , -0.0345047 ],\n         [-0.004345  ,  0.03219265, -0.00685621, ..., -0.07859609,\n           0.06323933, -0.05358142],\n         [ 0.02457728,  0.0408018 , -0.00118632, ..., -0.03826384,\n           0.07124622, -0.05614092]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/gamma:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 7.5099856e-02, -8.9831585e-03, -1.7786924e-02, ...,\n           8.0594085e-02, -8.1487805e-02,  3.0029789e-02],\n         [ 1.7842339e-02,  2.9523984e-02, -8.1233755e-03, ...,\n           1.9957755e-02, -5.6560870e-02, -2.5081730e-05],\n         [-1.5797760e-02, -2.6927613e-02,  2.2581900e-02, ...,\n          -9.3783578e-03, -6.0688374e-03, -2.5263911e-02],\n         ...,\n         [-3.8226977e-02,  2.5025753e-02,  1.4250455e-02, ...,\n          -6.4321011e-02, -3.0882681e-02, -3.3604253e-02],\n         [ 7.7694997e-02, -4.3030303e-02,  4.2262655e-02, ...,\n           2.2949072e-02, -7.2324507e-02,  2.7398553e-03],\n         [-3.1653494e-02,  1.0344838e-02, -2.9931890e-02, ...,\n           5.8528718e-02, -3.8647234e-02, -1.0123580e-02]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/squeeze_excitation/conv2d_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_353/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.13849488],\n         [ 0.02897866],\n         [-0.07185471],\n         [-0.16313478],\n         [-0.06370933],\n         [ 0.08449882],\n         [-0.09591664],\n         [ 0.13218993],\n         [ 0.03371559],\n         [ 0.14078301],\n         [ 0.05277188],\n         [-0.04513314],\n         [-0.10746551],\n         [ 0.1301198 ],\n         [-0.12517352],\n         [-0.00607796],\n         [-0.04420073],\n         [-0.01560271],\n         [-0.10181466],\n         [-0.12030029],\n         [ 0.03560224],\n         [ 0.10298756],\n         [ 0.09315181],\n         [ 0.06096803]],\n\n        [[ 0.1289083 ],\n         [-0.13086674],\n         [-0.00188552],\n         [ 0.13375822],\n         [-0.05067164],\n         [ 0.06413913],\n         [-0.03335604],\n         [-0.08779264],\n         [-0.07066435],\n         [ 0.03209385],\n         [-0.00485015],\n         [-0.06488166],\n         [ 0.01330392],\n         [ 0.01405156],\n         [-0.12815717],\n         [-0.10817936],\n         [-0.05917124],\n         [-0.12819333],\n         [-0.09434272],\n         [-0.04462093],\n         [-0.03463961],\n         [ 0.08506422],\n         [-0.07328302],\n         [ 0.11587828]],\n\n        [[ 0.10083047],\n         [ 0.09766015],\n         [ 0.00050169],\n         [-0.12740344],\n         [-0.08339427],\n         [-0.11373359],\n         [-0.01170456],\n         [-0.07792348],\n         [-0.02138443],\n         [ 0.14089778],\n         [ 0.10965672],\n         [-0.04187164],\n         [-0.07663396],\n         [-0.01406012],\n         [ 0.16258112],\n         [ 0.12789953],\n         [-0.09293009],\n         [ 0.09892866],\n         [-0.00890462],\n         [-0.08325501],\n         [-0.11338755],\n         [ 0.00055796],\n         [ 0.15617815],\n         [ 0.16254085]]],\n\n\n       [[[ 0.05785306],\n         [-0.02455457],\n         [-0.14726865],\n         [-0.01772518],\n         [-0.08700296],\n         [-0.1356391 ],\n         [ 0.1537045 ],\n         [-0.14312136],\n         [-0.16197842],\n         [ 0.13620618],\n         [ 0.04348142],\n         [-0.1349677 ],\n         [ 0.10783952],\n         [ 0.11449111],\n         [-0.05310293],\n         [-0.00686146],\n         [ 0.03816858],\n         [-0.0661655 ],\n         [-0.02866369],\n         [ 0.13562939],\n         [ 0.11119592],\n         [ 0.09225491],\n         [-0.11073255],\n         [-0.04627149]],\n\n        [[-0.09527521],\n         [ 0.0263105 ],\n         [ 0.12082401],\n         [ 0.16120282],\n         [ 0.12034109],\n         [-0.02056006],\n         [ 0.10700285],\n         [-0.0173223 ],\n         [-0.0571215 ],\n         [-0.04807582],\n         [ 0.11205998],\n         [-0.10625277],\n         [ 0.12528017],\n         [ 0.1247215 ],\n         [-0.11606404],\n         [ 0.0836274 ],\n         [ 0.08162206],\n         [ 0.09087798],\n         [-0.01115549],\n         [ 0.02544217],\n         [-0.07372694],\n         [ 0.00969583],\n         [-0.10373724],\n         [-0.09142876]],\n\n        [[-0.01747854],\n         [-0.09289146],\n         [ 0.13116187],\n         [ 0.00941414],\n         [-0.16147485],\n         [-0.05920437],\n         [ 0.14826769],\n         [ 0.12216702],\n         [-0.04528728],\n         [-0.13535933],\n         [-0.03953617],\n         [-0.13990627],\n         [ 0.02382432],\n         [-0.10780552],\n         [ 0.07998529],\n         [ 0.13866073],\n         [ 0.09606892],\n         [-0.01306958],\n         [-0.02496515],\n         [-0.02547172],\n         [-0.00026315],\n         [-0.08821733],\n         [ 0.06392771],\n         [-0.14167696]]],\n\n\n       [[[-0.0934789 ],\n         [ 0.10967278],\n         [-0.02268095],\n         [-0.03492032],\n         [ 0.11339512],\n         [ 0.07917415],\n         [-0.16083245],\n         [ 0.04575776],\n         [ 0.04448517],\n         [ 0.08861175],\n         [ 0.00100951],\n         [-0.1622566 ],\n         [ 0.05607858],\n         [ 0.07968107],\n         [-0.09459761],\n         [-0.13017619],\n         [ 0.16299564],\n         [ 0.12090075],\n         [-0.12790655],\n         [-0.09997084],\n         [-0.04945968],\n         [-0.09769723],\n         [ 0.15370592],\n         [-0.01436058]],\n\n        [[ 0.00155622],\n         [-0.02179335],\n         [ 0.07990396],\n         [ 0.1631676 ],\n         [-0.13359179],\n         [-0.04661316],\n         [ 0.1425178 ],\n         [ 0.11671162],\n         [-0.1062787 ],\n         [ 0.07332212],\n         [ 0.05208018],\n         [ 0.06097203],\n         [-0.05572534],\n         [ 0.01191519],\n         [ 0.01859282],\n         [-0.08418649],\n         [-0.07508659],\n         [-0.06353476],\n         [-0.08970284],\n         [ 0.10558009],\n         [-0.08706338],\n         [-0.1299974 ],\n         [ 0.06256886],\n         [ 0.01166372]],\n\n        [[-0.00765508],\n         [-0.14113945],\n         [ 0.08079234],\n         [-0.10584214],\n         [-0.02799076],\n         [-0.08138246],\n         [ 0.02568609],\n         [-0.06525726],\n         [-0.08336831],\n         [-0.04966214],\n         [-0.05686022],\n         [ 0.04603559],\n         [ 0.03964721],\n         [ 0.13066441],\n         [-0.02188641],\n         [ 0.0215814 ],\n         [-0.06033399],\n         [ 0.03386502],\n         [-0.05600457],\n         [ 0.04908063],\n         [-0.02449323],\n         [ 0.09225911],\n         [-0.12986058],\n         [ 0.01486866]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 240, 8) dtype=float32, numpy=\narray([[[[ 3.4974236e-02,  4.0096171e-02, -1.8591153e-02, ...,\n          -3.2003436e-02, -7.9247683e-02,  8.4725231e-02],\n         [-7.8437433e-02, -2.3399906e-02,  9.0212069e-02, ...,\n          -3.8341627e-02, -3.0448733e-02, -1.3374437e-02],\n         [-6.9455549e-02, -1.6197116e-03,  1.4379847e-02, ...,\n           2.1526795e-02, -1.2121414e-01,  9.6624739e-02],\n         ...,\n         [-1.5014499e-02,  2.7963048e-05,  2.6916457e-02, ...,\n          -3.9851893e-02, -5.5315755e-02, -7.9558380e-02],\n         [ 5.3736931e-03,  9.1576524e-02, -4.8750237e-02, ...,\n          -3.8119044e-02,  9.3422614e-02,  3.1993296e-02],\n         [-1.1105114e-01,  9.2410639e-02, -1.3369443e-01, ...,\n          -3.4973089e-02, -3.0608911e-02,  1.3594982e-01]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/moving_variance:0' shape=(16,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/squeeze_excitation/conv2d_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_860/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.02017228],\n         [-0.01151623],\n         [-0.00789383],\n         ...,\n         [ 0.00484896],\n         [ 0.01367104],\n         [ 0.00623519]],\n\n        [[ 0.00044052],\n         [ 0.02443755],\n         [-0.00860939],\n         ...,\n         [-0.00219958],\n         [ 0.00124043],\n         [ 0.00480329]],\n\n        [[ 0.01082526],\n         [ 0.0115036 ],\n         [-0.02170265],\n         ...,\n         [ 0.02083252],\n         [ 0.00915166],\n         [ 0.0230524 ]]],\n\n\n       [[[-0.01161856],\n         [ 0.02521697],\n         [ 0.0076262 ],\n         ...,\n         [ 0.00082509],\n         [-0.00126224],\n         [ 0.00825271]],\n\n        [[-0.01537788],\n         [ 0.0225614 ],\n         [ 0.01172892],\n         ...,\n         [-0.00044733],\n         [ 0.00332063],\n         [ 0.01808693]],\n\n        [[-0.01314352],\n         [-0.003966  ],\n         [-0.02428772],\n         ...,\n         [ 0.01708915],\n         [-0.01331055],\n         [-0.00778214]]],\n\n\n       [[[ 0.00837127],\n         [-0.01023646],\n         [-0.0141609 ],\n         ...,\n         [-0.01595775],\n         [-0.02467681],\n         [ 0.01089629]],\n\n        [[-0.0003353 ],\n         [-0.01173409],\n         [-0.01102669],\n         ...,\n         [-0.02343264],\n         [-0.02184847],\n         [ 0.01711092]],\n\n        [[-0.00066283],\n         [-0.01914847],\n         [-0.01192349],\n         ...,\n         [ 0.00704022],\n         [ 0.00017623],\n         [ 0.01328891]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_355/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.09269446],\n         [-0.01288679],\n         [ 0.06708951],\n         [-0.06255546],\n         [ 0.12168574],\n         [ 0.10496387],\n         [ 0.04545474],\n         [-0.10202396],\n         [-0.13733108],\n         [ 0.13268262],\n         [-0.13912818],\n         [-0.1320993 ],\n         [ 0.01688986],\n         [ 0.03911191],\n         [ 0.01015015],\n         [-0.12454732],\n         [ 0.07805601],\n         [-0.06554677],\n         [-0.05939475],\n         [ 0.13075036],\n         [-0.04195975],\n         [-0.06328613],\n         [-0.02970126],\n         [ 0.12993541]],\n\n        [[ 0.08413389],\n         [-0.11934552],\n         [ 0.01912406],\n         [-0.160735  ],\n         [-0.0731503 ],\n         [ 0.07060362],\n         [ 0.11601949],\n         [ 0.15515578],\n         [-0.10723001],\n         [ 0.00271535],\n         [-0.05833214],\n         [ 0.08732694],\n         [-0.12123305],\n         [-0.1452452 ],\n         [-0.00541991],\n         [ 0.10782027],\n         [-0.0072756 ],\n         [ 0.13823882],\n         [ 0.09904993],\n         [ 0.01572809],\n         [-0.12993568],\n         [-0.11935167],\n         [ 0.10636064],\n         [-0.0721047 ]],\n\n        [[-0.03184289],\n         [-0.03854185],\n         [ 0.07815008],\n         [-0.08041282],\n         [ 0.1288842 ],\n         [ 0.09504798],\n         [ 0.03231831],\n         [-0.0126072 ],\n         [-0.13856263],\n         [ 0.03962275],\n         [-0.10303631],\n         [ 0.04475491],\n         [-0.01651007],\n         [-0.03154221],\n         [-0.1412346 ],\n         [ 0.13627812],\n         [-0.0795557 ],\n         [-0.11119356],\n         [ 0.04392433],\n         [ 0.06009938],\n         [-0.11693202],\n         [-0.14295442],\n         [ 0.03680097],\n         [-0.12765804]]],\n\n\n       [[[ 0.0483074 ],\n         [-0.11818016],\n         [-0.00753559],\n         [-0.06340686],\n         [ 0.06363264],\n         [ 0.11563954],\n         [-0.0348106 ],\n         [ 0.04858722],\n         [ 0.13422772],\n         [-0.043624  ],\n         [-0.1470414 ],\n         [ 0.06906699],\n         [ 0.06273821],\n         [ 0.03705294],\n         [-0.10490952],\n         [-0.03354752],\n         [-0.09529826],\n         [-0.0415912 ],\n         [-0.04517835],\n         [ 0.04118162],\n         [-0.0210961 ],\n         [-0.04940587],\n         [ 0.02069998],\n         [ 0.09116167]],\n\n        [[-0.13297118],\n         [ 0.15001136],\n         [-0.02755992],\n         [-0.12241368],\n         [ 0.01992279],\n         [ 0.06407948],\n         [-0.06437288],\n         [ 0.00943065],\n         [ 0.14539641],\n         [ 0.1001541 ],\n         [-0.07872342],\n         [-0.14381614],\n         [-0.08720973],\n         [-0.041499  ],\n         [-0.00571515],\n         [ 0.01406628],\n         [-0.05493507],\n         [-0.00952733],\n         [-0.15234894],\n         [-0.06869525],\n         [ 0.04272585],\n         [-0.1039326 ],\n         [ 0.10173959],\n         [ 0.0951407 ]],\n\n        [[-0.01209678],\n         [-0.10130338],\n         [-0.02303934],\n         [-0.139551  ],\n         [ 0.13466263],\n         [ 0.05279757],\n         [-0.02733119],\n         [ 0.14191648],\n         [ 0.0677093 ],\n         [-0.06976175],\n         [ 0.07574196],\n         [-0.04425963],\n         [ 0.12402746],\n         [-0.1598713 ],\n         [-0.00876325],\n         [ 0.0572045 ],\n         [ 0.08567087],\n         [ 0.06938547],\n         [-0.15256217],\n         [-0.15812738],\n         [ 0.07876873],\n         [-0.1316569 ],\n         [ 0.06263675],\n         [-0.03180766]]],\n\n\n       [[[ 0.07397492],\n         [ 0.10051706],\n         [-0.03205508],\n         [-0.04766098],\n         [ 0.01373401],\n         [ 0.16122478],\n         [-0.0163205 ],\n         [-0.05664468],\n         [ 0.0171812 ],\n         [ 0.10179979],\n         [ 0.0593221 ],\n         [-0.14177173],\n         [ 0.08279306],\n         [-0.1401204 ],\n         [-0.0993349 ],\n         [-0.1573097 ],\n         [ 0.03865817],\n         [ 0.09140867],\n         [-0.10799669],\n         [-0.04494482],\n         [-0.07470375],\n         [-0.14041622],\n         [ 0.10016131],\n         [-0.15711935]],\n\n        [[ 0.14849514],\n         [-0.13938491],\n         [ 0.04092151],\n         [-0.14479437],\n         [-0.13778949],\n         [ 0.03896116],\n         [ 0.09166905],\n         [ 0.03831318],\n         [-0.01095051],\n         [ 0.13168657],\n         [ 0.00416721],\n         [ 0.13576624],\n         [-0.05778259],\n         [-0.06010428],\n         [-0.04157282],\n         [ 0.08086531],\n         [-0.11566941],\n         [-0.1401071 ],\n         [ 0.11043647],\n         [-0.02235334],\n         [ 0.05919752],\n         [-0.02376911],\n         [ 0.03531316],\n         [ 0.00431439]],\n\n        [[-0.01478989],\n         [-0.0404054 ],\n         [ 0.01434259],\n         [ 0.11781424],\n         [-0.12623766],\n         [ 0.10526732],\n         [-0.13766132],\n         [ 0.15785667],\n         [-0.14722706],\n         [-0.06357684],\n         [-0.02407852],\n         [ 0.12087491],\n         [-0.15142843],\n         [ 0.00590762],\n         [-0.1347552 ],\n         [-0.00799976],\n         [ 0.15857908],\n         [ 0.02078167],\n         [ 0.00017855],\n         [ 0.00757048],\n         [ 0.00604378],\n         [ 0.0099538 ],\n         [ 0.02369763],\n         [-0.04869989]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/squeeze_excitation/conv2d_3/bias:0' shape=(96,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_869/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.10592639, -0.17026709, -0.07162118, ...,  0.02469771,\n          -0.156245  , -0.09833174],\n         [ 0.09968647,  0.21304305, -0.03984497, ..., -0.07341669,\n          -0.20432045,  0.11369864],\n         [-0.15301932, -0.10845814, -0.04094265, ...,  0.19014755,\n           0.07070048,  0.05079155],\n         ...,\n         [ 0.03690203,  0.02658478,  0.06377494, ..., -0.0372372 ,\n          -0.01185   , -0.16090263],\n         [-0.12691054,  0.03265052,  0.1367361 , ..., -0.01871606,\n          -0.07647292,  0.16047268],\n         [-0.05541273,  0.03420696,  0.00142948, ...,  0.12095267,\n          -0.07917752,  0.16956376]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.01155742, -0.00524791, -0.04753219, ..., -0.03320216,\n           0.03468966,  0.02906549],\n         [ 0.00650545,  0.0076134 , -0.02321688, ...,  0.02695363,\n          -0.04825719, -0.01543849],\n         [ 0.07276434, -0.03177005,  0.05419445, ...,  0.07522202,\n           0.05643095, -0.00412206],\n         ...,\n         [-0.01949945, -0.04551144,  0.03964258, ..., -0.02649692,\n           0.00759518,  0.0207909 ],\n         [-0.03894961,  0.01449677, -0.01115661, ...,  0.05769029,\n           0.03066368, -0.00863155],\n         [ 0.01153878,  0.00901201, -0.02214593, ...,  0.06698662,\n          -0.02741809, -0.04417448]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_853/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.16193387, -0.37508973,  0.08705277, ...,  0.01701975,\n           0.15192893, -0.04754537],\n         [ 0.02943505,  0.19256023,  0.2590664 , ...,  0.35520983,\n          -0.00518594, -0.00350543],\n         [ 0.4648605 , -0.2680278 ,  0.22158462, ..., -0.11250801,\n           0.21562612,  0.10423541],\n         ...,\n         [-0.31060377, -0.17255054,  0.20477678, ...,  0.12670554,\n           0.08347422, -0.16853902],\n         [ 0.37753522, -0.10106166,  0.21652375, ..., -0.14339328,\n           0.05991311, -0.31484053],\n         [ 0.17065421, -0.0329602 ,  0.07007157, ...,  0.13431372,\n          -0.10313313, -0.05288402]]]], dtype=float32)>, <tf.Variable 'conv2d_849/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.0351841 ,  0.23216508, -0.11201655, ..., -0.09371081,\n           0.07142515,  0.11072045],\n         [ 0.06653243, -0.12167284,  0.02268673, ..., -0.11387742,\n          -0.21050474, -0.06499572],\n         [ 0.17949948, -0.1845357 ,  0.21261455, ...,  0.03640857,\n           0.13286114, -0.06381626],\n         ...,\n         [ 0.04578014, -0.10260485,  0.07663377, ...,  0.11811225,\n           0.03447432,  0.00667574],\n         [ 0.01730198, -0.13425732,  0.00642166, ...,  0.16024661,\n          -0.05570469,  0.04722622],\n         [ 0.08311965, -0.07642876,  0.15479963, ...,  0.17699969,\n           0.08706012,  0.01549458]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_856/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[ 0.01865456,  0.02448711,  0.06336626, ...,  0.01863312,\n           0.06645602, -0.01027271],\n         [-0.05046976, -0.07778978,  0.0923899 , ...,  0.07419171,\n          -0.08859947,  0.00970246],\n         [ 0.06254003,  0.02266415, -0.04971264, ...,  0.05631211,\n          -0.09927698,  0.04001227],\n         ...,\n         [-0.0252409 , -0.05158851, -0.06827082, ..., -0.0460006 ,\n           0.05745228,  0.06582876],\n         [-0.02060892, -0.04300323, -0.00547198, ...,  0.03776245,\n          -0.05827299,  0.03000936],\n         [ 0.00457463, -0.06207519,  0.042109  , ..., -0.02820795,\n           0.07345182, -0.06322144]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_900/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_883/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_351/depthwise_kernel:0' shape=(3, 3, 16, 1) dtype=float32, numpy=\narray([[[[-0.18156898],\n         [ 0.19505154],\n         [ 0.12156393],\n         [ 0.02849521],\n         [-0.13632303],\n         [-0.0960763 ],\n         [ 0.05003363],\n         [ 0.10355498],\n         [ 0.01060599],\n         [-0.04266867],\n         [-0.13654622],\n         [ 0.18727376],\n         [ 0.02451327],\n         [ 0.17977022],\n         [ 0.13572358],\n         [ 0.00656609]],\n\n        [[-0.16418095],\n         [-0.04750711],\n         [-0.05908103],\n         [ 0.12219118],\n         [ 0.05839451],\n         [-0.00379916],\n         [ 0.06902014],\n         [-0.01142336],\n         [-0.09227902],\n         [ 0.12532367],\n         [ 0.02946818],\n         [ 0.01296528],\n         [ 0.01123323],\n         [-0.05944246],\n         [-0.07007948],\n         [ 0.03112119]],\n\n        [[-0.00334752],\n         [-0.04870947],\n         [ 0.12945266],\n         [ 0.03037643],\n         [ 0.05273323],\n         [ 0.1808352 ],\n         [ 0.13996442],\n         [-0.19378418],\n         [ 0.08197828],\n         [ 0.18762355],\n         [ 0.13652964],\n         [-0.18967997],\n         [ 0.14133559],\n         [ 0.13443165],\n         [-0.07212397],\n         [ 0.12348302]]],\n\n\n       [[[-0.15704367],\n         [-0.17987463],\n         [-0.14626706],\n         [ 0.06493117],\n         [-0.10852023],\n         [ 0.08941413],\n         [ 0.02448201],\n         [ 0.07179783],\n         [ 0.10626198],\n         [ 0.10289763],\n         [-0.0161633 ],\n         [-0.15579174],\n         [ 0.10292868],\n         [ 0.05571733],\n         [-0.03318594],\n         [ 0.19201557]],\n\n        [[-0.10133867],\n         [-0.04271537],\n         [-0.12265202],\n         [-0.11693847],\n         [ 0.16743277],\n         [ 0.01850998],\n         [ 0.13967718],\n         [-0.00180532],\n         [-0.10186317],\n         [-0.10008807],\n         [-0.00190352],\n         [-0.1433066 ],\n         [-0.08448618],\n         [ 0.18880527],\n         [ 0.00458187],\n         [ 0.15746965]],\n\n        [[ 0.09598999],\n         [-0.11429355],\n         [ 0.09206222],\n         [ 0.03717443],\n         [ 0.17919262],\n         [ 0.16423129],\n         [-0.09106095],\n         [ 0.17646314],\n         [ 0.13589911],\n         [-0.05981819],\n         [-0.15076658],\n         [ 0.07567169],\n         [-0.07332292],\n         [-0.01439539],\n         [-0.19669236],\n         [ 0.0540788 ]]],\n\n\n       [[[-0.0592943 ],\n         [-0.05214687],\n         [ 0.1332853 ],\n         [-0.11282038],\n         [ 0.13121663],\n         [-0.03615089],\n         [-0.02158625],\n         [ 0.04025388],\n         [ 0.06182109],\n         [ 0.01381116],\n         [-0.10889266],\n         [ 0.12934671],\n         [-0.180569  ],\n         [-0.16137668],\n         [-0.0137952 ],\n         [ 0.00117974]],\n\n        [[ 0.13385583],\n         [ 0.14412688],\n         [ 0.16242118],\n         [-0.03222406],\n         [ 0.0567355 ],\n         [-0.10840352],\n         [-0.01351918],\n         [ 0.03361957],\n         [ 0.18568628],\n         [ 0.172716  ],\n         [ 0.05416353],\n         [-0.19283177],\n         [ 0.07712828],\n         [-0.01229554],\n         [-0.03825763],\n         [-0.15312935]],\n\n        [[-0.16509143],\n         [-0.07275805],\n         [-0.11268309],\n         [-0.11943939],\n         [ 0.07618068],\n         [-0.12953746],\n         [ 0.17552923],\n         [-0.08020052],\n         [-0.07263733],\n         [-0.00589035],\n         [ 0.05329488],\n         [-0.16969611],\n         [-0.16413625],\n         [ 0.11075388],\n         [ 0.06341593],\n         [ 0.08046152]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 0.00837232],\n         [-0.01258322],\n         [ 0.02133762],\n         ...,\n         [-0.00911685],\n         [-0.00111898],\n         [ 0.00674527]],\n\n        [[ 0.00736733],\n         [ 0.00937208],\n         [ 0.00607242],\n         ...,\n         [ 0.01452898],\n         [ 0.01414894],\n         [-0.00861313]],\n\n        [[-0.02222398],\n         [ 0.0035272 ],\n         [-0.00516614],\n         ...,\n         [ 0.00895134],\n         [-0.01209036],\n         [-0.00396691]]],\n\n\n       [[[-0.01443637],\n         [-0.02711247],\n         [-0.01229688],\n         ...,\n         [ 0.0080577 ],\n         [ 0.01007586],\n         [ 0.00142359]],\n\n        [[ 0.02332135],\n         [-0.01557416],\n         [ 0.01482667],\n         ...,\n         [-0.01860106],\n         [ 0.00421439],\n         [ 0.00445065]],\n\n        [[-0.00238347],\n         [-0.01076152],\n         [ 0.01432462],\n         ...,\n         [ 0.00475441],\n         [-0.01577962],\n         [ 0.00436   ]]],\n\n\n       [[[ 0.0114054 ],\n         [-0.00764033],\n         [ 0.01824616],\n         ...,\n         [-0.01345986],\n         [ 0.00701949],\n         [ 0.00367641]],\n\n        [[-0.01555288],\n         [-0.0027579 ],\n         [-0.01109826],\n         ...,\n         [ 0.00948778],\n         [ 0.01328037],\n         [-0.00083532]],\n\n        [[-0.01391051],\n         [ 0.01242126],\n         [ 0.00957648],\n         ...,\n         [ 0.00082009],\n         [ 0.00107349],\n         [-0.013445  ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_370/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-8.66720080e-03],\n         [-2.13127434e-02],\n         [-3.88052203e-02],\n         [ 6.42649382e-02],\n         [ 2.13145837e-02],\n         [-7.64561668e-02],\n         [-2.55294666e-02],\n         [ 1.10324845e-02],\n         [ 7.67508894e-02],\n         [-1.66203156e-02],\n         [ 8.97821337e-02],\n         [ 6.52015507e-02],\n         [-1.56597048e-03],\n         [ 3.13886926e-02],\n         [ 8.50393325e-02],\n         [-6.98380843e-02],\n         [ 3.20993811e-02],\n         [ 7.83130825e-02],\n         [-6.84964359e-02],\n         [-8.25381130e-02],\n         [-6.51107654e-02],\n         [ 8.35671723e-02],\n         [-6.77240342e-02],\n         [ 2.44721621e-02],\n         [-3.56141999e-02],\n         [-4.14163657e-02],\n         [-2.73776725e-02],\n         [ 1.09216273e-02],\n         [ 4.56602126e-02],\n         [-1.84890628e-02],\n         [-5.03567941e-02],\n         [-4.56571653e-02],\n         [-5.66402227e-02],\n         [-8.36497992e-02],\n         [-3.46601754e-02],\n         [ 6.80498481e-02],\n         [ 5.13101071e-02],\n         [-2.14021876e-02],\n         [-1.45603195e-02],\n         [ 6.17103130e-02],\n         [ 2.89156735e-02],\n         [-4.56256941e-02],\n         [-4.21318561e-02],\n         [-2.10093036e-02],\n         [-4.20958884e-02],\n         [ 8.80889595e-02],\n         [ 1.41220540e-03],\n         [-9.16565955e-03],\n         [ 8.33628178e-02],\n         [-7.29865134e-02],\n         [ 5.81384450e-02],\n         [ 1.13113150e-02],\n         [ 7.91448802e-02],\n         [-5.23621775e-02],\n         [-5.46597131e-02],\n         [ 6.22289032e-02],\n         [ 4.04786319e-03],\n         [-8.81686881e-02],\n         [ 6.32246435e-02],\n         [-8.68914947e-02],\n         [ 8.99612159e-02],\n         [-1.16892457e-02],\n         [ 2.23822072e-02],\n         [ 1.83739513e-02],\n         [ 6.49124682e-02],\n         [-8.25013816e-02],\n         [ 3.63224447e-02],\n         [-2.91193873e-02],\n         [-1.20958462e-02],\n         [ 6.74212724e-03],\n         [ 5.02381325e-02],\n         [-6.02036640e-02],\n         [-7.70059302e-02],\n         [ 4.70729768e-02],\n         [-5.99477366e-02],\n         [-1.78149343e-03],\n         [-5.38734943e-02],\n         [ 7.98156410e-02],\n         [ 6.51998371e-02],\n         [-6.06267825e-02]],\n\n        [[ 6.47040009e-02],\n         [ 2.41721347e-02],\n         [-9.01182443e-02],\n         [ 3.78489047e-02],\n         [-7.39553347e-02],\n         [-4.28463332e-02],\n         [-7.30725378e-02],\n         [-7.35043734e-02],\n         [-5.07073253e-02],\n         [-7.64100328e-02],\n         [-7.78117776e-03],\n         [ 7.64816850e-02],\n         [-6.89681992e-02],\n         [-2.94656344e-02],\n         [ 9.32216644e-05],\n         [ 8.39487463e-02],\n         [ 7.81932920e-02],\n         [ 6.78214431e-03],\n         [ 2.61025503e-02],\n         [-1.91596076e-02],\n         [-5.31842373e-02],\n         [-2.68305913e-02],\n         [-3.72442193e-02],\n         [-1.96978673e-02],\n         [-6.92160949e-02],\n         [-6.39034584e-02],\n         [ 3.76998931e-02],\n         [-3.12017277e-02],\n         [-6.85716122e-02],\n         [-3.38711217e-02],\n         [ 3.92690301e-02],\n         [-3.20080630e-02],\n         [ 3.57076228e-02],\n         [-2.59323418e-03],\n         [-1.91018805e-02],\n         [ 4.37287241e-02],\n         [ 4.36018109e-02],\n         [ 6.54489845e-02],\n         [-8.73395801e-02],\n         [-5.60364500e-02],\n         [-7.06417784e-02],\n         [-5.42678460e-02],\n         [ 2.85325944e-02],\n         [-7.92771429e-02],\n         [-5.25924712e-02],\n         [ 4.68801260e-02],\n         [ 1.49652362e-03],\n         [-1.91350579e-02],\n         [ 2.92248949e-02],\n         [ 6.26503527e-02],\n         [-4.60788161e-02],\n         [ 4.27370220e-02],\n         [ 7.56458789e-02],\n         [ 1.96570754e-02],\n         [ 2.63850540e-02],\n         [-3.72863337e-02],\n         [-6.19825386e-02],\n         [-2.67465115e-02],\n         [-1.62728801e-02],\n         [-6.86519295e-02],\n         [ 5.59081584e-02],\n         [ 3.00952047e-03],\n         [-1.70502737e-02],\n         [-1.53839812e-02],\n         [ 5.41786849e-02],\n         [ 5.23826629e-02],\n         [-4.25865166e-02],\n         [-1.21858269e-02],\n         [ 8.34462345e-02],\n         [-2.97904760e-03],\n         [ 4.49511409e-02],\n         [-8.17865133e-03],\n         [ 7.34964311e-02],\n         [ 7.08657801e-02],\n         [ 1.48458779e-02],\n         [ 3.38373333e-02],\n         [ 9.36627388e-03],\n         [ 2.34712660e-02],\n         [-6.37596846e-02],\n         [-3.82735170e-02]],\n\n        [[ 6.70440495e-03],\n         [-2.78624147e-02],\n         [-3.78119797e-02],\n         [ 8.39920640e-02],\n         [ 8.46782476e-02],\n         [ 7.44766146e-02],\n         [-4.61067185e-02],\n         [ 4.00467068e-02],\n         [-8.80319029e-02],\n         [-2.35529169e-02],\n         [ 8.82621706e-02],\n         [ 5.57739139e-02],\n         [ 4.27132398e-02],\n         [-6.93430230e-02],\n         [-4.26840670e-02],\n         [ 7.11494684e-02],\n         [ 3.49609107e-02],\n         [-3.71913798e-02],\n         [-5.37971407e-02],\n         [-8.60427171e-02],\n         [-3.08213681e-02],\n         [ 3.98330390e-04],\n         [ 5.73825985e-02],\n         [-6.33095279e-02],\n         [ 5.16120791e-02],\n         [-5.87291382e-02],\n         [-3.72196473e-02],\n         [ 1.28205717e-02],\n         [-2.67023593e-03],\n         [ 6.51233941e-02],\n         [ 4.88470346e-02],\n         [-2.30490789e-02],\n         [ 6.21873438e-02],\n         [-8.99210498e-02],\n         [ 3.04477811e-02],\n         [-8.57212767e-02],\n         [ 7.05604255e-02],\n         [-1.12945512e-02],\n         [ 6.36809915e-02],\n         [ 4.67116833e-02],\n         [-6.41801432e-02],\n         [-8.89959633e-02],\n         [ 6.47775084e-03],\n         [ 3.91512811e-02],\n         [ 3.88940275e-02],\n         [ 5.86843193e-02],\n         [-8.83258060e-02],\n         [-1.30565986e-02],\n         [-8.97243693e-02],\n         [-6.85198605e-03],\n         [ 5.94256222e-02],\n         [-8.82890150e-02],\n         [-5.27570732e-02],\n         [-6.50582910e-02],\n         [ 4.02529240e-02],\n         [-3.15060578e-02],\n         [ 1.94649547e-02],\n         [-3.47958617e-02],\n         [-3.88528034e-02],\n         [-8.61146599e-02],\n         [-5.52012809e-02],\n         [-2.53325328e-02],\n         [-4.06550206e-02],\n         [-9.01605114e-02],\n         [-7.11788088e-02],\n         [-5.25964499e-02],\n         [-2.08720192e-02],\n         [-6.18887953e-02],\n         [ 7.64862895e-02],\n         [-2.75530890e-02],\n         [ 3.88170779e-02],\n         [ 5.13875484e-03],\n         [-1.01784766e-02],\n         [ 4.67309505e-02],\n         [-6.01326749e-02],\n         [ 3.59575301e-02],\n         [-2.75589898e-02],\n         [-7.17716143e-02],\n         [ 1.73699632e-02],\n         [-7.21093863e-02]]],\n\n\n       [[[ 2.62801498e-02],\n         [ 8.14863890e-02],\n         [ 1.97267234e-02],\n         [-1.10455230e-02],\n         [-8.82565975e-03],\n         [-4.84527275e-02],\n         [-6.60223290e-02],\n         [-7.19866306e-02],\n         [-3.92277539e-03],\n         [-2.95662768e-02],\n         [-5.99202067e-02],\n         [-7.16961697e-02],\n         [-2.46731192e-03],\n         [ 1.65557340e-02],\n         [-1.12281665e-02],\n         [ 4.22407687e-03],\n         [-5.29213510e-02],\n         [ 5.10078073e-02],\n         [ 1.28445849e-02],\n         [ 8.17214996e-02],\n         [-5.48714474e-02],\n         [ 4.11119461e-02],\n         [ 8.35301578e-02],\n         [ 6.87580705e-02],\n         [ 1.83091462e-02],\n         [ 5.74252903e-02],\n         [-6.76059723e-02],\n         [ 2.96606272e-02],\n         [ 6.39719814e-02],\n         [ 1.87493786e-02],\n         [-8.30230862e-03],\n         [-6.16641343e-03],\n         [-4.12242487e-02],\n         [ 5.60820401e-02],\n         [ 4.29547131e-02],\n         [-3.97115946e-02],\n         [-6.34776354e-02],\n         [-2.74640769e-02],\n         [-6.98899925e-02],\n         [-1.63113549e-02],\n         [ 6.29158914e-02],\n         [ 8.96175206e-02],\n         [-3.01576592e-02],\n         [ 3.95234376e-02],\n         [ 8.50173831e-02],\n         [ 8.19786638e-02],\n         [ 3.79800498e-02],\n         [ 1.08044147e-02],\n         [-6.03665337e-02],\n         [-2.97432095e-02],\n         [ 7.58797824e-02],\n         [ 1.85215995e-02],\n         [ 7.20996410e-03],\n         [ 2.74261013e-02],\n         [-6.63442016e-02],\n         [ 7.90797770e-02],\n         [-3.90939340e-02],\n         [ 3.54459435e-02],\n         [-6.87695295e-02],\n         [ 8.47561359e-02],\n         [ 6.15354031e-02],\n         [ 1.00995228e-02],\n         [-5.05422279e-02],\n         [ 8.34452063e-02],\n         [-8.00335109e-02],\n         [-5.60612157e-02],\n         [-5.63906804e-02],\n         [-7.36494437e-02],\n         [ 7.85864145e-02],\n         [-7.99106583e-02],\n         [ 6.56358749e-02],\n         [-4.90115955e-02],\n         [-2.13449523e-02],\n         [-6.94891065e-02],\n         [-1.99389085e-02],\n         [ 2.17362121e-02],\n         [ 5.39780259e-02],\n         [ 2.23629177e-02],\n         [ 6.14463985e-02],\n         [-5.22234663e-02]],\n\n        [[-1.04146525e-02],\n         [ 7.11427331e-02],\n         [-8.13935325e-02],\n         [-1.18601248e-02],\n         [ 2.30892003e-02],\n         [ 1.56975016e-02],\n         [ 2.81500444e-02],\n         [-2.83871740e-02],\n         [-4.78716940e-03],\n         [ 7.75989294e-02],\n         [ 1.76681504e-02],\n         [ 3.21879834e-02],\n         [-5.42909466e-02],\n         [ 6.63600117e-02],\n         [-1.19371265e-02],\n         [ 7.57897496e-02],\n         [ 4.53603864e-02],\n         [ 6.93211108e-02],\n         [-7.00327009e-03],\n         [ 8.04007947e-02],\n         [ 1.18009001e-02],\n         [ 9.22209024e-03],\n         [ 1.60848051e-02],\n         [ 6.18357658e-02],\n         [ 5.26638031e-02],\n         [-7.56375864e-02],\n         [-3.53368223e-02],\n         [-5.06006926e-03],\n         [-8.54081213e-02],\n         [-6.75970912e-02],\n         [ 4.01512682e-02],\n         [ 3.20250019e-02],\n         [-5.59895486e-03],\n         [ 2.00522095e-02],\n         [ 6.71331584e-03],\n         [ 1.01447776e-02],\n         [ 3.89200896e-02],\n         [ 6.42025471e-03],\n         [-8.66741985e-02],\n         [-1.15655065e-02],\n         [-7.17285424e-02],\n         [ 8.74520242e-02],\n         [-6.56224862e-02],\n         [ 6.16853833e-02],\n         [ 6.89223260e-02],\n         [ 3.94560844e-02],\n         [ 9.89958644e-05],\n         [-2.37218291e-03],\n         [ 8.11796933e-02],\n         [ 2.53639370e-03],\n         [-2.99520008e-02],\n         [ 1.20805502e-02],\n         [ 2.47909650e-02],\n         [ 4.72950786e-02],\n         [-4.27586026e-02],\n         [-2.00201944e-02],\n         [ 6.35461807e-02],\n         [-7.65774250e-02],\n         [ 2.09345892e-02],\n         [-4.54149954e-02],\n         [ 4.98757660e-02],\n         [ 4.38040346e-02],\n         [-1.42264888e-02],\n         [-3.55059206e-02],\n         [-3.48351896e-03],\n         [-5.52938767e-02],\n         [ 7.22648948e-02],\n         [-2.87522413e-02],\n         [-6.95469007e-02],\n         [-4.81623039e-02],\n         [-8.01663250e-02],\n         [ 7.57557154e-03],\n         [ 9.06218290e-02],\n         [-1.90361589e-03],\n         [-2.11788565e-02],\n         [-6.09034747e-02],\n         [-9.00204331e-02],\n         [ 1.20628849e-02],\n         [ 3.04240063e-02],\n         [-5.60291372e-02]],\n\n        [[ 7.78300464e-02],\n         [-7.32453763e-02],\n         [-7.69731402e-02],\n         [ 6.59853220e-02],\n         [-2.76882052e-02],\n         [ 3.64506692e-02],\n         [ 5.73763102e-02],\n         [-6.18058220e-02],\n         [-9.05239731e-02],\n         [-5.33724837e-02],\n         [-7.94109479e-02],\n         [-1.89898387e-02],\n         [-5.41004762e-02],\n         [ 5.44473529e-02],\n         [ 3.29278484e-02],\n         [ 1.01084784e-02],\n         [ 1.67916939e-02],\n         [-8.15748721e-02],\n         [-3.90254334e-02],\n         [ 1.74498186e-02],\n         [-1.37196779e-02],\n         [-3.01492661e-02],\n         [ 3.83973122e-04],\n         [ 3.29140276e-02],\n         [ 7.97250718e-02],\n         [-4.72386889e-02],\n         [ 9.02785659e-02],\n         [-5.27401268e-03],\n         [-6.18153214e-02],\n         [-3.51565592e-02],\n         [-5.38068525e-02],\n         [-2.06493810e-02],\n         [-6.84127882e-02],\n         [ 7.55287260e-02],\n         [ 2.98400223e-03],\n         [ 4.62450236e-02],\n         [-6.29361719e-03],\n         [-4.17920761e-02],\n         [ 4.58817184e-02],\n         [ 5.82863092e-02],\n         [-5.95807247e-02],\n         [ 4.67566252e-02],\n         [ 7.59347528e-03],\n         [ 7.82608688e-02],\n         [-2.54447237e-02],\n         [ 8.13296735e-02],\n         [-3.60343792e-02],\n         [ 1.95392966e-02],\n         [-6.30896613e-02],\n         [ 7.00883418e-02],\n         [-1.74168348e-02],\n         [-4.18131426e-02],\n         [ 6.85076565e-02],\n         [-4.59557399e-02],\n         [-2.83844769e-04],\n         [ 3.47904712e-02],\n         [-5.75928837e-02],\n         [-1.45003945e-03],\n         [-3.74742597e-03],\n         [-8.23443383e-03],\n         [-8.04779008e-02],\n         [ 4.20557857e-02],\n         [-8.86777863e-02],\n         [-2.87189111e-02],\n         [-3.11012343e-02],\n         [-7.09311888e-02],\n         [-3.93627286e-02],\n         [ 4.72665876e-02],\n         [-8.03857595e-02],\n         [ 7.24331439e-02],\n         [ 6.89113736e-02],\n         [-6.34625107e-02],\n         [ 6.78108335e-02],\n         [ 8.46767575e-02],\n         [-2.24580616e-02],\n         [-6.13560304e-02],\n         [-3.30255479e-02],\n         [ 2.74264887e-02],\n         [ 7.65512288e-02],\n         [ 1.24840438e-03]]],\n\n\n       [[[-4.15212698e-02],\n         [-1.65857747e-02],\n         [-4.18476835e-02],\n         [ 5.97543269e-02],\n         [-5.01129180e-02],\n         [-4.46611792e-02],\n         [-7.71042705e-03],\n         [-8.98741186e-03],\n         [ 6.35068715e-02],\n         [-7.22834393e-02],\n         [ 2.92851105e-02],\n         [ 3.65661681e-02],\n         [ 8.21505040e-02],\n         [-4.67923395e-02],\n         [-5.21486066e-02],\n         [ 5.00400662e-02],\n         [-3.45263965e-02],\n         [ 6.91485405e-02],\n         [-6.49325848e-02],\n         [ 6.56836331e-02],\n         [ 2.71371752e-03],\n         [-3.84243615e-02],\n         [ 4.34292257e-02],\n         [ 6.21979684e-02],\n         [-3.09776850e-02],\n         [ 2.36947015e-02],\n         [-7.10669756e-02],\n         [-9.62924957e-03],\n         [-3.31154205e-02],\n         [ 1.27258971e-02],\n         [ 8.01828504e-02],\n         [-6.33612201e-02],\n         [-3.32447886e-02],\n         [-7.48300627e-02],\n         [-9.97699052e-03],\n         [ 1.13431513e-02],\n         [-3.38890329e-02],\n         [-4.57420610e-02],\n         [-3.79354879e-02],\n         [ 1.54659152e-03],\n         [-7.01940656e-02],\n         [ 7.71742314e-02],\n         [-2.50237435e-02],\n         [ 6.79738820e-04],\n         [ 1.99558586e-03],\n         [ 3.96522135e-02],\n         [-2.54567713e-02],\n         [-1.01723298e-02],\n         [-2.37911940e-02],\n         [-7.94683695e-02],\n         [-3.62368785e-02],\n         [ 7.14154541e-02],\n         [ 7.25253820e-02],\n         [ 8.91425461e-03],\n         [-1.09159872e-02],\n         [ 4.30653989e-02],\n         [ 4.45811450e-02],\n         [-1.75290480e-02],\n         [-8.96497816e-03],\n         [ 5.21661937e-02],\n         [ 6.61091357e-02],\n         [-6.40156716e-02],\n         [-6.33788928e-02],\n         [ 4.55363095e-03],\n         [-2.65718922e-02],\n         [ 2.57802755e-03],\n         [-2.03699023e-02],\n         [ 5.40879667e-02],\n         [-2.48151273e-02],\n         [ 9.05132294e-03],\n         [ 5.81189692e-02],\n         [ 1.64462626e-02],\n         [-9.08786058e-03],\n         [-1.23984367e-03],\n         [-7.96884298e-03],\n         [ 1.69560313e-02],\n         [-4.03613299e-02],\n         [-2.38711163e-02],\n         [ 5.21084666e-02],\n         [-8.39432478e-02]],\n\n        [[-5.32533973e-03],\n         [ 6.94005340e-02],\n         [ 6.39073998e-02],\n         [-9.16613638e-03],\n         [ 1.18176863e-02],\n         [-3.56114954e-02],\n         [-7.90868476e-02],\n         [-6.23369217e-02],\n         [ 2.46274620e-02],\n         [ 1.27945542e-02],\n         [ 3.14159915e-02],\n         [-8.07454586e-02],\n         [ 6.77292198e-02],\n         [ 6.31783009e-02],\n         [-4.53442894e-02],\n         [-2.61754617e-02],\n         [ 3.67901176e-02],\n         [ 1.94124877e-03],\n         [-4.13189679e-02],\n         [-1.43459439e-03],\n         [-4.92663719e-02],\n         [-7.83275291e-02],\n         [ 7.79393166e-02],\n         [-3.10968868e-02],\n         [-7.51439780e-02],\n         [ 6.48184121e-02],\n         [-5.09805754e-02],\n         [-1.77309662e-02],\n         [-8.58000144e-02],\n         [ 7.90582895e-02],\n         [ 3.64466459e-02],\n         [ 8.79381150e-02],\n         [-1.77353770e-02],\n         [-3.68133187e-05],\n         [-4.56023552e-02],\n         [ 6.35572076e-02],\n         [ 3.30103412e-02],\n         [ 6.78781420e-02],\n         [ 5.79086840e-02],\n         [ 7.33441114e-02],\n         [-3.86655331e-02],\n         [ 1.08553767e-02],\n         [-4.71937656e-03],\n         [-4.86585125e-02],\n         [ 8.16603154e-02],\n         [-3.35063152e-02],\n         [-5.80220856e-02],\n         [-1.65647268e-03],\n         [ 1.33805647e-02],\n         [-5.82382530e-02],\n         [-8.74474421e-02],\n         [ 1.01281181e-02],\n         [ 2.32846886e-02],\n         [ 7.57527500e-02],\n         [-4.13189083e-03],\n         [ 7.88294524e-02],\n         [-7.79333711e-02],\n         [-3.82337607e-02],\n         [-3.32482271e-02],\n         [-7.03862011e-02],\n         [ 6.96699917e-02],\n         [-7.34459907e-02],\n         [-9.04230550e-02],\n         [ 7.82419145e-02],\n         [-5.93036041e-02],\n         [ 2.81842798e-03],\n         [ 6.29189312e-02],\n         [-1.84516460e-02],\n         [ 7.74733126e-02],\n         [-4.75304537e-02],\n         [ 4.53350097e-02],\n         [-8.24960843e-02],\n         [-3.36195044e-02],\n         [-6.06605262e-02],\n         [-7.95032606e-02],\n         [ 5.45232296e-02],\n         [ 7.84163475e-02],\n         [ 4.95704710e-02],\n         [ 6.70588017e-03],\n         [ 2.43533701e-02]],\n\n        [[-6.02158159e-02],\n         [ 6.55934513e-02],\n         [ 2.42115036e-02],\n         [ 5.58568984e-02],\n         [-1.18216425e-02],\n         [-3.87412608e-02],\n         [-1.32587478e-02],\n         [-1.38917863e-02],\n         [ 2.72165313e-02],\n         [-6.54928535e-02],\n         [-6.87674955e-02],\n         [-2.03985199e-02],\n         [ 6.37516379e-02],\n         [-4.24799249e-02],\n         [ 7.47797489e-02],\n         [ 3.70633900e-02],\n         [-3.59726511e-02],\n         [ 4.05049324e-02],\n         [ 5.96642345e-02],\n         [ 1.37628540e-02],\n         [-5.11466265e-02],\n         [-6.47759363e-02],\n         [-1.28356069e-02],\n         [ 7.03348219e-03],\n         [ 3.61459404e-02],\n         [ 1.68216899e-02],\n         [ 9.48987156e-03],\n         [-1.83533132e-03],\n         [ 3.20909470e-02],\n         [ 7.49292970e-02],\n         [ 3.72575819e-02],\n         [-6.52565509e-02],\n         [ 5.67191988e-02],\n         [-6.35091215e-03],\n         [ 7.49246031e-02],\n         [-1.70183480e-02],\n         [-8.14317465e-02],\n         [-5.93253411e-02],\n         [ 8.10084790e-02],\n         [-3.56769040e-02],\n         [ 7.36415535e-02],\n         [ 1.45708993e-02],\n         [ 7.53114820e-02],\n         [-6.20543733e-02],\n         [ 4.27161902e-03],\n         [-1.40484050e-02],\n         [ 4.82401848e-02],\n         [ 1.56359226e-02],\n         [-4.18757834e-02],\n         [-4.63947169e-02],\n         [-6.13191128e-02],\n         [-8.71411636e-02],\n         [-1.40616447e-02],\n         [ 7.46802241e-03],\n         [-7.99229667e-02],\n         [-5.89055717e-02],\n         [ 1.93427503e-02],\n         [ 2.65355781e-02],\n         [ 6.00865334e-02],\n         [-3.03183235e-02],\n         [ 9.06062275e-02],\n         [-6.92652166e-03],\n         [ 2.95820236e-02],\n         [-7.95759261e-03],\n         [ 3.83987725e-02],\n         [ 4.73548472e-02],\n         [ 7.44029880e-02],\n         [-4.79479507e-02],\n         [ 3.91598791e-02],\n         [-7.95012712e-02],\n         [-6.58729151e-02],\n         [-2.51954868e-02],\n         [ 2.63304412e-02],\n         [ 3.73968333e-02],\n         [ 7.90280402e-02],\n         [ 7.94202089e-02],\n         [-5.42753302e-02],\n         [-6.16169088e-02],\n         [-2.83450410e-02],\n         [ 6.40583336e-02]]]], dtype=float32)>, <tf.Variable 'conv2d_859/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.10411051, -0.09993905,  0.10945921, ...,  0.0138134 ,\n          -0.09568352, -0.01320909],\n         [ 0.13120577,  0.10361341,  0.01597022, ..., -0.09409473,\n           0.11399805, -0.12183334],\n         [ 0.00971108,  0.10353881, -0.0794847 , ..., -0.08021943,\n           0.19035943,  0.01096168],\n         ...,\n         [-0.14632568,  0.11939848, -0.12212426, ...,  0.02531959,\n          -0.17951569, -0.13103734],\n         [-0.11415138, -0.18519133,  0.11686815, ...,  0.15166123,\n           0.11571956,  0.08748915],\n         [ 0.01324788, -0.00819887, -0.2116318 , ..., -0.02114077,\n           0.00374202,  0.08554063]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_868/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_910/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_837/kernel:0' shape=(3, 3, 3, 8) dtype=float32, numpy=\narray([[[[ 4.34860617e-01, -6.12443872e-02, -2.34070227e-01,\n          -6.79554269e-02,  3.35900247e-01, -1.01141036e-02,\n          -1.08897328e-01, -4.19404469e-02],\n         [ 4.18321043e-02, -6.16611950e-02,  1.59482077e-01,\n          -1.26871407e-01, -2.95461833e-01, -1.52698517e-01,\n           2.78214574e-01,  4.36488509e-01],\n         [ 1.37099147e-01, -1.17949862e-02, -1.08235322e-01,\n           2.34664115e-03,  1.69618309e-01, -7.34768137e-02,\n          -5.35418093e-02,  4.46267985e-02]],\n\n        [[-3.52367647e-02,  1.74914859e-02, -1.94057181e-01,\n          -2.17091754e-01, -1.77843153e-01,  1.08397566e-02,\n          -4.77415919e-02,  3.65599245e-01],\n         [-1.05641685e-01,  8.71259440e-03,  2.00579241e-02,\n           7.68682137e-02, -7.84347877e-02, -1.21652402e-01,\n           4.08379696e-02, -2.69199878e-01],\n         [ 5.96811771e-02, -7.08556473e-02,  1.80879999e-02,\n          -8.25090334e-02, -1.43719614e-01,  2.51296401e-01,\n          -2.75461942e-01,  1.52257442e-01]],\n\n        [[ 9.62612629e-02, -2.78844982e-01, -7.05683678e-02,\n           1.93157479e-01, -1.74849629e-01, -2.91720349e-02,\n          -2.90387031e-02, -1.32201582e-01],\n         [ 7.43680671e-02,  5.26263788e-02, -6.56763390e-02,\n          -5.09885699e-02,  4.71500978e-02,  1.28422743e-02,\n          -6.89756870e-02, -3.64297390e-01],\n         [ 1.06877729e-01,  2.85665747e-02,  2.92315464e-02,\n           1.32722288e-01,  5.98155074e-02,  9.30707082e-02,\n           1.04779646e-01, -3.04968417e-01]]],\n\n\n       [[[-3.73448908e-01, -4.44144122e-02,  1.24600559e-01,\n           2.76192483e-02, -4.64274958e-02, -1.49158865e-01,\n           1.92302361e-01,  3.15826297e-01],\n         [-2.51975268e-01, -1.93237916e-01, -1.82171896e-01,\n           2.53471375e-01, -1.31441236e-01,  3.64394099e-01,\n           1.09096549e-01,  3.60211372e-01],\n         [-1.94265336e-01, -3.88557017e-01, -1.17687561e-01,\n           2.96913058e-01, -1.85678527e-02,  1.21498958e-03,\n           3.95804554e-01,  1.58660769e-01]],\n\n        [[ 2.22440250e-02,  3.85935336e-01, -1.59623802e-01,\n          -6.19686618e-02, -1.35481641e-01, -1.06442370e-01,\n           1.97795272e-01, -1.00649916e-01],\n         [ 1.16978303e-01, -2.13973135e-01, -8.31322372e-02,\n           1.45909384e-01,  1.57183826e-01, -8.19479972e-02,\n           3.44110906e-01, -1.28656447e-01],\n         [-3.02926451e-01,  1.35517642e-01, -1.72126278e-01,\n          -4.61478271e-02,  1.47228554e-01,  1.08457848e-01,\n           1.53731465e-01,  1.21956535e-01]],\n\n        [[ 3.67071219e-02,  8.91752541e-02, -1.02156341e-01,\n           1.13416314e-02,  1.98783097e-03, -9.64439437e-02,\n           4.89879325e-02, -2.09098727e-01],\n         [ 2.83310592e-01,  1.16454080e-01, -3.93767953e-02,\n          -4.38202880e-02, -3.15381676e-01, -6.14104569e-02,\n          -3.83391738e-01, -1.44625410e-01],\n         [ 2.11003423e-01,  4.34468995e-04,  2.73406431e-02,\n          -5.92781343e-02, -3.75086784e-01,  7.01255500e-02,\n          -1.94294408e-01, -1.92789122e-01]]],\n\n\n       [[[ 1.40643612e-01, -1.64493680e-01,  2.79116511e-01,\n          -9.80716497e-02, -3.82111520e-02,  2.36558586e-01,\n          -1.01421215e-01, -3.15519385e-02],\n         [-1.44459143e-01,  8.53005126e-02, -1.98771074e-01,\n          -5.45773581e-02, -1.12990923e-01, -2.18943313e-01,\n          -2.04592466e-01,  6.73497021e-02],\n         [ 2.82178223e-01, -3.14117610e-01,  1.75205678e-01,\n           1.69952735e-01,  2.98341364e-01, -4.09468710e-02,\n           2.71549135e-01,  1.89843521e-01]],\n\n        [[-2.68893778e-01,  3.75231206e-02,  1.79400995e-01,\n          -2.13881597e-01, -1.68604493e-01, -1.04828462e-01,\n          -1.17957257e-01, -9.95254517e-02],\n         [-3.20701867e-01,  1.36785597e-01,  5.50708957e-02,\n           8.46281424e-02, -2.01541279e-02,  1.62159428e-01,\n          -2.35586807e-01,  2.56881684e-01],\n         [-2.25200191e-01,  3.51056308e-02, -8.72928798e-02,\n           2.27396891e-01,  3.85151617e-02,  3.09475422e-01,\n           1.04107819e-01,  1.51687354e-01]],\n\n        [[ 7.02244043e-02, -8.67525935e-02,  2.86658198e-01,\n           3.96883428e-01,  3.12807225e-02, -5.19500002e-02,\n           5.98939881e-02, -2.22012341e-01],\n         [ 2.73790926e-01,  2.84305841e-01,  7.07704201e-02,\n           2.06513658e-01, -1.50258556e-01,  3.22034270e-01,\n          -1.79023236e-01, -2.95934439e-01],\n         [-3.89295399e-01,  2.20175534e-01,  1.07977375e-01,\n           2.89510638e-02, -2.25162596e-01, -3.94590020e-01,\n          -3.11882794e-01, -1.61674961e-01]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[-0.2479917 , -0.23689294, -0.14518796, ...,  0.39041418,\n          -0.12793861,  0.39641052],\n         [ 0.3597114 ,  0.18744245,  0.2737869 , ...,  0.08534814,\n           0.05556985, -0.0025951 ],\n         [-0.2385604 , -0.271404  ,  0.28244513, ..., -0.29290363,\n          -0.04824167,  0.14886163],\n         ...,\n         [ 0.23674822, -0.22173344, -0.30637556, ..., -0.28418595,\n          -0.09394607,  0.2505591 ],\n         [ 0.08151749, -0.03971544,  0.0468292 , ...,  0.14265789,\n          -0.3311238 ,  0.22740376],\n         [ 0.27640203, -0.01170183, -0.32826698, ...,  0.13623905,\n          -0.09182345, -0.14845005]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_855/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.05691873, -0.08178847,  0.10209659, ...,  0.05336939,\n           0.04119298,  0.16145097],\n         [-0.07454727, -0.04499779, -0.14113724, ...,  0.08217024,\n          -0.01950422, -0.04713718],\n         [ 0.16121182,  0.04491493, -0.0777458 , ..., -0.11923408,\n           0.0611771 ,  0.13828753],\n         ...,\n         [-0.08755382, -0.08692743, -0.04167262, ...,  0.12630141,\n          -0.13755977, -0.07483485],\n         [-0.0057496 , -0.08392468, -0.08055364, ..., -0.02204002,\n          -0.1026118 , -0.03875181],\n         [-0.03894832,  0.11955823, -0.04138163, ...,  0.07989595,\n           0.00929255,  0.1405722 ]]]], dtype=float32)>, <tf.Variable 'conv2d_850/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[-0.17312704,  0.16594543,  0.03478403, ...,  0.02367057,\n           0.10055587,  0.23386765],\n         [ 0.05774681, -0.0216629 , -0.19633013, ..., -0.18767416,\n          -0.18666461, -0.10115756],\n         [ 0.11902137, -0.19842215, -0.06245279, ..., -0.2516125 ,\n           0.1320161 , -0.06040335],\n         ...,\n         [-0.08664814,  0.06752764, -0.07373308, ..., -0.16511129,\n          -0.00979579,  0.04597995],\n         [ 0.04794793,  0.13216718,  0.01690847, ..., -0.07301548,\n           0.02930633,  0.18098101],\n         [ 0.13800204,  0.00230392,  0.17418192, ..., -0.10249943,\n           0.02288403,  0.04760702]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_879/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[ 0.23353304, -0.20531552,  0.12357561, ...,  0.06063399,\n          -0.21159081,  0.03818657],\n         [ 0.29464367, -0.0783284 ,  0.06509706, ...,  0.22956146,\n           0.03700827, -0.34284928],\n         [-0.20444453,  0.5052561 ,  0.540054  , ..., -0.2820317 ,\n           0.19628468, -0.2687783 ],\n         ...,\n         [ 0.11366351, -0.2197347 , -0.19798149, ..., -0.08464143,\n           0.2715783 , -0.10311449],\n         [-0.5323078 ,  0.3015175 , -0.20705988, ..., -0.05869035,\n           0.19765744, -0.4617885 ],\n         [-0.00256486, -0.40370452,  0.02302782, ..., -0.3269101 ,\n           0.09300213,  0.28129053]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/conv2d_1/kernel:0' shape=(1, 1, 240, 40) dtype=float32, numpy=\narray([[[[-0.05071502, -0.00046771, -0.07373971, ...,  0.09413058,\n           0.01781907, -0.04042453],\n         [-0.09543748, -0.12304069, -0.06205228, ...,  0.02624068,\n           0.02881169,  0.00810569],\n         [-0.1163765 , -0.02997088,  0.01742249, ...,  0.02339732,\n           0.036571  , -0.01657863],\n         ...,\n         [-0.01074709,  0.13512889,  0.10065539, ...,  0.11613697,\n          -0.00763821, -0.02962824],\n         [-0.00809216,  0.06155474, -0.05628331, ..., -0.07483778,\n          -0.08880164, -0.0541205 ],\n         [-0.04729754, -0.09207111, -0.02092353, ..., -0.03724654,\n           0.05418466, -0.09004581]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_1/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/moving_mean:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'depthwise_conv2d_367/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.05658032],\n         [ 0.04513918],\n         [-0.06506998],\n         ...,\n         [ 0.03815841],\n         [ 0.02281986],\n         [ 0.02134433]],\n\n        [[ 0.07209826],\n         [-0.04146219],\n         [-0.03197265],\n         ...,\n         [ 0.01712053],\n         [ 0.02636585],\n         [-0.06394023]],\n\n        [[ 0.00481731],\n         [ 0.00850389],\n         [ 0.03421478],\n         ...,\n         [-0.03269311],\n         [-0.07010403],\n         [-0.03387936]]],\n\n\n       [[[-0.00750106],\n         [-0.02072125],\n         [-0.03230726],\n         ...,\n         [-0.06100129],\n         [-0.00659133],\n         [-0.04323304]],\n\n        [[-0.00846768],\n         [-0.07259206],\n         [ 0.0481456 ],\n         ...,\n         [-0.0550942 ],\n         [-0.01256686],\n         [-0.05775381]],\n\n        [[-0.02718295],\n         [-0.03214045],\n         [ 0.01380256],\n         ...,\n         [-0.07038531],\n         [-0.04531629],\n         [ 0.03864978]]],\n\n\n       [[[ 0.02549809],\n         [ 0.06117572],\n         [ 0.03622878],\n         ...,\n         [ 0.0331825 ],\n         [-0.0315299 ],\n         [ 0.0415382 ]],\n\n        [[-0.04904476],\n         [-0.01267374],\n         [-0.07439227],\n         ...,\n         [-0.02343307],\n         [ 0.05014357],\n         [ 0.04373406]],\n\n        [[-0.02252823],\n         [-0.02713235],\n         [-0.01811955],\n         ...,\n         [-0.02345107],\n         [ 0.07354911],\n         [ 0.01964509]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_902/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization/moving_variance:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/conv2d/kernel:0' shape=(1, 1, 112, 672) dtype=float32, numpy=\narray([[[[ 0.05322937,  0.00419696,  0.14083974, ...,  0.05964502,\n          -0.07552427,  0.03780741],\n         [ 0.04103354, -0.07011916, -0.09230108, ...,  0.10921484,\n           0.05243674,  0.07273926],\n         [ 0.10637338, -0.01923977, -0.01467316, ...,  0.07515216,\n           0.07851442, -0.06054208],\n         ...,\n         [ 0.08629661, -0.11335976,  0.11231662, ...,  0.04661131,\n           0.08741467, -0.10036431],\n         [ 0.00919535, -0.03788225,  0.06047742, ...,  0.18185467,\n           0.16720587,  0.14260915],\n         [ 0.0395638 , -0.08249996, -0.0670304 , ..., -0.09548555,\n           0.1436232 ,  0.00969846]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/squeeze_excitation/conv2d_2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_907/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_872/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 480, 1) dtype=float32, numpy=\narray([[[[-0.00198248],\n         [ 0.01609984],\n         [ 0.00836946],\n         ...,\n         [-0.01657758],\n         [-0.01932586],\n         [ 0.02946362]],\n\n        [[ 0.00518826],\n         [-0.0136152 ],\n         [-0.00768054],\n         ...,\n         [-0.00923684],\n         [ 0.01206317],\n         [-0.01039699]],\n\n        [[-0.00512563],\n         [ 0.01070204],\n         [ 0.00834193],\n         ...,\n         [-0.0032751 ],\n         [ 0.02260692],\n         [-0.02298075]]],\n\n\n       [[[ 0.00206978],\n         [-0.00096237],\n         [ 0.02283854],\n         ...,\n         [-0.00640933],\n         [-0.01373974],\n         [-0.02142998]],\n\n        [[-0.01529582],\n         [ 0.00130071],\n         [-0.0158083 ],\n         ...,\n         [-0.01130382],\n         [ 0.0061287 ],\n         [-0.02285107]],\n\n        [[ 0.00127067],\n         [-0.00029359],\n         [-0.0321688 ],\n         ...,\n         [ 0.00509909],\n         [ 0.00728624],\n         [-0.00528747]]],\n\n\n       [[[-0.01982355],\n         [ 0.00784959],\n         [ 0.00336699],\n         ...,\n         [-0.00233218],\n         [-0.01549122],\n         [ 0.01841665]],\n\n        [[-0.01651531],\n         [-0.01242766],\n         [-0.01246268],\n         ...,\n         [-0.01459251],\n         [-0.00059355],\n         [-0.00593053]],\n\n        [[-0.02197322],\n         [ 0.03255267],\n         [ 0.00084239],\n         ...,\n         [ 0.01762703],\n         [ 0.0056902 ],\n         [-0.01367214]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization/gamma:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/conv2d/kernel:0' shape=(1, 1, 16, 96) dtype=float32, numpy=\narray([[[[ 2.5876215e-01,  2.2885117e-01, -3.7943393e-02, ...,\n          -7.0458680e-02, -9.0687610e-02, -2.9245937e-01],\n         [ 1.9379990e-01, -1.4698873e-01, -3.6464572e-02, ...,\n           4.1912407e-01,  1.6572762e-01, -3.3918551e-01],\n         [ 2.7932101e-01, -3.4450549e-01, -2.6956692e-01, ...,\n           2.1920848e-01, -1.6603917e-01,  9.3559630e-02],\n         ...,\n         [ 1.8810408e-02,  2.1550113e-01,  1.1200634e-01, ...,\n           5.1735640e-01, -3.8649648e-01, -1.7318353e-03],\n         [ 4.4375995e-01, -2.4426644e-01,  4.0689960e-01, ...,\n           2.0198093e-01, -8.0465831e-02,  4.4801924e-02],\n         [ 3.4991312e-01,  3.9740109e-01, -5.2391659e-03, ...,\n           1.5180360e-01, -3.9457161e-02,  3.1451267e-04]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_891/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_866/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 16, 480) dtype=float32, numpy=\narray([[[[-0.28877535,  0.08674186,  0.00533257, ...,  0.05692507,\n           0.53369904,  0.38847327],\n         [-0.3101322 ,  0.0353773 ,  0.0509994 , ..., -0.13558097,\n          -0.18690796,  0.54423714],\n         [ 0.15576588,  0.10971843, -0.21223341, ...,  0.16388036,\n           0.13791399, -0.50099695],\n         ...,\n         [ 0.21520627, -0.05457871, -0.1527293 , ...,  0.29818162,\n          -0.18155313,  0.04517001],\n         [ 0.4248039 , -0.3429481 , -0.23517631, ..., -0.24873146,\n           0.02962397, -0.42239076],\n         [-0.38152325, -0.30858228, -0.03382488, ...,  0.387512  ,\n          -0.29318768,  0.21084514]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_881/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_847/beta:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_882/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_863/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_2/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_874/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[ 0.04510472,  0.20648754,  0.1176513 , ...,  0.2049702 ,\n           0.02841216, -0.14003591],\n         [ 0.02559275,  0.0421253 ,  0.00520388, ...,  0.02768417,\n          -0.00510083,  0.1624502 ],\n         [-0.01072824,  0.05431699, -0.12903199, ..., -0.04933112,\n          -0.09183082,  0.10126495],\n         ...,\n         [-0.05445305,  0.18244241,  0.13566735, ...,  0.03528935,\n           0.12248649,  0.14743344],\n         [-0.08861005, -0.14864802,  0.2048285 , ...,  0.01239545,\n          -0.05569541,  0.00600726],\n         [-0.13778675,  0.17862606, -0.01290794, ...,  0.06893931,\n          -0.09094699, -0.05378803]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_897/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_867/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[ 0.15957758, -0.11312751, -0.15851146, ..., -0.12608384,\n           0.09525088, -0.08314826],\n         [-0.02660082,  0.05745919, -0.09143284, ...,  0.02496169,\n          -0.12793098, -0.00145942],\n         [-0.18886368, -0.16361073,  0.01116989, ..., -0.09486587,\n          -0.05889914,  0.1590093 ],\n         ...,\n         [ 0.04246343,  0.05698205, -0.07096339, ...,  0.06296895,\n          -0.03187802, -0.18009189],\n         [ 0.01452543, -0.01232398, -0.08866816, ...,  0.04642151,\n          -0.11985493, -0.03702703],\n         [ 0.04189466, -0.01042653,  0.08280015, ...,  0.12869924,\n          -0.09729425, -0.15023673]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 4, 144) dtype=float32, numpy=\narray([[[[-0.16776745, -0.01107461,  0.83408785, -0.6419895 ,\n          -0.03528202,  0.64626026, -0.67606574,  0.13160484,\n          -0.29657876,  0.82573146,  0.1914607 , -0.00961619,\n          -0.47519082,  0.00666555,  0.7396214 , -0.14327317,\n           0.3349916 , -0.26881358, -0.29431713, -0.83039266,\n          -0.28265402,  0.3137494 ,  0.10342664,  0.19247799,\n           0.30707455,  0.6808928 ,  0.35664588, -0.9909029 ,\n           0.56933737,  0.41333726, -0.9657033 ,  1.0132818 ,\n          -0.09256936, -0.5227127 ,  1.0718073 , -0.05185861,\n          -0.05041257,  0.17077975, -0.6845666 ,  0.24249968,\n           0.0569461 , -0.16302364,  0.8806042 , -0.99391323,\n          -0.09921478,  0.6818946 ,  0.5285469 , -0.0279187 ,\n          -0.25445908, -0.33157763, -0.00393659, -0.6409969 ,\n          -0.09395363,  0.54187053, -0.32372445, -0.11142825,\n           0.19199812, -0.17920262, -0.4946462 , -0.01743084,\n          -0.2601722 ,  0.40456846, -0.9047628 , -0.65478045,\n          -0.06986048,  0.31659806,  0.11275043, -0.30804428,\n          -1.0519745 , -0.02870833,  0.66114515,  0.21226135,\n          -0.39647344,  0.3002576 , -0.18979299, -0.4999055 ,\n          -0.73667544,  0.09276333, -1.1361312 ,  1.0816007 ,\n          -0.65233743, -0.5979163 , -0.712924  ,  0.36949113,\n          -0.5170336 ,  0.36557817, -0.51443595, -0.7022156 ,\n           0.02008307,  0.3340164 ,  0.43797365, -0.5489855 ,\n          -0.17064345,  0.55959755, -0.122706  ,  0.13699171,\n          -0.10662575,  0.27799806, -0.2464436 ,  0.81737345,\n          -0.8665495 , -0.5111603 , -0.40959263, -0.7692196 ,\n           0.29745805,  0.71748877, -0.4497995 ,  0.38830143,\n           0.05356326, -0.33564323,  0.19943495,  0.61193085,\n          -0.8530397 , -0.10197708, -0.72405595,  0.62300456,\n           0.24674514,  0.27955812,  0.38849142, -0.05993968,\n          -0.5073567 ,  0.39661697,  0.39411092,  0.157851  ,\n          -0.75409806,  0.33312374, -0.31899762,  0.09761707,\n           0.56409353,  0.64576536,  0.32380137,  0.18089986,\n          -0.77493066, -0.23393588, -0.05034808, -0.8058799 ,\n          -0.8371362 ,  0.21467723,  0.17819731,  0.6864316 ,\n           0.40611446, -0.26745972, -0.14092351,  0.11800583],\n         [-0.39469   ,  0.30300498,  0.53789955, -0.52856624,\n          -1.0521023 , -0.39769587,  0.26218626,  0.48027346,\n          -0.42317685,  0.07384458,  0.02196375,  0.42948914,\n          -0.1745447 , -0.42808214, -0.02662465, -0.90202034,\n          -0.30277604,  0.9371252 ,  0.524054  ,  1.056957  ,\n           0.58215135, -0.975589  , -0.5591015 ,  0.48841473,\n           0.20607665,  0.9382853 ,  1.1080399 , -0.86645097,\n          -0.41629606,  0.6389021 ,  0.12614216,  1.0538548 ,\n          -0.19141994, -0.57476276,  0.00735889,  0.34256047,\n           0.04511756,  0.502965  , -0.97229046,  0.586565  ,\n          -0.9448496 ,  0.16441298,  0.664086  , -0.3116942 ,\n           0.3827091 ,  0.10757452,  0.22329819, -0.36200747,\n          -0.34872165, -1.1089379 , -0.11258741, -0.6987143 ,\n          -0.39123395,  0.79118615, -0.6871437 ,  0.98652273,\n           0.45614192, -0.8000015 ,  0.48945192, -0.5666781 ,\n           0.03681678,  0.47129726, -0.24828257,  0.02689931,\n           0.10958332, -0.329704  , -0.6835226 ,  0.28747895,\n           0.04841892,  0.04434224, -0.56140655,  0.6084956 ,\n          -0.6982782 , -0.8603141 , -0.9699785 ,  0.72398233,\n           0.64600843,  0.2879384 ,  0.29492298,  1.1124154 ,\n          -0.19271912,  0.6591149 ,  0.57711303, -1.0100758 ,\n          -0.1111366 ,  0.77275485, -0.22868526, -0.5988182 ,\n          -0.11498249, -0.27344736,  0.2709899 , -0.26077777,\n          -0.33749226,  0.8111305 , -0.18575278, -0.04168475,\n          -0.04411848, -1.0682193 ,  0.5733207 ,  0.774866  ,\n           0.538991  , -0.38923022,  0.05205485, -0.1860995 ,\n          -0.9577869 , -0.36246422,  0.26046517, -0.7757237 ,\n           0.60591906,  0.1543424 , -0.4295256 , -0.02982505,\n           0.26756245,  0.32862052,  0.2425808 ,  0.20770375,\n           0.54039216, -0.8881532 , -0.0658545 ,  0.1212695 ,\n          -0.0795048 ,  0.5900311 ,  0.11333069,  0.27838373,\n          -0.09550293, -0.68276167, -0.1973688 ,  0.9723001 ,\n           0.25163275, -0.63432914,  0.63903147, -0.62233347,\n          -0.17469533,  0.18646888, -0.7063749 , -0.2633393 ,\n          -0.16341127,  0.43954936, -0.3643338 , -0.6634698 ,\n           0.45505443, -0.21446237, -0.68083745,  0.3955437 ],\n         [ 0.9754646 , -0.00438527, -0.35573214,  0.34832147,\n           0.5408223 ,  0.46897078, -0.08874272,  0.14692575,\n           0.16078435,  0.0389923 , -0.44496182, -0.23117025,\n          -0.4639831 , -0.52893287,  0.23210871, -0.6741205 ,\n          -0.8130221 ,  0.1739061 , -0.21381497,  0.6114615 ,\n           0.5018714 , -0.5131973 , -0.05490024,  0.44681096,\n           0.42288497, -0.19716763,  0.14599109,  0.6564013 ,\n           0.4676522 ,  0.24036585,  0.11850829, -0.7254172 ,\n          -1.0944178 , -0.10014945,  0.6750436 ,  0.14813387,\n          -1.045056  ,  0.50445986, -0.04623822,  0.09868938,\n          -0.41627884, -0.16237122,  1.1205145 , -0.34445724,\n           0.05962926, -0.6128795 ,  0.83766705, -0.22920242,\n           0.56529564,  0.49025205, -0.15284525, -0.00703803,\n           0.06588357, -0.48238137, -0.8113619 ,  0.41264638,\n          -0.2875805 ,  0.1166129 , -0.20996325, -0.07270594,\n          -0.58980566, -0.831582  ,  0.6943867 , -0.08046342,\n          -0.12935568,  0.34449622, -0.6762317 , -0.6754419 ,\n           0.88747746, -0.58709174, -0.37066662,  0.06890481,\n           0.25350207, -0.38977683,  0.44481575, -0.74258065,\n           0.10313553, -0.9746051 , -0.42320952,  0.38481987,\n          -0.15555532, -0.80368644, -0.01303876,  0.42803398,\n           0.21563873,  0.4039424 , -0.04059639,  0.26639232,\n          -0.08367503,  0.3938428 , -0.46830386, -0.1440706 ,\n          -0.17425267, -0.04523797, -0.67745745, -0.6934136 ,\n           0.782805  ,  0.06349245,  0.7873974 , -0.49040392,\n           0.4589856 , -0.23889068,  0.28198406, -0.24196243,\n          -0.3547125 , -0.80859405,  0.5006063 ,  0.36697018,\n          -0.30710855, -1.1278713 , -0.09068426, -0.90145075,\n          -0.28888053, -0.45720378, -0.23874857,  0.624876  ,\n           0.60238147, -0.21903844, -0.1719479 , -0.3206194 ,\n           0.6145958 , -0.5016537 , -0.3736362 , -0.9036106 ,\n           0.42266077,  0.48498815,  0.7751404 , -0.38286912,\n          -0.20760374, -0.08962531,  0.15637088, -0.52028143,\n           0.11103437,  0.2873182 ,  0.7245172 ,  0.01077716,\n           0.2696031 , -1.1249957 , -0.7402211 , -0.9082132 ,\n           0.3822948 , -0.01565916,  0.3292175 ,  0.63007253],\n         [ 0.20066158, -0.39986926,  0.70086503,  0.25450036,\n          -0.42714983, -0.4481472 ,  0.58430934, -0.34443662,\n          -0.998419  , -0.6954459 ,  0.5982778 ,  0.15596342,\n           0.8363044 ,  0.40619704,  0.49438566,  0.21595173,\n          -0.41770044,  0.5155262 ,  0.31941435,  0.5943516 ,\n          -0.4207089 , -0.22839516, -0.2850254 , -0.48265067,\n          -0.3857148 ,  0.1600421 ,  0.5635464 ,  0.54957885,\n           0.00668295, -0.6173806 ,  0.1906684 ,  0.3727613 ,\n           0.3042391 ,  0.38187587,  0.08821028,  0.7179519 ,\n          -0.60850495,  0.38117087,  0.10388664,  0.07209044,\n           0.4224496 ,  0.30955866,  0.282565  ,  0.7405576 ,\n          -0.53897065, -0.44276372, -0.8774886 , -0.8751283 ,\n          -0.31016666, -0.13271686, -0.40718403,  0.5345011 ,\n          -0.44278276,  0.89124227, -0.6074596 ,  0.3430309 ,\n           0.2842252 , -0.64881885, -0.3956869 , -0.30742168,\n          -0.10451504,  0.2389749 ,  1.0267768 ,  0.6741248 ,\n           0.34706685, -0.83305746, -0.41279048, -0.07871567,\n          -0.2843145 , -0.14377773,  1.0640689 , -0.07497586,\n           0.4705423 , -1.0031061 , -0.36948532, -0.1916939 ,\n          -0.54547554,  0.67887676, -0.23877418,  0.33397022,\n           0.10341568,  0.40265772,  0.3355503 ,  0.48349556,\n          -0.2785468 ,  0.41726178, -0.48996758, -0.14610444,\n          -0.8965524 ,  0.53374225, -0.6285892 ,  0.17857426,\n          -0.73508686, -0.08894856, -0.52788913,  0.78603166,\n           0.6993428 ,  0.27794513, -0.8726327 , -0.07149154,\n           0.03367646, -0.40194854, -0.21028782, -0.12961254,\n          -0.7025133 , -0.5894277 ,  0.932474  ,  0.7977343 ,\n          -0.23513924,  0.9309386 , -0.5782518 ,  0.58637077,\n          -0.34770703,  0.65729386, -0.5561754 ,  0.04164503,\n          -0.9982304 ,  0.2352612 , -0.2568104 , -0.2858503 ,\n           0.6451764 ,  0.7721339 , -0.07506826,  0.32429686,\n          -0.39532852, -0.07099956,  1.1071563 , -0.2077619 ,\n          -0.02654623,  0.7633865 ,  1.1225549 , -0.25271323,\n           0.16528678, -0.740723  , -0.38473913,  0.5335051 ,\n          -0.7202439 , -0.95562524,  0.5452918 , -0.8490771 ,\n          -0.50285286, -0.13346614,  0.44031847, -0.51493686]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_864/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_893/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization_2/gamma:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_851/kernel:0' shape=(1, 1, 80, 80) dtype=float32, numpy=\narray([[[[ 0.14176348, -0.18495345,  0.21216701, ..., -0.08082036,\n           0.00323492, -0.09561373],\n         [-0.03675757,  0.04443929, -0.03111906, ..., -0.18890283,\n           0.00630859, -0.11341402],\n         [-0.06600282, -0.11612254,  0.19817844, ...,  0.24137457,\n           0.03846955,  0.2028332 ],\n         ...,\n         [ 0.06127869,  0.19625293, -0.01395706, ...,  0.149263  ,\n          -0.25050923, -0.21167158],\n         [-0.02569345,  0.08823421,  0.07141477, ..., -0.06534476,\n          -0.20569034, -0.14028575],\n         [ 0.01713383,  0.02133022, -0.13792536, ..., -0.21138842,\n          -0.07604994, -0.06765077]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_859/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_3/bias:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 480, 16) dtype=float32, numpy=\narray([[[[-0.01230802, -0.04724625,  0.04502202, ...,  0.03112269,\n          -0.02959301,  0.09607556],\n         [-0.03805686,  0.09795295,  0.00647715, ..., -0.01783718,\n           0.00159166,  0.0407985 ],\n         [ 0.05649356,  0.04052271,  0.06199136, ...,  0.02262933,\n           0.0109346 , -0.09812878],\n         ...,\n         [-0.02682485,  0.01743664, -0.02204785, ...,  0.0453328 ,\n           0.04073798, -0.066413  ],\n         [ 0.06118085, -0.0336022 , -0.06813037, ...,  0.04083523,\n           0.03830257,  0.01283902],\n         [ 0.0461296 , -0.00201737, -0.01553704, ..., -0.08509237,\n          -0.04542306, -0.02710045]]]], dtype=float32)>, <tf.Variable 'conv2d_856/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.01843976, -0.03098864,  0.05574783, ..., -0.13279253,\n           0.16101842, -0.05144629],\n         [ 0.14971836, -0.08997049, -0.1220033 , ..., -0.06152144,\n          -0.03506518, -0.0560917 ],\n         [ 0.07375477, -0.01566198,  0.10971449, ...,  0.17921707,\n          -0.14212574,  0.04531173],\n         ...,\n         [-0.06201873,  0.09663314,  0.0133636 , ..., -0.08341017,\n           0.0265577 , -0.0024548 ],\n         [ 0.0222892 , -0.13300845,  0.02199313, ...,  0.00113345,\n          -0.10096229,  0.12386192],\n         [-0.1473402 ,  0.05544004, -0.01258931, ...,  0.09006105,\n          -0.03448061,  0.02653985]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_874/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_846/moving_variance:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 240, 1) dtype=float32, numpy=\narray([[[[ 0.00603853],\n         [-0.00661407],\n         [ 0.01694463],\n         ...,\n         [-0.02450655],\n         [-0.00253637],\n         [-0.02337872]],\n\n        [[ 0.00250033],\n         [ 0.03330577],\n         [-0.01773065],\n         ...,\n         [ 0.02821982],\n         [-0.03204954],\n         [ 0.01769499]],\n\n        [[ 0.00617511],\n         [-0.00010343],\n         [ 0.03215319],\n         ...,\n         [ 0.00722378],\n         [-0.00159786],\n         [ 0.00946158]]],\n\n\n       [[[ 0.02254423],\n         [ 0.02320418],\n         [-0.01153665],\n         ...,\n         [-0.00807771],\n         [ 0.0385689 ],\n         [-0.01325462]],\n\n        [[-0.02658791],\n         [ 0.04491263],\n         [ 0.01900977],\n         ...,\n         [-0.00925941],\n         [ 0.04067061],\n         [-0.03203978]],\n\n        [[-0.02860303],\n         [ 0.00088431],\n         [-0.03354765],\n         ...,\n         [-0.02702828],\n         [-0.0178824 ],\n         [ 0.0075737 ]]],\n\n\n       [[[ 0.03257695],\n         [ 0.00523627],\n         [ 0.01086204],\n         ...,\n         [-0.01027123],\n         [-0.01318854],\n         [-0.0080928 ]],\n\n        [[ 0.01711234],\n         [-0.00469417],\n         [-0.02240466],\n         ...,\n         [ 0.0386394 ],\n         [-0.03802041],\n         [-0.0040078 ]],\n\n        [[-0.00369647],\n         [ 0.01324173],\n         [-0.03341268],\n         ...,\n         [ 0.01164204],\n         [ 0.01389095],\n         [-0.03039853]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/conv2d_1/kernel:0' shape=(1, 1, 672, 112) dtype=float32, numpy=\narray([[[[-0.00266667,  0.03014395,  0.02668047, ..., -0.0314961 ,\n          -0.03319273, -0.00969079],\n         [ 0.07900628,  0.03745876, -0.01490635, ...,  0.02624054,\n          -0.01047033, -0.07650313],\n         [ 0.02356237, -0.03130692,  0.03067523, ..., -0.06359611,\n           0.04184388,  0.03455317],\n         ...,\n         [ 0.04103096,  0.01069454,  0.06131755, ...,  0.04147609,\n           0.02061796,  0.01619933],\n         [ 0.02983697, -0.07677518, -0.03068724, ..., -0.03915524,\n          -0.05607092,  0.02268139],\n         [-0.00462203,  0.05226349,  0.08682993, ..., -0.02759304,\n          -0.05311427,  0.01523298]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/moving_mean:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 22, 672) dtype=float32, numpy=\narray([[[[ 0.18786344,  0.12604521, -0.04501265, ...,  0.07109242,\n          -0.47982773, -0.0677612 ],\n         [ 0.2618899 , -0.3980752 , -0.30758515, ..., -0.06631817,\n          -0.08941885, -0.15816832],\n         [-0.11506429, -0.00277571,  0.13713962, ..., -0.0566028 ,\n           0.27663597, -0.09413323],\n         ...,\n         [-0.15575771, -0.15221483,  0.14853598, ..., -0.4634371 ,\n          -0.02095373, -0.09162367],\n         [-0.14941089,  0.3243132 ,  0.00394255, ...,  0.0455074 ,\n          -0.15589875,  0.23712142],\n         [-0.18219858, -0.3280798 ,  0.14526923, ..., -0.22644341,\n          -0.31533128, -0.06355378]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/conv2d_1/kernel:0' shape=(1, 1, 48, 16) dtype=float32, numpy=\narray([[[[-1.02181524e-01, -7.25777596e-02,  8.90106559e-02,\n          -1.86004907e-01,  3.00907761e-01,  1.48552343e-01,\n           1.39019474e-01,  2.88058668e-01,  2.10673902e-02,\n           6.88962862e-02, -8.51926580e-02,  6.53823167e-02,\n          -1.45136029e-01, -7.85291642e-02, -7.25867748e-02,\n           1.43174782e-01],\n         [-2.24682406e-01,  3.22753221e-01, -7.08048493e-02,\n          -1.45695597e-01, -7.21457079e-02,  4.24870341e-05,\n           3.03617232e-02,  1.96206316e-01,  1.14046913e-02,\n           2.52127089e-02,  6.18198179e-02,  2.98034642e-02,\n          -8.43900163e-03,  9.62586105e-02, -7.30514824e-02,\n          -2.18906458e-02],\n         [ 2.34150097e-01,  1.07950263e-01,  1.79907173e-01,\n          -5.66559024e-02, -4.23578881e-02,  2.81627208e-01,\n          -2.13104650e-01,  2.06335634e-01,  1.24032654e-01,\n          -8.56553018e-02, -1.46149606e-01, -7.23259971e-02,\n          -1.16082333e-01, -1.14865407e-01,  2.63576269e-01,\n          -8.24334621e-02],\n         [-1.45542622e-01,  1.78907692e-01,  2.66639769e-01,\n           2.89792955e-01,  9.97686014e-02, -2.76628067e-03,\n           2.23187730e-01,  6.13700449e-02, -5.67456074e-02,\n          -3.86756659e-02,  9.64571759e-02,  3.98134328e-02,\n           1.04198404e-01, -4.98739928e-02, -1.59259260e-01,\n          -2.66742676e-01],\n         [-1.18493266e-01, -7.02051222e-02, -6.59645349e-02,\n           3.38049755e-02, -1.47867560e-01,  7.02824965e-02,\n          -1.11968569e-01, -8.70006606e-02, -4.94164042e-02,\n           2.51324032e-03,  2.62915753e-02, -8.96383300e-02,\n           1.51135623e-01, -3.12440507e-02,  2.36292910e-02,\n           1.65162478e-02],\n         [ 1.57954067e-01, -2.94619471e-01,  1.96081097e-03,\n          -1.03333600e-01, -3.27900261e-01,  2.21132159e-01,\n           2.66339853e-02, -2.32908860e-01,  1.36533543e-01,\n          -7.41727203e-02,  4.98304330e-02,  2.18312502e-01,\n          -3.13802212e-01,  8.79045278e-02,  1.25991076e-01,\n          -2.50706524e-01],\n         [-3.24532464e-02, -2.65887558e-01,  5.73137403e-02,\n          -1.34154081e-01,  3.15417955e-03,  4.95391898e-02,\n          -1.13012120e-01,  1.82941690e-01, -1.01797050e-02,\n          -1.74275801e-01,  1.98419928e-03, -9.65388194e-02,\n          -3.27803999e-01, -2.52139084e-02,  8.77076164e-02,\n           9.16032307e-03],\n         [ 1.58155132e-02, -2.43053406e-01,  2.11689353e-01,\n           1.99067090e-02, -2.16767602e-02, -1.84347257e-01,\n          -1.48267925e-01,  1.27169728e-01, -9.10081938e-02,\n           2.47795582e-01,  2.41188314e-02,  2.45306417e-01,\n           3.35509167e-03,  2.88400143e-01,  5.10288030e-02,\n          -1.09803133e-01],\n         [ 1.30566165e-01, -1.11069545e-01, -2.45236121e-02,\n           6.36465475e-02, -9.49181914e-02,  1.42550290e-01,\n          -1.62568361e-01, -1.56498358e-01,  8.97106081e-02,\n          -2.99477391e-02,  1.59102216e-01,  4.52981591e-02,\n          -1.56800807e-01,  4.24487256e-02, -2.40603969e-01,\n           8.72158036e-02],\n         [ 3.25359590e-02,  1.00344390e-01,  1.18712731e-01,\n          -1.10225484e-01,  1.34726658e-01, -4.22361642e-02,\n           2.78295577e-01,  9.33252946e-02,  8.67340565e-02,\n           4.10922132e-02, -2.91002523e-02,  8.76883566e-02,\n          -1.20117262e-01,  1.93860456e-01,  5.09554483e-02,\n           1.69934273e-01],\n         [-2.64407061e-02, -2.43461058e-02, -1.11113265e-01,\n          -2.92662323e-01,  2.00214267e-01,  6.42837584e-02,\n           8.26920494e-02,  1.18289873e-01, -1.08833961e-01,\n          -8.54469091e-03,  1.98734090e-01,  1.04158401e-01,\n           1.05692248e-03,  1.59713015e-01, -1.24541976e-01,\n          -4.95548313e-03],\n         [ 8.57236087e-02, -1.82414078e-04,  6.72515780e-02,\n          -1.83787152e-01,  2.76540667e-02, -7.11885318e-02,\n           6.62677409e-03, -7.98571929e-02, -1.85721040e-01,\n           2.97254622e-01,  2.09907070e-01,  1.14811979e-01,\n          -7.12441653e-02, -2.12579090e-02, -1.22004353e-01,\n          -7.18095377e-02],\n         [ 7.74764493e-02, -8.07218179e-02, -6.34014010e-02,\n           1.46065578e-01, -1.12367524e-02,  3.08802873e-02,\n           8.15941840e-02,  1.97391003e-01,  1.47138536e-01,\n           6.80283457e-02, -1.42199159e-01,  9.17010605e-02,\n           1.95323110e-01, -6.29295781e-02, -1.09015472e-01,\n           1.22423016e-01],\n         [ 3.36311720e-02,  7.94820189e-02, -1.55627057e-01,\n           2.49369070e-01, -3.18250626e-01,  1.33801103e-01,\n           1.24305658e-01, -8.40935484e-02, -6.46493882e-02,\n          -1.89908937e-01, -1.50145084e-01, -1.21420972e-01,\n           2.13825062e-01,  1.14537135e-01, -1.08218752e-01,\n           6.87922314e-02],\n         [ 1.33074284e-01, -1.18591987e-01, -5.25621660e-02,\n          -5.02595007e-02,  4.52356646e-03,  1.24821030e-01,\n          -3.27542424e-02, -2.02210504e-03,  8.90989788e-03,\n           2.82372534e-01, -4.53988686e-02,  1.47531062e-01,\n          -7.41540566e-02,  6.54057413e-02,  1.59883536e-02,\n           1.37441322e-01],\n         [ 1.01780362e-01, -3.11982329e-03,  3.23392376e-02,\n          -1.50009841e-01, -1.68700755e-01,  3.46118063e-02,\n           1.29430935e-01, -7.40154386e-02, -1.94036499e-01,\n          -1.52886033e-01,  2.40291879e-01,  3.24320406e-01,\n          -1.15377896e-01, -7.74510652e-02, -1.47420123e-01,\n          -4.02958989e-02],\n         [-3.82325277e-02,  2.32930750e-01, -2.28026465e-01,\n           5.03906198e-02, -5.62171079e-02,  4.12754752e-02,\n          -2.38826293e-02, -6.89155608e-02, -8.18880349e-02,\n           4.42061061e-03, -1.13892987e-01, -3.97676378e-02,\n           4.21150438e-02,  9.08962712e-02,  3.07603270e-01,\n          -4.75876890e-02],\n         [ 2.25391343e-01,  5.63282408e-02,  7.41237728e-03,\n           1.23824105e-01,  6.29147440e-02, -1.28068149e-01,\n           1.47795275e-01, -2.41845883e-02,  2.00235531e-01,\n          -1.06524386e-01, -2.74975210e-01, -1.93612754e-01,\n          -3.13928723e-01,  6.29700199e-02, -3.06633450e-02,\n           9.24778059e-02],\n         [-1.89643294e-01, -1.58751546e-03,  2.84088384e-02,\n          -2.97337115e-01,  1.72584325e-01, -1.55372918e-01,\n           1.28265530e-01, -1.32720489e-02,  1.08151361e-01,\n           1.69150084e-01,  1.70283616e-01, -2.14693382e-01,\n          -3.55941541e-02, -1.01406336e-01, -1.51374996e-01,\n          -1.00705154e-01],\n         [ 2.14555457e-01, -1.27922930e-02, -4.87317108e-02,\n          -1.91085979e-01, -8.85218754e-03, -2.12998569e-01,\n           1.61059603e-01,  2.14747444e-01, -8.53616744e-02,\n          -5.25604934e-02,  2.36451596e-01, -6.25107139e-02,\n          -1.59164481e-02, -2.91219831e-01,  1.55970827e-01,\n          -1.14534318e-01],\n         [ 1.73278913e-01,  9.88745131e-04,  2.70399332e-01,\n          -2.49358296e-01,  3.17873061e-02,  1.27640646e-02,\n          -8.49547461e-02, -5.36032878e-02,  4.84497100e-02,\n           7.64451921e-02, -1.76088177e-02, -1.08589411e-01,\n           3.53286345e-03,  6.78457320e-02,  1.03090495e-01,\n           6.02727942e-02],\n         [-1.86414480e-01, -5.57431839e-02, -3.84370722e-02,\n           1.21744864e-01,  7.30370730e-02,  1.01285741e-01,\n           3.93401347e-02,  5.85956313e-03, -1.38463110e-01,\n           1.28210843e-01,  2.21437380e-01,  1.41965196e-01,\n           2.15172172e-01, -2.73327027e-02, -1.75234050e-01,\n          -9.61982924e-03],\n         [ 2.38107637e-01, -3.53073664e-02,  1.68440744e-01,\n           2.96526644e-02,  1.21617101e-01,  2.21708447e-01,\n           7.18526244e-02, -1.11687444e-01, -4.19403203e-02,\n           4.43263426e-02,  5.94520867e-02, -7.71521777e-02,\n          -4.82642651e-02,  3.08729261e-01, -7.03656301e-02,\n           1.98290542e-01],\n         [ 5.99126369e-02,  2.05281049e-01,  5.15868664e-02,\n          -3.52837965e-02, -8.69954601e-02,  6.91513047e-02,\n           9.27370861e-02, -2.25239679e-01, -1.60201974e-02,\n          -1.05777249e-01,  1.10523298e-01,  1.09623961e-01,\n           7.89763406e-02,  1.42659664e-01,  1.58130631e-01,\n          -9.13958848e-02],\n         [ 3.56138200e-02,  3.25297415e-02,  1.07691579e-01,\n           1.76336542e-01, -1.33302942e-01,  3.27597931e-02,\n           2.93018669e-01,  8.23027194e-02, -2.54388243e-01,\n          -2.44387046e-01,  1.56651139e-01, -2.83729255e-01,\n           5.83191216e-02,  8.30602646e-02, -1.85414448e-01,\n          -7.65476674e-02],\n         [-2.39664271e-01,  2.61359751e-01,  2.22969040e-01,\n          -2.92681813e-01,  3.34077328e-02,  9.23342109e-02,\n          -3.05619210e-01, -3.80843952e-02, -7.14975819e-02,\n           1.12608612e-01,  1.01626419e-01,  1.71271130e-01,\n           9.52569768e-02,  6.74543343e-03, -4.49980162e-02,\n          -3.05042230e-02],\n         [ 4.56222259e-02,  1.36861712e-01, -2.84185946e-01,\n          -8.54362249e-02, -4.35483754e-02,  8.63322616e-02,\n           1.80963650e-01,  7.72910425e-03, -2.26032570e-01,\n           1.35270804e-01,  1.47955166e-02,  2.82299370e-01,\n          -7.48860091e-02, -1.34217203e-01,  7.32719600e-02,\n          -7.65958726e-02],\n         [ 2.17576653e-01,  5.17210737e-03,  5.50453216e-02,\n          -3.38355033e-03, -8.10837895e-02, -1.42146409e-01,\n          -1.66495234e-01,  7.87371099e-02,  9.20132361e-03,\n           1.77631274e-01, -3.75026949e-02, -1.43959031e-01,\n           1.84399232e-01,  1.23184867e-01,  1.47548810e-01,\n           1.28731102e-01],\n         [ 2.30618581e-01,  1.84325278e-01,  2.68379390e-01,\n           2.50827044e-01,  1.96538925e-01,  2.73314625e-01,\n          -1.60220433e-02,  1.80634558e-01,  1.17443822e-01,\n           1.88180059e-02, -1.01446703e-01,  1.96876720e-01,\n           1.74266115e-01,  3.60445678e-02,  1.21307746e-02,\n          -1.11937791e-01],\n         [-1.91131365e-02, -4.53058481e-02, -1.15102626e-01,\n           4.95938286e-02, -7.81944096e-02, -4.97212000e-02,\n           1.92438856e-01, -2.39768162e-01, -1.63508281e-01,\n          -3.30265961e-04,  1.26804352e-01, -1.82086140e-01,\n          -5.62040973e-03, -2.17691690e-01,  2.76131004e-01,\n           1.84075549e-01],\n         [-1.10748328e-01,  6.51763454e-02,  2.29822338e-01,\n           1.67506576e-01, -4.07474115e-02, -5.39673120e-02,\n          -2.27724448e-01, -6.65826574e-02,  2.79039532e-01,\n           3.28486995e-03, -9.92082879e-02, -5.25546409e-02,\n          -1.04851097e-01,  2.50993595e-02,  8.60331357e-02,\n          -3.08229923e-02],\n         [-3.55478562e-02, -4.16829437e-02,  1.03898264e-01,\n           2.36273721e-01, -1.38596063e-02, -2.31124789e-01,\n           1.04059204e-01, -2.83180743e-01, -9.62332077e-03,\n          -1.47309005e-01,  1.05392158e-01,  5.36897853e-02,\n          -2.50509307e-02, -7.95836896e-02,  4.15101871e-02,\n          -2.75264859e-01],\n         [ 2.10245803e-01, -3.98529172e-02, -2.64765590e-01,\n           1.07619330e-01,  1.79662243e-01, -1.74933285e-01,\n          -1.71799675e-01, -1.41173258e-01, -3.84134017e-02,\n          -1.96545906e-02,  1.47436917e-01, -1.49164245e-01,\n           7.49868676e-02, -9.84556079e-02,  2.12001249e-01,\n          -5.78430817e-02],\n         [-8.97223800e-02,  2.86912173e-01, -2.62841787e-02,\n          -2.56170660e-01, -9.64613352e-03,  2.69677285e-02,\n          -5.41694579e-04,  2.34047547e-01,  3.34745320e-03,\n           6.37298748e-02,  1.46696419e-01, -2.53614128e-01,\n           4.58766669e-02, -1.11500196e-01, -1.74091198e-02,\n           7.75560364e-02],\n         [-1.71826091e-02, -2.10667387e-01,  1.37687966e-01,\n          -1.19939111e-01, -7.41712824e-02, -6.40208200e-02,\n          -1.67886000e-02,  1.39687777e-01,  4.21378836e-02,\n           3.89180668e-02,  1.74796417e-01, -1.99876532e-01,\n          -2.99249589e-01,  7.10245296e-02, -9.38150659e-02,\n           5.01777139e-03],\n         [-1.13493584e-01, -1.09270714e-01,  3.28636058e-02,\n           4.92055640e-02, -1.46066859e-01,  1.91645488e-01,\n          -5.97882979e-02,  3.00473511e-01,  1.90640986e-02,\n           3.11508887e-02, -1.43666938e-01, -2.18929276e-01,\n           2.31208906e-01, -3.36096622e-02, -1.67405102e-02,\n           1.22818239e-01],\n         [-1.45999864e-01,  7.32734352e-02,  2.54455954e-01,\n           1.92452028e-01, -4.89150956e-02, -7.94497356e-02,\n           9.09663737e-02,  1.15875915e-01,  1.83012649e-01,\n          -8.38058963e-02, -6.29356652e-02,  7.82416388e-02,\n           2.92102575e-01, -2.64993876e-01,  6.84432760e-02,\n           4.14422713e-02],\n         [ 1.37558043e-01, -6.48783054e-03,  1.33791342e-02,\n           5.58794253e-02, -1.12529777e-01, -1.61715299e-01,\n           9.51136574e-02, -1.47645086e-01,  9.76647139e-02,\n           1.34419456e-01,  6.70032750e-04,  1.80288628e-02,\n           2.04077557e-01,  6.98165745e-02, -4.42982838e-02,\n          -2.10351869e-01],\n         [-5.06078042e-02,  2.24750131e-01, -3.49927694e-02,\n           4.29473333e-02, -2.20072329e-01,  1.82456225e-01,\n           9.55630466e-02,  1.69595510e-01, -1.00732967e-01,\n          -1.73102200e-01, -5.59920967e-02, -1.48348108e-01,\n           5.40265888e-02, -1.93006486e-01,  1.17594130e-01,\n          -7.79562071e-02],\n         [-6.01457953e-02,  2.99031317e-01, -5.18117212e-02,\n          -2.80229956e-01, -1.11987256e-01,  1.35468200e-01,\n          -9.81529057e-02, -5.28691895e-02,  1.24282166e-01,\n          -5.77128865e-02,  8.37636068e-02, -1.27593100e-01,\n          -2.16098428e-01, -1.09928995e-02, -4.94445600e-02,\n           2.47993737e-01],\n         [ 2.05893114e-01,  4.09197398e-02,  2.46151671e-01,\n          -2.72073783e-02, -2.68758178e-01, -2.99959958e-01,\n          -1.04729973e-01,  1.64711162e-01, -2.20185012e-01,\n           3.30054425e-02, -9.62202176e-02,  2.28863955e-01,\n          -1.75233960e-01, -6.57974109e-02, -9.78763551e-02,\n           3.98478508e-02],\n         [-8.92820209e-02,  8.28092918e-02, -1.22760050e-01,\n           5.92688681e-04, -1.35606572e-01, -3.15818638e-02,\n          -2.29801431e-01, -9.98021066e-02, -1.80383578e-01,\n          -3.47576216e-02, -1.23595476e-01,  1.35637328e-01,\n           1.70570984e-02,  1.37430981e-01,  1.38109267e-01,\n          -2.65610665e-01],\n         [-7.37612769e-02, -1.16773784e-01,  5.43266684e-02,\n           2.11834937e-01,  2.91099280e-01,  1.79449245e-01,\n           1.35207614e-02, -9.66300082e-04, -1.23524241e-01,\n           1.10784717e-01, -1.25249609e-01,  1.70965753e-02,\n          -5.92054650e-02, -8.25566798e-02, -3.71096618e-02,\n          -3.02544355e-01],\n         [-1.44560695e-01,  1.17624514e-01, -6.80882931e-02,\n          -2.18734075e-03,  7.92770386e-02, -6.66104332e-02,\n          -5.99203296e-02,  2.71038651e-01,  1.10681474e-01,\n           5.78726381e-02,  2.00314801e-02, -2.24641219e-01,\n          -8.10881704e-02, -2.86036611e-01, -1.02746487e-01,\n          -1.77701876e-01],\n         [ 1.17489479e-01,  1.07996063e-02, -4.15525027e-02,\n          -2.91466918e-02,  3.07904202e-02, -1.04048001e-02,\n           6.87485337e-02, -2.45118737e-01,  8.25035200e-03,\n          -1.28545919e-02,  1.24011412e-01,  1.52969494e-01,\n          -2.43195996e-01,  8.16511512e-02,  1.31879270e-01,\n          -8.99414718e-03],\n         [-2.58023441e-01,  5.46123162e-02,  2.76821945e-02,\n          -9.41413566e-02, -5.22293635e-02, -3.28014433e-01,\n           2.70314872e-01, -1.94480389e-01,  1.15801260e-01,\n          -1.11605279e-01,  3.01359519e-02, -2.47813053e-02,\n           2.07918193e-02, -2.12495979e-02,  2.27290541e-01,\n           8.60297605e-02],\n         [ 1.91424325e-01,  1.29608423e-01,  2.65128780e-02,\n          -9.84849259e-02,  1.33727938e-01, -1.89162463e-01,\n          -2.21847117e-01,  4.89297211e-02,  1.06917962e-01,\n          -1.06698759e-01, -4.88257036e-02,  1.37369588e-01,\n          -1.72220275e-01,  1.38163000e-01, -1.02464557e-01,\n          -9.28356126e-02],\n         [-3.33271734e-02,  1.12439118e-01, -5.66471368e-02,\n           8.81095454e-02,  1.42193526e-01,  2.24082530e-01,\n          -2.61987895e-02, -3.26926336e-02, -1.26960486e-01,\n           2.93076605e-01, -1.89460814e-01, -5.85879311e-02,\n          -2.26266265e-01, -3.90795618e-02,  2.25898791e-02,\n          -7.29364753e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/beta:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_374/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.03971641],\n         [ 0.02154293],\n         [ 0.06626424],\n         ...,\n         [-0.07487623],\n         [ 0.06870477],\n         [-0.07227591]],\n\n        [[ 0.07187608],\n         [ 0.05755942],\n         [ 0.04431364],\n         ...,\n         [ 0.0232104 ],\n         [-0.04937269],\n         [-0.00543904]],\n\n        [[ 0.02613164],\n         [ 0.04544594],\n         [ 0.06915727],\n         ...,\n         [ 0.03430823],\n         [ 0.00054798],\n         [ 0.00852149]]],\n\n\n       [[[ 0.05902345],\n         [ 0.06464124],\n         [ 0.0472585 ],\n         ...,\n         [ 0.02441438],\n         [ 0.05487467],\n         [ 0.04975504]],\n\n        [[-0.04066389],\n         [ 0.03292453],\n         [-0.06758874],\n         ...,\n         [ 0.07410011],\n         [-0.05377408],\n         [ 0.0054394 ]],\n\n        [[ 0.002588  ],\n         [-0.04081379],\n         [ 0.06389795],\n         ...,\n         [-0.00103398],\n         [ 0.07333204],\n         [-0.06200524]]],\n\n\n       [[[-0.00235611],\n         [ 0.00851078],\n         [-0.05419039],\n         ...,\n         [-0.02631247],\n         [ 0.07017735],\n         [ 0.052789  ]],\n\n        [[ 0.00757284],\n         [ 0.02946821],\n         [ 0.02877439],\n         ...,\n         [ 0.00752001],\n         [ 0.03604785],\n         [ 0.07542095]],\n\n        [[-0.04866141],\n         [ 0.04339413],\n         [-0.04499489],\n         ...,\n         [-0.02147651],\n         [ 0.05177794],\n         [ 0.06711251]]]], dtype=float32)>, <tf.Variable 'conv2d_873/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[-0.08228299, -0.10042142, -0.14646548, ..., -0.06682579,\n          -0.12935759,  0.06716952],\n         [ 0.12372063, -0.08948938, -0.12282396, ..., -0.04901413,\n          -0.03705778,  0.18005234],\n         [ 0.14789614, -0.03093061, -0.14247869, ...,  0.03753457,\n          -0.10338383, -0.00158537],\n         ...,\n         [-0.09937522, -0.04977391,  0.09749693, ...,  0.00172218,\n          -0.12187161,  0.09031255],\n         [-0.00452282, -0.16338657, -0.11814156, ...,  0.09473725,\n           0.03825827,  0.0155141 ],\n         [-0.1459344 , -0.05121383,  0.11358248, ..., -0.05892809,\n           0.0844176 ,  0.10785883]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/conv2d_1/kernel:0' shape=(1, 1, 480, 80) dtype=float32, numpy=\narray([[[[ 0.06176353, -0.01652106, -0.01412831, ...,  0.01955262,\n           0.09287293, -0.02693438],\n         [ 0.00824071, -0.00586807,  0.08832687, ..., -0.02067577,\n          -0.05568636, -0.0871231 ],\n         [-0.04435338,  0.0541266 , -0.00054808, ...,  0.01516627,\n          -0.02366685, -0.07100553],\n         ...,\n         [ 0.07872646,  0.00419506,  0.03426314, ..., -0.08489309,\n          -0.04017992,  0.0593922 ],\n         [ 0.00327188, -0.00678592, -0.04918166, ..., -0.01181698,\n           0.00403947,  0.03008547],\n         [ 0.0136309 , -0.04501588, -0.01774996, ..., -0.03336721,\n          -0.02977681,  0.0736668 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/squeeze_excitation/conv2d_3/kernel:0' shape=(1, 1, 8, 240) dtype=float32, numpy=\narray([[[[ 0.19422825, -0.05745029, -0.01499916, ...,  0.517576  ,\n           0.10424303, -0.01301186],\n         [-0.11046448, -0.29540455,  0.1400048 , ..., -0.40834996,\n           0.27793723, -0.06076267],\n         [-0.37831515, -0.1006196 ,  0.5182175 , ..., -0.49494174,\n           0.04465031,  0.27039543],\n         ...,\n         [ 0.15394491,  0.01537794, -0.37696788, ...,  0.04789364,\n           0.47758695,  0.07914821],\n         [-0.22362801, -0.24872197,  0.42814654, ..., -0.18299043,\n           0.16262025,  0.12342016],\n         [-0.77522725,  0.18929759,  0.07792163, ..., -0.52205354,\n          -0.4897011 , -0.04682273]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_376/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-7.54119456e-02],\n         [ 4.35901135e-02],\n         [-1.56401843e-02],\n         [-6.54867589e-02],\n         [ 7.67492950e-02],\n         [ 4.23647016e-02],\n         [-8.69500265e-02],\n         [-1.82650238e-02],\n         [ 5.17879277e-02],\n         [-1.35912597e-02],\n         [-2.25840509e-03],\n         [-3.96893136e-02],\n         [ 3.28698754e-03],\n         [-5.64172417e-02],\n         [ 3.91502827e-02],\n         [ 3.59694660e-03],\n         [ 8.13923776e-02],\n         [-3.53698283e-02],\n         [-6.39253110e-03],\n         [ 6.44260347e-02],\n         [-5.92353195e-02],\n         [ 4.34220880e-02],\n         [-3.61393504e-02],\n         [-2.70348340e-02],\n         [ 5.60555905e-02],\n         [ 8.85745883e-03],\n         [-8.93270746e-02],\n         [ 7.36064017e-02],\n         [ 3.74496132e-02],\n         [ 5.99114597e-02],\n         [-5.98261356e-02],\n         [-7.08203167e-02],\n         [-5.12632988e-02],\n         [ 4.85774279e-02],\n         [-4.03982103e-02],\n         [ 9.84951854e-04],\n         [-4.07257266e-02],\n         [-4.96313311e-02],\n         [-2.37129554e-02],\n         [ 7.44497031e-02],\n         [ 2.98440233e-02],\n         [-5.14727198e-02],\n         [-7.16835558e-02],\n         [ 7.04396516e-02],\n         [-7.32333958e-02],\n         [-4.76629809e-02],\n         [-6.45708218e-02],\n         [-7.50364736e-02],\n         [-8.82310271e-02],\n         [ 8.57872516e-02],\n         [ 4.08156812e-02],\n         [-7.69297779e-03],\n         [-3.03034000e-02],\n         [ 5.38863689e-02],\n         [ 7.10701793e-02],\n         [-8.30060318e-02],\n         [ 5.83906919e-02],\n         [ 5.42241335e-03],\n         [ 8.59430730e-02],\n         [-6.49167448e-02],\n         [ 7.64623284e-03],\n         [ 3.19572985e-02],\n         [ 2.73965299e-02],\n         [ 5.62180281e-02],\n         [ 6.87173158e-02],\n         [-2.93542407e-02],\n         [ 6.68308288e-02],\n         [ 4.19791788e-02],\n         [ 3.95928174e-02],\n         [-4.38746326e-02],\n         [ 6.07686043e-02],\n         [-6.77663609e-02],\n         [-1.86048523e-02],\n         [-5.30321151e-03],\n         [ 5.28227240e-02],\n         [-4.06262726e-02],\n         [-5.43178990e-02],\n         [ 6.49656504e-02],\n         [-4.05533612e-02],\n         [ 6.90804571e-02]],\n\n        [[ 5.72535843e-02],\n         [-5.54751568e-02],\n         [ 4.13765311e-02],\n         [-7.56911188e-02],\n         [ 2.15933919e-02],\n         [ 5.49217165e-02],\n         [-8.08221176e-02],\n         [ 7.95510858e-02],\n         [ 7.74058402e-02],\n         [-7.44868219e-02],\n         [ 5.91836721e-02],\n         [ 6.47287220e-02],\n         [ 8.20962340e-02],\n         [-8.57135355e-02],\n         [ 1.17464140e-02],\n         [ 5.54461926e-02],\n         [-3.93197276e-02],\n         [-2.38975883e-02],\n         [ 3.91321927e-02],\n         [-1.58593580e-02],\n         [-4.27885577e-02],\n         [ 7.74641931e-02],\n         [ 8.28367770e-02],\n         [ 8.44681859e-02],\n         [ 7.99739957e-02],\n         [ 7.27482140e-02],\n         [-6.67780787e-02],\n         [-6.94502369e-02],\n         [ 3.25453654e-02],\n         [ 6.40894324e-02],\n         [ 3.41777205e-02],\n         [-7.27396533e-02],\n         [-5.77187054e-02],\n         [ 7.22127408e-03],\n         [ 2.84705982e-02],\n         [-2.93121934e-02],\n         [ 1.44367889e-02],\n         [-7.52701387e-02],\n         [-2.44244933e-04],\n         [ 4.01310325e-02],\n         [ 3.17976028e-02],\n         [ 1.95085406e-02],\n         [-6.42912835e-03],\n         [ 3.41976881e-02],\n         [ 8.25452656e-02],\n         [ 8.32222551e-02],\n         [ 1.14671141e-02],\n         [-3.17213833e-02],\n         [-2.28364766e-02],\n         [ 8.07520747e-02],\n         [ 2.58139670e-02],\n         [-3.49797569e-02],\n         [ 2.95975730e-02],\n         [ 5.67703545e-02],\n         [ 3.17150205e-02],\n         [-3.10653932e-02],\n         [ 6.08955920e-02],\n         [ 4.40307558e-02],\n         [ 6.77395910e-02],\n         [-2.28326023e-03],\n         [ 6.36583418e-02],\n         [ 3.98417413e-02],\n         [ 5.18492311e-02],\n         [-3.65202054e-02],\n         [ 7.15821981e-03],\n         [ 3.04634571e-02],\n         [ 1.22026131e-02],\n         [-2.46368945e-02],\n         [-5.31151108e-02],\n         [-8.70133117e-02],\n         [-1.54497549e-02],\n         [-5.12846038e-02],\n         [ 4.39778715e-03],\n         [-6.43447042e-03],\n         [-4.65566590e-02],\n         [ 5.70022464e-02],\n         [ 7.15953857e-03],\n         [-7.95828179e-02],\n         [ 1.54453665e-02],\n         [-3.50460745e-02]],\n\n        [[ 2.77394727e-02],\n         [-2.58966163e-02],\n         [-1.66886449e-02],\n         [ 4.86398190e-02],\n         [ 7.33190328e-02],\n         [ 1.42366514e-02],\n         [ 4.08184826e-02],\n         [ 4.73294407e-03],\n         [-1.73185468e-02],\n         [ 5.09149581e-03],\n         [ 8.98689628e-02],\n         [ 3.43587697e-02],\n         [ 2.32455358e-02],\n         [-1.31728128e-02],\n         [-4.32538167e-02],\n         [ 3.86973321e-02],\n         [ 7.14071989e-02],\n         [ 6.28632307e-02],\n         [-6.61212876e-02],\n         [-7.52777085e-02],\n         [-1.90151259e-02],\n         [-8.97690728e-02],\n         [ 5.31234741e-02],\n         [ 5.40803969e-02],\n         [-8.41703564e-02],\n         [ 7.28517771e-05],\n         [ 3.60610932e-02],\n         [ 3.57715338e-02],\n         [ 4.11098748e-02],\n         [-4.83782589e-03],\n         [ 3.55465710e-03],\n         [-7.91186839e-03],\n         [-1.03218332e-02],\n         [ 5.51280826e-02],\n         [ 2.87270248e-02],\n         [ 4.55874950e-02],\n         [ 6.97382838e-02],\n         [-2.90578045e-02],\n         [-4.26749587e-02],\n         [-3.41850780e-02],\n         [ 7.10358322e-02],\n         [ 3.52026224e-02],\n         [-4.95918803e-02],\n         [ 8.34358186e-02],\n         [ 4.77175564e-02],\n         [ 7.21576065e-03],\n         [ 6.23911023e-02],\n         [ 8.79271477e-02],\n         [ 7.99205005e-02],\n         [ 8.46968740e-02],\n         [-2.15377584e-02],\n         [ 3.15198153e-02],\n         [ 8.96793604e-02],\n         [ 5.97443581e-02],\n         [ 7.38078356e-02],\n         [-5.77374361e-02],\n         [ 4.46983427e-03],\n         [ 2.87043303e-02],\n         [ 5.88855296e-02],\n         [-8.09071660e-02],\n         [-8.23021084e-02],\n         [-5.89700751e-02],\n         [-6.90551847e-03],\n         [ 3.82395089e-03],\n         [-7.72838295e-03],\n         [ 1.76490098e-03],\n         [-2.36759931e-02],\n         [-5.43821827e-02],\n         [ 2.58054212e-02],\n         [ 1.64693445e-02],\n         [-3.86437736e-02],\n         [ 3.78810018e-02],\n         [ 4.91713136e-02],\n         [-4.72817123e-02],\n         [-9.72598046e-03],\n         [ 8.03824067e-02],\n         [-7.08978102e-02],\n         [-5.27104400e-02],\n         [-4.05620113e-02],\n         [ 2.76838392e-02]]],\n\n\n       [[[-4.85326461e-02],\n         [ 4.39600050e-02],\n         [-5.95268235e-02],\n         [ 3.71420234e-02],\n         [-6.09204546e-02],\n         [ 2.76806951e-03],\n         [-4.10207808e-02],\n         [ 2.48205960e-02],\n         [-1.76252797e-02],\n         [-5.30926138e-02],\n         [-8.63287076e-02],\n         [ 8.56080502e-02],\n         [-6.08716533e-02],\n         [-5.60354739e-02],\n         [ 1.54790208e-02],\n         [ 6.68514073e-02],\n         [ 3.98461521e-03],\n         [ 4.14566249e-02],\n         [ 7.88684040e-02],\n         [-4.81401980e-02],\n         [-8.16377923e-02],\n         [-6.90909252e-02],\n         [ 3.32543924e-02],\n         [ 1.72690377e-02],\n         [ 7.26426840e-02],\n         [ 3.09421942e-02],\n         [-4.61755209e-02],\n         [ 2.53612101e-02],\n         [ 2.51372978e-02],\n         [-1.04279742e-02],\n         [ 8.02167356e-02],\n         [ 8.52757245e-02],\n         [-2.88596340e-02],\n         [-5.40694594e-03],\n         [ 8.91544819e-02],\n         [-6.70565367e-02],\n         [ 6.17378205e-02],\n         [-6.25343323e-02],\n         [ 1.67820677e-02],\n         [ 4.90984023e-02],\n         [ 6.57731742e-02],\n         [-7.30120167e-02],\n         [-6.64066970e-02],\n         [-4.40580547e-02],\n         [-2.23393142e-02],\n         [-6.70069158e-02],\n         [ 8.76470655e-02],\n         [-8.35113898e-02],\n         [-6.83190003e-02],\n         [ 4.06610519e-02],\n         [-5.38447239e-02],\n         [ 9.35472548e-03],\n         [ 7.03892708e-02],\n         [ 3.75416577e-02],\n         [-8.53907317e-02],\n         [-9.01272893e-02],\n         [-1.94965154e-02],\n         [-1.20610446e-02],\n         [ 3.00763920e-02],\n         [ 2.98872218e-02],\n         [-8.15392509e-02],\n         [-8.28994587e-02],\n         [ 1.31528303e-02],\n         [ 7.25422949e-02],\n         [-3.66053730e-03],\n         [-6.93501160e-02],\n         [ 2.78297737e-02],\n         [-2.78673470e-02],\n         [-5.69179058e-02],\n         [-8.00205767e-02],\n         [ 1.46418884e-02],\n         [-2.18716189e-02],\n         [ 4.04654145e-02],\n         [ 2.49038935e-02],\n         [-4.65729907e-02],\n         [-3.62633094e-02],\n         [-4.67263684e-02],\n         [ 7.71150291e-02],\n         [ 9.03513134e-02],\n         [-6.82108775e-02]],\n\n        [[-6.86773658e-03],\n         [ 2.84425169e-03],\n         [ 1.60290897e-02],\n         [-5.76147959e-02],\n         [ 5.59065789e-02],\n         [ 8.72246921e-03],\n         [-3.86033207e-03],\n         [ 5.89344501e-02],\n         [ 6.35267794e-02],\n         [ 6.69771284e-02],\n         [-2.06507668e-02],\n         [ 8.59850645e-03],\n         [-3.59203257e-02],\n         [-6.88398033e-02],\n         [ 4.79807258e-02],\n         [ 2.70279348e-02],\n         [ 2.09501684e-02],\n         [-6.67875037e-02],\n         [-2.23895907e-03],\n         [-6.07346743e-03],\n         [-8.38409811e-02],\n         [-1.76290423e-02],\n         [ 8.59877765e-02],\n         [-1.54868290e-02],\n         [ 2.40212902e-02],\n         [-3.28111127e-02],\n         [-1.77472532e-02],\n         [ 3.92719060e-02],\n         [-4.82305139e-03],\n         [ 4.73845452e-02],\n         [-6.26439601e-03],\n         [ 8.44971836e-02],\n         [ 8.92895907e-02],\n         [-6.10536039e-02],\n         [-5.08295000e-03],\n         [ 6.68126643e-02],\n         [ 5.00462800e-02],\n         [ 8.63014907e-03],\n         [-9.65531170e-03],\n         [ 4.73418236e-02],\n         [-7.01506957e-02],\n         [ 3.93184572e-02],\n         [-5.71880601e-02],\n         [ 6.40861690e-02],\n         [-6.55363798e-02],\n         [ 1.01189464e-02],\n         [-9.00772139e-02],\n         [-6.91317767e-03],\n         [ 4.52731550e-02],\n         [-8.97936448e-02],\n         [-7.39973560e-02],\n         [-1.29010528e-03],\n         [-3.18109095e-02],\n         [ 2.75859013e-02],\n         [ 2.88908258e-02],\n         [-7.13028312e-02],\n         [ 4.53336835e-02],\n         [ 2.08915696e-02],\n         [-6.74519092e-02],\n         [-5.10602593e-02],\n         [-1.28109008e-02],\n         [-3.69329900e-02],\n         [-2.38917693e-02],\n         [-5.60949147e-02],\n         [-8.21346343e-02],\n         [ 1.28431767e-02],\n         [-1.23234093e-02],\n         [ 5.99144995e-02],\n         [ 3.80396992e-02],\n         [-2.93520093e-03],\n         [-2.87279747e-02],\n         [-3.92357185e-02],\n         [ 4.94959503e-02],\n         [ 6.81902766e-02],\n         [-7.47677237e-02],\n         [-4.52791639e-02],\n         [ 5.59632033e-02],\n         [-7.65921324e-02],\n         [-8.07574838e-02],\n         [-5.48767671e-02]],\n\n        [[-6.12904504e-02],\n         [ 6.41111284e-02],\n         [-1.51006132e-03],\n         [ 7.54247755e-02],\n         [-6.87352717e-02],\n         [-3.54361460e-02],\n         [-3.48017439e-02],\n         [ 1.80127770e-02],\n         [-1.16605461e-02],\n         [-8.91515911e-02],\n         [ 5.24214059e-02],\n         [-3.52071933e-02],\n         [ 8.41010213e-02],\n         [ 2.60445625e-02],\n         [-8.77312571e-03],\n         [-7.71957636e-03],\n         [-9.04813856e-02],\n         [ 5.47045916e-02],\n         [ 2.36725509e-02],\n         [-7.17540458e-02],\n         [ 8.89526606e-02],\n         [-2.98593603e-02],\n         [-5.99487796e-02],\n         [ 4.22368050e-02],\n         [ 8.83581638e-02],\n         [ 3.24770808e-04],\n         [-3.22478525e-02],\n         [ 2.87808552e-02],\n         [ 6.92919493e-02],\n         [ 1.00817233e-02],\n         [ 2.61961669e-02],\n         [ 8.11803192e-02],\n         [ 1.15083605e-02],\n         [ 1.64433569e-03],\n         [ 3.29069570e-02],\n         [ 5.50898463e-02],\n         [ 7.63210654e-03],\n         [-3.37506831e-03],\n         [ 7.86510706e-02],\n         [ 1.18321180e-03],\n         [ 6.92457110e-02],\n         [-8.94948319e-02],\n         [-5.85604496e-02],\n         [ 4.63472456e-02],\n         [-6.96153939e-03],\n         [-8.78670588e-02],\n         [-4.63373959e-04],\n         [ 8.69005322e-02],\n         [ 1.90617591e-02],\n         [-6.78759590e-02],\n         [ 6.38314784e-02],\n         [-5.95875084e-04],\n         [-7.52058327e-02],\n         [ 2.32845172e-02],\n         [ 6.45345896e-02],\n         [-8.37997347e-02],\n         [-3.92290205e-03],\n         [-5.53201139e-03],\n         [-2.36374512e-02],\n         [-6.25461638e-02],\n         [-8.00660029e-02],\n         [ 1.64624304e-03],\n         [-8.52125660e-02],\n         [-6.83658943e-02],\n         [-5.88944331e-02],\n         [-5.19454144e-02],\n         [ 1.98286176e-02],\n         [ 4.45530564e-02],\n         [ 3.18888426e-02],\n         [ 5.38064837e-02],\n         [-8.52606297e-02],\n         [-1.66572854e-02],\n         [-5.55831529e-02],\n         [ 2.91081369e-02],\n         [ 4.71771806e-02],\n         [-3.00210640e-02],\n         [-4.62510735e-02],\n         [ 1.56757683e-02],\n         [ 8.45512599e-02],\n         [-3.24767083e-03]]],\n\n\n       [[[ 7.70245045e-02],\n         [ 5.20891249e-02],\n         [-7.88103715e-02],\n         [-1.50790662e-02],\n         [ 4.06879038e-02],\n         [-8.47895443e-03],\n         [-5.21993637e-03],\n         [-5.86379468e-02],\n         [-7.13074133e-02],\n         [-4.54593152e-02],\n         [ 4.28686738e-02],\n         [-4.68212143e-02],\n         [ 2.88642868e-02],\n         [ 6.15573376e-02],\n         [ 5.01982868e-04],\n         [-2.05515698e-02],\n         [ 2.90653557e-02],\n         [-4.02364172e-02],\n         [ 8.95099044e-02],\n         [-7.75196999e-02],\n         [ 1.93311349e-02],\n         [ 1.86079666e-02],\n         [ 3.49725783e-02],\n         [ 3.07957828e-02],\n         [-3.69704291e-02],\n         [ 6.35100156e-02],\n         [-3.71705070e-02],\n         [-1.53027624e-02],\n         [-7.95486569e-03],\n         [-3.58980037e-02],\n         [ 3.20954919e-02],\n         [ 8.60620588e-02],\n         [-8.27630162e-02],\n         [ 1.72983706e-02],\n         [-5.33646531e-02],\n         [ 6.85070306e-02],\n         [-1.96834430e-02],\n         [ 4.95140702e-02],\n         [-4.83306497e-03],\n         [ 5.60732633e-02],\n         [-9.01016593e-03],\n         [-2.80307606e-02],\n         [ 2.53148377e-03],\n         [-7.50318170e-04],\n         [-3.84659767e-02],\n         [ 2.58073881e-02],\n         [ 1.96034089e-02],\n         [-6.89935684e-02],\n         [-8.82329941e-02],\n         [-2.50657275e-02],\n         [ 8.04955512e-02],\n         [ 7.42507279e-02],\n         [ 2.37861574e-02],\n         [-3.23145352e-02],\n         [-8.71522650e-02],\n         [-5.56358658e-02],\n         [-5.36520891e-02],\n         [ 7.43738413e-02],\n         [ 3.78282070e-02],\n         [-2.05851421e-02],\n         [-3.29628028e-02],\n         [ 8.96409005e-02],\n         [-1.77031904e-02],\n         [-2.29756460e-02],\n         [-7.85612836e-02],\n         [-5.95954135e-02],\n         [-2.77704895e-02],\n         [-8.00159052e-02],\n         [ 7.17392713e-02],\n         [ 4.61034328e-02],\n         [-2.80745625e-02],\n         [-4.22720835e-02],\n         [-1.98911056e-02],\n         [ 1.80563405e-02],\n         [-1.92397907e-02],\n         [-6.23371154e-02],\n         [-1.32834911e-02],\n         [-4.66507263e-02],\n         [-1.36140808e-02],\n         [-8.40737596e-02]],\n\n        [[-3.34782824e-02],\n         [ 4.49158847e-02],\n         [-2.88777053e-03],\n         [ 1.62878036e-02],\n         [ 7.54041970e-03],\n         [ 1.03477687e-02],\n         [ 2.95691341e-02],\n         [-3.32284793e-02],\n         [-4.12497073e-02],\n         [ 8.22490901e-02],\n         [-2.88310163e-02],\n         [ 4.19954211e-02],\n         [ 8.43392015e-02],\n         [-2.58238539e-02],\n         [ 4.67277914e-02],\n         [ 8.06306750e-02],\n         [ 8.16586614e-03],\n         [ 1.16798431e-02],\n         [-3.78326587e-02],\n         [-7.51038045e-02],\n         [ 5.19819707e-02],\n         [ 6.24464154e-02],\n         [ 4.45526987e-02],\n         [-3.11202258e-02],\n         [ 6.23544604e-02],\n         [-1.31400228e-02],\n         [-8.86063874e-02],\n         [-8.37758183e-03],\n         [ 5.87020814e-02],\n         [-5.78902066e-02],\n         [ 5.38229197e-02],\n         [ 1.55037045e-02],\n         [-3.97254378e-02],\n         [ 1.71234459e-02],\n         [ 8.11417401e-02],\n         [ 1.33733228e-02],\n         [-6.39583543e-02],\n         [ 6.36905730e-02],\n         [ 6.31818175e-02],\n         [-3.21312435e-02],\n         [ 3.74408066e-02],\n         [ 3.39820385e-02],\n         [ 1.78786069e-02],\n         [-5.06299771e-02],\n         [ 6.70386702e-02],\n         [ 7.02214241e-02],\n         [-8.21430236e-02],\n         [-2.94084027e-02],\n         [ 2.45264322e-02],\n         [ 8.50942582e-02],\n         [ 2.16991603e-02],\n         [-7.98663571e-02],\n         [ 7.88633078e-02],\n         [-3.40039730e-02],\n         [ 5.61790168e-03],\n         [-3.07871066e-02],\n         [ 8.78598392e-02],\n         [-2.82317214e-02],\n         [ 5.07672876e-02],\n         [ 9.04510170e-02],\n         [ 4.04788852e-02],\n         [ 8.09549689e-02],\n         [-2.39593834e-02],\n         [ 5.43897599e-03],\n         [-2.92186663e-02],\n         [ 8.75832289e-02],\n         [-4.19654809e-02],\n         [ 8.89285058e-02],\n         [-5.54370433e-02],\n         [ 7.34764636e-02],\n         [ 1.68509781e-02],\n         [ 1.29503980e-02],\n         [ 1.90058649e-02],\n         [-1.01192519e-02],\n         [ 2.62008607e-02],\n         [ 2.77597606e-02],\n         [ 1.82159916e-02],\n         [-2.32556388e-02],\n         [-4.07052226e-02],\n         [-8.07569623e-02]],\n\n        [[ 5.06176651e-02],\n         [-7.73551241e-02],\n         [ 3.62409055e-02],\n         [-7.33292550e-02],\n         [-5.08749783e-02],\n         [-9.15957987e-03],\n         [-5.54373115e-03],\n         [-4.67265621e-02],\n         [ 3.08878124e-02],\n         [ 7.41918683e-02],\n         [-5.31534366e-02],\n         [-7.18746334e-03],\n         [ 4.92269844e-02],\n         [-4.77470756e-02],\n         [ 7.89286047e-02],\n         [-7.44131282e-02],\n         [-1.37471259e-02],\n         [-2.53833383e-02],\n         [ 4.78912443e-02],\n         [ 4.55887914e-02],\n         [ 7.25449175e-02],\n         [ 6.84077740e-02],\n         [-4.77341413e-02],\n         [ 3.26667354e-02],\n         [-7.66998902e-02],\n         [ 7.12538511e-03],\n         [ 7.10932612e-02],\n         [-7.98799023e-02],\n         [ 4.36253101e-03],\n         [-5.44134602e-02],\n         [-5.25496639e-02],\n         [ 5.49928099e-02],\n         [ 2.81137228e-03],\n         [-2.02295929e-02],\n         [ 3.06400657e-02],\n         [-2.21785009e-02],\n         [ 4.49724793e-02],\n         [ 4.88250852e-02],\n         [-1.07727051e-02],\n         [ 2.94051394e-02],\n         [ 4.38403785e-02],\n         [-7.84317628e-02],\n         [-8.97113457e-02],\n         [-3.64493914e-02],\n         [-3.17702442e-03],\n         [-7.20982850e-02],\n         [ 2.04602629e-03],\n         [ 5.76119870e-03],\n         [-5.25772572e-03],\n         [-5.53819537e-02],\n         [ 5.52791506e-02],\n         [ 1.23902261e-02],\n         [-3.86110693e-03],\n         [ 6.37449920e-02],\n         [-2.72645801e-03],\n         [-1.47141293e-02],\n         [-3.94627005e-02],\n         [-5.98062798e-02],\n         [ 7.54276067e-02],\n         [ 2.93297321e-02],\n         [-4.38237824e-02],\n         [ 2.28748694e-02],\n         [ 3.14440876e-02],\n         [ 5.97440749e-02],\n         [ 2.86214054e-03],\n         [-8.93861651e-02],\n         [ 7.55555034e-02],\n         [-5.64641356e-02],\n         [-8.82589296e-02],\n         [-1.04819983e-03],\n         [-7.61698931e-02],\n         [-8.76631364e-02],\n         [-3.03780884e-02],\n         [-5.85255399e-02],\n         [-7.01234043e-02],\n         [ 8.02656412e-02],\n         [-3.17775533e-02],\n         [ 6.59556240e-02],\n         [ 2.57648677e-02],\n         [ 2.73409635e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_1/moving_mean:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_377/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[ 0.05196753],\n         [-0.04946721],\n         [-0.04075183],\n         ...,\n         [-0.03433312],\n         [-0.02869372],\n         [-0.03257717]],\n\n        [[ 0.02662175],\n         [ 0.0266779 ],\n         [ 0.05813749],\n         ...,\n         [-0.05355116],\n         [ 0.02629628],\n         [ 0.00244688]],\n\n        [[ 0.03518628],\n         [ 0.04306196],\n         [ 0.05291317],\n         ...,\n         [ 0.01209816],\n         [ 0.05349943],\n         [-0.05977012]]],\n\n\n       [[[ 0.04053825],\n         [ 0.00969673],\n         [ 0.02626443],\n         ...,\n         [-0.04226689],\n         [-0.04979882],\n         [-0.01517585]],\n\n        [[-0.01728126],\n         [ 0.002227  ],\n         [-0.01256393],\n         ...,\n         [ 0.04798179],\n         [-0.06487456],\n         [-0.04146526]],\n\n        [[ 0.04391406],\n         [-0.02389202],\n         [ 0.01749081],\n         ...,\n         [-0.01623254],\n         [ 0.00468493],\n         [-0.07047215]]],\n\n\n       [[[-0.02832882],\n         [ 0.07033147],\n         [ 0.04166061],\n         ...,\n         [-0.01961127],\n         [-0.00354851],\n         [ 0.03070489]],\n\n        [[-0.05504709],\n         [ 0.0293152 ],\n         [-0.05304461],\n         ...,\n         [-0.0142126 ],\n         [-0.04848078],\n         [-0.0476849 ]],\n\n        [[ 0.01213649],\n         [ 0.03701131],\n         [ 0.06323072],\n         ...,\n         [ 0.06401858],\n         [-0.04995251],\n         [ 0.00824822]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization_2/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_252/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_238/sync_batch_normalization/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_368/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-2.18102708e-02],\n         [-6.41603544e-02],\n         [ 7.29615241e-03],\n         [ 8.77435058e-02],\n         [-1.88252330e-02],\n         [ 8.87093097e-02],\n         [-4.50338386e-02],\n         [-2.94286907e-02],\n         [-6.16472960e-02],\n         [-1.92121267e-02],\n         [ 7.55837113e-02],\n         [ 4.05267328e-02],\n         [-6.25152141e-03],\n         [ 8.35019499e-02],\n         [ 6.08466268e-02],\n         [-4.38588448e-02],\n         [-6.76913932e-02],\n         [-5.30068316e-02],\n         [ 8.98498446e-02],\n         [ 2.87644640e-02],\n         [-8.09025764e-02],\n         [-5.06592654e-02],\n         [-2.71893144e-02],\n         [-5.19277155e-03],\n         [ 2.34405100e-02],\n         [-4.80502397e-02],\n         [-3.82184051e-02],\n         [-5.35756722e-02],\n         [ 8.12756270e-03],\n         [-7.93830007e-02],\n         [-8.87104273e-02],\n         [ 3.83218378e-02],\n         [ 3.24957073e-03],\n         [ 1.67576224e-02],\n         [ 1.21007785e-02],\n         [ 7.04792291e-02],\n         [ 7.43386894e-03],\n         [ 2.99349353e-02],\n         [-1.09607577e-02],\n         [-2.74258181e-02],\n         [ 2.22629234e-02],\n         [-6.71797842e-02],\n         [-4.82663624e-02],\n         [ 2.16031447e-02],\n         [ 1.42999813e-02],\n         [-6.81215674e-02],\n         [ 5.76147884e-02],\n         [ 1.61182657e-02],\n         [-7.17826188e-02],\n         [-1.32220015e-02],\n         [-8.94065797e-02],\n         [ 3.13203484e-02],\n         [-6.73711225e-02],\n         [ 7.77266175e-03],\n         [-3.29103321e-03],\n         [ 2.14463100e-02],\n         [-1.87514350e-02],\n         [-3.18834744e-02],\n         [-3.86751369e-02],\n         [ 6.74265772e-02],\n         [ 8.98409486e-02],\n         [-6.22067973e-02],\n         [-5.99242486e-02],\n         [ 7.58714527e-02],\n         [-5.72273396e-02],\n         [ 8.40091705e-03],\n         [-3.85930538e-02],\n         [-8.20485875e-02],\n         [ 2.79474631e-02],\n         [ 2.47621983e-02],\n         [-7.63550699e-02],\n         [-6.39753342e-02],\n         [ 4.93818074e-02],\n         [ 8.35829675e-02],\n         [-5.60280792e-02],\n         [-8.45174119e-02],\n         [ 7.27991164e-02],\n         [ 1.66817233e-02],\n         [ 3.75016183e-02],\n         [ 6.92256093e-02]],\n\n        [[-4.20919806e-03],\n         [ 5.51334023e-02],\n         [ 5.26752621e-02],\n         [ 7.43701011e-02],\n         [ 3.21623906e-02],\n         [-7.19796494e-02],\n         [ 3.77919972e-02],\n         [-1.08985305e-02],\n         [ 6.89286739e-03],\n         [-7.46415406e-02],\n         [-8.72995853e-02],\n         [-1.88707411e-02],\n         [-3.76431830e-02],\n         [-5.40231057e-02],\n         [ 7.78765529e-02],\n         [ 1.17334723e-03],\n         [-3.06395926e-02],\n         [ 7.11224526e-02],\n         [-6.75399154e-02],\n         [-4.01493385e-02],\n         [ 8.46541673e-03],\n         [-6.59588054e-02],\n         [-8.62221420e-03],\n         [ 5.29159606e-03],\n         [ 3.57347429e-02],\n         [-2.94847339e-02],\n         [ 3.47555429e-02],\n         [-5.15429080e-02],\n         [-4.96219657e-02],\n         [-1.22503042e-02],\n         [-1.13357976e-02],\n         [ 3.49531472e-02],\n         [ 7.79607296e-02],\n         [-9.30798054e-03],\n         [ 5.64286560e-02],\n         [-7.95902759e-02],\n         [-9.30220634e-03],\n         [ 6.81759715e-02],\n         [-8.76343921e-02],\n         [ 1.51923224e-02],\n         [-2.37704068e-02],\n         [ 6.02407306e-02],\n         [-8.60547274e-03],\n         [ 6.38726801e-02],\n         [-1.28410533e-02],\n         [ 4.89972979e-02],\n         [-6.42421395e-02],\n         [-1.78357139e-02],\n         [-4.03082520e-02],\n         [ 2.28663906e-02],\n         [ 4.87780124e-02],\n         [ 2.92855874e-02],\n         [-7.24780858e-02],\n         [ 1.35740489e-02],\n         [ 4.69204932e-02],\n         [-2.71589458e-02],\n         [ 7.40651190e-02],\n         [-8.54456425e-03],\n         [-5.82772717e-02],\n         [ 1.73688829e-02],\n         [ 1.21932849e-02],\n         [-3.84873487e-02],\n         [ 7.03026503e-02],\n         [-5.56204431e-02],\n         [-5.25875799e-02],\n         [ 2.24404782e-02],\n         [ 6.17537349e-02],\n         [-6.79277629e-02],\n         [ 5.05482554e-02],\n         [ 3.84213775e-03],\n         [ 4.94484752e-02],\n         [-8.59238654e-02],\n         [-6.93360120e-02],\n         [ 7.47185200e-03],\n         [-1.63550302e-02],\n         [ 7.09845722e-02],\n         [-6.19326159e-02],\n         [-4.03806455e-02],\n         [-2.48318911e-02],\n         [-8.06715265e-02]],\n\n        [[ 5.60779423e-02],\n         [-1.97308064e-02],\n         [ 4.77646440e-02],\n         [-8.65824670e-02],\n         [ 6.51492923e-02],\n         [-7.13063776e-02],\n         [ 6.60654455e-02],\n         [ 5.68741262e-02],\n         [-7.43172839e-02],\n         [ 2.56045908e-02],\n         [-4.82629910e-02],\n         [-6.60116673e-02],\n         [ 1.42986402e-02],\n         [ 8.25365782e-02],\n         [ 1.49335414e-02],\n         [-2.98368894e-02],\n         [-4.39672098e-02],\n         [ 5.66675812e-02],\n         [ 8.67018700e-02],\n         [-1.21704489e-03],\n         [-1.93664432e-03],\n         [ 2.51788944e-02],\n         [ 6.74016178e-02],\n         [-2.88060121e-02],\n         [-2.75055021e-02],\n         [ 6.31175786e-02],\n         [ 4.65025902e-02],\n         [-3.47253680e-02],\n         [ 7.43450820e-02],\n         [-1.36887729e-02],\n         [-1.12130046e-02],\n         [-7.43731782e-02],\n         [-8.86712372e-02],\n         [-4.96190451e-02],\n         [-4.30893190e-02],\n         [ 1.96057484e-02],\n         [ 5.95064759e-02],\n         [ 6.17258400e-02],\n         [ 8.92618150e-02],\n         [-5.82217500e-02],\n         [-6.18983805e-03],\n         [-4.56119366e-02],\n         [ 5.66044450e-03],\n         [ 6.59593940e-02],\n         [ 2.04445496e-02],\n         [-3.42872590e-02],\n         [-5.89643866e-02],\n         [ 7.95955807e-02],\n         [-1.84371099e-02],\n         [ 3.64708900e-02],\n         [-6.56759515e-02],\n         [-6.65107965e-02],\n         [ 5.21381199e-02],\n         [ 2.39790455e-02],\n         [-6.42899126e-02],\n         [-2.95672528e-02],\n         [ 1.35737658e-02],\n         [ 2.03157961e-03],\n         [-3.02016325e-02],\n         [-3.15735415e-02],\n         [-6.42105788e-02],\n         [-1.44505948e-02],\n         [-7.68862963e-02],\n         [ 2.87680551e-02],\n         [ 3.69787365e-02],\n         [ 7.01536238e-02],\n         [-2.44697407e-02],\n         [ 4.07574177e-02],\n         [-5.09107560e-02],\n         [-1.91402510e-02],\n         [-4.90480214e-02],\n         [-4.05987166e-02],\n         [ 8.92209709e-02],\n         [-8.06793794e-02],\n         [ 3.07240114e-02],\n         [-7.24650845e-02],\n         [ 2.26465017e-02],\n         [-8.48072767e-03],\n         [ 6.94514960e-02],\n         [-2.21898556e-02]]],\n\n\n       [[[-5.84914535e-03],\n         [ 4.02110070e-02],\n         [ 1.63446665e-02],\n         [-5.69291115e-02],\n         [ 8.27340633e-02],\n         [-8.82607028e-02],\n         [ 1.71127170e-02],\n         [ 1.14939958e-02],\n         [ 7.85786957e-02],\n         [-6.22779131e-02],\n         [-7.60759786e-02],\n         [ 1.27326921e-02],\n         [-8.40346739e-02],\n         [-7.88068026e-02],\n         [-2.74899676e-02],\n         [-4.09957319e-02],\n         [ 6.94286376e-02],\n         [ 3.41528282e-02],\n         [ 9.96386260e-03],\n         [ 3.46415788e-02],\n         [-1.69359371e-02],\n         [-8.93547609e-02],\n         [ 2.61240527e-02],\n         [ 5.07808924e-02],\n         [ 4.04805541e-02],\n         [ 8.52264762e-02],\n         [ 7.47723132e-02],\n         [ 7.85450637e-02],\n         [-8.82485434e-02],\n         [ 5.67145646e-02],\n         [ 3.31989527e-02],\n         [ 4.20712978e-02],\n         [ 2.01429427e-03],\n         [-4.00751829e-03],\n         [ 2.11855024e-03],\n         [ 7.74366707e-02],\n         [-6.47244155e-02],\n         [ 3.29666287e-02],\n         [-7.52783418e-02],\n         [-1.64425671e-02],\n         [-1.19299442e-02],\n         [ 3.98874432e-02],\n         [ 2.90291682e-02],\n         [ 5.29039353e-02],\n         [-7.88714141e-02],\n         [ 5.08626550e-03],\n         [-2.57832706e-02],\n         [ 8.58855397e-02],\n         [-1.99269727e-02],\n         [ 2.48298794e-02],\n         [-1.91675499e-02],\n         [ 2.29682699e-02],\n         [-2.73090824e-02],\n         [-2.05718800e-02],\n         [ 2.45416388e-02],\n         [ 2.54698172e-02],\n         [-6.37732446e-04],\n         [ 7.00749308e-02],\n         [-4.74069901e-02],\n         [ 2.62927264e-03],\n         [-7.59925321e-02],\n         [-2.80511528e-02],\n         [ 8.50294530e-02],\n         [ 2.07103342e-02],\n         [ 6.65345639e-02],\n         [-1.54794157e-02],\n         [-7.36126304e-03],\n         [ 6.21038824e-02],\n         [-6.11460954e-03],\n         [ 8.59016031e-02],\n         [-4.34976816e-03],\n         [ 3.99707258e-03],\n         [-1.58403665e-02],\n         [-1.36785209e-02],\n         [ 1.79912969e-02],\n         [ 6.76628053e-02],\n         [-1.84908360e-02],\n         [ 7.83569217e-02],\n         [ 1.96401402e-02],\n         [ 6.95898235e-02]],\n\n        [[-7.32464567e-02],\n         [ 4.11924720e-02],\n         [-2.21378803e-02],\n         [-7.67942369e-02],\n         [-8.40384215e-02],\n         [-3.03809419e-02],\n         [-6.10423163e-02],\n         [-5.22996262e-02],\n         [-1.07485726e-02],\n         [-1.27563104e-02],\n         [-7.67806321e-02],\n         [-8.71716216e-02],\n         [-1.03444159e-02],\n         [-1.09770447e-02],\n         [-2.44840235e-03],\n         [-3.32902968e-02],\n         [ 1.61893442e-02],\n         [-7.84727335e-02],\n         [ 2.97270492e-02],\n         [-7.01100752e-02],\n         [-8.05274323e-02],\n         [ 3.36493552e-02],\n         [-7.69060254e-02],\n         [-6.39460236e-02],\n         [ 8.28910470e-02],\n         [-6.14771396e-02],\n         [-7.23859817e-02],\n         [ 3.08289379e-03],\n         [ 7.46534914e-02],\n         [-4.45334539e-02],\n         [-5.57460710e-02],\n         [ 2.15701386e-02],\n         [ 2.14174390e-04],\n         [-2.08491087e-02],\n         [ 2.44848803e-02],\n         [-5.14538772e-02],\n         [ 8.64233971e-02],\n         [-2.06746235e-02],\n         [-1.97097659e-02],\n         [-3.36059183e-02],\n         [ 5.72589785e-02],\n         [-5.62186800e-02],\n         [-4.16086540e-02],\n         [-6.96336403e-02],\n         [-1.97108090e-03],\n         [-4.03421894e-02],\n         [ 1.06892362e-02],\n         [-1.12686381e-02],\n         [-5.44629917e-02],\n         [-7.57636875e-03],\n         [ 3.31712067e-02],\n         [ 1.79309547e-02],\n         [ 6.37766868e-02],\n         [ 4.84747291e-02],\n         [ 6.75583333e-02],\n         [ 7.44717866e-02],\n         [ 6.87533468e-02],\n         [-3.58613208e-02],\n         [ 1.71726346e-02],\n         [-6.83299229e-02],\n         [ 2.25956962e-02],\n         [-7.86925331e-02],\n         [-6.34106994e-03],\n         [-1.25122815e-02],\n         [ 6.78445995e-02],\n         [ 9.02007669e-02],\n         [ 8.51386786e-03],\n         [ 3.54807228e-02],\n         [ 1.86202526e-02],\n         [-7.24346712e-02],\n         [-7.15015009e-02],\n         [-7.17307553e-02],\n         [ 5.47309667e-02],\n         [-5.06162643e-03],\n         [ 8.51254910e-02],\n         [-3.17127965e-02],\n         [-5.51393107e-02],\n         [-1.59985721e-02],\n         [ 4.54620421e-02],\n         [ 1.11843050e-02]],\n\n        [[-8.53091478e-05],\n         [ 6.91594929e-03],\n         [ 5.94755560e-02],\n         [-1.45619884e-02],\n         [-7.31065348e-02],\n         [ 7.19336122e-02],\n         [ 4.70753610e-02],\n         [-4.24152501e-02],\n         [-5.71407564e-02],\n         [-4.50520478e-02],\n         [ 1.72860622e-02],\n         [ 6.01129979e-03],\n         [ 2.33177170e-02],\n         [-5.82444817e-02],\n         [ 3.17270681e-02],\n         [-2.97086015e-02],\n         [-4.57729474e-02],\n         [ 8.96536857e-02],\n         [ 5.97913116e-02],\n         [-7.84944892e-02],\n         [ 7.69010186e-02],\n         [ 2.36018226e-02],\n         [-6.05088808e-02],\n         [ 7.93994218e-02],\n         [-6.73169643e-02],\n         [-4.34751324e-02],\n         [-2.55097225e-02],\n         [-1.69676691e-02],\n         [ 3.28890905e-02],\n         [ 3.55202556e-02],\n         [ 3.97144556e-02],\n         [-4.41646241e-02],\n         [-6.66345209e-02],\n         [-5.47794364e-02],\n         [-2.81448811e-02],\n         [-1.54666528e-02],\n         [ 7.88435787e-02],\n         [ 1.85766667e-02],\n         [ 8.98566544e-02],\n         [ 6.88901842e-02],\n         [ 7.38283396e-02],\n         [ 8.72630477e-02],\n         [-8.98000300e-02],\n         [ 2.05239505e-02],\n         [ 1.64571181e-02],\n         [-7.38870278e-02],\n         [-7.20257163e-02],\n         [ 6.71169013e-02],\n         [ 5.51901907e-02],\n         [ 2.06734985e-02],\n         [ 5.24660051e-02],\n         [-4.01865393e-02],\n         [-5.46478480e-03],\n         [-2.46686265e-02],\n         [-8.21819603e-02],\n         [-8.88603181e-03],\n         [ 4.98017818e-02],\n         [ 5.62631935e-02],\n         [-3.75733599e-02],\n         [ 4.18387502e-02],\n         [ 5.23654670e-02],\n         [-6.31816536e-02],\n         [ 3.09696198e-02],\n         [-3.27555090e-03],\n         [ 3.91517431e-02],\n         [-6.41032532e-02],\n         [ 1.56040192e-02],\n         [ 6.25575185e-02],\n         [-8.04004669e-02],\n         [ 9.05000120e-02],\n         [ 2.06054077e-02],\n         [ 7.87998587e-02],\n         [-6.71841726e-02],\n         [ 8.60875547e-02],\n         [-8.06511194e-03],\n         [-2.68246159e-02],\n         [ 2.42396221e-02],\n         [ 7.70409405e-03],\n         [-4.87914905e-02],\n         [-5.84577024e-03]]],\n\n\n       [[[-5.18979169e-02],\n         [-1.29781663e-02],\n         [-4.42067347e-02],\n         [ 2.07927004e-02],\n         [ 9.03669596e-02],\n         [ 7.68898875e-02],\n         [ 1.74083784e-02],\n         [-8.67637694e-02],\n         [-1.80084705e-02],\n         [ 6.28810972e-02],\n         [-6.71272650e-02],\n         [-7.43137822e-02],\n         [-6.01076260e-02],\n         [ 6.83317631e-02],\n         [ 5.94337583e-02],\n         [ 6.11006916e-02],\n         [ 4.50369120e-02],\n         [ 1.58677772e-02],\n         [-2.91393287e-02],\n         [ 8.43183547e-02],\n         [-2.33400390e-02],\n         [-6.56155199e-02],\n         [ 4.50850278e-02],\n         [-4.66600917e-02],\n         [ 3.47312242e-02],\n         [ 5.65498322e-02],\n         [ 5.23720831e-02],\n         [ 8.81164372e-02],\n         [ 3.87121290e-02],\n         [ 8.00198466e-02],\n         [ 2.30577588e-03],\n         [-8.37183446e-02],\n         [-8.58316571e-02],\n         [ 2.71602049e-02],\n         [ 1.54801682e-02],\n         [-8.77510160e-02],\n         [ 3.49156708e-02],\n         [-5.48282079e-02],\n         [-7.40876868e-02],\n         [ 1.91271678e-02],\n         [-8.34271610e-02],\n         [ 7.08111674e-02],\n         [-3.13480757e-02],\n         [-6.76752627e-03],\n         [-2.61476710e-02],\n         [-6.52745888e-02],\n         [ 9.19596106e-03],\n         [ 3.94702852e-02],\n         [-2.73025036e-02],\n         [ 1.18244588e-02],\n         [ 1.00233704e-02],\n         [ 9.75269079e-03],\n         [ 1.50873736e-02],\n         [ 1.12585127e-02],\n         [-1.16562843e-02],\n         [-6.76131994e-02],\n         [-3.73151861e-02],\n         [ 2.79009789e-02],\n         [ 5.94480485e-02],\n         [ 1.13650635e-02],\n         [-8.67695659e-02],\n         [ 6.93037361e-03],\n         [ 1.24204829e-02],\n         [ 7.09071159e-02],\n         [ 2.00572014e-02],\n         [ 3.69146466e-02],\n         [-4.51577976e-02],\n         [ 7.35674053e-03],\n         [ 7.86654800e-02],\n         [-7.00597465e-02],\n         [-3.24099883e-02],\n         [-4.23965417e-02],\n         [ 1.70223266e-02],\n         [ 5.45520782e-02],\n         [-4.19597477e-02],\n         [ 5.09645045e-03],\n         [ 8.47926736e-02],\n         [-6.14454299e-02],\n         [ 1.21515989e-03],\n         [-4.99765649e-02]],\n\n        [[ 6.57738447e-02],\n         [ 6.24109805e-02],\n         [ 8.74182433e-02],\n         [ 8.73289257e-03],\n         [ 4.61881608e-02],\n         [-3.81395966e-03],\n         [-8.02959278e-02],\n         [-6.69443011e-02],\n         [-6.45301789e-02],\n         [ 4.92454618e-02],\n         [-8.16550553e-02],\n         [-6.38800114e-02],\n         [ 1.29331574e-02],\n         [-3.11547033e-02],\n         [ 7.88394213e-02],\n         [-5.89481406e-02],\n         [ 1.72838569e-02],\n         [ 6.49392605e-02],\n         [ 8.28227997e-02],\n         [-4.48755063e-02],\n         [ 9.84593481e-03],\n         [ 8.48104656e-02],\n         [-7.23440871e-02],\n         [-4.25726920e-02],\n         [ 3.58900279e-02],\n         [-4.16989587e-02],\n         [ 2.90746316e-02],\n         [ 8.41400027e-03],\n         [-1.88604072e-02],\n         [ 2.15766951e-02],\n         [ 6.29189312e-02],\n         [-4.38243225e-02],\n         [-6.85873851e-02],\n         [-2.70587578e-02],\n         [ 8.75262469e-02],\n         [ 7.11815804e-02],\n         [-1.08493194e-02],\n         [ 6.76216781e-02],\n         [ 1.60098597e-02],\n         [-1.17600188e-02],\n         [ 8.35716277e-02],\n         [ 4.97377217e-02],\n         [-6.35839403e-02],\n         [-8.62665474e-02],\n         [-8.69972855e-02],\n         [ 7.41271228e-02],\n         [ 8.38458538e-03],\n         [-4.91441786e-03],\n         [ 3.59526873e-02],\n         [-5.11599518e-02],\n         [-1.94199681e-02],\n         [-6.80598542e-02],\n         [ 8.40997845e-02],\n         [ 3.43301892e-02],\n         [ 8.91987383e-02],\n         [-4.12658863e-02],\n         [ 3.19558457e-02],\n         [-6.04224280e-02],\n         [ 8.80318433e-02],\n         [-6.38480484e-03],\n         [-5.49390204e-02],\n         [ 5.01138717e-02],\n         [ 2.56813318e-02],\n         [-4.02124524e-02],\n         [ 3.97543162e-02],\n         [-4.54578027e-02],\n         [-5.25314957e-02],\n         [ 7.22054988e-02],\n         [-2.86726654e-02],\n         [ 2.26465687e-02],\n         [ 4.84447032e-02],\n         [ 6.62037581e-02],\n         [-2.12631524e-02],\n         [-4.19703275e-02],\n         [ 4.47040200e-02],\n         [ 9.03887749e-02],\n         [-3.35769579e-02],\n         [-3.92476581e-02],\n         [ 3.06936651e-02],\n         [-3.01413275e-02]],\n\n        [[-6.86226860e-02],\n         [ 2.56546438e-02],\n         [ 9.05700028e-04],\n         [-7.46324956e-02],\n         [ 4.18021530e-03],\n         [-4.43961695e-02],\n         [ 3.14273238e-02],\n         [ 6.53959811e-02],\n         [ 6.25206679e-02],\n         [-3.89690697e-03],\n         [-8.27523321e-02],\n         [ 6.36325181e-02],\n         [ 1.25399679e-02],\n         [-3.25430743e-02],\n         [-5.08897975e-02],\n         [-6.98667467e-02],\n         [ 5.19038886e-02],\n         [-8.96776691e-02],\n         [ 4.90792394e-02],\n         [-2.71956995e-02],\n         [ 2.63153687e-02],\n         [-7.94061273e-03],\n         [-4.44498993e-02],\n         [ 3.11568901e-02],\n         [-8.91817808e-02],\n         [ 1.04742795e-02],\n         [ 3.27769592e-02],\n         [ 2.36314163e-02],\n         [-8.32556784e-02],\n         [ 6.31143749e-02],\n         [-3.06018889e-02],\n         [-7.65512139e-03],\n         [ 7.88181424e-02],\n         [-4.68332618e-02],\n         [ 5.35438210e-03],\n         [ 4.00155634e-02],\n         [ 3.35958824e-02],\n         [-4.07227650e-02],\n         [-4.90287468e-02],\n         [ 3.24261039e-02],\n         [ 3.56603563e-02],\n         [ 4.64657247e-02],\n         [ 3.60893607e-02],\n         [-1.73000321e-02],\n         [ 2.16753706e-02],\n         [-7.57938400e-02],\n         [ 5.20444810e-02],\n         [-7.80439675e-02],\n         [-4.99321148e-02],\n         [-3.92834321e-02],\n         [ 1.15781128e-02],\n         [ 2.30405107e-02],\n         [-1.62133351e-02],\n         [-4.15987037e-02],\n         [ 1.24722868e-02],\n         [ 1.60832703e-03],\n         [ 2.77733058e-03],\n         [-5.77132553e-02],\n         [-1.00504905e-02],\n         [-2.95329243e-02],\n         [ 8.14649761e-02],\n         [-6.08291961e-02],\n         [ 4.59731072e-02],\n         [ 2.64740214e-02],\n         [-4.40926626e-02],\n         [-1.39200389e-02],\n         [-6.26430213e-02],\n         [-4.96255122e-02],\n         [ 6.73583150e-02],\n         [ 1.95362493e-02],\n         [-5.08857518e-03],\n         [ 4.05250192e-02],\n         [-2.81211957e-02],\n         [-7.79925734e-02],\n         [-7.48280957e-02],\n         [ 2.66898870e-02],\n         [-3.24114785e-02],\n         [ 5.29607385e-02],\n         [-8.56849402e-02],\n         [-9.46895033e-03]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_369/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[-0.01600621],\n         [-0.0206226 ],\n         [-0.05870853],\n         [ 0.07041705],\n         [-0.08658364],\n         [-0.0837106 ],\n         [-0.09041726],\n         [-0.06074735],\n         [-0.04771982],\n         [ 0.07986329],\n         [ 0.04748525],\n         [ 0.06918384],\n         [-0.03831931],\n         [-0.04343462],\n         [ 0.05270354],\n         [ 0.08669657],\n         [-0.02835546],\n         [ 0.06845921],\n         [-0.01128858],\n         [ 0.08573388],\n         [ 0.04985376],\n         [ 0.0107471 ],\n         [-0.05223337],\n         [-0.03628594],\n         [ 0.07356998],\n         [-0.06135752],\n         [-0.03760758],\n         [-0.0186867 ],\n         [-0.04661478],\n         [-0.0695835 ],\n         [-0.08027875],\n         [ 0.08215152],\n         [-0.06020347],\n         [-0.0775924 ],\n         [-0.02817166],\n         [-0.00459857],\n         [ 0.02732104],\n         [ 0.05444027],\n         [ 0.07827002],\n         [ 0.04020494],\n         [ 0.00154802],\n         [ 0.03795271],\n         [-0.03571411],\n         [ 0.02884784],\n         [-0.05169555],\n         [-0.04088529],\n         [ 0.0391954 ],\n         [ 0.05324049],\n         [ 0.04587327],\n         [-0.08285181],\n         [-0.00216667],\n         [-0.07414357],\n         [-0.0495032 ],\n         [-0.0634231 ],\n         [-0.03617192],\n         [-0.00133503],\n         [-0.07008895],\n         [-0.05924229],\n         [-0.00211243],\n         [ 0.06468417],\n         [ 0.08749191],\n         [ 0.03379022],\n         [ 0.02569479],\n         [ 0.02337521],\n         [ 0.06108853],\n         [-0.08352179],\n         [ 0.08037116],\n         [ 0.05618405],\n         [ 0.08567195],\n         [ 0.04495244],\n         [ 0.08281152],\n         [ 0.07639305],\n         [ 0.06881417],\n         [-0.03728664],\n         [-0.080458  ],\n         [ 0.07462579],\n         [ 0.0338658 ],\n         [-0.02745286],\n         [ 0.02065434],\n         [-0.06552455]],\n\n        [[ 0.06454384],\n         [ 0.02544671],\n         [-0.08284193],\n         [-0.07031135],\n         [ 0.07840705],\n         [ 0.00757066],\n         [-0.03221459],\n         [-0.04674406],\n         [-0.06118564],\n         [ 0.03810154],\n         [-0.00148616],\n         [ 0.04116797],\n         [ 0.06399305],\n         [ 0.00229814],\n         [-0.05166531],\n         [ 0.0120061 ],\n         [ 0.00890303],\n         [ 0.02730787],\n         [ 0.0586262 ],\n         [-0.07085326],\n         [-0.02227953],\n         [-0.04130259],\n         [-0.0715718 ],\n         [ 0.02267756],\n         [ 0.02873881],\n         [ 0.07358196],\n         [ 0.06912003],\n         [ 0.00881037],\n         [ 0.07535508],\n         [-0.03026325],\n         [-0.05525306],\n         [ 0.0818425 ],\n         [ 0.04866399],\n         [-0.01226088],\n         [-0.07912634],\n         [-0.05115699],\n         [ 0.08867393],\n         [ 0.01141189],\n         [ 0.010703  ],\n         [-0.08298659],\n         [-0.03415677],\n         [-0.0479064 ],\n         [ 0.07922077],\n         [-0.019612  ],\n         [ 0.0547884 ],\n         [ 0.03872889],\n         [ 0.02949293],\n         [-0.06313352],\n         [ 0.05025709],\n         [-0.09000675],\n         [-0.04600253],\n         [-0.04075696],\n         [-0.08642825],\n         [ 0.0378263 ],\n         [ 0.02591559],\n         [ 0.07144879],\n         [ 0.03760752],\n         [ 0.06288363],\n         [-0.01431212],\n         [-0.02159153],\n         [ 0.01015607],\n         [-0.08264425],\n         [ 0.05647694],\n         [-0.03154404],\n         [ 0.00279271],\n         [-0.04473792],\n         [ 0.06829026],\n         [ 0.07636249],\n         [-0.0173232 ],\n         [ 0.02805622],\n         [ 0.08407116],\n         [-0.02082247],\n         [-0.08899893],\n         [ 0.06630994],\n         [-0.04920302],\n         [ 0.01240251],\n         [-0.07652726],\n         [ 0.05057393],\n         [ 0.01986223],\n         [-0.06521591]],\n\n        [[ 0.06106016],\n         [ 0.04444835],\n         [-0.04862328],\n         [ 0.08014607],\n         [ 0.0185731 ],\n         [ 0.00763246],\n         [ 0.01646703],\n         [-0.02231226],\n         [ 0.01734747],\n         [-0.0656421 ],\n         [-0.0362459 ],\n         [-0.05090353],\n         [-0.06204948],\n         [ 0.040162  ],\n         [-0.0291345 ],\n         [-0.05862651],\n         [ 0.08315486],\n         [ 0.0162378 ],\n         [-0.07629269],\n         [ 0.08780169],\n         [ 0.02022412],\n         [-0.08628324],\n         [-0.07226743],\n         [ 0.05807839],\n         [-0.06170176],\n         [-0.06870501],\n         [ 0.05182597],\n         [ 0.04086147],\n         [-0.00543617],\n         [-0.07205366],\n         [-0.02906797],\n         [ 0.08504102],\n         [-0.02236218],\n         [ 0.03399744],\n         [-0.07358938],\n         [-0.08874545],\n         [-0.02938199],\n         [-0.01679076],\n         [-0.05750435],\n         [ 0.08886965],\n         [ 0.04435591],\n         [-0.04876385],\n         [-0.06633183],\n         [ 0.08405508],\n         [ 0.07615724],\n         [-0.07540823],\n         [ 0.01486044],\n         [-0.05777754],\n         [-0.08844194],\n         [ 0.06136224],\n         [-0.07163232],\n         [ 0.04050763],\n         [-0.02731129],\n         [ 0.08520986],\n         [-0.02314357],\n         [ 0.08000842],\n         [ 0.04039456],\n         [ 0.07959454],\n         [ 0.01398768],\n         [ 0.05429527],\n         [-0.04258416],\n         [-0.03303466],\n         [-0.03775131],\n         [ 0.01311076],\n         [ 0.08606456],\n         [ 0.0547407 ],\n         [-0.03649241],\n         [-0.03879999],\n         [ 0.03170715],\n         [ 0.05338366],\n         [ 0.00604353],\n         [-0.08491962],\n         [-0.04821305],\n         [ 0.08843155],\n         [-0.06926277],\n         [ 0.01609599],\n         [-0.04646367],\n         [ 0.02595581],\n         [-0.00704869],\n         [ 0.07099125]]],\n\n\n       [[[-0.03439318],\n         [ 0.05464979],\n         [ 0.06814954],\n         [ 0.07287803],\n         [-0.05960675],\n         [ 0.00679958],\n         [ 0.08388372],\n         [ 0.05153243],\n         [-0.04720237],\n         [-0.04091014],\n         [ 0.02461005],\n         [-0.07180804],\n         [ 0.03277101],\n         [-0.00893807],\n         [ 0.08697055],\n         [ 0.03065449],\n         [-0.05237619],\n         [ 0.07568575],\n         [ 0.00192421],\n         [-0.01069659],\n         [-0.00659702],\n         [-0.08936873],\n         [ 0.00382103],\n         [-0.07518393],\n         [ 0.05479001],\n         [-0.0330368 ],\n         [-0.0660102 ],\n         [-0.05359979],\n         [-0.0437606 ],\n         [-0.05239904],\n         [ 0.07488513],\n         [-0.05932895],\n         [ 0.07576726],\n         [-0.08361151],\n         [ 0.00968017],\n         [-0.03202684],\n         [ 0.03183699],\n         [ 0.03335508],\n         [-0.02320001],\n         [-0.05790762],\n         [-0.00117021],\n         [ 0.02891076],\n         [ 0.0527461 ],\n         [ 0.04134075],\n         [-0.01271605],\n         [ 0.03478827],\n         [ 0.0056755 ],\n         [ 0.05732571],\n         [ 0.03975552],\n         [ 0.00780277],\n         [-0.04020789],\n         [ 0.05645049],\n         [-0.03051157],\n         [-0.07079345],\n         [ 0.04343908],\n         [-0.01440632],\n         [-0.05538935],\n         [-0.06777376],\n         [-0.07733899],\n         [-0.08893438],\n         [ 0.08936045],\n         [ 0.04630409],\n         [-0.00832902],\n         [ 0.04109794],\n         [-0.08449624],\n         [ 0.02117929],\n         [-0.07794204],\n         [-0.07332753],\n         [-0.07813239],\n         [ 0.01198562],\n         [-0.01843277],\n         [-0.00338741],\n         [-0.06394293],\n         [-0.02035232],\n         [-0.03099361],\n         [ 0.08444282],\n         [-0.01290114],\n         [ 0.03934237],\n         [-0.05370608],\n         [ 0.04444964]],\n\n        [[ 0.04795139],\n         [-0.05006955],\n         [-0.08449902],\n         [ 0.08656631],\n         [-0.07934783],\n         [-0.07238637],\n         [ 0.04571348],\n         [ 0.05784106],\n         [-0.08663724],\n         [-0.02568722],\n         [-0.06806206],\n         [-0.05583685],\n         [-0.03087903],\n         [-0.00434838],\n         [-0.07153343],\n         [-0.07858845],\n         [-0.03677648],\n         [-0.0474926 ],\n         [ 0.0672465 ],\n         [ 0.05960694],\n         [ 0.04241595],\n         [ 0.03242076],\n         [ 0.04172051],\n         [-0.05686058],\n         [-0.02280974],\n         [-0.04594781],\n         [ 0.05692723],\n         [ 0.0128015 ],\n         [ 0.03092422],\n         [-0.06508881],\n         [ 0.0083436 ],\n         [ 0.04642199],\n         [-0.09023134],\n         [ 0.05540383],\n         [ 0.08533372],\n         [-0.04996486],\n         [ 0.07013816],\n         [ 0.02422011],\n         [-0.03511105],\n         [-0.08318097],\n         [-0.02801962],\n         [ 0.062619  ],\n         [ 0.05514929],\n         [ 0.00088003],\n         [ 0.00961305],\n         [ 0.03457424],\n         [-0.00572824],\n         [ 0.00104087],\n         [ 0.06182562],\n         [-0.01831153],\n         [-0.08123594],\n         [-0.08651081],\n         [-0.02462154],\n         [ 0.08303367],\n         [-0.00522128],\n         [ 0.01555525],\n         [-0.08419406],\n         [-0.03876471],\n         [-0.01294966],\n         [-0.01523703],\n         [-0.07200619],\n         [-0.07770481],\n         [ 0.08491018],\n         [-0.02954939],\n         [ 0.01237104],\n         [ 0.02095315],\n         [-0.03640401],\n         [ 0.09063245],\n         [ 0.02780644],\n         [-0.08265509],\n         [-0.04961604],\n         [ 0.02904656],\n         [ 0.02795975],\n         [ 0.02803621],\n         [ 0.08968671],\n         [ 0.00079295],\n         [ 0.04115978],\n         [ 0.07075083],\n         [-0.01063058],\n         [-0.08415087]],\n\n        [[ 0.04289268],\n         [ 0.02253383],\n         [ 0.02521108],\n         [ 0.00552247],\n         [-0.04373315],\n         [ 0.06863317],\n         [-0.01576283],\n         [ 0.07880753],\n         [-0.0817377 ],\n         [-0.03646507],\n         [ 0.01314285],\n         [ 0.03727648],\n         [-0.07778986],\n         [ 0.0040131 ],\n         [-0.03475442],\n         [-0.02355272],\n         [ 0.05532633],\n         [ 0.05746979],\n         [ 0.00388023],\n         [-0.02011409],\n         [ 0.02624319],\n         [-0.07128261],\n         [ 0.02495412],\n         [-0.02145927],\n         [-0.04908412],\n         [ 0.05741556],\n         [ 0.01613925],\n         [-0.05212189],\n         [ 0.04068768],\n         [ 0.07601371],\n         [ 0.05732544],\n         [-0.01296292],\n         [ 0.00994273],\n         [-0.00780037],\n         [-0.01887916],\n         [ 0.06144768],\n         [ 0.02504261],\n         [-0.03740054],\n         [ 0.03239471],\n         [-0.0095595 ],\n         [ 0.05132715],\n         [-0.07979634],\n         [-0.07203699],\n         [ 0.03362973],\n         [ 0.01250707],\n         [-0.01115906],\n         [-0.06675653],\n         [-0.03852055],\n         [ 0.08017631],\n         [-0.04855302],\n         [-0.07270706],\n         [ 0.06638491],\n         [ 0.078354  ],\n         [ 0.01830097],\n         [ 0.0393759 ],\n         [-0.04577898],\n         [-0.06185605],\n         [-0.06433676],\n         [ 0.02336165],\n         [ 0.03888601],\n         [-0.00698512],\n         [-0.02915953],\n         [-0.05568836],\n         [-0.00137289],\n         [-0.0340073 ],\n         [ 0.02974269],\n         [-0.08003635],\n         [-0.08871648],\n         [-0.06783809],\n         [ 0.04988261],\n         [ 0.01790869],\n         [-0.08514535],\n         [ 0.0243558 ],\n         [ 0.07767427],\n         [-0.05715869],\n         [-0.0641366 ],\n         [ 0.05355912],\n         [-0.05489305],\n         [-0.08908144],\n         [ 0.03220511]]],\n\n\n       [[[-0.00921452],\n         [ 0.0803498 ],\n         [-0.08006564],\n         [ 0.00664341],\n         [-0.00819857],\n         [-0.0092383 ],\n         [-0.08308002],\n         [ 0.03703022],\n         [ 0.02280276],\n         [-0.07295965],\n         [-0.02472242],\n         [-0.00789887],\n         [ 0.06652224],\n         [ 0.08374992],\n         [-0.06964504],\n         [ 0.04821539],\n         [-0.04014177],\n         [-0.05125577],\n         [ 0.01146798],\n         [ 0.02154462],\n         [ 0.02256513],\n         [ 0.04684851],\n         [ 0.0073119 ],\n         [ 0.01258602],\n         [ 0.01630591],\n         [-0.08093256],\n         [-0.04007504],\n         [-0.02742815],\n         [-0.01965506],\n         [ 0.02373669],\n         [-0.0072577 ],\n         [-0.04185859],\n         [ 0.08790347],\n         [ 0.01798648],\n         [-0.0357546 ],\n         [ 0.02926634],\n         [ 0.05560397],\n         [-0.05917413],\n         [ 0.01684429],\n         [-0.07449038],\n         [-0.04452478],\n         [-0.07550339],\n         [ 0.07128809],\n         [-0.05355911],\n         [-0.07850723],\n         [ 0.00247869],\n         [ 0.06466383],\n         [ 0.02426475],\n         [-0.05038818],\n         [-0.08217754],\n         [-0.05163583],\n         [-0.07642098],\n         [-0.08651254],\n         [ 0.05633286],\n         [ 0.01005168],\n         [ 0.0829557 ],\n         [-0.04722948],\n         [ 0.02617657],\n         [-0.00626238],\n         [-0.01940751],\n         [ 0.03215223],\n         [ 0.01465224],\n         [-0.07727533],\n         [ 0.00451645],\n         [ 0.08965227],\n         [-0.05691884],\n         [-0.07671122],\n         [-0.07998491],\n         [ 0.0429627 ],\n         [-0.00506941],\n         [-0.0647569 ],\n         [-0.05407454],\n         [ 0.04066515],\n         [-0.02502465],\n         [ 0.02083133],\n         [-0.07419092],\n         [ 0.06905513],\n         [-0.04689573],\n         [-0.01026058],\n         [-0.01963817]],\n\n        [[-0.00042576],\n         [ 0.02825534],\n         [-0.07700498],\n         [-0.08751058],\n         [ 0.06672238],\n         [ 0.02742995],\n         [-0.03742941],\n         [-0.04620892],\n         [ 0.08442891],\n         [-0.0709316 ],\n         [-0.01839037],\n         [-0.0542335 ],\n         [-0.06751826],\n         [ 0.07714646],\n         [-0.0104171 ],\n         [ 0.01074695],\n         [ 0.02469435],\n         [ 0.07063743],\n         [-0.0327493 ],\n         [-0.0755353 ],\n         [ 0.00591516],\n         [ 0.04403464],\n         [-0.03788291],\n         [ 0.01440731],\n         [ 0.0596998 ],\n         [ 0.03732093],\n         [-0.02360446],\n         [ 0.09070389],\n         [-0.0526428 ],\n         [-0.08513747],\n         [ 0.05910468],\n         [ 0.08513291],\n         [-0.08437148],\n         [-0.01315188],\n         [ 0.04105917],\n         [ 0.06920059],\n         [-0.01534907],\n         [-0.0135079 ],\n         [-0.04427939],\n         [ 0.05362083],\n         [ 0.0640797 ],\n         [ 0.00205128],\n         [-0.01989764],\n         [-0.00851627],\n         [-0.07596673],\n         [ 0.02637255],\n         [ 0.04401585],\n         [ 0.04327717],\n         [ 0.04830043],\n         [-0.00292231],\n         [ 0.01323822],\n         [ 0.03646477],\n         [-0.08690289],\n         [ 0.02839699],\n         [-0.04851104],\n         [ 0.02587734],\n         [ 0.07510634],\n         [-0.0533677 ],\n         [-0.08331601],\n         [ 0.03574041],\n         [ 0.07514776],\n         [-0.05801672],\n         [-0.07079626],\n         [-0.02076923],\n         [ 0.08842552],\n         [ 0.0693385 ],\n         [ 0.07639015],\n         [ 0.07331933],\n         [-0.04775411],\n         [-0.02329315],\n         [-0.07337005],\n         [-0.00239167],\n         [-0.080801  ],\n         [-0.05133885],\n         [-0.01261067],\n         [-0.0412913 ],\n         [-0.04999951],\n         [-0.06438401],\n         [ 0.04126069],\n         [ 0.03144409]],\n\n        [[-0.03387536],\n         [ 0.03176899],\n         [-0.02875099],\n         [ 0.00553655],\n         [ 0.04028113],\n         [ 0.02161485],\n         [-0.00026284],\n         [-0.04835786],\n         [ 0.05722496],\n         [ 0.06647928],\n         [-0.03651828],\n         [ 0.07866651],\n         [-0.06662171],\n         [-0.03158788],\n         [-0.04929345],\n         [ 0.01912864],\n         [-0.00304266],\n         [-0.07884619],\n         [ 0.03785446],\n         [-0.00327944],\n         [ 0.05006424],\n         [-0.05030322],\n         [ 0.05671658],\n         [-0.07199451],\n         [ 0.05695082],\n         [-0.02219864],\n         [-0.02198619],\n         [ 0.06546898],\n         [ 0.06142278],\n         [-0.02687625],\n         [ 0.06183472],\n         [-0.03455735],\n         [ 0.04254839],\n         [ 0.05322735],\n         [ 0.01316968],\n         [ 0.07830706],\n         [ 0.02586642],\n         [-0.07009414],\n         [ 0.08445281],\n         [-0.06079325],\n         [ 0.06495531],\n         [ 0.01944076],\n         [ 0.02505359],\n         [-0.02044953],\n         [ 0.05903317],\n         [-0.04032047],\n         [ 0.06159015],\n         [ 0.03527623],\n         [ 0.04042086],\n         [ 0.06553836],\n         [ 0.02051701],\n         [ 0.07365525],\n         [ 0.08486727],\n         [ 0.01555815],\n         [ 0.02324913],\n         [ 0.0709354 ],\n         [-0.08552174],\n         [ 0.08135769],\n         [ 0.0457149 ],\n         [-0.03494783],\n         [ 0.00343809],\n         [-0.03860806],\n         [-0.04027758],\n         [-0.02931628],\n         [ 0.0539455 ],\n         [-0.08106333],\n         [ 0.05497667],\n         [-0.08832414],\n         [ 0.08937459],\n         [-0.02014273],\n         [-0.0336242 ],\n         [ 0.01431895],\n         [ 0.07311136],\n         [ 0.05644143],\n         [-0.01560835],\n         [-0.03821421],\n         [ 0.03716514],\n         [ 0.0191099 ],\n         [ 0.07970025],\n         [-0.03246188]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_2/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_858/kernel:0' shape=(1, 1, 112, 112) dtype=float32, numpy=\narray([[[[-0.0303254 , -0.0819697 ,  0.08410805, ..., -0.06141984,\n          -0.08405113,  0.02839591],\n         [-0.01751167,  0.11686455, -0.1423717 , ..., -0.00651311,\n          -0.07611485, -0.10667967],\n         [ 0.154586  ,  0.03512892, -0.02582129, ...,  0.04207398,\n           0.11323774, -0.1730972 ],\n         ...,\n         [-0.17776512,  0.18271811,  0.03414432, ..., -0.09747736,\n           0.06577013,  0.07179998],\n         [-0.10561133, -0.01691975, -0.05215042, ..., -0.11437327,\n          -0.05070565,  0.09380252],\n         [-0.13176028,  0.0462377 , -0.05236724, ...,  0.05854955,\n          -0.02808286, -0.10600992]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_901/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.1032524 , -0.0852347 , -0.17175597, ...,  0.06863623,\n          -0.16006066, -0.09043074],\n         [ 0.06144108,  0.03829359,  0.03092938, ..., -0.05503388,\n          -0.03225653, -0.02320758],\n         [ 0.03018818,  0.01783336,  0.05729922, ...,  0.07761155,\n          -0.2282479 , -0.06780922],\n         ...,\n         [ 0.17606936,  0.12889607, -0.17214462, ...,  0.05573615,\n           0.08149698,  0.22606923],\n         [ 0.08149737,  0.12252472,  0.02563435, ...,  0.05499631,\n          -0.07131711,  0.17855643],\n         [ 0.06686174,  0.00555492,  0.14189926, ...,  0.06560292,\n           0.04463634,  0.12230655]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 144, 4) dtype=float32, numpy=\narray([[[[ 0.02781812, -0.10467465,  0.00763623, -0.18184307],\n         [-0.10790048,  0.01949662,  0.00228341, -0.02564921],\n         [ 0.10475592, -0.05194062,  0.00470034, -0.0009797 ],\n         [-0.02483257,  0.01449299, -0.00221108,  0.07965975],\n         [-0.00880836, -0.08095035,  0.05068102, -0.03321116],\n         [ 0.07774796,  0.05541421, -0.01019561, -0.00738755],\n         [ 0.07167569,  0.09657817, -0.08016557,  0.00460754],\n         [ 0.10482001, -0.00587355, -0.02716144, -0.1231537 ],\n         [ 0.01614355, -0.0390297 , -0.18049675,  0.05236965],\n         [-0.0414603 , -0.11422865,  0.08183887, -0.15308303],\n         [-0.04233493, -0.00621603,  0.02066295,  0.05311586],\n         [-0.11993722, -0.05538895,  0.12665986,  0.12747706],\n         [ 0.11302688,  0.10914613,  0.05164585, -0.138162  ],\n         [ 0.00137327,  0.04312422, -0.11729242, -0.09260522],\n         [ 0.03482617, -0.02629261, -0.11653887, -0.04376264],\n         [-0.1418027 ,  0.07619706, -0.01736691, -0.02391838],\n         [-0.05393205,  0.00058426, -0.04389622,  0.06046414],\n         [-0.15328075, -0.0171194 ,  0.1412294 ,  0.08382887],\n         [-0.06514154, -0.10495731,  0.1785092 ,  0.02724832],\n         [ 0.06038187, -0.10013646,  0.08798193, -0.06743342],\n         [ 0.17818542,  0.07686073,  0.09393784,  0.00141435],\n         [ 0.01476073,  0.03074213,  0.04083981,  0.03966681],\n         [ 0.12831053,  0.00565182,  0.03811986, -0.01918929],\n         [-0.16411954, -0.00378172,  0.08017598,  0.02592126],\n         [-0.03222862,  0.17076059,  0.08582189,  0.06488298],\n         [-0.04534769, -0.07555675, -0.09187201,  0.03024918],\n         [ 0.04430831,  0.04746226, -0.08159558,  0.02088543],\n         [-0.12769966, -0.1406385 ,  0.14367042,  0.08048964],\n         [ 0.04510144,  0.06538825,  0.10111261,  0.01675177],\n         [ 0.02263882, -0.06764921,  0.06164803, -0.0747363 ],\n         [-0.07113492, -0.16860454,  0.1107435 ,  0.01606433],\n         [-0.06703167, -0.03916488,  0.06900434,  0.0857251 ],\n         [-0.11859088, -0.02712234,  0.02407813,  0.10918757],\n         [-0.01572594, -0.00342232, -0.10131246, -0.0034873 ],\n         [ 0.1601355 , -0.04543341,  0.019896  , -0.01303508],\n         [ 0.03964147, -0.115504  , -0.04012456,  0.10991706],\n         [ 0.03378871,  0.00206046, -0.06423229,  0.05971781],\n         [-0.07236121, -0.04041272, -0.0386173 , -0.15356416],\n         [-0.12539357, -0.1717742 , -0.0625822 ,  0.16011864],\n         [-0.06222475, -0.03065197, -0.0134316 , -0.03281127],\n         [-0.05859878,  0.11652099,  0.01211956, -0.16647477],\n         [-0.0118046 ,  0.03708535,  0.00945484, -0.00457471],\n         [-0.12068707, -0.02912297, -0.08979406, -0.07850562],\n         [ 0.09730059, -0.08763624,  0.05224653,  0.02733338],\n         [ 0.13149309, -0.02282393,  0.13077568,  0.12508166],\n         [ 0.06256086, -0.06049864, -0.03094569, -0.04552351],\n         [-0.03685125,  0.0229169 , -0.12412675,  0.06657435],\n         [ 0.03647917, -0.12029204, -0.17516567,  0.07715946],\n         [-0.10658403,  0.11799251, -0.08898059, -0.05066445],\n         [-0.0200756 , -0.07743263, -0.07239279,  0.02045222],\n         [-0.09816105, -0.02788364,  0.04272325, -0.06470992],\n         [ 0.14765032, -0.07892913,  0.06642003, -0.02861522],\n         [ 0.0860071 , -0.11518759,  0.02554224, -0.01693372],\n         [ 0.04510541, -0.10765831,  0.14720987,  0.01197299],\n         [-0.17210904, -0.08002077,  0.10323658,  0.04554013],\n         [-0.03632028, -0.01370316,  0.01973625,  0.15068756],\n         [ 0.01775385,  0.04000584, -0.00929072,  0.06062938],\n         [-0.03964074, -0.01880754, -0.05460619, -0.10628366],\n         [-0.18053329,  0.07793874, -0.08137066, -0.14814475],\n         [ 0.13764939, -0.02763202,  0.02531153,  0.00732083],\n         [-0.13969319,  0.03051428,  0.10970824,  0.05044277],\n         [ 0.16025524,  0.13886319,  0.00454604, -0.03589414],\n         [-0.04580107,  0.05267937, -0.10092057, -0.09903374],\n         [-0.17318746,  0.00293897,  0.00089837,  0.02475446],\n         [-0.04353496,  0.05663297, -0.00168399, -0.10670562],\n         [ 0.01641766, -0.09341971, -0.08044145, -0.07330538],\n         [ 0.00268797,  0.08154051, -0.12635797,  0.02417696],\n         [ 0.0340312 , -0.07623601,  0.12978488, -0.08772268],\n         [-0.12161236, -0.08259763, -0.10462891,  0.01370023],\n         [-0.00738282, -0.03372376, -0.1271356 , -0.01789768],\n         [-0.01221484, -0.01397653, -0.00155973,  0.13049084],\n         [-0.07796519,  0.02867266, -0.03495677, -0.07061622],\n         [ 0.09797794,  0.01851783, -0.0485487 ,  0.02205472],\n         [ 0.03562444, -0.06502075,  0.05930261, -0.03671053],\n         [-0.12492716, -0.13721663,  0.06473758,  0.00604675],\n         [ 0.070114  , -0.01902341,  0.05244958, -0.0936335 ],\n         [-0.12206123,  0.11637246,  0.02030917, -0.02577622],\n         [-0.04966445,  0.12071061, -0.1429379 , -0.06815837],\n         [-0.04834042, -0.01325547,  0.02769884, -0.0166651 ],\n         [ 0.00218471, -0.07542607, -0.12479062, -0.04049531],\n         [-0.02186379,  0.04181989,  0.01509402, -0.16750224],\n         [ 0.03025393,  0.09274626,  0.08653527,  0.18617915],\n         [-0.08553559,  0.12182727,  0.05546219, -0.06653943],\n         [-0.01760615, -0.03670194, -0.11697042,  0.02722358],\n         [-0.04513986, -0.16960108, -0.04496966,  0.00640422],\n         [ 0.04990316,  0.10711133,  0.06566343,  0.09644027],\n         [ 0.12983647,  0.00266442, -0.14251651, -0.09428623],\n         [ 0.15761271,  0.01112566, -0.0604986 ,  0.0471209 ],\n         [ 0.05440122, -0.00222425, -0.05638983, -0.0531702 ],\n         [-0.08496695, -0.04488914,  0.07705095, -0.08783916],\n         [-0.1614243 ,  0.00813478, -0.01612123, -0.06694531],\n         [ 0.07071088,  0.12121177,  0.03337152,  0.01874368],\n         [-0.09960195,  0.09487536, -0.13873644, -0.09701242],\n         [-0.12459549,  0.09799752,  0.02508489,  0.00279215],\n         [-0.04410345, -0.03381923, -0.11009634, -0.03064325],\n         [ 0.13902055,  0.08125252, -0.04899363, -0.06853049],\n         [ 0.00429458, -0.03418063,  0.13988534,  0.01229757],\n         [-0.00297144,  0.00167207, -0.09436485, -0.03940474],\n         [ 0.13002272, -0.10842835,  0.02537668, -0.08801584],\n         [ 0.05087539,  0.12321518,  0.09751833, -0.1145931 ],\n         [-0.11106663,  0.10242482, -0.06019084, -0.00707043],\n         [ 0.03710387,  0.13167235, -0.04639511, -0.03251163],\n         [ 0.04181461, -0.0442941 ,  0.04968412, -0.13256364],\n         [ 0.1288824 , -0.02596609, -0.08981573,  0.10586812],\n         [ 0.15427276,  0.02435395,  0.04180205, -0.11795913],\n         [ 0.04712658,  0.00182793,  0.08125487, -0.11472569],\n         [ 0.13352992, -0.07388116, -0.05926284,  0.07106   ],\n         [ 0.12169028,  0.04248454,  0.05388284, -0.05092555],\n         [-0.03049528,  0.00694684, -0.01086393, -0.02781583],\n         [-0.04314344,  0.1655162 , -0.01598664, -0.05014084],\n         [-0.17657654,  0.04656468, -0.1563552 , -0.06544053],\n         [ 0.09241959,  0.01808688,  0.03161157, -0.00464515],\n         [ 0.03739675, -0.12678948, -0.07785824, -0.00226444],\n         [ 0.00252193,  0.04234374,  0.02774007, -0.07421461],\n         [ 0.15311487, -0.06055634,  0.06075127, -0.10565766],\n         [-0.128886  , -0.13769747, -0.159068  , -0.05143348],\n         [ 0.0950316 , -0.00615977, -0.11900305, -0.02050137],\n         [-0.05680747, -0.09456473, -0.03905823,  0.00235562],\n         [-0.04001148, -0.0253312 , -0.09710392, -0.09817521],\n         [-0.15209791, -0.02605542, -0.00302898,  0.03755013],\n         [ 0.13905612,  0.12455417, -0.01791719, -0.03234477],\n         [ 0.16744149,  0.04360336,  0.06300595, -0.03470729],\n         [-0.05102193, -0.1452873 ,  0.13981695,  0.02392637],\n         [-0.02224801, -0.1296511 ,  0.0298916 ,  0.04581955],\n         [-0.05060181,  0.03933307, -0.03699891, -0.00718969],\n         [-0.10295284, -0.1461309 ,  0.00513936, -0.07845126],\n         [ 0.0991139 ,  0.09987702,  0.16783518, -0.06146259],\n         [-0.00878084,  0.04451089, -0.0242034 , -0.00290466],\n         [ 0.05170459,  0.0212477 , -0.04025416, -0.06230281],\n         [-0.09381144,  0.09066012, -0.01569835,  0.16495815],\n         [-0.10223784,  0.03141678, -0.04474649,  0.1285678 ],\n         [ 0.00156122, -0.10547151, -0.13626057, -0.08621756],\n         [-0.08295612, -0.01915357,  0.06684773,  0.05639355],\n         [ 0.06895996, -0.08734882, -0.14016761,  0.1212548 ],\n         [-0.0158081 , -0.03138791,  0.00259429, -0.02383161],\n         [-0.12326996, -0.12929712, -0.00574765,  0.01299437],\n         [ 0.1307537 , -0.17042147,  0.00517274, -0.08292925],\n         [-0.08437347,  0.1136998 , -0.14168651,  0.18472771],\n         [-0.1371271 , -0.05755889, -0.04240495,  0.09164174],\n         [-0.05730253,  0.04933271,  0.06620687, -0.13063405],\n         [ 0.04163403, -0.09053862,  0.00620647, -0.02328288],\n         [ 0.02546123, -0.11092508, -0.01112259, -0.02433479],\n         [-0.1380404 , -0.17200045, -0.0439747 , -0.01185329],\n         [ 0.06170368,  0.03581291,  0.06952105,  0.12660606]]]],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_2/beta:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 48, 1) dtype=float32, numpy=\narray([[[[ 3.53159457e-02],\n         [ 5.03814556e-02],\n         [ 3.07737049e-02],\n         [-2.15988215e-02],\n         [ 4.19876724e-03],\n         [-5.33763021e-02],\n         [-8.51735994e-02],\n         [-2.09488291e-02],\n         [-2.15752143e-02],\n         [-2.50222702e-02],\n         [-5.24209626e-02],\n         [-2.07700301e-02],\n         [-4.41363342e-02],\n         [-2.01633628e-02],\n         [ 7.71572962e-02],\n         [ 1.03974834e-01],\n         [ 7.07042217e-02],\n         [-4.88279201e-02],\n         [ 4.27590646e-02],\n         [-4.47826013e-02],\n         [-7.53735229e-02],\n         [ 3.93768325e-02],\n         [-1.94847491e-02],\n         [ 1.05290534e-02],\n         [ 3.27172205e-02],\n         [-1.13758286e-02],\n         [ 8.64494815e-02],\n         [-3.85653600e-02],\n         [-2.71121785e-02],\n         [-2.99452133e-02],\n         [ 3.63736451e-02],\n         [-2.41101789e-05],\n         [-1.35222292e-02],\n         [ 5.39063215e-02],\n         [ 8.62861648e-02],\n         [-4.24535349e-02],\n         [ 4.51135216e-03],\n         [ 4.61910963e-02],\n         [ 1.28559060e-02],\n         [ 9.04856101e-02],\n         [ 2.29352769e-02],\n         [ 6.60367459e-02],\n         [ 4.71788235e-02],\n         [-8.91620815e-02],\n         [-5.94145581e-02],\n         [-1.83062479e-02],\n         [-2.16789171e-03],\n         [ 4.17781137e-02]],\n\n        [[-1.10544013e-02],\n         [ 2.77538374e-02],\n         [ 4.25366014e-02],\n         [-8.11855122e-02],\n         [-7.34824464e-02],\n         [ 2.91182846e-02],\n         [-3.53838801e-02],\n         [-8.43996033e-02],\n         [-4.09992747e-02],\n         [ 9.57622472e-03],\n         [ 7.88755864e-02],\n         [ 2.84397155e-02],\n         [ 7.03790486e-02],\n         [-3.75360297e-03],\n         [ 8.29164833e-02],\n         [-1.04061039e-02],\n         [-2.10589655e-02],\n         [-2.99800187e-02],\n         [ 6.16447702e-02],\n         [ 4.25974047e-03],\n         [-7.45044574e-02],\n         [ 1.42984455e-02],\n         [ 3.56371738e-02],\n         [ 3.49963121e-02],\n         [ 4.69331406e-02],\n         [-1.01489738e-01],\n         [-4.20799218e-02],\n         [ 4.64648046e-02],\n         [ 5.84333315e-02],\n         [ 1.35016004e-02],\n         [-3.72487381e-02],\n         [-1.34304436e-02],\n         [ 3.26460823e-02],\n         [-3.02999914e-02],\n         [-8.83728564e-02],\n         [ 8.60380605e-02],\n         [ 6.65825419e-03],\n         [-7.72655755e-02],\n         [-8.19081888e-02],\n         [ 5.57227544e-02],\n         [-3.38321999e-02],\n         [-4.83520105e-02],\n         [-3.83248068e-02],\n         [-2.92716399e-02],\n         [ 2.84039066e-03],\n         [-1.36643904e-03],\n         [ 1.39363986e-02],\n         [-5.42569906e-02]],\n\n        [[-1.05620874e-02],\n         [ 5.66055300e-03],\n         [-2.31237859e-02],\n         [ 3.80208939e-02],\n         [ 9.30777118e-02],\n         [-3.79978530e-02],\n         [-4.48042266e-02],\n         [ 9.41825733e-02],\n         [-2.14360226e-02],\n         [-1.00182248e-02],\n         [-2.63821706e-02],\n         [ 5.45234606e-02],\n         [-1.47585385e-02],\n         [-4.30061668e-02],\n         [ 1.80854220e-02],\n         [ 3.27795520e-02],\n         [-6.09450378e-02],\n         [-7.69356266e-02],\n         [-5.77506311e-02],\n         [ 3.63277979e-02],\n         [ 7.19530284e-02],\n         [-7.94472471e-02],\n         [-3.95163186e-02],\n         [ 4.45337966e-02],\n         [-6.61355704e-02],\n         [-2.78428365e-02],\n         [-1.01313412e-01],\n         [-2.78258715e-02],\n         [ 1.96183268e-02],\n         [ 4.92886417e-02],\n         [-3.31377573e-02],\n         [-5.91154695e-02],\n         [-8.64304006e-02],\n         [ 6.26434200e-03],\n         [-5.53163663e-02],\n         [-2.06293687e-02],\n         [ 4.71837409e-02],\n         [ 2.93763615e-02],\n         [-2.23852135e-02],\n         [-7.31137097e-02],\n         [-2.36331783e-02],\n         [-6.30450323e-02],\n         [ 6.93192612e-03],\n         [ 4.29211184e-02],\n         [-9.05910414e-03],\n         [ 3.25310193e-02],\n         [-2.02540513e-02],\n         [-1.38577148e-02]]],\n\n\n       [[[-2.79277768e-02],\n         [-5.62481582e-02],\n         [-2.28641815e-02],\n         [-4.19692397e-02],\n         [ 1.06789172e-02],\n         [-4.74768318e-02],\n         [-3.79102565e-02],\n         [-7.51478672e-02],\n         [ 4.63297628e-02],\n         [ 4.25189594e-03],\n         [ 2.61666626e-02],\n         [ 2.80124284e-02],\n         [ 8.14502388e-02],\n         [ 2.86713075e-02],\n         [-2.59397109e-03],\n         [ 4.75228950e-02],\n         [ 4.31774855e-02],\n         [-7.67606795e-02],\n         [ 6.30831867e-02],\n         [-1.00543194e-01],\n         [-3.22792754e-02],\n         [ 6.17848756e-03],\n         [ 2.03208588e-02],\n         [ 3.78086120e-02],\n         [ 3.44711021e-02],\n         [-1.16852187e-02],\n         [-3.78838852e-02],\n         [-1.54898490e-03],\n         [ 6.92383647e-02],\n         [-7.46587515e-02],\n         [ 3.50788571e-02],\n         [-3.77873145e-03],\n         [-4.66197692e-02],\n         [-5.64974546e-02],\n         [-7.91984499e-02],\n         [ 5.05828522e-02],\n         [ 2.21440066e-02],\n         [-1.09414160e-02],\n         [-5.27949482e-02],\n         [ 3.79642136e-02],\n         [ 1.94794424e-02],\n         [-2.77312868e-03],\n         [-4.97424640e-02],\n         [ 3.61784659e-02],\n         [ 3.92357782e-02],\n         [-3.78513746e-02],\n         [-1.95586891e-03],\n         [ 9.43043306e-02]],\n\n        [[ 1.39089739e-02],\n         [-2.37878021e-02],\n         [-9.25822482e-02],\n         [ 9.19769183e-02],\n         [-9.83104259e-02],\n         [-3.48892175e-02],\n         [-2.68912427e-02],\n         [-9.96044874e-02],\n         [ 4.34916355e-02],\n         [-7.23978803e-02],\n         [-2.09711213e-02],\n         [ 2.26920191e-03],\n         [ 7.14952052e-02],\n         [-1.69049613e-02],\n         [-4.46030349e-02],\n         [ 4.41316590e-02],\n         [ 5.54548623e-03],\n         [-9.16829854e-02],\n         [-4.89749052e-02],\n         [-5.27027175e-02],\n         [ 7.69813135e-02],\n         [-1.42667666e-02],\n         [ 6.14000894e-02],\n         [-3.34884450e-02],\n         [-3.31978314e-02],\n         [-4.75349836e-02],\n         [ 6.68137372e-02],\n         [-8.15757923e-03],\n         [-2.34489273e-02],\n         [ 4.26237769e-02],\n         [ 2.95912102e-02],\n         [-3.88364643e-02],\n         [ 8.46106932e-02],\n         [-5.05492911e-02],\n         [-6.93544075e-02],\n         [ 1.15405498e-02],\n         [-2.08933055e-02],\n         [-3.15332599e-02],\n         [ 8.03300587e-04],\n         [ 1.69281960e-02],\n         [-1.64860785e-02],\n         [ 2.91454475e-02],\n         [-2.07784139e-02],\n         [ 1.16712777e-02],\n         [-7.96888843e-02],\n         [ 6.38474897e-02],\n         [-2.59472001e-02],\n         [-6.30716905e-02]],\n\n        [[-4.85102460e-02],\n         [ 1.65536981e-02],\n         [-1.43328048e-02],\n         [ 4.80605252e-02],\n         [-2.67029479e-02],\n         [-3.62486318e-02],\n         [ 9.25540701e-02],\n         [ 3.19261588e-02],\n         [ 6.34673983e-02],\n         [-6.42840862e-02],\n         [-2.19921190e-02],\n         [-5.08274361e-02],\n         [ 4.64251153e-02],\n         [-1.60259083e-02],\n         [ 4.44377139e-02],\n         [-6.41317219e-02],\n         [ 1.09003473e-03],\n         [-1.31795090e-02],\n         [ 4.71654497e-02],\n         [ 7.37250149e-02],\n         [-1.44194858e-02],\n         [-1.05053023e-01],\n         [-5.32207973e-02],\n         [-3.15502882e-02],\n         [ 7.78401792e-02],\n         [-2.80140154e-02],\n         [-4.26099822e-02],\n         [-7.79997259e-02],\n         [ 9.48408172e-02],\n         [ 4.26637232e-02],\n         [ 2.82237511e-02],\n         [ 8.41055438e-02],\n         [ 3.61208469e-02],\n         [ 8.96926448e-02],\n         [ 7.77909905e-02],\n         [-2.48177424e-02],\n         [-1.00088092e-02],\n         [ 7.70199811e-04],\n         [ 7.22677074e-03],\n         [ 5.43387197e-02],\n         [ 8.37420486e-03],\n         [ 1.91782080e-02],\n         [ 9.26666483e-02],\n         [-8.43878686e-02],\n         [ 8.74332897e-03],\n         [ 3.58072594e-02],\n         [ 5.50977737e-02],\n         [-6.13569617e-02]]],\n\n\n       [[[ 3.63879949e-02],\n         [-5.04389107e-02],\n         [ 9.03431606e-03],\n         [-2.61386670e-03],\n         [-3.75118442e-02],\n         [ 3.28350961e-02],\n         [-1.09143689e-01],\n         [-6.48222566e-02],\n         [-4.68815211e-03],\n         [-7.73714110e-02],\n         [ 4.88298610e-02],\n         [ 5.26318289e-02],\n         [-6.18577898e-02],\n         [-8.75663944e-03],\n         [-1.01612182e-02],\n         [ 4.21457402e-02],\n         [ 2.91728098e-02],\n         [ 1.43084396e-02],\n         [-6.33279160e-02],\n         [-7.44637325e-02],\n         [ 7.07439110e-02],\n         [-5.98586909e-02],\n         [ 2.31313109e-02],\n         [ 5.80266528e-02],\n         [-1.37082068e-02],\n         [ 1.37210740e-02],\n         [-1.55142499e-02],\n         [-2.40824441e-03],\n         [ 1.63402166e-02],\n         [ 7.07966881e-03],\n         [ 9.01942700e-02],\n         [-2.58190017e-02],\n         [-2.78343316e-02],\n         [ 1.01193681e-01],\n         [ 1.08919226e-01],\n         [-4.77640443e-02],\n         [-3.68368700e-02],\n         [-3.92691046e-02],\n         [ 7.88680557e-03],\n         [ 6.16163947e-02],\n         [ 2.05405243e-02],\n         [-8.97570164e-04],\n         [ 1.82925388e-02],\n         [ 9.45965797e-02],\n         [-4.27553244e-02],\n         [-6.72508255e-02],\n         [-1.68191288e-02],\n         [ 1.25851613e-02]],\n\n        [[ 2.44568735e-02],\n         [ 5.06686233e-03],\n         [-1.05945505e-02],\n         [ 2.43188925e-02],\n         [-9.09846053e-02],\n         [ 1.03353029e-02],\n         [-8.29538517e-03],\n         [-7.20995069e-02],\n         [ 2.39007100e-02],\n         [ 7.88740739e-02],\n         [-8.35611895e-02],\n         [-3.59471105e-02],\n         [-2.41697431e-02],\n         [-6.53790757e-02],\n         [-4.12599146e-02],\n         [ 1.24697462e-02],\n         [ 7.42886662e-02],\n         [ 8.32449123e-02],\n         [-4.48404402e-02],\n         [-3.56145985e-02],\n         [ 4.65434529e-02],\n         [-4.89874072e-02],\n         [-5.65120280e-02],\n         [ 1.57853737e-02],\n         [-4.78245392e-02],\n         [-1.04616903e-01],\n         [-3.88760827e-02],\n         [-8.78322572e-02],\n         [ 9.70100518e-04],\n         [ 1.35737900e-02],\n         [-9.53916609e-02],\n         [ 6.40029386e-02],\n         [-1.15573443e-02],\n         [-4.10155877e-02],\n         [ 1.97382737e-02],\n         [ 2.55914535e-02],\n         [-3.34017649e-02],\n         [-1.05393343e-02],\n         [ 3.74893062e-02],\n         [ 3.69113497e-02],\n         [-3.42543498e-02],\n         [-1.31756440e-02],\n         [-5.67687228e-02],\n         [-2.57813092e-02],\n         [-1.52693605e-02],\n         [-1.98891871e-02],\n         [-3.07427328e-02],\n         [ 7.66428784e-02]],\n\n        [[-7.16740042e-02],\n         [ 5.69579229e-02],\n         [ 5.90049662e-03],\n         [-7.64006078e-02],\n         [ 2.24321913e-02],\n         [-4.77536619e-02],\n         [-5.58662862e-02],\n         [ 2.67203245e-02],\n         [-1.58236083e-02],\n         [ 6.88611418e-02],\n         [-6.67586327e-02],\n         [ 4.53167669e-02],\n         [-2.33590454e-02],\n         [ 2.05879640e-02],\n         [-6.13767244e-02],\n         [ 3.18792909e-02],\n         [ 5.73027395e-02],\n         [-2.28201542e-02],\n         [ 4.83403467e-02],\n         [ 5.57980239e-02],\n         [-4.77933474e-02],\n         [ 2.33414024e-02],\n         [ 2.32983828e-02],\n         [ 3.41300890e-02],\n         [-7.73488823e-03],\n         [-2.33861282e-02],\n         [-1.44032165e-02],\n         [ 2.48822179e-02],\n         [-1.06486976e-01],\n         [-2.03070100e-02],\n         [-7.03199059e-02],\n         [-8.40019360e-02],\n         [ 1.04896137e-02],\n         [-1.12567900e-03],\n         [ 3.64941433e-02],\n         [ 2.43053827e-02],\n         [ 5.60640544e-03],\n         [-4.31202464e-02],\n         [-5.10355877e-03],\n         [ 6.55611679e-02],\n         [ 2.94309873e-02],\n         [ 5.28715625e-02],\n         [-2.27759797e-02],\n         [ 3.00714429e-02],\n         [ 2.05432670e-03],\n         [ 1.08848670e-02],\n         [-9.61027760e-03],\n         [ 9.56708863e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_906/moving_variance:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/sync_batch_normalization_2/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_250/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_909/gamma:0' shape=(48,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[-0.01417633, -0.03319129,  0.00286524, ...,  0.04760628,\n           0.02724828,  0.02691896],\n         [ 0.03771644,  0.07957841,  0.04870487, ...,  0.00988172,\n          -0.02380049, -0.00231152],\n         [ 0.0382299 ,  0.04970492, -0.03999446, ...,  0.03511826,\n           0.08485122, -0.05274315],\n         ...,\n         [-0.01438226, -0.08192959,  0.01288222, ...,  0.00827811,\n           0.01224355, -0.03826889],\n         [-0.01319871,  0.03518998, -0.07306327, ..., -0.06097677,\n           0.03845571, -0.08157586],\n         [ 0.00127259,  0.02016406,  0.01575197, ..., -0.0404964 ,\n           0.04768638,  0.06940842]]]], dtype=float32)>, <tf.Variable 'conv2d_864/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.00893544,  0.00931665,  0.00565999, ..., -0.02806362,\n          -0.02665524,  0.12389425],\n         [-0.18776798, -0.18925822,  0.02337648, ...,  0.05347696,\n           0.06285261,  0.03375933],\n         [ 0.11734153,  0.07295968, -0.05787664, ..., -0.12069435,\n          -0.06886938,  0.12980045],\n         ...,\n         [ 0.03962326, -0.13732831,  0.17900416, ..., -0.03899585,\n          -0.06190008,  0.01398859],\n         [-0.1371161 ,  0.00211848,  0.05134314, ...,  0.12428765,\n           0.20507903,  0.15506223],\n         [ 0.01173747,  0.13485728, -0.00387883, ..., -0.06674843,\n           0.13342224,  0.0603268 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_844/kernel:0' shape=(1, 1, 24, 40) dtype=float32, numpy=\narray([[[[-0.26612765,  0.03539177, -0.03010099, -0.07685361,\n           0.20067775, -0.24287722, -0.33287975,  0.4183457 ,\n           0.25707003, -0.13190171,  0.43313092, -0.06353056,\n           0.15011865, -0.09036477,  0.05158886,  0.07530625,\n          -0.18704566, -0.24176463, -0.07085809,  0.17440704,\n          -0.11164927, -0.09579259,  0.24499743, -0.17246103,\n          -0.27655062,  0.23568289, -0.19660127,  0.42349058,\n          -0.09335127, -0.27969927, -0.36118516,  0.2766599 ,\n          -0.4124004 ,  0.2447695 , -0.2750374 ,  0.14996801,\n          -0.22801284, -0.3275562 ,  0.40218624,  0.08543184],\n         [ 0.02760542, -0.1022142 ,  0.01950224, -0.29201382,\n          -0.24712808, -0.01616955, -0.1714271 ,  0.27840713,\n          -0.15799658,  0.05762885,  0.11866532, -0.01749915,\n           0.21127133, -0.15286581,  0.15736781, -0.16343082,\n          -0.26516587, -0.31273413, -0.15783918, -0.25324246,\n          -0.03646548, -0.21888506,  0.24075603,  0.03661891,\n           0.42971668, -0.15031898,  0.03665186,  0.18387263,\n          -0.04490378, -0.11625357,  0.0596994 , -0.10842396,\n           0.16878104,  0.12240873,  0.25805238,  0.23097195,\n           0.18400913, -0.17084856,  0.1533958 , -0.093521  ],\n         [-0.17441136,  0.13797534,  0.05565358, -0.41164976,\n          -0.07375833,  0.42785686, -0.1793502 , -0.03087219,\n          -0.01667484,  0.29367438,  0.13757153,  0.36647794,\n           0.01900608,  0.34951788,  0.15879296,  0.14030989,\n           0.32498214,  0.30281392, -0.12969168,  0.03235579,\n           0.36160567,  0.368509  , -0.01446664, -0.08962359,\n          -0.1525086 , -0.07711559,  0.14647909,  0.04995252,\n          -0.12380992,  0.17655186, -0.25552142, -0.02930377,\n           0.37407365,  0.11124046, -0.04503384,  0.06300842,\n           0.08235773,  0.213994  ,  0.02669655, -0.02076308],\n         [-0.38985303, -0.39230025,  0.10929905, -0.18809451,\n           0.42426923, -0.19428578, -0.23750228, -0.01487223,\n           0.21898156, -0.05823644, -0.25372   , -0.3777752 ,\n           0.38529953, -0.26071587,  0.3375565 ,  0.02722104,\n          -0.03519839,  0.3869795 , -0.1336692 ,  0.02585745,\n           0.0338083 , -0.00156765, -0.11782176, -0.31203067,\n          -0.2270928 , -0.1984539 ,  0.2984742 , -0.08511255,\n          -0.08396938, -0.2160836 , -0.02074038,  0.04352935,\n          -0.2220997 , -0.32769802,  0.31321204,  0.01259614,\n           0.20286883, -0.14696471, -0.19427735,  0.07024283],\n         [-0.3331219 ,  0.21216762, -0.38397554,  0.37801495,\n           0.05204998, -0.00815488,  0.10213754,  0.05495131,\n          -0.05822546, -0.26441944, -0.09523135,  0.07770756,\n           0.36111182,  0.09291603,  0.01347374,  0.24783754,\n          -0.26751524, -0.01596982, -0.0693484 ,  0.05634258,\n          -0.04294525,  0.15577057, -0.0170864 ,  0.04750102,\n           0.02832501, -0.16439876,  0.01768424,  0.00054948,\n           0.02267146,  0.04675772, -0.11960793,  0.02872481,\n          -0.30074987,  0.08002444, -0.11517092,  0.18286076,\n          -0.10061716,  0.19056948, -0.31814408,  0.40550297],\n         [-0.30751976,  0.22278789,  0.06436134, -0.08272123,\n          -0.23657992,  0.30457327,  0.2408229 ,  0.17367011,\n           0.15933962, -0.03249415, -0.20639968,  0.12999274,\n           0.02718118,  0.22092266,  0.23868819,  0.36281896,\n           0.29599398,  0.4320648 ,  0.28759035, -0.18543464,\n           0.00461237, -0.17913595,  0.11695091,  0.21002087,\n          -0.05013748,  0.05743557,  0.2952539 ,  0.16416705,\n          -0.16420043, -0.12554374,  0.11104595,  0.2647914 ,\n           0.28961322,  0.4131639 , -0.01286893, -0.2654958 ,\n           0.04271907, -0.28657883,  0.13446228,  0.06460872],\n         [-0.1443402 , -0.06399219,  0.27283114,  0.38340366,\n           0.36619362,  0.2306422 ,  0.0878112 ,  0.09166153,\n          -0.01406525, -0.21166506, -0.04848509,  0.14059405,\n           0.03481422,  0.07951848, -0.1739722 , -0.400549  ,\n           0.0647438 ,  0.20734277, -0.03430211,  0.3305663 ,\n           0.24181153, -0.23509836, -0.03420889, -0.17804445,\n          -0.2796256 ,  0.17701761,  0.27608898,  0.04669648,\n           0.25997078,  0.18438675, -0.11276163,  0.08107632,\n           0.3302622 , -0.05758501, -0.0164114 , -0.07507894,\n           0.12887318,  0.18627018,  0.2555415 , -0.27708003],\n         [-0.2634517 ,  0.30746722, -0.15585753,  0.22625153,\n           0.38095275,  0.21207178, -0.06137256,  0.29889044,\n          -0.22840302,  0.37019625,  0.35120937, -0.26527044,\n          -0.3463419 , -0.20458324,  0.0068853 ,  0.29969892,\n          -0.18551363,  0.04943659,  0.0439841 ,  0.19670455,\n          -0.00133047, -0.17500031, -0.37108597, -0.0769826 ,\n           0.17162162,  0.04533614,  0.2626481 , -0.00734868,\n          -0.09853044,  0.42154455, -0.04103972, -0.17537934,\n           0.16155909, -0.17501317, -0.09401121, -0.20617306,\n          -0.42599836,  0.030265  ,  0.23222825,  0.23349908],\n         [-0.41936803,  0.37516555, -0.11884803,  0.30028796,\n           0.34312603,  0.4075996 ,  0.00375418, -0.12759939,\n          -0.13075104,  0.05297039, -0.12681012,  0.05836933,\n           0.24926496, -0.31209552, -0.00976384,  0.25806454,\n          -0.44350228,  0.2849175 , -0.19418086,  0.17200883,\n          -0.02415418, -0.05521749, -0.4215325 ,  0.12385736,\n           0.06298042,  0.04003501,  0.138103  , -0.31618324,\n          -0.06742612, -0.17845657,  0.14380437,  0.04574826,\n           0.17975941,  0.03723933,  0.19766103,  0.10188191,\n          -0.02858445, -0.17888357, -0.01486607,  0.07851655],\n         [-0.05536302,  0.26031595, -0.3516389 ,  0.18534024,\n          -0.10805655, -0.11935399,  0.08193924,  0.13583788,\n           0.15625446, -0.21298549, -0.30798465,  0.20153232,\n           0.32222646, -0.10716551,  0.17941168,  0.06163031,\n           0.10845102,  0.18192211,  0.00198092,  0.1256109 ,\n           0.28104275, -0.17905737, -0.10289639,  0.33829412,\n          -0.08557675,  0.36513355,  0.06322505,  0.01937181,\n           0.01712705, -0.18976107,  0.42853302,  0.45543876,\n          -0.4005901 ,  0.18054976,  0.13052465,  0.1596327 ,\n          -0.3378976 ,  0.03734895,  0.01261216, -0.02560599],\n         [ 0.19420688,  0.24152932, -0.2738372 ,  0.0574615 ,\n           0.04559427, -0.14552984,  0.41244003, -0.15594277,\n          -0.04256302, -0.23256166,  0.2991894 ,  0.18004656,\n           0.34139362, -0.33223185,  0.04614733,  0.30934703,\n           0.039724  ,  0.30182582,  0.16940568, -0.20466511,\n          -0.1362336 , -0.03044419, -0.32169405, -0.19622493,\n           0.06439164, -0.25640315, -0.30964527, -0.1239585 ,\n          -0.07131123, -0.11010169,  0.0191714 , -0.28776374,\n          -0.39162078, -0.15761662,  0.36517996, -0.02510663,\n          -0.08894569,  0.00769533,  0.12738949, -0.01253839],\n         [-0.4497005 ,  0.13914731, -0.19806302, -0.16818118,\n          -0.41837156, -0.12098682,  0.05196934, -0.13239385,\n           0.14837602,  0.29936   , -0.20102647, -0.07059862,\n          -0.06621028,  0.2234595 ,  0.01684102, -0.12272306,\n          -0.03963729, -0.1920501 , -0.18856807,  0.00700842,\n           0.13952023,  0.23870659,  0.22175245, -0.06058592,\n           0.13067655, -0.32535428,  0.04258349, -0.11056731,\n           0.20736244, -0.18920767,  0.01975874,  0.11414749,\n          -0.07578363,  0.39530325, -0.14123948, -0.29406244,\n          -0.18265855, -0.2892531 ,  0.364718  ,  0.38575736],\n         [ 0.27707914,  0.04710755, -0.12688656, -0.01721698,\n           0.04282366,  0.2604268 ,  0.22586921, -0.2868515 ,\n          -0.251027  , -0.11194225, -0.08980644,  0.13758025,\n           0.36530164,  0.37803793,  0.3866741 , -0.22601545,\n          -0.37253618,  0.30739567, -0.03073063,  0.12404712,\n           0.17264578, -0.32391268, -0.22178732, -0.01223296,\n           0.11609384,  0.0757632 ,  0.2964583 , -0.35540453,\n          -0.24322674,  0.37437227, -0.05056396,  0.12491502,\n          -0.02962478, -0.4013013 , -0.01696869, -0.28358784,\n          -0.11382962,  0.1088635 , -0.13343582, -0.15464821],\n         [ 0.06946544, -0.06768081, -0.1031743 , -0.23153976,\n           0.12644683,  0.16024828, -0.13626692, -0.06004736,\n          -0.2850844 , -0.03006786, -0.17581382, -0.2119357 ,\n           0.4094881 ,  0.03771643, -0.17363505,  0.14754231,\n          -0.18658045,  0.12486137, -0.01730932, -0.25173682,\n          -0.0516717 , -0.1272997 ,  0.26505265,  0.17360497,\n          -0.32806087,  0.3508029 ,  0.36579394,  0.00754141,\n          -0.29493862, -0.06661863,  0.12967014, -0.22087497,\n           0.19735593, -0.06390043, -0.08938279,  0.13409956,\n           0.06445905,  0.05386739,  0.07088631,  0.12261354],\n         [ 0.09729882, -0.15903388,  0.17876945,  0.18069077,\n           0.3798783 ,  0.02753179,  0.10748763,  0.1767273 ,\n          -0.25072965, -0.01079263,  0.29257762,  0.27935654,\n          -0.11697014, -0.04883001, -0.00641297, -0.318633  ,\n           0.3399769 , -0.19843449, -0.1301943 , -0.08776686,\n          -0.01529333, -0.08259024,  0.40131626,  0.1682398 ,\n           0.3331283 ,  0.1303495 , -0.10764422, -0.2347675 ,\n           0.11949359,  0.1555066 , -0.45952138, -0.22474845,\n           0.3082912 ,  0.29830483, -0.34177932,  0.14336285,\n          -0.08031669, -0.12034832,  0.22637908, -0.2994427 ],\n         [-0.15006673, -0.01378446,  0.13234746,  0.22631086,\n          -0.09306253,  0.09801712, -0.17393805, -0.27421582,\n          -0.03991576,  0.11299498,  0.23515877,  0.16165458,\n           0.08464465, -0.33795577,  0.26129913, -0.08001439,\n          -0.38156837, -0.28234112, -0.15267865, -0.03464477,\n           0.13398603, -0.25033855, -0.337025  ,  0.01325399,\n          -0.0447702 ,  0.12821981, -0.1429522 ,  0.06470641,\n           0.13511096,  0.12876196, -0.28609785,  0.18516445,\n          -0.0470242 , -0.13911627, -0.1260926 ,  0.17518559,\n          -0.15979275, -0.37225538, -0.22824155, -0.31986883],\n         [ 0.02420627,  0.10199033, -0.29586083,  0.16805045,\n           0.3240896 , -0.24461368, -0.04408116, -0.3894818 ,\n           0.06190571,  0.07943973,  0.31324726, -0.22212279,\n           0.33722585,  0.19169994, -0.28927568,  0.17652024,\n           0.26221076, -0.07251318,  0.23510292,  0.44161934,\n          -0.06303921, -0.12677667,  0.20609759, -0.13964136,\n          -0.30503997, -0.16382529,  0.22308536, -0.06889992,\n          -0.075771  , -0.2913703 , -0.33822072, -0.24617912,\n          -0.08902863, -0.29792723,  0.23306003, -0.13686919,\n          -0.12873462,  0.16795625,  0.05351104,  0.154744  ],\n         [ 0.08763546, -0.18022923, -0.03294386,  0.06805636,\n          -0.07171855,  0.2605746 ,  0.01097168,  0.24657239,\n           0.21632311, -0.19709869, -0.13290423, -0.09989335,\n           0.12477641,  0.14554241, -0.16026525,  0.00280446,\n           0.01563234,  0.07242709,  0.28772455, -0.2986819 ,\n          -0.05915742,  0.30262142, -0.01766063, -0.15191483,\n           0.02856509, -0.00915187, -0.02375627,  0.27065602,\n           0.1022602 ,  0.07587232, -0.3117727 ,  0.08361859,\n          -0.16309178, -0.11843568,  0.21476053,  0.00467917,\n          -0.13806637, -0.1254266 ,  0.05112955, -0.13238683],\n         [ 0.35669038,  0.05614121, -0.25424355, -0.08128577,\n           0.13306387, -0.24759427, -0.4546411 ,  0.15776418,\n           0.14185682,  0.13924907, -0.2249725 , -0.39843374,\n           0.11038958,  0.41711953, -0.3669926 ,  0.06033428,\n          -0.06482619, -0.28510076, -0.02815536,  0.04190137,\n          -0.21179637, -0.15555811,  0.07052849, -0.18483718,\n          -0.04127508, -0.13930203, -0.4455054 ,  0.17786127,\n          -0.3457968 , -0.2918939 , -0.10577527, -0.31302375,\n          -0.00723211,  0.20127435,  0.17139535, -0.31524232,\n          -0.01925805,  0.01276865, -0.05545994, -0.14071578],\n         [-0.19877805,  0.4390016 ,  0.14079106,  0.01844993,\n          -0.04676826, -0.16754402, -0.39681628,  0.16673757,\n          -0.0356009 , -0.10559606, -0.12446998,  0.17895772,\n           0.05603748,  0.16005942, -0.00516651, -0.31618026,\n           0.09006545,  0.10866824, -0.2890184 ,  0.08678721,\n           0.36295837, -0.26434368,  0.16564968, -0.3712366 ,\n           0.03313078,  0.01882163, -0.02027442, -0.26889062,\n           0.3474036 , -0.07299661, -0.3799147 ,  0.23087016,\n           0.10814088,  0.16715388,  0.0114469 ,  0.14813192,\n           0.02990018, -0.00540092,  0.06299698, -0.01916094],\n         [ 0.09225386, -0.09043281,  0.07119819, -0.01800496,\n          -0.04227459, -0.09253699, -0.14877221,  0.09818866,\n          -0.22063951,  0.04366291,  0.18619518, -0.2602888 ,\n          -0.09240307,  0.29722038,  0.16359796,  0.16288732,\n           0.01286373,  0.16240959, -0.00831234, -0.00719998,\n           0.23148592,  0.22359373,  0.02428894,  0.06910174,\n          -0.15467952,  0.36659357,  0.04818127,  0.12478944,\n           0.36288878, -0.01701926, -0.17572847, -0.19010995,\n          -0.12768528, -0.37327302,  0.15119368, -0.03899619,\n           0.00651566, -0.08161657,  0.44762132,  0.09201499],\n         [-0.00096833, -0.16610275,  0.00957482, -0.13241282,\n          -0.3787512 ,  0.1865296 , -0.23480009, -0.09229969,\n           0.11001218,  0.32114103,  0.24047793,  0.20699112,\n          -0.12491856,  0.22574641,  0.06402686,  0.44879815,\n           0.272528  ,  0.04274595, -0.23817708,  0.29930636,\n           0.31458136, -0.11090562,  0.03667688,  0.11129505,\n          -0.10801628, -0.12049586,  0.01047495, -0.28445372,\n          -0.0796704 ,  0.45121607,  0.00855509, -0.31021333,\n          -0.07645407, -0.00856624, -0.01604011, -0.19731057,\n          -0.18300876, -0.4244736 ,  0.04728486,  0.12921283],\n         [ 0.14853111,  0.09289654, -0.09426411,  0.03368388,\n           0.20055242,  0.0331548 , -0.08234011,  0.31251115,\n           0.36040065, -0.1448588 ,  0.23381497, -0.1368149 ,\n          -0.10675763, -0.15270075, -0.03700992, -0.27636224,\n           0.4277965 ,  0.1556857 ,  0.25048342, -0.21749131,\n          -0.06007688, -0.15035053,  0.36123127,  0.232577  ,\n          -0.12087265, -0.03857862, -0.07297247,  0.03051981,\n           0.12450643,  0.03933071, -0.09821913, -0.10123347,\n          -0.17982943, -0.03278572, -0.2366058 , -0.0145291 ,\n          -0.07628655, -0.16001341, -0.1115007 ,  0.01261141],\n         [ 0.1377829 , -0.00886243,  0.13906124,  0.23228301,\n          -0.43146566,  0.2505391 ,  0.2177207 ,  0.30927545,\n           0.08572311, -0.34716436, -0.13779445,  0.03378799,\n           0.04955504,  0.19748144, -0.14517608, -0.15466875,\n          -0.06533208,  0.07988477,  0.00753112,  0.07374901,\n          -0.17887443, -0.17260677, -0.15784723,  0.36253494,\n          -0.20754693, -0.34404004,  0.05335993, -0.03839185,\n           0.39778095, -0.11600128, -0.01954329,  0.29894316,\n           0.050449  , -0.16397692,  0.44146144,  0.01031566,\n           0.25981775,  0.18380827, -0.12638122,  0.22857845]]]],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_857/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_867/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_888/moving_variance:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'conv2d_872/kernel:0' shape=(1, 1, 112, 48) dtype=float32, numpy=\narray([[[[ 0.007216  , -0.2006934 ,  0.06595994, ..., -0.10638613,\n           0.03039303, -0.06347275],\n         [-0.20517051,  0.13212545, -0.02837271, ...,  0.09439936,\n           0.12070698,  0.06202617],\n         [ 0.03411064,  0.08945523, -0.05197076, ..., -0.08014309,\n           0.0764438 ,  0.00438121],\n         ...,\n         [ 0.02949173, -0.02795532, -0.06832376, ..., -0.06677493,\n           0.12151764, -0.0473615 ],\n         [ 0.0828369 ,  0.00741579,  0.12542737, ...,  0.08023496,\n           0.03417279,  0.05050914],\n         [ 0.08378289, -0.08632613, -0.11509917, ..., -0.13094294,\n           0.0048934 , -0.05380997]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 240, 1) dtype=float32, numpy=\narray([[[[ 0.00361359],\n         [ 0.04095529],\n         [ 0.00316548],\n         ...,\n         [ 0.02852679],\n         [-0.00127756],\n         [-0.00396635]],\n\n        [[-0.01464037],\n         [ 0.02170953],\n         [ 0.00711485],\n         ...,\n         [-0.01353325],\n         [-0.01001555],\n         [ 0.00088421]],\n\n        [[-0.00073993],\n         [ 0.0342293 ],\n         [ 0.00517643],\n         ...,\n         [ 0.00198585],\n         [ 0.03166028],\n         [ 0.00753639]]],\n\n\n       [[[ 0.03673049],\n         [ 0.00388108],\n         [ 0.00144381],\n         ...,\n         [ 0.00307223],\n         [-0.03761655],\n         [-0.03889809]],\n\n        [[ 0.00630493],\n         [ 0.00058662],\n         [-0.00015376],\n         ...,\n         [ 0.04104026],\n         [ 0.01272106],\n         [-0.02278687]],\n\n        [[ 0.02781311],\n         [-0.00788468],\n         [ 0.04180369],\n         ...,\n         [ 0.02702546],\n         [ 0.01159141],\n         [-0.02160001]]],\n\n\n       [[[ 0.02890312],\n         [-0.00567244],\n         [ 0.00483864],\n         ...,\n         [-0.0016178 ],\n         [ 0.01079715],\n         [ 0.00109585]],\n\n        [[ 0.00929708],\n         [ 0.00790813],\n         [ 0.01690235],\n         ...,\n         [-0.00819204],\n         [ 0.02864849],\n         [ 0.02318237]],\n\n        [[-0.03781854],\n         [-0.00231716],\n         [-0.00362662],\n         ...,\n         [ 0.03110815],\n         [-0.01950197],\n         [-0.0275612 ]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_248/sync_batch_normalization/beta:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[ 2.27700863e-02],\n         [ 6.18389947e-03],\n         [-1.68393645e-02],\n         ...,\n         [ 1.29628554e-02],\n         [-1.50023848e-02],\n         [ 4.19705920e-03]],\n\n        [[-2.49519851e-02],\n         [ 1.65948514e-02],\n         [ 7.82239344e-03],\n         ...,\n         [-8.48267879e-03],\n         [ 9.95279843e-05],\n         [-2.87308656e-02]],\n\n        [[ 2.34211814e-02],\n         [-8.48619640e-03],\n         [ 9.87909269e-03],\n         ...,\n         [ 5.90163562e-03],\n         [ 6.06126431e-03],\n         [-2.36742795e-02]]],\n\n\n       [[[ 1.48242861e-02],\n         [-1.38357542e-02],\n         [ 8.01176485e-03],\n         ...,\n         [-8.31632502e-03],\n         [ 4.21907241e-03],\n         [-7.87684508e-03]],\n\n        [[-8.34575109e-03],\n         [ 1.26982881e-02],\n         [ 1.33783529e-02],\n         ...,\n         [-4.65760211e-04],\n         [ 1.28695741e-02],\n         [-2.19112262e-03]],\n\n        [[-1.35911889e-02],\n         [-1.34860747e-03],\n         [-1.09946765e-02],\n         ...,\n         [ 4.68300330e-03],\n         [ 8.82822741e-03],\n         [ 7.00743264e-03]]],\n\n\n       [[[ 6.50743459e-06],\n         [-2.54191016e-03],\n         [-1.48029365e-02],\n         ...,\n         [-1.02036651e-02],\n         [-1.60242841e-02],\n         [ 2.62133498e-02]],\n\n        [[-1.96620333e-03],\n         [ 1.13371189e-03],\n         [ 5.82671724e-03],\n         ...,\n         [-2.26821490e-02],\n         [-1.72922085e-03],\n         [-3.47829424e-03]],\n\n        [[-3.76356533e-03],\n         [ 7.86869880e-03],\n         [ 1.61905941e-02],\n         ...,\n         [-6.50087546e-04],\n         [ 2.39117630e-03],\n         [-2.53763460e-02]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_871/kernel:0' shape=(1, 1, 80, 48) dtype=float32, numpy=\narray([[[[ 0.03833852,  0.20332606, -0.09309868, ..., -0.05508476,\n           0.06792289, -0.13238743],\n         [-0.08538309,  0.0172676 ,  0.15478314, ...,  0.0847337 ,\n           0.01861911, -0.09736871],\n         [ 0.03905815,  0.02464032,  0.0310296 , ..., -0.13386288,\n          -0.04234823, -0.03500171],\n         ...,\n         [-0.12071764,  0.18907587, -0.05510516, ..., -0.21982713,\n           0.08482188,  0.06529619],\n         [-0.00628479, -0.13129911, -0.07300559, ...,  0.09685443,\n          -0.03105544,  0.09022444],\n         [ 0.01251499, -0.07774226, -0.02430129, ...,  0.1024375 ,\n           0.10441688, -0.14937389]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_854/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_2/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_249/sync_batch_normalization_1/beta:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_2/gamma:0' shape=(40,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_865/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[ 0.02411344, -0.13661703,  0.02722762, ...,  0.00925887,\n           0.08891682,  0.0897679 ],\n         [ 0.11008906, -0.09490944,  0.13148436, ...,  0.14169534,\n          -0.07897919,  0.01057128],\n         [ 0.12693833,  0.16536288, -0.06694122, ..., -0.04913049,\n           0.07672325,  0.16468029],\n         ...,\n         [ 0.05694449, -0.01258849,  0.14806037, ...,  0.08759274,\n           0.02142863, -0.01292466],\n         [-0.12036449, -0.14026907,  0.00601822, ..., -0.11640905,\n          -0.14340554,  0.04850876],\n         [-0.00213935,  0.05652082, -0.06207975, ...,  0.10701577,\n           0.10216901, -0.03753307]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_855/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/moving_variance:0' shape=(240,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_243/squeeze_excitation/conv2d_3/bias:0' shape=(480,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/squeeze_excitation/conv2d_2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization/moving_mean:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/sync_batch_normalization_1/beta:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_235/sync_batch_normalization_1/beta:0' shape=(48,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>, <tf.Variable 'sync_batch_normalization_850/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/beta:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_251/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[-0.01490578, -0.05710156, -0.04545795, ..., -0.05189452,\n           0.0215784 , -0.03356608],\n         [ 0.05173114,  0.02754072,  0.03241063, ...,  0.05668699,\n          -0.02749225, -0.06422673],\n         [ 0.06804349, -0.0539492 , -0.02078557, ...,  0.03017703,\n          -0.0204422 ,  0.06679015],\n         ...,\n         [-0.00368524,  0.0425052 ,  0.02759175, ..., -0.00398665,\n          -0.05968226, -0.02618733],\n         [-0.07207836,  0.02183909, -0.02732921, ..., -0.05292643,\n          -0.05857046, -0.00968426],\n         [ 0.0762352 ,  0.01691345,  0.01194862, ..., -0.04609174,\n          -0.01583928, -0.00638036]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization_1/moving_variance:0' shape=(144,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_887/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_899/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/conv2d/kernel:0' shape=(1, 1, 80, 480) dtype=float32, numpy=\narray([[[[ 0.13249783,  0.02318034, -0.1469356 , ..., -0.21334508,\n           0.13531697,  0.06542119],\n         [ 0.08150274,  0.094526  ,  0.16939604, ..., -0.01665658,\n          -0.24367528,  0.07418942],\n         [ 0.09712027,  0.08825405, -0.20956749, ...,  0.01624975,\n           0.06103171, -0.06181553],\n         ...,\n         [ 0.0553126 ,  0.08008792, -0.17248517, ..., -0.13454898,\n           0.01710662, -0.08034048],\n         [-0.1250034 , -0.05013902,  0.16992112, ...,  0.10233922,\n           0.03171736,  0.10239489],\n         [ 0.01610618, -0.03048126, -0.10421265, ..., -0.04390194,\n           0.08561885,  0.17167659]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization/moving_variance:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_890/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_247/squeeze_excitation/conv2d_3/bias:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_852/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_851/moving_variance:0' shape=(24,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_240/sync_batch_normalization_1/moving_mean:0' shape=(240,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_2/moving_mean:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_244/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 672, 1) dtype=float32, numpy=\narray([[[[-0.01272625],\n         [ 0.00728031],\n         [-0.01217502],\n         ...,\n         [-0.027579  ],\n         [ 0.01250099],\n         [-0.01037847]],\n\n        [[-0.0066451 ],\n         [ 0.02831286],\n         [-0.02853808],\n         ...,\n         [-0.01873752],\n         [ 0.00382689],\n         [-0.00273907]],\n\n        [[-0.01166499],\n         [-0.01857358],\n         [ 0.00578545],\n         ...,\n         [-0.01336968],\n         [-0.02097239],\n         [ 0.00595605]]],\n\n\n       [[[-0.0128473 ],\n         [ 0.02809521],\n         [-0.00572962],\n         ...,\n         [-0.02010335],\n         [-0.011215  ],\n         [-0.02284807]],\n\n        [[-0.00082153],\n         [ 0.01884537],\n         [ 0.00780495],\n         ...,\n         [-0.00696189],\n         [ 0.00565941],\n         [ 0.00305079]],\n\n        [[ 0.00650343],\n         [-0.01017918],\n         [ 0.00605743],\n         ...,\n         [ 0.01090154],\n         [ 0.01851295],\n         [ 0.00105348]]],\n\n\n       [[[ 0.00415246],\n         [ 0.01017713],\n         [-0.00482241],\n         ...,\n         [ 0.00561099],\n         [-0.00199022],\n         [-0.01361026]],\n\n        [[ 0.00386302],\n         [-0.00073984],\n         [-0.01768358],\n         ...,\n         [ 0.01622449],\n         [ 0.01467205],\n         [-0.00592439]],\n\n        [[ 0.00721675],\n         [ 0.00694128],\n         [ 0.00374853],\n         ...,\n         [-0.01006365],\n         [-0.01590519],\n         [ 0.00629308]]]], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_242/sync_batch_normalization_2/moving_mean:0' shape=(112,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32, numpy=\narray([[[[ 0.00273761],\n         [ 0.01840184],\n         [ 0.00101   ],\n         ...,\n         [ 0.03413397],\n         [-0.02954865],\n         [-0.02038744]],\n\n        [[-0.03126529],\n         [-0.00116317],\n         [-0.02669207],\n         ...,\n         [-0.06302322],\n         [ 0.03095977],\n         [-0.05862692]],\n\n        [[ 0.01780701],\n         [-0.00188849],\n         [ 0.00049404],\n         ...,\n         [ 0.00953829],\n         [-0.01585733],\n         [-0.03262889]]],\n\n\n       [[[ 0.00426864],\n         [-0.03473822],\n         [ 0.01711899],\n         ...,\n         [-0.03901818],\n         [-0.0070464 ],\n         [ 0.04326975]],\n\n        [[-0.03147697],\n         [-0.03441074],\n         [-0.04883455],\n         ...,\n         [ 0.01327733],\n         [-0.00314525],\n         [-0.03477336]],\n\n        [[ 0.03656965],\n         [-0.03191112],\n         [-0.01642364],\n         ...,\n         [-0.04224136],\n         [-0.02051395],\n         [-0.01923537]]],\n\n\n       [[[ 0.01101114],\n         [ 0.0202704 ],\n         [-0.02399719],\n         ...,\n         [-0.00708194],\n         [ 0.02386889],\n         [-0.01342128]],\n\n        [[-0.00869599],\n         [ 0.01933667],\n         [ 0.05174597],\n         ...,\n         [-0.02846763],\n         [ 0.04372767],\n         [ 0.00262401]],\n\n        [[ 0.04888885],\n         [-0.03226555],\n         [ 0.02704348],\n         ...,\n         [-0.00147522],\n         [-0.04485749],\n         [-0.02772819]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_373/depthwise_kernel:0' shape=(3, 3, 112, 1) dtype=float32, numpy=\narray([[[[-0.04263331],\n         [-0.06288601],\n         [ 0.00477404],\n         ...,\n         [-0.04807945],\n         [-0.03820441],\n         [ 0.07037295]],\n\n        [[-0.04663417],\n         [ 0.05784094],\n         [-0.02211667],\n         ...,\n         [ 0.03838182],\n         [-0.07275215],\n         [ 0.06997608]],\n\n        [[ 0.01055564],\n         [-0.01345254],\n         [ 0.01151282],\n         ...,\n         [ 0.05672888],\n         [-0.07261999],\n         [-0.05797169]]],\n\n\n       [[[ 0.03376754],\n         [-0.06496424],\n         [ 0.01581814],\n         ...,\n         [ 0.01900373],\n         [ 0.05719236],\n         [ 0.02423024]],\n\n        [[-0.04545081],\n         [-0.06339463],\n         [-0.00745048],\n         ...,\n         [ 0.02355675],\n         [ 0.05960526],\n         [-0.04625335]],\n\n        [[-0.04928169],\n         [-0.05738964],\n         [ 0.01630542],\n         ...,\n         [-0.0734398 ],\n         [ 0.02155813],\n         [-0.06700976]]],\n\n\n       [[[-0.04644428],\n         [-0.05793499],\n         [ 0.00464613],\n         ...,\n         [-0.00151309],\n         [-0.01399658],\n         [-0.00424643]],\n\n        [[ 0.00160737],\n         [ 0.06047013],\n         [-0.06176232],\n         ...,\n         [-0.0256828 ],\n         [ 0.01875258],\n         [ 0.06401441]],\n\n        [[ 0.04411042],\n         [ 0.03984445],\n         [ 0.02975758],\n         ...,\n         [-0.02810097],\n         [ 0.07215598],\n         [ 0.04747872]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_889/beta:0' shape=(40,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/sync_batch_normalization_1/gamma:0' shape=(96,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_2/moving_variance:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_873/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_241/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_878/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_896/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_352/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[ 0.10001469],\n         [ 0.13312617],\n         [-0.10059712],\n         [-0.0840577 ],\n         [ 0.15206873],\n         [-0.02083839],\n         [-0.05155053],\n         [ 0.11020508],\n         [ 0.04702321],\n         [-0.14137912],\n         [-0.1479309 ],\n         [ 0.0529359 ],\n         [-0.15588734],\n         [-0.10804333],\n         [ 0.00547558],\n         [ 0.12429106],\n         [ 0.09541672],\n         [ 0.11415061],\n         [ 0.15873662],\n         [ 0.06989884],\n         [-0.07574955],\n         [ 0.02112775],\n         [-0.04514755],\n         [-0.096457  ]],\n\n        [[-0.11175588],\n         [-0.10096493],\n         [-0.04420754],\n         [ 0.09282717],\n         [ 0.09311378],\n         [ 0.00801577],\n         [-0.01964749],\n         [ 0.15509629],\n         [ 0.10698187],\n         [-0.09048147],\n         [ 0.1383042 ],\n         [-0.14744654],\n         [ 0.09268925],\n         [ 0.00713992],\n         [ 0.14048791],\n         [-0.14807212],\n         [ 0.09999919],\n         [ 0.14294553],\n         [ 0.05660161],\n         [-0.1587643 ],\n         [ 0.10146621],\n         [-0.08437513],\n         [-0.15285765],\n         [ 0.12299672]],\n\n        [[ 0.05398941],\n         [-0.07741972],\n         [ 0.08774626],\n         [-0.03212458],\n         [-0.08111857],\n         [ 0.11453387],\n         [-0.04332289],\n         [-0.06567338],\n         [-0.11189935],\n         [-0.13045798],\n         [ 0.05246216],\n         [ 0.07704316],\n         [ 0.00615275],\n         [ 0.15890399],\n         [ 0.06699404],\n         [-0.10015266],\n         [ 0.14846304],\n         [-0.05691737],\n         [-0.10016005],\n         [ 0.11074159],\n         [-0.0517714 ],\n         [-0.04316311],\n         [ 0.04376271],\n         [ 0.05692628]]],\n\n\n       [[[-0.12783639],\n         [-0.10170139],\n         [ 0.05655801],\n         [-0.14350346],\n         [ 0.12432042],\n         [-0.03622015],\n         [-0.15380968],\n         [ 0.04874548],\n         [-0.06748558],\n         [ 0.09952906],\n         [ 0.04137835],\n         [-0.11922128],\n         [-0.08485452],\n         [-0.11527473],\n         [ 0.15233809],\n         [-0.03582931],\n         [ 0.0767682 ],\n         [-0.02584696],\n         [-0.09713982],\n         [ 0.13235423],\n         [-0.01523331],\n         [-0.02064836],\n         [ 0.07878618],\n         [-0.11750065]],\n\n        [[ 0.15693933],\n         [-0.14667861],\n         [-0.01683559],\n         [-0.06964134],\n         [-0.04093365],\n         [-0.15532312],\n         [-0.10566639],\n         [ 0.00439276],\n         [ 0.09001011],\n         [ 0.03539565],\n         [ 0.08309819],\n         [-0.11804089],\n         [-0.03537281],\n         [ 0.15246367],\n         [ 0.07489519],\n         [ 0.00810347],\n         [ 0.04117543],\n         [-0.06719658],\n         [-0.10137074],\n         [ 0.08326864],\n         [-0.14270668],\n         [-0.15749429],\n         [ 0.02940795],\n         [-0.16020153]],\n\n        [[-0.138672  ],\n         [ 0.09224272],\n         [-0.12069394],\n         [-0.03783582],\n         [-0.03645808],\n         [ 0.09374353],\n         [ 0.08863407],\n         [-0.07007342],\n         [ 0.00406517],\n         [ 0.13580924],\n         [ 0.00430785],\n         [-0.08296581],\n         [-0.08947582],\n         [ 0.11991331],\n         [ 0.10833943],\n         [-0.04485465],\n         [ 0.09659362],\n         [ 0.13178083],\n         [-0.10084346],\n         [ 0.02697369],\n         [ 0.04423881],\n         [-0.0880885 ],\n         [-0.1458118 ],\n         [-0.1355086 ]]],\n\n\n       [[[ 0.0764813 ],\n         [ 0.00084466],\n         [ 0.1470544 ],\n         [ 0.03860888],\n         [ 0.09628525],\n         [-0.1228219 ],\n         [-0.00537167],\n         [-0.0010125 ],\n         [ 0.09705555],\n         [-0.10845147],\n         [-0.10109757],\n         [ 0.01278307],\n         [-0.08098249],\n         [ 0.09342444],\n         [-0.043586  ],\n         [-0.06804086],\n         [ 0.0301805 ],\n         [ 0.03195545],\n         [-0.04866224],\n         [-0.04038659],\n         [-0.10356363],\n         [ 0.14262527],\n         [-0.04422198],\n         [ 0.0871256 ]],\n\n        [[ 0.10301226],\n         [ 0.06864262],\n         [ 0.09682655],\n         [-0.01638652],\n         [-0.00502971],\n         [ 0.02334718],\n         [-0.05787011],\n         [-0.05860911],\n         [-0.10093546],\n         [ 0.0394312 ],\n         [-0.01531971],\n         [-0.06164613],\n         [-0.09779137],\n         [-0.00999573],\n         [ 0.12439638],\n         [-0.14875735],\n         [ 0.07475911],\n         [ 0.00815199],\n         [ 0.14240155],\n         [-0.02571942],\n         [ 0.02418785],\n         [ 0.09044281],\n         [-0.1175582 ],\n         [-0.09185926]],\n\n        [[-0.09505134],\n         [ 0.03327794],\n         [ 0.14172608],\n         [ 0.05927561],\n         [-0.15562664],\n         [ 0.06807913],\n         [ 0.02597198],\n         [-0.15241863],\n         [ 0.13160947],\n         [ 0.14953697],\n         [-0.14661382],\n         [ 0.13706541],\n         [-0.08536934],\n         [-0.04065181],\n         [-0.04539762],\n         [-0.10432474],\n         [-0.09098157],\n         [-0.03015107],\n         [ 0.08694902],\n         [-0.10212013],\n         [ 0.00323857],\n         [ 0.0143093 ],\n         [ 0.14501524],\n         [ 0.15223223]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/moving_variance:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_895/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization_1/gamma:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_236/depthwise_conv2d/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32, numpy=\narray([[[[-1.90160889e-02],\n         [ 8.55769869e-03],\n         [ 7.40848249e-03],\n         [-2.57769898e-02],\n         [-8.13578907e-03],\n         [ 4.95368242e-02],\n         [-2.97863968e-02],\n         [-5.42707406e-02],\n         [ 5.83589189e-02],\n         [-3.51196043e-02],\n         [ 3.67196612e-02],\n         [ 2.20721811e-02],\n         [-1.73089001e-02],\n         [ 3.81607525e-02],\n         [ 2.25758459e-02],\n         [ 9.88030992e-03],\n         [-1.72919910e-02],\n         [-3.60557698e-02],\n         [ 5.29062189e-03],\n         [ 3.98513526e-02],\n         [ 5.33022843e-02],\n         [ 6.36270195e-02],\n         [ 4.85002287e-02],\n         [-7.95493601e-04],\n         [ 2.21737735e-02],\n         [-2.58481465e-02],\n         [ 5.59286075e-03],\n         [ 2.51820702e-02],\n         [ 7.62233511e-02],\n         [ 2.08746344e-02],\n         [-3.49819520e-03],\n         [-1.65728629e-02],\n         [-6.16216324e-02],\n         [-2.43379399e-02],\n         [ 4.15821970e-02],\n         [ 6.39693514e-02],\n         [ 5.13687842e-02],\n         [-1.97514184e-02],\n         [ 1.02070663e-02],\n         [-7.61961341e-02],\n         [ 1.27179129e-02],\n         [-3.63764428e-02],\n         [ 2.18997691e-02],\n         [-5.46428338e-02],\n         [ 3.82360481e-02],\n         [-6.28425507e-03],\n         [-5.72638810e-02],\n         [ 6.90188631e-02],\n         [-2.40503587e-02],\n         [ 4.62326966e-03],\n         [-3.29692513e-02],\n         [ 3.23206298e-02],\n         [ 8.83722678e-04],\n         [-8.41705222e-03],\n         [-3.99606526e-02],\n         [-6.34750957e-03],\n         [-1.58585738e-02],\n         [-5.50634563e-02],\n         [ 5.30995317e-02],\n         [-1.28836920e-02],\n         [ 9.30537470e-03],\n         [ 2.09804229e-03],\n         [-1.93841681e-02],\n         [ 1.05347782e-02],\n         [ 1.11155827e-02],\n         [ 1.08445976e-02],\n         [ 3.60366516e-02],\n         [-5.78090083e-03],\n         [-2.81825718e-02],\n         [-2.33819038e-02],\n         [-1.38428351e-02],\n         [-4.12552245e-02],\n         [-2.40287231e-03],\n         [-1.84646677e-02],\n         [ 1.22904507e-02],\n         [ 1.01066642e-02],\n         [-2.47031040e-02],\n         [ 2.50838269e-02],\n         [-6.12689331e-02],\n         [-2.15557180e-02],\n         [-7.14254230e-02],\n         [-6.04167720e-03],\n         [-2.48565488e-02],\n         [ 4.50144745e-02],\n         [-5.07047167e-04],\n         [-5.17293848e-02],\n         [ 2.43586348e-03],\n         [ 4.10685092e-02],\n         [ 2.12247614e-02],\n         [ 5.87182976e-02],\n         [ 1.75710134e-02],\n         [ 2.07354277e-02],\n         [ 3.40621993e-02],\n         [-3.07670422e-02],\n         [-3.18118371e-02],\n         [ 7.58629814e-02]],\n\n        [[ 2.86841504e-02],\n         [-2.90753748e-02],\n         [-1.42791783e-02],\n         [-1.68650951e-02],\n         [-3.34790535e-02],\n         [-7.30769560e-02],\n         [-2.68030539e-02],\n         [-2.50302125e-02],\n         [ 3.29320505e-02],\n         [-4.12235931e-02],\n         [ 6.47536665e-02],\n         [ 1.28947559e-03],\n         [ 7.37283230e-02],\n         [-3.77494097e-02],\n         [ 9.20705206e-04],\n         [-3.54500264e-02],\n         [-1.45461299e-02],\n         [-1.19312601e-02],\n         [ 1.35813914e-02],\n         [-3.44959833e-02],\n         [-4.54218015e-02],\n         [ 6.48302399e-03],\n         [-3.09914420e-03],\n         [ 4.10082899e-02],\n         [ 2.12972742e-02],\n         [-8.24617688e-03],\n         [ 1.34761585e-02],\n         [-7.67567893e-03],\n         [ 2.13364623e-02],\n         [ 1.93197583e-03],\n         [ 5.43924384e-02],\n         [ 1.37227057e-02],\n         [ 5.92507683e-02],\n         [-3.05025559e-02],\n         [ 2.62016691e-02],\n         [ 3.02824434e-02],\n         [ 1.97384413e-02],\n         [ 2.61941403e-02],\n         [ 2.94937622e-02],\n         [-2.90962961e-02],\n         [-1.31109320e-02],\n         [-7.49762058e-02],\n         [-4.10516839e-03],\n         [-4.37277332e-02],\n         [ 5.34159429e-02],\n         [-5.68089895e-02],\n         [ 1.47542451e-02],\n         [-4.15044837e-02],\n         [-7.65726268e-02],\n         [-4.73236479e-02],\n         [ 2.94470717e-03],\n         [-1.71788596e-02],\n         [ 4.39810827e-02],\n         [-4.03269082e-02],\n         [ 8.02136119e-03],\n         [ 4.82406989e-02],\n         [-1.82129294e-02],\n         [-2.97666881e-02],\n         [-4.25536893e-02],\n         [ 6.04979023e-02],\n         [ 3.35657783e-02],\n         [-1.33670690e-02],\n         [-1.22372331e-02],\n         [-2.02408787e-02],\n         [ 6.53217360e-02],\n         [-6.83558881e-02],\n         [ 4.01681960e-02],\n         [ 3.35166976e-02],\n         [ 3.00301351e-02],\n         [-1.89380590e-02],\n         [ 3.87645094e-03],\n         [-1.97119974e-02],\n         [ 1.04216486e-02],\n         [-4.26318496e-02],\n         [ 3.41201983e-02],\n         [ 7.13122264e-02],\n         [ 2.44827699e-02],\n         [ 7.34582990e-02],\n         [-6.37584424e-04],\n         [-6.93784282e-02],\n         [-6.25360943e-03],\n         [-3.82769071e-02],\n         [ 7.26265684e-02],\n         [ 2.31881142e-02],\n         [-1.45788128e-02],\n         [-3.99686843e-02],\n         [-3.75398062e-02],\n         [ 5.28801680e-02],\n         [ 2.03776583e-02],\n         [-6.08669966e-02],\n         [ 5.80535047e-02],\n         [ 9.90150124e-03],\n         [-1.22612445e-02],\n         [-2.12487788e-03],\n         [-6.13570679e-03],\n         [ 1.28253167e-02]],\n\n        [[ 1.78321991e-02],\n         [ 3.52540263e-03],\n         [ 8.69328529e-03],\n         [ 5.51350340e-02],\n         [-1.66669693e-02],\n         [-9.05857701e-03],\n         [-4.19413624e-03],\n         [ 2.45327484e-02],\n         [ 4.02850695e-02],\n         [ 3.66112334e-03],\n         [-3.10312118e-02],\n         [-1.79302786e-02],\n         [ 2.75723431e-02],\n         [-6.43176660e-02],\n         [-2.88273860e-03],\n         [-6.10434338e-02],\n         [ 3.04565940e-04],\n         [-3.06480639e-02],\n         [ 3.88599187e-02],\n         [ 5.06903790e-02],\n         [ 1.03382682e-02],\n         [ 2.36488190e-02],\n         [-6.06590556e-03],\n         [-3.16828154e-02],\n         [ 3.57676484e-02],\n         [-5.13529181e-02],\n         [-3.35097965e-03],\n         [-2.34881770e-02],\n         [ 1.06381942e-02],\n         [ 2.10531224e-02],\n         [-5.78047335e-03],\n         [ 1.32255554e-02],\n         [ 4.16406542e-02],\n         [ 2.08775289e-02],\n         [ 2.24578083e-02],\n         [-3.14511284e-02],\n         [-1.43834874e-02],\n         [-4.88085076e-02],\n         [-7.12350830e-02],\n         [-4.14953940e-02],\n         [-3.08229658e-03],\n         [ 3.93391885e-02],\n         [-6.54832721e-02],\n         [-1.33407849e-03],\n         [ 6.23984151e-02],\n         [ 2.61615124e-02],\n         [-1.31307133e-02],\n         [-1.50887929e-02],\n         [ 1.52213611e-02],\n         [-2.41810903e-02],\n         [ 2.77113784e-02],\n         [ 2.50880551e-02],\n         [-1.17928656e-02],\n         [-4.20650356e-02],\n         [-1.07062813e-02],\n         [-6.51940405e-02],\n         [ 3.41940895e-02],\n         [-1.63996238e-02],\n         [-2.32980177e-02],\n         [ 3.29232849e-02],\n         [-8.85374751e-03],\n         [ 3.85922119e-02],\n         [-3.52485701e-02],\n         [ 2.44478825e-02],\n         [-1.32598449e-02],\n         [ 1.24570075e-02],\n         [-1.68649759e-02],\n         [-2.37990972e-02],\n         [ 4.80658635e-02],\n         [-2.06871852e-02],\n         [-3.64925899e-02],\n         [-4.18528877e-02],\n         [-4.08642143e-02],\n         [-4.44239518e-03],\n         [ 2.18017735e-02],\n         [ 4.11264002e-02],\n         [ 1.07586952e-02],\n         [-6.25929087e-02],\n         [-1.52672930e-02],\n         [ 1.18325092e-02],\n         [-4.81702201e-02],\n         [-6.55871704e-02],\n         [-2.69706286e-02],\n         [-5.61708659e-02],\n         [ 1.89562719e-02],\n         [ 4.14320081e-02],\n         [-6.60058334e-02],\n         [-4.98724431e-02],\n         [-3.36601697e-02],\n         [ 1.34921949e-02],\n         [-3.34772691e-02],\n         [-1.11695761e-02],\n         [-2.40365509e-02],\n         [ 5.01842946e-02],\n         [-4.98277992e-02],\n         [ 9.67855845e-03]]],\n\n\n       [[[-4.64680139e-03],\n         [-1.91865284e-02],\n         [-3.99850458e-02],\n         [-5.87839866e-04],\n         [-3.54266502e-02],\n         [ 5.48285395e-02],\n         [ 4.90917340e-02],\n         [ 1.41928615e-02],\n         [ 3.41797806e-02],\n         [-8.72857345e-04],\n         [-6.58218041e-02],\n         [-3.75170335e-02],\n         [-2.62529701e-02],\n         [-9.77869891e-03],\n         [-5.11245504e-02],\n         [ 3.84107605e-02],\n         [-5.34661040e-02],\n         [ 3.89951952e-02],\n         [ 7.43405148e-02],\n         [-4.82621370e-03],\n         [ 4.16626520e-02],\n         [ 3.83932702e-02],\n         [ 3.54097076e-02],\n         [ 5.22870645e-02],\n         [ 4.62999418e-02],\n         [ 1.05635673e-02],\n         [-1.58611126e-02],\n         [ 4.64394353e-02],\n         [-5.10240300e-03],\n         [-1.60327461e-02],\n         [-2.50356775e-02],\n         [-1.60772111e-02],\n         [ 1.23649277e-03],\n         [ 4.06242087e-02],\n         [-6.39205948e-02],\n         [-3.28747705e-02],\n         [-1.69761237e-02],\n         [ 3.26623432e-02],\n         [ 3.53783965e-02],\n         [-4.04498465e-02],\n         [ 1.03932517e-02],\n         [-1.35556208e-02],\n         [-4.81741615e-02],\n         [ 2.86245323e-03],\n         [-2.69097299e-03],\n         [ 2.89227925e-02],\n         [-2.93226354e-02],\n         [ 2.15702970e-02],\n         [-4.49868385e-03],\n         [ 1.20356455e-02],\n         [-4.08714563e-02],\n         [ 3.31743434e-02],\n         [-5.18817315e-03],\n         [ 2.42372621e-02],\n         [ 2.65531838e-02],\n         [-9.19512566e-03],\n         [-2.84051476e-03],\n         [ 1.65928621e-02],\n         [ 1.21588707e-02],\n         [-4.61118761e-03],\n         [ 2.41015088e-02],\n         [-8.43095500e-03],\n         [ 1.47917762e-03],\n         [ 1.08291553e-02],\n         [ 5.81129678e-02],\n         [ 4.13350500e-02],\n         [-2.56471825e-03],\n         [ 7.21534118e-02],\n         [ 6.96794922e-03],\n         [ 3.47403390e-03],\n         [ 3.62009145e-02],\n         [-4.63912785e-02],\n         [-3.15381326e-02],\n         [ 1.03032095e-02],\n         [-4.83709499e-02],\n         [ 4.81650345e-02],\n         [ 3.32553163e-02],\n         [-7.05641881e-03],\n         [-2.76282672e-02],\n         [-1.90628767e-02],\n         [-3.56937572e-02],\n         [-5.38310260e-02],\n         [ 5.00832684e-02],\n         [-2.71977810e-03],\n         [-1.42642995e-02],\n         [ 2.00925227e-02],\n         [ 5.20729944e-02],\n         [-7.02719986e-02],\n         [-9.84746683e-03],\n         [-4.33089025e-02],\n         [-3.70783806e-02],\n         [-1.95435341e-03],\n         [-5.50831743e-02],\n         [ 1.93897057e-02],\n         [-2.73871876e-04],\n         [ 2.90807392e-02]],\n\n        [[-6.74395263e-02],\n         [ 4.32557203e-02],\n         [ 1.94679629e-02],\n         [ 1.38694318e-02],\n         [-3.02368961e-02],\n         [-3.89602520e-02],\n         [ 1.02418754e-02],\n         [-1.25367567e-03],\n         [ 1.96299180e-02],\n         [ 3.93325426e-02],\n         [ 1.10083465e-02],\n         [ 2.40730140e-02],\n         [ 8.18834174e-03],\n         [-2.28850432e-02],\n         [ 8.12405348e-03],\n         [ 1.79094542e-02],\n         [ 4.31548171e-02],\n         [-4.68930565e-02],\n         [ 9.19088628e-03],\n         [-5.05662896e-02],\n         [ 1.66500546e-02],\n         [-1.60634462e-02],\n         [-6.83423318e-03],\n         [-3.87573354e-02],\n         [ 2.43681762e-03],\n         [ 2.42828391e-02],\n         [ 8.33588373e-03],\n         [-1.88937166e-03],\n         [-4.78344448e-02],\n         [ 1.81965530e-02],\n         [-6.88301474e-02],\n         [-4.47501764e-02],\n         [ 2.51650028e-02],\n         [ 7.39559829e-02],\n         [-3.35531048e-02],\n         [-2.98859123e-02],\n         [ 2.12868042e-02],\n         [-2.35810112e-02],\n         [ 7.38676861e-02],\n         [ 9.60389432e-03],\n         [-8.34713131e-03],\n         [ 3.15413438e-02],\n         [-7.29163736e-02],\n         [-4.23950776e-02],\n         [-1.14294840e-02],\n         [-4.59900200e-02],\n         [-3.70372236e-02],\n         [ 1.38172572e-02],\n         [ 3.21126543e-02],\n         [-6.51196763e-03],\n         [-1.85906719e-02],\n         [ 2.43448615e-02],\n         [-8.59650597e-03],\n         [-4.25778553e-02],\n         [ 4.63605113e-02],\n         [-1.34887930e-03],\n         [-3.80540569e-03],\n         [-2.94191241e-02],\n         [-5.56971990e-02],\n         [ 3.11283059e-02],\n         [-5.89338178e-03],\n         [-1.88801754e-02],\n         [ 5.56643717e-02],\n         [-5.57514206e-02],\n         [-6.38994295e-03],\n         [ 3.25407237e-02],\n         [-5.25850430e-02],\n         [-9.33761057e-03],\n         [-2.09331177e-02],\n         [-2.79502720e-02],\n         [ 4.27337065e-02],\n         [ 7.46503007e-03],\n         [-2.12693792e-02],\n         [ 2.87652463e-02],\n         [ 4.72236723e-02],\n         [ 6.55288901e-03],\n         [-7.00667426e-02],\n         [ 4.98267300e-02],\n         [ 4.71049827e-03],\n         [-3.96759761e-03],\n         [ 2.63300957e-03],\n         [-3.52290235e-02],\n         [ 7.62251467e-02],\n         [-4.11124229e-02],\n         [ 1.02957794e-02],\n         [-1.16070807e-02],\n         [-7.51058850e-03],\n         [ 6.47347420e-02],\n         [-3.83506995e-03],\n         [ 6.78133890e-02],\n         [ 7.71264965e-03],\n         [ 4.10412773e-02],\n         [-1.00502521e-02],\n         [-3.81018594e-02],\n         [-1.73107032e-02],\n         [ 2.35231695e-04]],\n\n        [[-2.06546541e-02],\n         [-4.05387394e-02],\n         [-6.36429293e-04],\n         [-2.48058159e-02],\n         [ 3.93921211e-02],\n         [-1.64525229e-02],\n         [ 7.79196806e-03],\n         [ 2.15941612e-02],\n         [ 3.55941802e-02],\n         [ 1.44613907e-02],\n         [-1.09461127e-02],\n         [-2.54917797e-02],\n         [ 8.22267123e-03],\n         [ 1.57667901e-02],\n         [ 1.44752637e-02],\n         [ 2.23349705e-02],\n         [-1.89722665e-02],\n         [ 6.37795450e-03],\n         [-4.54066843e-02],\n         [ 2.61826552e-02],\n         [ 1.34759005e-02],\n         [-1.84010845e-02],\n         [-3.08709797e-02],\n         [-5.64446300e-02],\n         [ 3.84760350e-02],\n         [ 9.87800490e-03],\n         [ 1.29271932e-02],\n         [-1.55530013e-02],\n         [-2.79720202e-02],\n         [ 3.90259437e-02],\n         [ 3.06299850e-02],\n         [ 1.65673569e-02],\n         [ 2.13436764e-02],\n         [-1.01100300e-02],\n         [ 2.37435885e-02],\n         [ 1.41908992e-02],\n         [ 2.78286356e-02],\n         [-5.78923500e-04],\n         [ 5.55674965e-03],\n         [-6.27913186e-03],\n         [ 6.37861639e-02],\n         [-3.20162647e-03],\n         [ 3.09657641e-02],\n         [-3.52709182e-02],\n         [-4.55339737e-02],\n         [ 6.42167404e-02],\n         [ 4.14626822e-02],\n         [-6.60510287e-02],\n         [ 8.82186182e-03],\n         [ 3.83737287e-03],\n         [-5.67292683e-02],\n         [ 2.93677635e-02],\n         [ 1.40585089e-02],\n         [-4.11898345e-02],\n         [-2.76859794e-02],\n         [-1.62277948e-02],\n         [ 1.66427679e-02],\n         [-4.81642485e-02],\n         [-2.58113090e-02],\n         [ 2.12432761e-02],\n         [ 7.71180615e-02],\n         [-2.19570436e-02],\n         [-1.30429771e-02],\n         [ 3.58745903e-02],\n         [-7.77779007e-03],\n         [-2.78367326e-02],\n         [ 4.28582216e-03],\n         [ 5.82197532e-02],\n         [ 1.22893229e-02],\n         [-2.56866310e-02],\n         [-3.34948935e-02],\n         [-4.86595090e-03],\n         [-4.89291698e-02],\n         [ 2.93815206e-03],\n         [-1.32133695e-03],\n         [ 9.30861011e-03],\n         [-2.66279485e-02],\n         [ 1.78464856e-02],\n         [ 8.67902674e-03],\n         [-4.10268158e-02],\n         [ 3.09227896e-03],\n         [-2.98239440e-02],\n         [ 1.38280243e-02],\n         [ 2.18158471e-03],\n         [ 1.91902462e-03],\n         [-4.53047752e-02],\n         [ 2.33070999e-02],\n         [ 3.57807763e-02],\n         [-1.18171070e-02],\n         [-2.12659650e-02],\n         [-7.57923201e-02],\n         [ 3.11290268e-02],\n         [ 1.92667656e-02],\n         [ 6.86241686e-02],\n         [-4.68439143e-03],\n         [-6.04944527e-02]]],\n\n\n       [[[-3.41465659e-02],\n         [ 5.81638254e-02],\n         [ 1.56380925e-02],\n         [-4.25218679e-02],\n         [ 5.37979370e-03],\n         [ 1.60052981e-02],\n         [-5.82351089e-02],\n         [ 6.57215863e-02],\n         [-1.13178901e-02],\n         [-2.88999341e-02],\n         [-6.28021732e-02],\n         [ 3.29784453e-02],\n         [ 5.43721095e-02],\n         [ 2.54591610e-02],\n         [-3.21672820e-02],\n         [ 5.53741939e-02],\n         [ 9.81798396e-03],\n         [ 3.46757285e-02],\n         [ 3.66533324e-02],\n         [ 3.15880626e-02],\n         [ 7.01450557e-02],\n         [-6.43768162e-02],\n         [-2.48144064e-02],\n         [ 1.67769790e-02],\n         [ 4.55061346e-02],\n         [-5.07331314e-03],\n         [-1.75252501e-02],\n         [-1.59028824e-02],\n         [ 1.13984076e-02],\n         [ 4.06104922e-02],\n         [-6.69032708e-02],\n         [-5.58005348e-02],\n         [-2.88016107e-02],\n         [-4.96260673e-02],\n         [-3.39032039e-02],\n         [ 5.62938675e-03],\n         [ 4.66414578e-02],\n         [ 5.90855964e-02],\n         [ 5.44242226e-02],\n         [ 2.20182557e-02],\n         [-3.43444990e-03],\n         [ 2.90858727e-02],\n         [ 5.94939431e-03],\n         [-2.86477674e-02],\n         [-3.08004990e-02],\n         [-2.47117653e-02],\n         [-4.63868231e-02],\n         [ 7.17238784e-02],\n         [ 1.71008836e-02],\n         [-4.71023470e-02],\n         [-4.42099161e-02],\n         [ 1.19843511e-02],\n         [ 6.47959858e-02],\n         [-3.29784416e-02],\n         [-7.45706772e-03],\n         [-2.95829382e-02],\n         [-2.45215856e-02],\n         [ 4.37009074e-02],\n         [-3.24823521e-03],\n         [-2.67674327e-02],\n         [-1.08348038e-02],\n         [-9.31677781e-03],\n         [-2.88844872e-02],\n         [ 1.33068049e-02],\n         [-3.11212689e-02],\n         [-3.12990695e-02],\n         [-5.04442025e-04],\n         [ 2.57508047e-02],\n         [-3.94091681e-02],\n         [-6.17339015e-02],\n         [ 4.90235910e-02],\n         [-1.21262120e-02],\n         [ 4.22374792e-02],\n         [ 4.33656387e-02],\n         [-3.88936885e-02],\n         [-1.06513966e-02],\n         [-1.76367145e-02],\n         [-3.03303972e-02],\n         [ 1.84642561e-02],\n         [-6.80963099e-02],\n         [-2.75295936e-02],\n         [-3.93952755e-03],\n         [ 1.29523044e-02],\n         [ 3.19160782e-02],\n         [-4.56807017e-02],\n         [ 1.50446594e-02],\n         [ 2.22309362e-02],\n         [-4.81259525e-02],\n         [ 1.13944318e-02],\n         [-7.22853541e-02],\n         [-2.72589419e-02],\n         [ 1.10309981e-02],\n         [ 5.54347336e-02],\n         [-8.10986571e-03],\n         [ 2.04334650e-02],\n         [ 2.21726410e-02]],\n\n        [[ 1.97344963e-02],\n         [ 3.34124155e-02],\n         [-3.41649167e-02],\n         [ 7.55426884e-02],\n         [-1.34485746e-02],\n         [-1.51635744e-02],\n         [-3.00866384e-02],\n         [-6.88824654e-02],\n         [ 4.37152311e-02],\n         [-5.35400212e-02],\n         [ 1.92199938e-03],\n         [-3.85545641e-02],\n         [ 1.57548990e-02],\n         [-2.57950258e-02],\n         [-5.36139421e-02],\n         [-5.46980090e-02],\n         [ 7.39246316e-04],\n         [ 2.41459347e-03],\n         [-7.41394311e-02],\n         [ 1.49446102e-02],\n         [ 2.38039414e-03],\n         [-4.62909378e-02],\n         [-3.22352946e-02],\n         [ 4.58682664e-02],\n         [ 1.51627911e-02],\n         [-5.31959571e-02],\n         [ 4.84510027e-02],\n         [-8.54962133e-03],\n         [ 2.98969522e-02],\n         [ 1.64800901e-02],\n         [ 7.50461295e-02],\n         [ 3.26598622e-03],\n         [ 3.09518464e-02],\n         [ 2.26831678e-02],\n         [-2.00685468e-02],\n         [-3.74395847e-02],\n         [-5.02397232e-02],\n         [ 5.43880882e-03],\n         [ 3.20787504e-02],\n         [-3.10423169e-02],\n         [-5.80419712e-02],\n         [-6.11436963e-02],\n         [-5.78401759e-02],\n         [-7.58594414e-03],\n         [ 4.02283929e-02],\n         [ 2.67925840e-02],\n         [-3.57044004e-02],\n         [-1.77380107e-02],\n         [-6.91286477e-05],\n         [-1.28558958e-02],\n         [ 4.72057238e-03],\n         [ 5.82720786e-02],\n         [-2.31368910e-03],\n         [ 6.48346916e-03],\n         [-2.45214216e-02],\n         [-1.68843176e-02],\n         [-4.50990163e-02],\n         [ 1.57752354e-02],\n         [-1.87138673e-02],\n         [-1.33384662e-02],\n         [ 5.75799495e-03],\n         [-1.15012228e-02],\n         [-2.13075746e-02],\n         [-1.59209203e-02],\n         [-3.75638716e-03],\n         [-1.38817811e-02],\n         [ 3.01352013e-02],\n         [-9.30990186e-03],\n         [-5.95276069e-04],\n         [ 4.41431776e-02],\n         [ 1.77764334e-02],\n         [ 1.06397877e-02],\n         [-4.87470925e-02],\n         [ 6.56936467e-02],\n         [-1.34581001e-02],\n         [-5.13215847e-02],\n         [ 2.46132202e-02],\n         [ 1.25330370e-02],\n         [ 3.60654742e-02],\n         [ 4.65048151e-03],\n         [ 1.26185296e-02],\n         [-2.38201767e-02],\n         [ 1.16250257e-03],\n         [-1.94289126e-02],\n         [ 6.59322441e-02],\n         [-2.35691555e-02],\n         [-5.02180122e-02],\n         [-5.74936206e-03],\n         [-2.66437884e-02],\n         [-5.63602836e-04],\n         [-2.21516155e-02],\n         [-1.99179891e-02],\n         [-6.03596531e-02],\n         [ 1.84425469e-02],\n         [ 3.49337831e-02],\n         [ 3.97745073e-02]],\n\n        [[ 2.85815615e-02],\n         [ 2.44856812e-02],\n         [-1.54120205e-02],\n         [ 5.79418913e-02],\n         [ 2.56738868e-02],\n         [-1.81693025e-02],\n         [-9.73844528e-03],\n         [-1.73406042e-02],\n         [-3.53817479e-03],\n         [ 4.20774817e-02],\n         [ 2.33705249e-02],\n         [ 1.07041504e-02],\n         [-9.59975459e-03],\n         [-5.45060188e-02],\n         [ 4.00467729e-03],\n         [-4.34475020e-02],\n         [ 5.36432266e-02],\n         [ 5.89255951e-02],\n         [-1.29372543e-02],\n         [-4.00446691e-02],\n         [-4.62214870e-04],\n         [-1.11353640e-02],\n         [-1.04453731e-02],\n         [ 2.89717573e-03],\n         [-6.44698292e-02],\n         [-7.59332394e-03],\n         [-8.54592770e-03],\n         [ 1.50192585e-02],\n         [-4.32775840e-02],\n         [ 5.03191613e-02],\n         [ 1.44195631e-02],\n         [-1.84308086e-02],\n         [ 5.44398930e-03],\n         [ 5.10232635e-02],\n         [-3.08292601e-02],\n         [-2.55938247e-03],\n         [ 3.02674482e-03],\n         [-3.78650427e-02],\n         [ 3.64730433e-02],\n         [ 5.53104356e-02],\n         [ 5.60677908e-02],\n         [-3.41725908e-02],\n         [-2.39204541e-02],\n         [-5.17999679e-02],\n         [-2.22356506e-02],\n         [ 2.10858379e-02],\n         [ 2.44526491e-02],\n         [-1.97184142e-02],\n         [-7.24752396e-02],\n         [-2.36421339e-02],\n         [ 5.70698008e-02],\n         [ 8.17507133e-03],\n         [ 4.20638872e-03],\n         [-1.52752139e-02],\n         [ 4.60575037e-02],\n         [ 2.75822226e-02],\n         [-5.43203689e-02],\n         [-4.19757217e-02],\n         [ 1.30052445e-02],\n         [-3.48091982e-02],\n         [-2.14055795e-02],\n         [ 7.56405219e-02],\n         [-6.59000352e-02],\n         [ 1.51229417e-02],\n         [ 6.39136136e-02],\n         [-1.55721344e-02],\n         [ 5.41127007e-03],\n         [ 3.42050823e-03],\n         [ 2.36518234e-02],\n         [ 7.56104589e-02],\n         [-4.93267775e-02],\n         [-1.66745856e-02],\n         [ 1.90046653e-02],\n         [-2.80911904e-02],\n         [ 8.18926934e-03],\n         [ 6.37791604e-02],\n         [ 8.76459200e-03],\n         [-4.53863330e-02],\n         [ 2.36270893e-02],\n         [-4.82450984e-02],\n         [ 2.53257584e-02],\n         [-5.70374429e-02],\n         [-7.23257139e-02],\n         [ 5.51828146e-02],\n         [-3.17415893e-02],\n         [ 1.58346016e-02],\n         [ 1.78072024e-02],\n         [-5.49448505e-02],\n         [ 5.24226483e-03],\n         [-1.70902368e-02],\n         [-2.16505975e-02],\n         [ 9.50210914e-03],\n         [-1.80623569e-02],\n         [ 2.51439703e-03],\n         [ 8.21074354e-04],\n         [ 1.93892773e-02]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_858/beta:0' shape=(24,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_246/squeeze_excitation/conv2d_2/bias:0' shape=(22,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/squeeze_excitation/conv2d_2/kernel:0' shape=(1, 1, 672, 22) dtype=float32, numpy=\narray([[[[ 0.08582504, -0.03154688, -0.02472441, ...,  0.05114538,\n           0.02134192,  0.08217423],\n         [-0.02687356, -0.03523573, -0.02748936, ...,  0.00829158,\n          -0.00424485, -0.05202765],\n         [-0.02399553,  0.01546687, -0.01261965, ..., -0.02033881,\n          -0.01851904, -0.01318672],\n         ...,\n         [ 0.04365416,  0.00028961, -0.0380946 , ...,  0.03771873,\n          -0.00818539,  0.00801078],\n         [ 0.05301303,  0.00112985,  0.01298863, ..., -0.06383356,\n          -0.07071722,  0.07320289],\n         [ 0.03127687,  0.03877531,  0.07543416, ...,  0.05840112,\n          -0.05934082, -0.03483654]]]], dtype=float32)>, <tf.Variable 'depthwise_conv2d_362/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 4.28269953e-02],\n         [ 8.46724361e-02],\n         [ 5.39221615e-03],\n         [-8.17120820e-03],\n         [ 2.07749680e-02],\n         [ 5.07356673e-02],\n         [ 4.58774865e-02],\n         [-8.47737864e-02],\n         [-1.13191381e-02],\n         [-4.20750156e-02],\n         [-7.80195445e-02],\n         [-1.50079727e-02],\n         [-7.85644650e-02],\n         [ 8.66185874e-02],\n         [-3.74215618e-02],\n         [-1.83688924e-02],\n         [-3.13784629e-02],\n         [-8.08448717e-02],\n         [ 2.97465846e-02],\n         [ 3.77123356e-02],\n         [ 8.81125182e-02],\n         [ 5.50087690e-02],\n         [ 3.96977365e-03],\n         [ 1.18944049e-02],\n         [-8.63856599e-02],\n         [ 2.30550691e-02],\n         [ 6.94445968e-02],\n         [-2.06224769e-02],\n         [ 6.03375882e-02],\n         [ 5.93662411e-02],\n         [ 1.40510872e-02],\n         [-5.61439060e-02],\n         [ 4.38373834e-02],\n         [-6.04808703e-02],\n         [ 4.10610735e-02],\n         [ 4.32150811e-02],\n         [-1.61305964e-02],\n         [-3.47953178e-02],\n         [-6.06836900e-02],\n         [ 1.37610584e-02],\n         [-2.92449258e-02],\n         [-4.65401150e-02],\n         [ 3.27540711e-02],\n         [ 6.15942180e-02],\n         [-6.50064051e-02],\n         [ 4.36626673e-02],\n         [-7.31704533e-02],\n         [ 6.83103055e-02],\n         [ 4.90907580e-02],\n         [ 8.22643042e-02],\n         [-9.00026560e-02],\n         [-2.92925984e-02],\n         [ 6.45719022e-02],\n         [-5.06734326e-02],\n         [ 8.25121105e-02],\n         [-6.83700070e-02],\n         [ 4.37162369e-02],\n         [-8.68562609e-02],\n         [ 7.01926649e-02],\n         [-5.28914146e-02],\n         [-5.66179864e-02],\n         [-3.80210541e-02],\n         [ 5.92679828e-02],\n         [ 8.95935446e-02],\n         [-5.53652570e-02],\n         [ 8.95287097e-02],\n         [-2.78583169e-03],\n         [ 6.20062053e-02],\n         [ 1.57074779e-02],\n         [ 7.71839023e-02],\n         [-2.28914618e-02],\n         [-8.08405653e-02],\n         [ 2.13974044e-02],\n         [-2.10771561e-02],\n         [ 1.47674233e-02],\n         [ 3.37278694e-02],\n         [-5.44464588e-03],\n         [-3.60045321e-02],\n         [-3.27149034e-02],\n         [-3.12917493e-02]],\n\n        [[ 8.08229148e-02],\n         [ 6.97452873e-02],\n         [ 1.84553042e-02],\n         [ 8.07527304e-02],\n         [ 1.02674365e-02],\n         [-5.81119992e-02],\n         [ 4.50941175e-02],\n         [-5.34976982e-02],\n         [ 4.39196080e-02],\n         [-6.65856600e-02],\n         [ 6.70263469e-02],\n         [ 8.39530677e-02],\n         [-6.19964227e-02],\n         [-3.29031795e-03],\n         [ 5.79956472e-02],\n         [ 2.65475810e-02],\n         [ 4.28702086e-02],\n         [-2.96014696e-02],\n         [-1.80319399e-02],\n         [-1.39070973e-02],\n         [ 6.30037189e-02],\n         [-7.66180903e-02],\n         [-7.40779340e-02],\n         [-3.33965011e-02],\n         [-6.76903725e-02],\n         [-9.38634574e-03],\n         [ 6.59121573e-03],\n         [-4.78502288e-02],\n         [-4.37137708e-02],\n         [-2.59595364e-02],\n         [-3.03943753e-02],\n         [-7.51628131e-02],\n         [-6.52876347e-02],\n         [-8.59321728e-02],\n         [-8.33602175e-02],\n         [-5.36965169e-02],\n         [-7.01468438e-02],\n         [-5.29133528e-03],\n         [ 7.92012662e-02],\n         [-3.98632400e-02],\n         [-6.78558424e-02],\n         [-4.95172776e-02],\n         [ 8.75190645e-02],\n         [ 8.59352797e-02],\n         [-4.44206968e-02],\n         [ 2.66710892e-02],\n         [ 3.95102054e-02],\n         [ 5.07500619e-02],\n         [ 3.21748704e-02],\n         [-4.72914651e-02],\n         [ 3.83873284e-02],\n         [ 5.09196520e-02],\n         [ 2.86727324e-02],\n         [-7.61229545e-03],\n         [ 7.09731430e-02],\n         [-5.91117926e-02],\n         [ 4.53509986e-02],\n         [ 1.59333646e-03],\n         [-5.61313406e-02],\n         [-2.27809101e-02],\n         [-8.73516053e-02],\n         [ 4.30742651e-02],\n         [ 1.10983849e-04],\n         [-5.40995039e-02],\n         [ 7.17569888e-03],\n         [ 6.26754463e-02],\n         [-3.02238874e-02],\n         [ 6.54036105e-02],\n         [-8.37131962e-02],\n         [-7.20845088e-02],\n         [ 6.73909783e-02],\n         [-6.08345792e-02],\n         [-8.37994069e-02],\n         [-4.73284088e-02],\n         [-8.65198970e-02],\n         [-2.93880068e-02],\n         [-5.48602864e-02],\n         [ 7.05562383e-02],\n         [-7.91203529e-02],\n         [ 4.69418019e-02]],\n\n        [[ 7.28705078e-02],\n         [-8.51018056e-02],\n         [-4.59615178e-02],\n         [ 7.04643875e-03],\n         [ 3.02229822e-02],\n         [ 4.77257669e-02],\n         [ 6.80828691e-02],\n         [-7.70705193e-02],\n         [ 3.41712385e-02],\n         [ 4.79703844e-02],\n         [-4.95088659e-02],\n         [-2.79208571e-02],\n         [ 8.78461897e-02],\n         [-7.13086724e-02],\n         [-7.69459754e-02],\n         [ 6.42100573e-02],\n         [-1.54028833e-02],\n         [ 1.78284049e-02],\n         [-7.36938715e-02],\n         [ 9.12173092e-03],\n         [ 6.09690994e-02],\n         [ 4.29426879e-03],\n         [-2.59544104e-02],\n         [ 4.13956046e-02],\n         [ 1.02830082e-02],\n         [ 7.62232989e-02],\n         [-3.07073146e-02],\n         [-2.06271484e-02],\n         [-8.80261064e-02],\n         [-6.04937226e-03],\n         [ 8.07984471e-02],\n         [-1.94637477e-03],\n         [-7.80182928e-02],\n         [ 7.07685053e-02],\n         [ 2.80540958e-02],\n         [ 6.70236349e-02],\n         [ 8.73848200e-02],\n         [ 5.02893478e-02],\n         [ 2.37325951e-02],\n         [ 7.00959116e-02],\n         [-6.11191206e-02],\n         [-8.48576427e-04],\n         [-4.78450805e-02],\n         [-8.12107772e-02],\n         [-1.58459917e-02],\n         [-1.73354149e-03],\n         [ 5.71528226e-02],\n         [-8.92080441e-02],\n         [ 2.62036473e-02],\n         [-4.40712906e-02],\n         [ 1.26582608e-02],\n         [ 8.75729024e-02],\n         [ 7.45024383e-02],\n         [ 4.31228280e-02],\n         [-6.07036352e-02],\n         [-4.48594354e-02],\n         [ 7.86433667e-02],\n         [ 6.26421124e-02],\n         [-4.62650694e-02],\n         [-6.89353868e-02],\n         [-5.42144664e-02],\n         [-3.14252041e-02],\n         [ 5.24268448e-02],\n         [ 3.08040231e-02],\n         [-6.66236803e-02],\n         [-8.19105208e-02],\n         [-4.98717912e-02],\n         [-2.16535032e-02],\n         [ 5.03255427e-03],\n         [-1.52296945e-02],\n         [ 4.59656417e-02],\n         [-4.83131260e-02],\n         [ 1.51817501e-03],\n         [-1.84968337e-02],\n         [ 6.24037087e-02],\n         [-1.07339695e-02],\n         [-3.93754654e-02],\n         [-8.40526968e-02],\n         [-1.11565068e-02],\n         [-7.02010095e-02]]],\n\n\n       [[[-1.88174844e-03],\n         [-3.95279340e-02],\n         [-1.16212219e-02],\n         [-5.74074313e-02],\n         [-2.06013247e-02],\n         [-8.26342776e-02],\n         [-7.36834258e-02],\n         [-1.08584240e-02],\n         [ 8.21966827e-02],\n         [ 5.38731515e-02],\n         [-6.95563853e-03],\n         [-8.21231231e-02],\n         [ 7.84364790e-02],\n         [-7.03761280e-02],\n         [-2.77230889e-03],\n         [-6.93803951e-02],\n         [ 3.57173383e-04],\n         [ 8.28897506e-02],\n         [ 7.91763961e-02],\n         [-5.46111986e-02],\n         [ 2.53843591e-02],\n         [-8.99789482e-02],\n         [-3.33938412e-02],\n         [ 6.86710328e-02],\n         [-3.76909822e-02],\n         [ 6.14869744e-02],\n         [ 7.20043927e-02],\n         [ 1.50363892e-03],\n         [ 5.52062094e-02],\n         [ 5.70312291e-02],\n         [ 1.45866647e-02],\n         [-5.88830784e-02],\n         [-3.54687832e-02],\n         [ 4.34832275e-02],\n         [-5.01024053e-02],\n         [-2.76517123e-03],\n         [-4.00847271e-02],\n         [ 6.14974946e-02],\n         [ 8.09743404e-02],\n         [-3.15937027e-02],\n         [-4.48716134e-02],\n         [ 1.10346898e-02],\n         [-8.54407847e-02],\n         [-8.79987851e-02],\n         [-2.05985084e-02],\n         [ 3.40024829e-02],\n         [ 8.72720033e-03],\n         [ 1.27187148e-02],\n         [ 8.37341547e-02],\n         [ 2.95871496e-02],\n         [-1.18961409e-02],\n         [ 8.29768181e-03],\n         [-8.82872194e-02],\n         [ 2.92985886e-03],\n         [-2.52170935e-02],\n         [ 2.35160440e-02],\n         [-4.91173007e-02],\n         [ 6.32706732e-02],\n         [ 4.74678129e-02],\n         [ 4.81871516e-02],\n         [ 4.86250669e-02],\n         [ 9.04350579e-02],\n         [-1.94194689e-02],\n         [ 8.98382664e-02],\n         [-2.97903642e-02],\n         [ 6.71013296e-02],\n         [-1.99943036e-02],\n         [-4.10344936e-02],\n         [-6.06265254e-02],\n         [ 6.49362355e-02],\n         [-8.97735730e-02],\n         [ 5.78931421e-02],\n         [ 5.61877638e-02],\n         [ 1.08370334e-02],\n         [ 7.03570098e-02],\n         [ 6.59906864e-02],\n         [-5.09135239e-02],\n         [ 4.20082659e-02],\n         [-4.42665629e-02],\n         [-2.26240531e-02]],\n\n        [[-2.61288732e-02],\n         [ 3.26860696e-03],\n         [ 1.06093809e-02],\n         [ 6.15821928e-02],\n         [ 8.47809017e-02],\n         [-8.64596963e-02],\n         [ 9.78504866e-03],\n         [ 1.17909312e-02],\n         [ 2.80781910e-02],\n         [-2.14898065e-02],\n         [-4.42550778e-02],\n         [-3.04374099e-03],\n         [-6.37948513e-02],\n         [ 5.68743646e-02],\n         [ 3.23657990e-02],\n         [-6.91337138e-03],\n         [ 2.35499963e-02],\n         [-5.26974835e-02],\n         [-3.15858945e-02],\n         [ 5.04564643e-02],\n         [-6.41708449e-02],\n         [ 6.00376129e-02],\n         [ 4.54047024e-02],\n         [-7.36108422e-03],\n         [ 2.84871683e-02],\n         [ 5.01757711e-02],\n         [-2.07389072e-02],\n         [-4.28575575e-02],\n         [-8.57160464e-02],\n         [-5.04826158e-02],\n         [ 1.11802146e-02],\n         [-1.62985548e-02],\n         [-2.57684812e-02],\n         [ 1.24095827e-02],\n         [ 6.02629036e-03],\n         [-2.32553408e-02],\n         [-8.02639574e-02],\n         [-2.17057839e-02],\n         [-5.11438400e-03],\n         [ 1.80221871e-02],\n         [ 5.17442822e-02],\n         [-5.03415614e-03],\n         [ 6.18252009e-02],\n         [ 4.17437702e-02],\n         [ 6.45234734e-02],\n         [-2.24099830e-02],\n         [-1.86283812e-02],\n         [-5.79401068e-02],\n         [ 8.93696845e-02],\n         [-8.47689658e-02],\n         [ 6.00128174e-02],\n         [ 6.93603009e-02],\n         [-2.16657445e-02],\n         [ 4.61700857e-02],\n         [-5.07384539e-02],\n         [-1.20193809e-02],\n         [ 4.92925942e-02],\n         [-1.32743642e-02],\n         [ 2.10070983e-02],\n         [-3.89861315e-02],\n         [ 4.94220853e-03],\n         [ 2.58753747e-02],\n         [-5.25311492e-02],\n         [ 5.99264801e-02],\n         [ 2.50149220e-02],\n         [-4.02270295e-02],\n         [-1.09766573e-02],\n         [ 7.99624175e-02],\n         [ 8.55708122e-03],\n         [-4.94656041e-02],\n         [-8.81139860e-02],\n         [-6.36781007e-02],\n         [-3.83532867e-02],\n         [ 6.63741231e-02],\n         [ 5.14726490e-02],\n         [ 3.54928523e-02],\n         [ 8.98922235e-03],\n         [ 3.78441513e-02],\n         [-2.97950767e-02],\n         [-6.48227856e-02]],\n\n        [[-5.54358102e-02],\n         [-7.77578503e-02],\n         [-8.96378607e-03],\n         [-5.00068031e-02],\n         [-5.41034341e-03],\n         [ 7.64813721e-02],\n         [-8.66460204e-02],\n         [-2.15928704e-02],\n         [ 8.32418650e-02],\n         [ 6.56603128e-02],\n         [-2.75039673e-03],\n         [-1.93122923e-02],\n         [-4.27472442e-02],\n         [ 1.26364827e-02],\n         [ 7.45639056e-02],\n         [ 9.40008461e-03],\n         [ 4.14515138e-02],\n         [-6.77006245e-02],\n         [ 7.45674819e-02],\n         [-2.35171467e-02],\n         [-3.67381275e-02],\n         [-7.07440823e-03],\n         [-2.57614031e-02],\n         [-4.28733043e-02],\n         [ 7.81133771e-02],\n         [ 4.25002128e-02],\n         [-9.59236920e-03],\n         [-7.71595240e-02],\n         [ 1.23315454e-02],\n         [-7.16127604e-02],\n         [ 8.64599794e-02],\n         [ 6.62310421e-03],\n         [-3.20300460e-05],\n         [ 2.25376412e-02],\n         [-5.11577241e-02],\n         [ 6.11948222e-02],\n         [-2.70512775e-02],\n         [-8.60325322e-02],\n         [-6.41967803e-02],\n         [-6.22589663e-02],\n         [-7.01373070e-02],\n         [ 2.40609348e-02],\n         [-4.69311997e-02],\n         [ 8.30149800e-02],\n         [ 6.53957427e-02],\n         [ 1.75359100e-03],\n         [ 2.38923579e-02],\n         [ 8.63955617e-02],\n         [-4.05928344e-02],\n         [ 6.23798370e-03],\n         [-5.27035184e-02],\n         [-5.64305484e-03],\n         [ 3.66475433e-02],\n         [-4.12845612e-03],\n         [-9.07036364e-02],\n         [-3.17191742e-02],\n         [ 1.72224939e-02],\n         [ 1.63192526e-02],\n         [ 5.96878082e-02],\n         [-2.58554742e-02],\n         [-5.86879142e-02],\n         [-2.48274729e-02],\n         [ 3.47564071e-02],\n         [-4.19784375e-02],\n         [ 3.45746279e-02],\n         [-2.07633749e-02],\n         [-8.04629773e-02],\n         [-7.79192671e-02],\n         [ 5.74323982e-02],\n         [ 1.07824206e-02],\n         [-7.52278566e-02],\n         [-3.81230153e-02],\n         [ 8.75751674e-02],\n         [-1.94032043e-02],\n         [ 7.98942894e-02],\n         [-6.83071688e-02],\n         [-8.01637918e-02],\n         [-5.80620356e-02],\n         [-5.56412712e-02],\n         [-8.63611698e-04]]],\n\n\n       [[[ 4.26595956e-02],\n         [ 4.18077409e-02],\n         [ 7.04083890e-02],\n         [-1.56771317e-02],\n         [-1.20178014e-02],\n         [ 4.88903224e-02],\n         [ 5.01275808e-02],\n         [-7.61444420e-02],\n         [-1.37378275e-02],\n         [ 3.17263380e-02],\n         [ 2.13926211e-02],\n         [ 8.32998753e-02],\n         [ 1.12161860e-02],\n         [ 4.41337377e-02],\n         [-6.12845048e-02],\n         [-7.62168318e-03],\n         [-7.29644895e-02],\n         [ 1.37341693e-02],\n         [ 2.08148956e-02],\n         [-7.03651458e-03],\n         [ 4.08317596e-02],\n         [ 6.63416982e-02],\n         [ 7.97964483e-02],\n         [-3.69173288e-02],\n         [-6.95387498e-02],\n         [-5.39264828e-03],\n         [-8.88661817e-02],\n         [ 4.08463329e-02],\n         [ 1.94887966e-02],\n         [ 6.13608509e-02],\n         [ 5.68960011e-02],\n         [ 8.81732553e-02],\n         [ 3.41234803e-02],\n         [-1.21322498e-02],\n         [-5.36374487e-02],\n         [-4.53162566e-02],\n         [-1.60529241e-02],\n         [-2.15667635e-02],\n         [-7.13304281e-02],\n         [-3.88340503e-02],\n         [-3.23315598e-02],\n         [-7.09931776e-02],\n         [ 2.67773345e-02],\n         [ 3.28914449e-02],\n         [-2.83065811e-02],\n         [ 6.81047887e-03],\n         [-1.06015503e-02],\n         [-4.04884703e-02],\n         [ 3.06448340e-03],\n         [ 4.79763448e-02],\n         [-1.14663318e-02],\n         [ 6.16762042e-03],\n         [ 4.10256833e-02],\n         [ 6.89630657e-02],\n         [-2.31774077e-02],\n         [-3.07180211e-02],\n         [-3.18850130e-02],\n         [ 6.82625920e-02],\n         [ 7.82368332e-02],\n         [-5.00280671e-02],\n         [-3.78705114e-02],\n         [ 8.63984674e-02],\n         [ 8.05471539e-02],\n         [-4.03002910e-02],\n         [ 3.27968821e-02],\n         [-3.79887186e-02],\n         [ 1.46899447e-02],\n         [ 3.29197794e-02],\n         [-7.59748369e-02],\n         [-5.72847016e-02],\n         [-7.73597509e-03],\n         [-5.96136227e-02],\n         [-6.97472841e-02],\n         [ 6.60738945e-02],\n         [ 8.84169936e-02],\n         [ 1.60476044e-02],\n         [ 8.65660459e-02],\n         [ 5.31691164e-02],\n         [-7.92297274e-02],\n         [ 4.45018262e-02]],\n\n        [[ 2.59382278e-02],\n         [ 2.98092663e-02],\n         [ 6.80446327e-02],\n         [-6.13748506e-02],\n         [ 4.99933958e-02],\n         [ 5.91568649e-02],\n         [-2.13061273e-02],\n         [ 5.66306412e-02],\n         [-2.65929103e-03],\n         [ 8.96140188e-02],\n         [-6.38575181e-02],\n         [ 8.34863186e-02],\n         [-4.88398559e-02],\n         [-2.86746323e-02],\n         [ 6.70631230e-03],\n         [ 7.28157461e-02],\n         [-1.15867481e-02],\n         [ 4.15063649e-02],\n         [-4.16673720e-04],\n         [ 2.04535499e-02],\n         [-5.51038608e-02],\n         [ 3.21254730e-02],\n         [ 1.17579252e-02],\n         [-8.26735571e-02],\n         [ 1.63267553e-02],\n         [-2.59094164e-02],\n         [-6.06765747e-02],\n         [-1.77703947e-02],\n         [ 1.26971304e-02],\n         [-6.21755198e-02],\n         [-4.63599376e-02],\n         [-1.24521554e-04],\n         [ 1.17802694e-02],\n         [ 6.48866147e-02],\n         [-3.23696919e-02],\n         [ 3.19117680e-02],\n         [ 5.93329072e-02],\n         [-1.61769688e-02],\n         [-1.16089582e-02],\n         [ 4.22929376e-02],\n         [ 6.75553828e-02],\n         [-7.60738179e-02],\n         [-7.70254806e-02],\n         [-6.14794940e-02],\n         [-8.88771564e-03],\n         [ 4.35371399e-02],\n         [ 4.75450605e-03],\n         [ 2.63791084e-02],\n         [ 8.35929364e-02],\n         [-1.76268592e-02],\n         [ 5.46123832e-03],\n         [ 2.01231316e-02],\n         [ 7.49666393e-02],\n         [ 4.14167047e-02],\n         [-7.37124979e-02],\n         [-2.29581669e-02],\n         [ 9.02353525e-02],\n         [-7.47415125e-02],\n         [-2.35016569e-02],\n         [-5.82432933e-02],\n         [ 8.68637264e-02],\n         [ 8.23300928e-02],\n         [-5.99479675e-03],\n         [-8.12120363e-02],\n         [ 7.72652924e-02],\n         [ 2.06527561e-02],\n         [-1.39459670e-02],\n         [-5.18173724e-03],\n         [ 6.56164438e-02],\n         [ 8.67024511e-02],\n         [-7.50793517e-03],\n         [ 1.58068463e-02],\n         [-7.06612244e-02],\n         [ 4.30848897e-02],\n         [-6.47549778e-02],\n         [-8.62887129e-02],\n         [-1.64756328e-02],\n         [-4.72717173e-02],\n         [ 1.29260197e-02],\n         [ 6.00086302e-02]],\n\n        [[-4.56284732e-03],\n         [ 3.99043858e-02],\n         [-4.14173603e-02],\n         [ 9.52903926e-03],\n         [ 1.13097578e-03],\n         [ 3.08772400e-02],\n         [-1.74266100e-02],\n         [-5.90561181e-02],\n         [ 5.74377179e-02],\n         [-7.72907585e-03],\n         [ 9.00814384e-02],\n         [ 5.23706377e-02],\n         [-6.06794730e-02],\n         [-6.11447953e-02],\n         [ 6.40147477e-02],\n         [ 5.10952324e-02],\n         [ 2.33447552e-02],\n         [ 5.07457852e-02],\n         [-3.13534588e-02],\n         [-5.77361397e-02],\n         [ 2.41619274e-02],\n         [-1.46108046e-02],\n         [-2.19585747e-03],\n         [-3.77264135e-02],\n         [-4.60195728e-02],\n         [-2.75286883e-02],\n         [ 2.17884481e-02],\n         [ 2.45093033e-02],\n         [ 2.42421925e-02],\n         [-1.13943666e-02],\n         [ 6.24240935e-02],\n         [ 5.10726869e-03],\n         [ 4.76746261e-03],\n         [ 1.76798925e-02],\n         [ 3.70710790e-02],\n         [-3.12309712e-02],\n         [-4.25287634e-02],\n         [ 8.49948227e-02],\n         [-2.24267244e-02],\n         [-3.73374224e-02],\n         [-5.64185828e-02],\n         [-5.19541092e-02],\n         [-4.30715829e-02],\n         [ 7.65275508e-02],\n         [-3.87361981e-02],\n         [-4.36279885e-02],\n         [-3.53991576e-02],\n         [-1.12169981e-03],\n         [ 8.88430178e-02],\n         [-3.18342447e-02],\n         [ 7.05901086e-02],\n         [ 4.06839103e-02],\n         [ 3.23081985e-02],\n         [ 3.46971601e-02],\n         [ 4.83417213e-02],\n         [ 5.50644547e-02],\n         [ 7.31638074e-03],\n         [-9.03065503e-02],\n         [ 4.10574377e-02],\n         [ 1.24988928e-02],\n         [-6.97014481e-02],\n         [-5.60067073e-02],\n         [-7.88989663e-02],\n         [-6.45250306e-02],\n         [-5.36771603e-02],\n         [ 5.55333495e-03],\n         [-1.38175935e-02],\n         [-2.18377411e-02],\n         [ 8.66425782e-03],\n         [-2.45454237e-02],\n         [-6.92906976e-02],\n         [-2.49377638e-02],\n         [-7.07231537e-02],\n         [-4.46874350e-02],\n         [ 7.57945925e-02],\n         [-6.01265728e-02],\n         [-7.19261989e-02],\n         [ 5.46445996e-02],\n         [-6.03293628e-03],\n         [ 7.17076659e-03]]]], dtype=float32)>, <tf.Variable 'conv2d_868/kernel:0' shape=(1, 1, 80, 112) dtype=float32, numpy=\narray([[[[-0.11377605, -0.19837369, -0.10293127, ...,  0.03562347,\n          -0.18975647, -0.02582112],\n         [ 0.10182679,  0.01593432,  0.03020365, ...,  0.009907  ,\n          -0.00535053, -0.09950298],\n         [ 0.0855576 , -0.127197  , -0.08279993, ...,  0.09936242,\n          -0.05976695,  0.05062583],\n         ...,\n         [-0.24529052, -0.02732827, -0.00027736, ...,  0.11329194,\n          -0.11313015, -0.13003397],\n         [-0.19731423, -0.03873628, -0.20429744, ...,  0.21081927,\n          -0.01312663, -0.16429222],\n         [ 0.1405715 , -0.00138492,  0.1414134 , ...,  0.01170814,\n          -0.01567286,  0.05142608]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_875/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_239/sync_batch_normalization/moving_variance:0' shape=(480,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization/moving_mean:0' shape=(672,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_894/gamma:0' shape=(80,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_356/depthwise_kernel:0' shape=(3, 3, 24, 1) dtype=float32, numpy=\narray([[[[-0.14340137],\n         [-0.08418159],\n         [ 0.10534087],\n         [-0.11075669],\n         [-0.03815177],\n         [ 0.06203593],\n         [ 0.02642174],\n         [ 0.04302326],\n         [ 0.10022238],\n         [ 0.05761124],\n         [ 0.05405563],\n         [ 0.13017288],\n         [-0.15817238],\n         [ 0.0664524 ],\n         [ 0.12732226],\n         [-0.08743418],\n         [-0.12439197],\n         [ 0.12777665],\n         [-0.15144914],\n         [ 0.10406849],\n         [ 0.09318924],\n         [-0.00128275],\n         [-0.09732779],\n         [ 0.10372761]],\n\n        [[ 0.10296056],\n         [-0.05869111],\n         [ 0.01091655],\n         [ 0.05750546],\n         [ 0.02351768],\n         [ 0.04889004],\n         [-0.05116598],\n         [-0.06799826],\n         [ 0.01638015],\n         [ 0.07803227],\n         [ 0.08502676],\n         [ 0.11258233],\n         [-0.15656272],\n         [-0.13711524],\n         [ 0.04636733],\n         [-0.1131624 ],\n         [ 0.00166009],\n         [ 0.11383539],\n         [-0.14547984],\n         [ 0.02747874],\n         [ 0.02423362],\n         [ 0.09881812],\n         [-0.06227331],\n         [-0.09644669]],\n\n        [[-0.10719107],\n         [-0.0035094 ],\n         [ 0.00278959],\n         [-0.1298213 ],\n         [ 0.0928914 ],\n         [ 0.15386549],\n         [ 0.08788311],\n         [-0.07467841],\n         [-0.09631143],\n         [ 0.06356439],\n         [ 0.0592282 ],\n         [-0.01641122],\n         [-0.13982958],\n         [ 0.03058729],\n         [-0.10343094],\n         [-0.02755797],\n         [-0.13711372],\n         [ 0.03288919],\n         [ 0.14578092],\n         [-0.00610331],\n         [ 0.10902637],\n         [-0.06512679],\n         [-0.08758812],\n         [ 0.03284201]]],\n\n\n       [[[ 0.14794993],\n         [-0.07280301],\n         [ 0.1460459 ],\n         [ 0.1381455 ],\n         [ 0.04432176],\n         [-0.03030466],\n         [-0.13750586],\n         [ 0.05140468],\n         [-0.04495747],\n         [ 0.06694192],\n         [ 0.09736428],\n         [ 0.00194964],\n         [ 0.072345  ],\n         [-0.1620485 ],\n         [-0.15177895],\n         [ 0.12911889],\n         [-0.13187525],\n         [ 0.13725403],\n         [-0.0977779 ],\n         [ 0.00980504],\n         [ 0.13831535],\n         [ 0.11125684],\n         [-0.01418884],\n         [-0.09442148]],\n\n        [[ 0.15736821],\n         [-0.00862259],\n         [-0.09820578],\n         [ 0.11407554],\n         [-0.15723331],\n         [-0.09020294],\n         [ 0.02782907],\n         [-0.02137613],\n         [-0.08519721],\n         [-0.01988187],\n         [-0.12133288],\n         [ 0.04116012],\n         [ 0.09762278],\n         [ 0.09618241],\n         [-0.15225911],\n         [ 0.05478311],\n         [ 0.14637521],\n         [-0.14642562],\n         [-0.02799571],\n         [ 0.00862208],\n         [-0.07752488],\n         [-0.16157728],\n         [-0.06047893],\n         [-0.13463053]],\n\n        [[ 0.09026361],\n         [ 0.06642258],\n         [ 0.14101288],\n         [-0.04409311],\n         [ 0.0086033 ],\n         [-0.06567015],\n         [-0.14833087],\n         [ 0.02079596],\n         [ 0.12021786],\n         [ 0.15288576],\n         [-0.01743361],\n         [-0.12073404],\n         [ 0.02286515],\n         [-0.12555106],\n         [ 0.07635018],\n         [-0.07986639],\n         [-0.01178087],\n         [-0.0014002 ],\n         [ 0.07575636],\n         [ 0.1027998 ],\n         [-0.16324918],\n         [ 0.13055208],\n         [ 0.00924727],\n         [-0.00898354]]],\n\n\n       [[[ 0.1501388 ],\n         [ 0.11451405],\n         [-0.07104454],\n         [ 0.05734381],\n         [-0.14877604],\n         [ 0.1525822 ],\n         [-0.14026228],\n         [ 0.04728715],\n         [-0.13821156],\n         [-0.07567448],\n         [ 0.07381606],\n         [-0.06193272],\n         [ 0.08085775],\n         [-0.04403739],\n         [ 0.0650564 ],\n         [ 0.04998952],\n         [-0.07261878],\n         [-0.10575512],\n         [-0.13955559],\n         [-0.00409834],\n         [-0.12075993],\n         [-0.05481094],\n         [ 0.05576271],\n         [ 0.00463387]],\n\n        [[-0.0325347 ],\n         [ 0.07343136],\n         [-0.14436798],\n         [ 0.14143744],\n         [-0.00939149],\n         [-0.00686255],\n         [ 0.00649199],\n         [-0.10386813],\n         [-0.14436257],\n         [ 0.02648079],\n         [-0.1363825 ],\n         [ 0.12504905],\n         [-0.15712246],\n         [-0.09095681],\n         [ 0.03356683],\n         [-0.0382178 ],\n         [-0.07120024],\n         [-0.08896598],\n         [ 0.11554801],\n         [-0.10271048],\n         [ 0.04675201],\n         [ 0.08268806],\n         [-0.10615049],\n         [-0.08132538]],\n\n        [[-0.01475766],\n         [-0.06688647],\n         [ 0.1612347 ],\n         [-0.0804479 ],\n         [ 0.00622654],\n         [ 0.07393162],\n         [ 0.101621  ],\n         [ 0.1587502 ],\n         [-0.16110246],\n         [-0.11021995],\n         [-0.09468786],\n         [-0.01166391],\n         [ 0.10361844],\n         [-0.08487037],\n         [ 0.09539708],\n         [-0.08777291],\n         [ 0.076672  ],\n         [-0.14978823],\n         [-0.1465212 ],\n         [-0.04055825],\n         [ 0.038368  ],\n         [ 0.01941599],\n         [-0.07661279],\n         [ 0.03800572]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/beta:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_237/sync_batch_normalization/moving_mean:0' shape=(144,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_898/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'inverted_bottleneck_block_245/sync_batch_normalization_1/gamma:0' shape=(672,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'sync_batch_normalization_870/moving_mean:0' shape=(80,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'depthwise_conv2d_361/depthwise_kernel:0' shape=(3, 3, 80, 1) dtype=float32, numpy=\narray([[[[ 0.05862133],\n         [-0.06787249],\n         [-0.00143874],\n         [ 0.0522846 ],\n         [ 0.02843143],\n         [-0.05796753],\n         [-0.03070563],\n         [ 0.03558707],\n         [ 0.00286934],\n         [ 0.04302962],\n         [-0.0577325 ],\n         [ 0.04925835],\n         [-0.06406352],\n         [-0.01138317],\n         [ 0.00832298],\n         [-0.05808154],\n         [ 0.00169984],\n         [ 0.08342668],\n         [-0.08837145],\n         [-0.08583248],\n         [-0.0452465 ],\n         [-0.06962996],\n         [ 0.01602703],\n         [ 0.08493581],\n         [-0.03485757],\n         [ 0.06025551],\n         [-0.06781401],\n         [-0.01794404],\n         [ 0.0348888 ],\n         [-0.07669795],\n         [-0.0490337 ],\n         [ 0.07483491],\n         [ 0.06025095],\n         [-0.00535823],\n         [-0.02514351],\n         [ 0.03641158],\n         [ 0.00575929],\n         [-0.0299454 ],\n         [ 0.00780084],\n         [ 0.01027875],\n         [ 0.06777018],\n         [ 0.04706654],\n         [-0.02420408],\n         [-0.07793529],\n         [ 0.08365996],\n         [ 0.07645322],\n         [ 0.04628013],\n         [-0.02425781],\n         [ 0.07502417],\n         [ 0.06599805],\n         [ 0.03913902],\n         [ 0.01872989],\n         [-0.06520419],\n         [-0.00075293],\n         [ 0.01351236],\n         [-0.04886895],\n         [ 0.043605  ],\n         [-0.05501736],\n         [-0.07609047],\n         [-0.06157172],\n         [-0.05589629],\n         [-0.01788189],\n         [-0.04286225],\n         [ 0.02731637],\n         [-0.07283528],\n         [ 0.04904722],\n         [-0.04857277],\n         [-0.05936235],\n         [ 0.0266699 ],\n         [ 0.0253202 ],\n         [-0.07372662],\n         [ 0.0230236 ],\n         [-0.07591793],\n         [ 0.06320105],\n         [-0.06062237],\n         [-0.02340686],\n         [ 0.0557498 ],\n         [ 0.08509123],\n         [ 0.0446057 ],\n         [-0.07428408]],\n\n        [[ 0.07721901],\n         [ 0.02545991],\n         [-0.02271096],\n         [ 0.07300392],\n         [-0.08588627],\n         [-0.02822874],\n         [-0.00096042],\n         [ 0.04805009],\n         [-0.04831713],\n         [-0.02971262],\n         [ 0.0291623 ],\n         [-0.01356574],\n         [-0.02229521],\n         [-0.07300246],\n         [-0.03045924],\n         [-0.00594945],\n         [-0.02454614],\n         [-0.0476848 ],\n         [ 0.03519863],\n         [ 0.02090736],\n         [ 0.05277282],\n         [-0.046572  ],\n         [-0.05920203],\n         [ 0.03778207],\n         [ 0.05434914],\n         [-0.01817024],\n         [-0.00426063],\n         [ 0.08842298],\n         [ 0.07764566],\n         [-0.04779985],\n         [ 0.0873276 ],\n         [ 0.03511068],\n         [ 0.03061718],\n         [-0.00619334],\n         [-0.0184059 ],\n         [-0.02919291],\n         [ 0.00738354],\n         [-0.01426036],\n         [ 0.01189101],\n         [ 0.02988032],\n         [ 0.0846733 ],\n         [ 0.00946552],\n         [-0.02045307],\n         [ 0.00101848],\n         [ 0.08865036],\n         [-0.08417495],\n         [ 0.08208813],\n         [-0.0785756 ],\n         [ 0.03740524],\n         [ 0.02468041],\n         [ 0.03092171],\n         [-0.03615016],\n         [-0.0801071 ],\n         [ 0.03581479],\n         [ 0.05957553],\n         [ 0.08237936],\n         [-0.07721847],\n         [ 0.06855331],\n         [ 0.0003814 ],\n         [-0.02432015],\n         [ 0.05368485],\n         [-0.00667358],\n         [ 0.00073729],\n         [-0.02639027],\n         [-0.01773159],\n         [ 0.03252644],\n         [-0.05595233],\n         [ 0.00672303],\n         [-0.07951189],\n         [-0.03684853],\n         [-0.06077854],\n         [ 0.02722027],\n         [ 0.07564095],\n         [ 0.00493526],\n         [-0.06356188],\n         [-0.03022943],\n         [ 0.02337889],\n         [-0.02516462],\n         [ 0.08925943],\n         [ 0.0522835 ]],\n\n        [[-0.02456156],\n         [ 0.02857678],\n         [ 0.03507963],\n         [ 0.07255268],\n         [-0.01634862],\n         [-0.01399302],\n         [ 0.06031664],\n         [ 0.0779556 ],\n         [-0.06671466],\n         [-0.00915476],\n         [ 0.0672055 ],\n         [ 0.02125512],\n         [ 0.00261952],\n         [ 0.04044171],\n         [-0.07184018],\n         [-0.00181242],\n         [ 0.08271779],\n         [-0.00473344],\n         [-0.03401157],\n         [ 0.03392548],\n         [-0.05159209],\n         [-0.0717988 ],\n         [-0.02933209],\n         [-0.00342577],\n         [ 0.00734285],\n         [ 0.03482041],\n         [-0.07988546],\n         [ 0.02886037],\n         [-0.07378212],\n         [-0.05460815],\n         [-0.0393249 ],\n         [ 0.06679575],\n         [-0.00195777],\n         [ 0.04739965],\n         [-0.08581632],\n         [ 0.04518142],\n         [-0.00184961],\n         [ 0.01261881],\n         [-0.00224381],\n         [-0.01192985],\n         [-0.01102502],\n         [-0.05512393],\n         [-0.04728866],\n         [ 0.00331844],\n         [ 0.01729564],\n         [-0.0501302 ],\n         [-0.07037815],\n         [ 0.03195289],\n         [ 0.07023205],\n         [-0.01874557],\n         [-0.01445946],\n         [ 0.04807998],\n         [-0.01940126],\n         [-0.01581582],\n         [-0.01973686],\n         [ 0.03475253],\n         [ 0.08207478],\n         [-0.07116315],\n         [ 0.05247119],\n         [ 0.03359995],\n         [-0.07978815],\n         [ 0.04428263],\n         [ 0.03059847],\n         [ 0.01560552],\n         [-0.04788633],\n         [ 0.02635573],\n         [ 0.01764799],\n         [ 0.05597052],\n         [-0.07732634],\n         [ 0.01235746],\n         [-0.05946237],\n         [ 0.04475005],\n         [-0.05329708],\n         [ 0.08195986],\n         [ 0.04055862],\n         [ 0.03729253],\n         [ 0.06574923],\n         [-0.02528181],\n         [-0.05548031],\n         [ 0.03708637]]],\n\n\n       [[[ 0.04131354],\n         [-0.02366098],\n         [-0.00551046],\n         [-0.00086305],\n         [ 0.05134383],\n         [-0.03414534],\n         [ 0.00183507],\n         [-0.02873745],\n         [ 0.00403973],\n         [-0.08824188],\n         [ 0.0222329 ],\n         [ 0.08102261],\n         [ 0.07718936],\n         [-0.05539208],\n         [ 0.01658904],\n         [-0.07282518],\n         [ 0.02694903],\n         [ 0.07285637],\n         [ 0.08844501],\n         [ 0.07910861],\n         [ 0.02708575],\n         [ 0.08990203],\n         [-0.0240164 ],\n         [-0.05650413],\n         [-0.04124846],\n         [-0.07619873],\n         [ 0.08021528],\n         [-0.00269753],\n         [-0.0348221 ],\n         [ 0.03171368],\n         [-0.08979475],\n         [-0.06474152],\n         [ 0.07013246],\n         [ 0.0086266 ],\n         [-0.00619234],\n         [-0.08474578],\n         [-0.09029496],\n         [ 0.05931535],\n         [ 0.04343687],\n         [ 0.04223551],\n         [ 0.07155059],\n         [ 0.07888953],\n         [ 0.03588842],\n         [-0.07390042],\n         [-0.04451332],\n         [-0.08843549],\n         [ 0.0579996 ],\n         [ 0.02964737],\n         [ 0.00341677],\n         [-0.02227283],\n         [ 0.00178009],\n         [ 0.08750346],\n         [-0.02411523],\n         [ 0.08277509],\n         [ 0.05163233],\n         [ 0.05877222],\n         [ 0.04689845],\n         [-0.05654879],\n         [-0.05907158],\n         [-0.02672895],\n         [-0.03180189],\n         [ 0.08623222],\n         [-0.05974528],\n         [ 0.03930502],\n         [ 0.06115223],\n         [ 0.06551525],\n         [ 0.02286189],\n         [ 0.07035287],\n         [-0.08282754],\n         [-0.07002901],\n         [ 0.05888487],\n         [-0.04605331],\n         [-0.06600455],\n         [-0.08956316],\n         [-0.0674441 ],\n         [ 0.07339886],\n         [-0.04315964],\n         [ 0.03424843],\n         [ 0.03260674],\n         [ 0.07929479]],\n\n        [[ 0.08247361],\n         [-0.01025383],\n         [-0.0355892 ],\n         [-0.07657394],\n         [ 0.0091054 ],\n         [-0.01682857],\n         [-0.04353513],\n         [-0.07771338],\n         [ 0.04457857],\n         [ 0.02758469],\n         [ 0.02358595],\n         [ 0.03270664],\n         [ 0.06104478],\n         [-0.03830769],\n         [ 0.06694925],\n         [-0.01769655],\n         [-0.05800402],\n         [-0.0330021 ],\n         [ 0.07623743],\n         [-0.0177782 ],\n         [ 0.01703777],\n         [-0.0837172 ],\n         [-0.01936416],\n         [-0.03471963],\n         [ 0.01185422],\n         [-0.04075783],\n         [-0.03957249],\n         [-0.00642893],\n         [ 0.06090166],\n         [-0.06661635],\n         [-0.03783067],\n         [ 0.08443964],\n         [-0.02471675],\n         [ 0.00353675],\n         [-0.0468951 ],\n         [-0.01810096],\n         [ 0.00715558],\n         [-0.08179883],\n         [ 0.07040827],\n         [ 0.02572674],\n         [-0.06271429],\n         [-0.03628284],\n         [ 0.05091259],\n         [-0.05034399],\n         [ 0.0786377 ],\n         [ 0.0280863 ],\n         [-0.04355047],\n         [ 0.03778856],\n         [ 0.04001403],\n         [ 0.06786926],\n         [ 0.00249891],\n         [ 0.02162971],\n         [-0.06200027],\n         [-0.03715584],\n         [ 0.00671139],\n         [-0.03643687],\n         [-0.04893312],\n         [-0.07927226],\n         [-0.06967054],\n         [-0.00533827],\n         [ 0.00943832],\n         [ 0.04864115],\n         [-0.07900567],\n         [-0.00270824],\n         [-0.01999229],\n         [-0.03156742],\n         [ 0.03180978],\n         [-0.00216118],\n         [-0.05231823],\n         [ 0.02281787],\n         [ 0.07461306],\n         [ 0.02685514],\n         [-0.00315276],\n         [ 0.05754547],\n         [ 0.00546037],\n         [-0.06526371],\n         [ 0.06875122],\n         [ 0.05377905],\n         [-0.04036626],\n         [ 0.06201176]],\n\n        [[ 0.00949335],\n         [ 0.08289196],\n         [-0.04254466],\n         [-0.08694872],\n         [-0.07277346],\n         [-0.07764788],\n         [ 0.05940598],\n         [ 0.02990221],\n         [ 0.0803875 ],\n         [-0.07934746],\n         [-0.03326341],\n         [ 0.08784597],\n         [ 0.0128228 ],\n         [ 0.06761551],\n         [ 0.04819334],\n         [ 0.05613832],\n         [-0.05433987],\n         [-0.05080116],\n         [ 0.04192294],\n         [ 0.01857803],\n         [ 0.06814912],\n         [-0.01618525],\n         [-0.04278021],\n         [ 0.00103077],\n         [ 0.01503325],\n         [ 0.07725485],\n         [ 0.0611382 ],\n         [ 0.06120856],\n         [ 0.03415036],\n         [ 0.04896116],\n         [ 0.06452547],\n         [-0.08227083],\n         [ 0.0720647 ],\n         [ 0.00602363],\n         [ 0.06589034],\n         [-0.00748993],\n         [ 0.0238327 ],\n         [-0.08020195],\n         [-0.03807123],\n         [ 0.08222513],\n         [-0.05276975],\n         [-0.03908035],\n         [-0.07836901],\n         [ 0.02132025],\n         [-0.03410187],\n         [ 0.0266423 ],\n         [-0.03243826],\n         [ 0.06792916],\n         [ 0.05551526],\n         [-0.05240239],\n         [ 0.02939975],\n         [-0.04590768],\n         [ 0.06535724],\n         [-0.08101938],\n         [ 0.03674592],\n         [ 0.04880942],\n         [-0.02492849],\n         [-0.03719017],\n         [-0.02101711],\n         [ 0.07957974],\n         [ 0.07638951],\n         [-0.07266613],\n         [ 0.03130862],\n         [ 0.08442576],\n         [ 0.08298282],\n         [-0.0768824 ],\n         [-0.08268139],\n         [ 0.01941225],\n         [-0.05475246],\n         [ 0.02066569],\n         [ 0.01758488],\n         [ 0.06787933],\n         [-0.06037681],\n         [ 0.08864908],\n         [-0.0720289 ],\n         [ 0.07373147],\n         [ 0.09013467],\n         [ 0.05156834],\n         [ 0.06052239],\n         [ 0.0318631 ]]],\n\n\n       [[[-0.03392524],\n         [ 0.00912499],\n         [-0.03485991],\n         [-0.06790743],\n         [-0.07071039],\n         [-0.06318291],\n         [-0.00849964],\n         [-0.02936424],\n         [-0.02635108],\n         [ 0.03226935],\n         [ 0.03140797],\n         [ 0.00033191],\n         [-0.0304587 ],\n         [ 0.01048739],\n         [-0.04042747],\n         [-0.05333292],\n         [ 0.01903509],\n         [-0.0355407 ],\n         [ 0.02509222],\n         [-0.08152802],\n         [ 0.00059201],\n         [ 0.06729455],\n         [ 0.02589207],\n         [-0.05556232],\n         [-0.04875301],\n         [ 0.01317454],\n         [ 0.04868667],\n         [ 0.0268387 ],\n         [-0.0246893 ],\n         [-0.04488046],\n         [ 0.04566497],\n         [-0.07064676],\n         [-0.07056984],\n         [ 0.03463709],\n         [-0.02291454],\n         [-0.008719  ],\n         [-0.02562536],\n         [-0.03146546],\n         [-0.06284931],\n         [ 0.04440957],\n         [-0.07968035],\n         [ 0.05213402],\n         [-0.02299087],\n         [ 0.04789007],\n         [-0.09047034],\n         [ 0.07150608],\n         [-0.01475951],\n         [ 0.02269763],\n         [-0.07563212],\n         [-0.00975929],\n         [ 0.08480932],\n         [ 0.00114093],\n         [-0.02058414],\n         [-0.00842404],\n         [-0.00774994],\n         [ 0.03215186],\n         [ 0.06082876],\n         [-0.07206398],\n         [-0.02735444],\n         [ 0.01445282],\n         [-0.00354075],\n         [ 0.06043807],\n         [ 0.00200986],\n         [-0.01584757],\n         [ 0.04492085],\n         [ 0.04690719],\n         [-0.06885198],\n         [-0.07592513],\n         [ 0.00753573],\n         [ 0.0634876 ],\n         [-0.01528414],\n         [ 0.03892908],\n         [ 0.06138667],\n         [ 0.08318278],\n         [ 0.07324603],\n         [-0.00943415],\n         [ 0.06991668],\n         [ 0.05192149],\n         [-0.00508434],\n         [-0.0098428 ]],\n\n        [[ 0.04794404],\n         [-0.08520563],\n         [ 0.01584879],\n         [ 0.00127707],\n         [-0.01096416],\n         [ 0.06917842],\n         [-0.02692366],\n         [ 0.07861941],\n         [-0.01046617],\n         [-0.03980467],\n         [-0.05822581],\n         [ 0.05601834],\n         [ 0.03866021],\n         [ 0.07628843],\n         [-0.01748268],\n         [ 0.00183295],\n         [-0.03276833],\n         [ 0.05582231],\n         [ 0.03761731],\n         [ 0.08075538],\n         [ 0.0675859 ],\n         [ 0.06167038],\n         [ 0.04227944],\n         [-0.02539866],\n         [-0.08508437],\n         [-0.03594803],\n         [ 0.0129812 ],\n         [ 0.05990578],\n         [-0.06660353],\n         [-0.00040136],\n         [ 0.05011389],\n         [-0.08077427],\n         [-0.0151326 ],\n         [ 0.00020023],\n         [-0.06197159],\n         [ 0.01304068],\n         [ 0.06728661],\n         [ 0.0667434 ],\n         [-0.06405506],\n         [-0.00077231],\n         [ 0.03447378],\n         [ 0.02687009],\n         [-0.0570691 ],\n         [-0.02197856],\n         [-0.04235393],\n         [ 0.04266931],\n         [ 0.07164069],\n         [-0.06393702],\n         [ 0.03450568],\n         [-0.04970691],\n         [-0.02636155],\n         [ 0.06492317],\n         [ 0.06755865],\n         [-0.03215123],\n         [ 0.05774942],\n         [-0.03554027],\n         [ 0.06879117],\n         [-0.06295136],\n         [-0.0464917 ],\n         [-0.00615349],\n         [-0.0686335 ],\n         [-0.02820376],\n         [ 0.02623101],\n         [-0.05194769],\n         [-0.03156608],\n         [ 0.04817665],\n         [-0.02641541],\n         [-0.02007347],\n         [-0.0414317 ],\n         [ 0.07679266],\n         [ 0.06080408],\n         [ 0.07480045],\n         [-0.09010449],\n         [ 0.0259641 ],\n         [ 0.03417961],\n         [-0.06173239],\n         [ 0.01845957],\n         [-0.07137416],\n         [ 0.04579808],\n         [-0.00348966]],\n\n        [[ 0.00680531],\n         [ 0.0589366 ],\n         [-0.02025044],\n         [-0.03384155],\n         [-0.03997241],\n         [ 0.05575636],\n         [ 0.06276664],\n         [-0.04335844],\n         [ 0.06811893],\n         [ 0.03964104],\n         [ 0.0797206 ],\n         [ 0.02679319],\n         [ 0.0156488 ],\n         [-0.03093265],\n         [ 0.0359986 ],\n         [-0.0618838 ],\n         [ 0.08989947],\n         [-0.02006587],\n         [-0.09001925],\n         [ 0.04252441],\n         [-0.05294558],\n         [-0.02587382],\n         [ 0.07319094],\n         [ 0.09016059],\n         [ 0.07911155],\n         [-0.08186112],\n         [ 0.07288016],\n         [-0.05612703],\n         [ 0.06419812],\n         [ 0.08612832],\n         [ 0.03541279],\n         [ 0.03683811],\n         [ 0.03753251],\n         [-0.03604174],\n         [ 0.07631277],\n         [ 0.00750179],\n         [ 0.03689261],\n         [-0.08473907],\n         [ 0.06278251],\n         [ 0.07894029],\n         [ 0.08228348],\n         [-0.03164697],\n         [ 0.06372122],\n         [ 0.01757789],\n         [-0.07366971],\n         [ 0.01894738],\n         [ 0.01700513],\n         [-0.03727212],\n         [-0.02945125],\n         [ 0.09013818],\n         [ 0.03047349],\n         [ 0.04940854],\n         [ 0.02127507],\n         [ 0.08978595],\n         [-0.07326807],\n         [ 0.04303537],\n         [-0.02022564],\n         [-0.08902168],\n         [-0.02779374],\n         [-0.0635439 ],\n         [-0.02826819],\n         [ 0.07579274],\n         [-0.07877778],\n         [-0.01744852],\n         [ 0.02953462],\n         [-0.06369025],\n         [ 0.04691987],\n         [-0.07481118],\n         [-0.07864437],\n         [ 0.08330482],\n         [-0.07464539],\n         [ 0.05260731],\n         [-0.04967913],\n         [ 0.03227251],\n         [ 0.04554082],\n         [ 0.06617132],\n         [-0.03394462],\n         [-0.03974465],\n         [-0.01948126],\n         [-0.06254589]]]], dtype=float32)>, <tf.Variable 'sync_batch_normalization_903/gamma:0' shape=(112,) dtype=float32, numpy=\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'conv2d_842/kernel:0' shape=(1, 1, 24, 80) dtype=float32, numpy=\narray([[[[ 0.11949858,  0.06378268,  0.03810585, ..., -0.05398615,\n           0.21680692,  0.34825197],\n         [-0.11084814,  0.32638538,  0.07742921, ...,  0.06220793,\n          -0.2845991 , -0.07662066],\n         [ 0.34297124, -0.01897088, -0.04536596, ...,  0.08679746,\n          -0.16584131,  0.03761359],\n         ...,\n         [-0.42379293,  0.17675616, -0.03988766, ..., -0.21568966,\n           0.16601686, -0.12089289],\n         [ 0.04077285, -0.2336567 ,  0.38495407, ...,  0.34639072,\n          -0.29553336, -0.11165991],\n         [ 0.37638202, -0.04997886,  0.07167383, ...,  0.16532663,\n          -0.09114525,  0.330695  ]]]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "det.model.load_weights(\"models/ckpt-277200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "30cfb6fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (80,) when attempting to restore variable with shape (112,) and name backbone/layer_with_weights-100/beta/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py:132\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_safe_assign_variable_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:308\u001b[0m, in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    307\u001b[0m   value_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value)\n\u001b[1;32m--> 308\u001b[0m \u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39massign_variable_op(\n\u001b[0;32m    310\u001b[0m     handle, value_tensor, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1307\u001b[0m, in \u001b[0;36mTensorShape.assert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[1;32m-> 1307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are incompatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (112,) and (80,) are incompatible",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[235], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(model\u001b[38;5;241m=\u001b[39mdet\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mckpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/ckpt-277200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpect_partial()\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2563\u001b[0m, in \u001b[0;36mCheckpoint.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2560\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m utils_impl\u001b[38;5;241m.\u001b[39mget_variables_path(save_path)\n\u001b[0;32m   2562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2563\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2564\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2565\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()  \u001b[38;5;66;03m# Ensure restore operations have completed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2441\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2439\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(save_path)\n\u001b[0;32m   2440\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[1;32m-> 2441\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2442\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[0;32m   2443\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_CHECKPOINT_V2,\n\u001b[0;32m   2444\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n\u001b[0;32m   2445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1494\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1484\u001b[0m object_graph_proto\u001b[38;5;241m.\u001b[39mParseFromString(object_graph_string)\n\u001b[0;32m   1485\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _CheckpointRestoreCoordinator(\n\u001b[0;32m   1486\u001b[0m     object_graph_proto\u001b[38;5;241m=\u001b[39mobject_graph_proto,\n\u001b[0;32m   1487\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1493\u001b[0m     saveables_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveables_cache)\n\u001b[1;32m-> 1494\u001b[0m \u001b[43mrestore_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointPosition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# Attached dependencies are not attached to the root, so should be restored\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view\u001b[38;5;241m.\u001b[39mattached_dependencies:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:55\u001b[0m, in \u001b[0;36mCheckpointPosition.restore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_object(trackable):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# This object's correspondence with a checkpointed object is new, so\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# process deferred restorations for it and its dependencies.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     restore_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_descendants\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m restore_ops:\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mnew_restore_ops(restore_ops)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:458\u001b[0m, in \u001b[0;36mCheckpointPosition._restore_descendants\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m   _queue_children_for_restoration(current_position, visit_queue)\n\u001b[0;32m    455\u001b[0m   _queue_slot_variables(current_position, visit_queue)\n\u001b[0;32m    457\u001b[0m restore_ops\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 458\u001b[0m     \u001b[43mcurrent_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_saveables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mpython_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:352\u001b[0m, in \u001b[0;36m_CheckpointRestoreCoordinator.restore_saveables\u001b[1;34m(self, tensor_saveables, python_positions, registered_savers)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_saveables \u001b[38;5;129;01mor\u001b[39;00m registered_savers:\n\u001b[0;32m    350\u001b[0m   flat_saveables \u001b[38;5;241m=\u001b[39m saveable_object_util\u001b[38;5;241m.\u001b[39mvalidate_and_slice_inputs(\n\u001b[0;32m    351\u001b[0m       tensor_saveables)\n\u001b[1;32m--> 352\u001b[0m   new_restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDeviceSaver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m      \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, restore_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(new_restore_ops\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:403\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    401\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m tf_function_restore()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:385\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore.<locals>.restore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device, saver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_device_savers\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 385\u001b[0m     restore_ops\u001b[38;5;241m.\u001b[39mupdate(\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Run registered restore methods after the default restore ops.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (_, restore_fn) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_savers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:111\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    108\u001b[0m restore_ops \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m saveable, restored_tensors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveable_objects,\n\u001b[0;32m    110\u001b[0m                                       structured_restored_tensors):\n\u001b[1;32m--> 111\u001b[0m   restore_ops[saveable\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestored_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py:135\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[0;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[1;31mValueError\u001b[0m: Received incompatible tensor with shape (80,) when attempting to restore variable with shape (112,) and name backbone/layer_with_weights-100/beta/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=det.model)\n",
    "ckpt.restore(\"models/ckpt-277200\").expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "11676fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (80,) when attempting to restore variable with shape (112,) and name backbone/layer_with_weights-100/beta/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py:132\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_safe_assign_variable_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:308\u001b[0m, in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    307\u001b[0m   value_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value)\n\u001b[1;32m--> 308\u001b[0m \u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_is_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39massign_variable_op(\n\u001b[0;32m    310\u001b[0m     handle, value_tensor, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1307\u001b[0m, in \u001b[0;36mTensorShape.assert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_compatible_with(other):\n\u001b[1;32m-> 1307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m are incompatible\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m, other))\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (112,) and (80,) are incompatible",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m task \u001b[38;5;241m=\u001b[39m tfm\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mtask_factory\u001b[38;5;241m.\u001b[39mget_task(cfg\u001b[38;5;241m.\u001b[39mtask)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\official\\vision\\tasks\\retinanet.py:80\u001b[0m, in \u001b[0;36mRetinaNetTask.initialize\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_config\u001b[38;5;241m.\u001b[39minit_checkpoint_modules \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     79\u001b[0m   ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcheckpoint_items)\n\u001b[1;32m---> 80\u001b[0m   status \u001b[38;5;241m=\u001b[39m \u001b[43mckpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_dir_or_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m   status\u001b[38;5;241m.\u001b[39mexpect_partial()\u001b[38;5;241m.\u001b[39massert_existing_objects_matched()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:2441\u001b[0m, in \u001b[0;36mCheckpoint.read\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2439\u001b[0m   save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(save_path)\n\u001b[0;32m   2440\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;129;01mor\u001b[39;00m checkpoint_options\u001b[38;5;241m.\u001b[39mCheckpointOptions()\n\u001b[1;32m-> 2441\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2442\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[0;32m   2443\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_CHECKPOINT_V2,\n\u001b[0;32m   2444\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n\u001b[0;32m   2445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:1494\u001b[0m, in \u001b[0;36mTrackableSaver.restore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1484\u001b[0m object_graph_proto\u001b[38;5;241m.\u001b[39mParseFromString(object_graph_string)\n\u001b[0;32m   1485\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _CheckpointRestoreCoordinator(\n\u001b[0;32m   1486\u001b[0m     object_graph_proto\u001b[38;5;241m=\u001b[39mobject_graph_proto,\n\u001b[0;32m   1487\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1492\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1493\u001b[0m     saveables_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveables_cache)\n\u001b[1;32m-> 1494\u001b[0m \u001b[43mrestore_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointPosition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# Attached dependencies are not attached to the root, so should be restored\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# separately.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_view\u001b[38;5;241m.\u001b[39mattached_dependencies:\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:55\u001b[0m, in \u001b[0;36mCheckpointPosition.restore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_object(trackable):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# This object's correspondence with a checkpointed object is new, so\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# process deferred restorations for it and its dependencies.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     restore_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_descendants\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m restore_ops:\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint\u001b[38;5;241m.\u001b[39mnew_restore_ops(restore_ops)\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\restore.py:458\u001b[0m, in \u001b[0;36mCheckpointPosition._restore_descendants\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m   _queue_children_for_restoration(current_position, visit_queue)\n\u001b[0;32m    455\u001b[0m   _queue_slot_variables(current_position, visit_queue)\n\u001b[0;32m    457\u001b[0m restore_ops\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 458\u001b[0m     \u001b[43mcurrent_position\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_saveables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mpython_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py:352\u001b[0m, in \u001b[0;36m_CheckpointRestoreCoordinator.restore_saveables\u001b[1;34m(self, tensor_saveables, python_positions, registered_savers)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_saveables \u001b[38;5;129;01mor\u001b[39;00m registered_savers:\n\u001b[0;32m    350\u001b[0m   flat_saveables \u001b[38;5;241m=\u001b[39m saveable_object_util\u001b[38;5;241m.\u001b[39mvalidate_and_slice_inputs(\n\u001b[0;32m    351\u001b[0m       tensor_saveables)\n\u001b[1;32m--> 352\u001b[0m   new_restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDeviceSaver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m      \u001b[49m\u001b[43mregistered_savers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, restore_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(new_restore_ops\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:403\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    401\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m tf_function_restore()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m   restore_ops \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:385\u001b[0m, in \u001b[0;36mMultiDeviceSaver.restore.<locals>.restore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device, saver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_device_savers\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 385\u001b[0m     restore_ops\u001b[38;5;241m.\u001b[39mupdate(\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Run registered restore methods after the default restore ops.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (_, restore_fn) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_savers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\functional_saver.py:111\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.restore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    108\u001b[0m restore_ops \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m saveable, restored_tensors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saveable_objects,\n\u001b[0;32m    110\u001b[0m                                       structured_restored_tensors):\n\u001b[1;32m--> 111\u001b[0m   restore_ops[saveable\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrestored_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestored_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_ops\n",
      "File \u001b[1;32m~\\PycharmProjects\\xplique\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py:135\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[0;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[1;31mValueError\u001b[0m: Received incompatible tensor with shape (80,) when attempting to restore variable with shape (112,) and name backbone/layer_with_weights-100/beta/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "task = tfm.core.task_factory.get_task(cfg.task)\n",
    "model = task.build_model()\n",
    "task.initialize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52416bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
